2022-11-27 16:47:50 log_path: logs/20391127_200_1126_1.txt
2022-11-27 16:47:50 cuda is available: False
2022-11-27 16:47:50 
--------------------------------------------------
 NEW RUN 
--------------------------------------------------
2022-11-27 16:47:50 using cpu
2022-11-27 16:47:50 epoch = 30000
2022-11-27 16:47:50 epoch_step = 1000
2022-11-27 16:47:50 model_name = SimpleNetworkAD
2022-11-27 16:47:50 now_string = 2022-11-27-16-47-50
2022-11-27 16:47:50 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_last.pt
2022-11-27 16:47:50 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_best.pt
2022-11-27 16:47:50 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_loss_30000.npy
2022-11-27 16:47:50 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 29900, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-16-47-50'}
2022-11-27 16:47:50 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 16:47:50 --------------------------------------------------training start--------------------------------------------------
2022-11-27 16:48:09 NUM_SUB: 0;----------------------------
2022-11-27 16:48:09 Epoch [01000/30000] Loss:0.024981 Loss_1:0.020060 Loss_2:0.001243 Loss_3:0.000000 Lr:0.000909 Time:19.571171s (0.33min in total, 9.46min remains)
2022-11-27 16:48:29 NUM_SUB: 0;----------------------------
2022-11-27 16:48:29 Epoch [02000/30000] Loss:0.019833 Loss_1:0.019133 Loss_2:0.000289 Loss_3:0.000000 Lr:0.000833 Time:19.709451s (0.65min in total, 9.17min remains)
2022-11-27 16:48:49 NUM_SUB: 0;----------------------------
2022-11-27 16:48:49 Epoch [03000/30000] Loss:0.018139 Loss_1:0.017989 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000769 Time:19.635493s (0.98min in total, 8.84min remains)
2022-11-27 16:49:09 NUM_SUB: 0;----------------------------
2022-11-27 16:49:09 Epoch [04000/30000] Loss:0.016505 Loss_1:0.016441 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000714 Time:20.301579s (1.32min in total, 8.58min remains)
2022-11-27 16:49:29 NUM_SUB: 0;----------------------------
2022-11-27 16:49:29 Epoch [05000/30000] Loss:0.014839 Loss_1:0.014752 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000667 Time:20.317073s (1.66min in total, 8.29min remains)
2022-11-27 16:49:50 NUM_SUB: 0;----------------------------
2022-11-27 16:49:50 Epoch [06000/30000] Loss:0.012879 Loss_1:0.012795 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000625 Time:20.503643s (2.00min in total, 8.00min remains)
2022-11-27 16:50:10 NUM_SUB: 0;----------------------------
2022-11-27 16:50:10 Epoch [07000/30000] Loss:0.010264 Loss_1:0.010168 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000588 Time:19.845274s (2.33min in total, 7.66min remains)
2022-11-27 16:50:30 NUM_SUB: 0;----------------------------
2022-11-27 16:50:30 Epoch [08000/30000] Loss:0.008010 Loss_1:0.007917 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000556 Time:20.292851s (2.67min in total, 7.34min remains)
2022-11-27 16:50:50 NUM_SUB: 0;----------------------------
2022-11-27 16:50:50 Epoch [09000/30000] Loss:0.006561 Loss_1:0.006505 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000526 Time:19.882485s (3.00min in total, 7.00min remains)
2022-11-27 16:51:10 NUM_SUB: 0;----------------------------
2022-11-27 16:51:10 Epoch [10000/30000] Loss:0.005912 Loss_1:0.005899 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000500 Time:19.834855s (3.33min in total, 6.66min remains)
2022-11-27 16:51:30 NUM_SUB: 0;----------------------------
2022-11-27 16:51:30 Epoch [11000/30000] Loss:0.005586 Loss_1:0.005580 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000476 Time:19.853325s (3.66min in total, 6.33min remains)
2022-11-27 16:51:50 NUM_SUB: 0;----------------------------
2022-11-27 16:51:50 Epoch [12000/30000] Loss:0.005278 Loss_1:0.005270 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000455 Time:20.081646s (4.00min in total, 6.00min remains)
2022-11-27 16:52:10 NUM_SUB: 0;----------------------------
2022-11-27 16:52:10 Epoch [13000/30000] Loss:0.004961 Loss_1:0.004949 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000435 Time:20.038009s (4.33min in total, 5.66min remains)
2022-11-27 16:52:30 NUM_SUB: 0;----------------------------
2022-11-27 16:52:30 Epoch [14000/30000] Loss:0.004732 Loss_1:0.004724 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000417 Time:20.041344s (4.67min in total, 5.33min remains)
2022-11-27 16:52:49 NUM_SUB: 0;----------------------------
2022-11-27 16:52:49 Epoch [15000/30000] Loss:0.004646 Loss_1:0.004639 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000400 Time:19.538368s (4.99min in total, 4.99min remains)
2022-11-27 16:53:09 NUM_SUB: 0;----------------------------
2022-11-27 16:53:09 Epoch [16000/30000] Loss:0.004619 Loss_1:0.004611 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:19.663333s (5.32min in total, 4.65min remains)
2022-11-27 16:53:28 NUM_SUB: 0;----------------------------
2022-11-27 16:53:28 Epoch [17000/30000] Loss:0.004599 Loss_1:0.004591 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:19.535174s (5.64min in total, 4.32min remains)
2022-11-27 16:53:48 NUM_SUB: 0;----------------------------
2022-11-27 16:53:48 Epoch [18000/30000] Loss:0.004579 Loss_1:0.004574 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:19.255614s (5.97min in total, 3.98min remains)
2022-11-27 16:54:07 NUM_SUB: 0;----------------------------
2022-11-27 16:54:07 Epoch [19000/30000] Loss:0.004567 Loss_1:0.004559 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:19.601941s (6.29min in total, 3.64min remains)
2022-11-27 16:54:27 NUM_SUB: 0;----------------------------
2022-11-27 16:54:27 Epoch [20000/30000] Loss:0.004562 Loss_1:0.004556 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.508126s (6.62min in total, 3.31min remains)
2022-11-27 16:54:46 NUM_SUB: 0;----------------------------
2022-11-27 16:54:46 Epoch [21000/30000] Loss:0.004562 Loss_1:0.004560 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.410991s (6.94min in total, 2.97min remains)
2022-11-27 16:55:06 NUM_SUB: 0;----------------------------
2022-11-27 16:55:06 Epoch [22000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000313 Time:19.491205s (7.27min in total, 2.64min remains)
2022-11-27 16:55:25 NUM_SUB: 0;----------------------------
2022-11-27 16:55:25 Epoch [23000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000303 Time:19.763839s (7.59min in total, 2.31min remains)
2022-11-27 16:55:45 NUM_SUB: 0;----------------------------
2022-11-27 16:55:45 Epoch [24000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.900725s (7.93min in total, 1.98min remains)
2022-11-27 16:56:05 NUM_SUB: 0;----------------------------
2022-11-27 16:56:05 Epoch [25000/30000] Loss:0.004561 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:19.288216s (8.25min in total, 1.65min remains)
2022-11-27 16:56:24 NUM_SUB: 0;----------------------------
2022-11-27 16:56:24 Epoch [26000/30000] Loss:0.004564 Loss_1:0.004561 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.487852s (8.57min in total, 1.32min remains)
2022-11-27 16:56:44 NUM_SUB: 0;----------------------------
2022-11-27 16:56:44 Epoch [27000/30000] Loss:0.004575 Loss_1:0.004572 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.533046s (8.90min in total, 0.99min remains)
2022-11-27 16:57:03 NUM_SUB: 0;----------------------------
2022-11-27 16:57:03 Epoch [28000/30000] Loss:0.004562 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.171512s (9.22min in total, 0.66min remains)
2022-11-27 16:57:22 NUM_SUB: 0;----------------------------
2022-11-27 16:57:22 Epoch [29000/30000] Loss:0.004561 Loss_1:0.004556 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.389730s (9.54min in total, 0.33min remains)
2022-11-27 16:57:40 Testing & drawing...
2022-11-27 16:57:40 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-16-47-50/
2022-11-27 16:57:41 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-16-47-50_sub=0/
2022-11-27 16:57:41 [Loss]
2022-11-27 16:57:41 NUM_SUB: 0; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 16:57:41 NUM_SUB: 0; Personalized parameter estimation: Parameter containing:
tensor([1.8704e-01, 1.0632e+00, 9.2724e-03, 2.0752e+00, 3.0742e-01, 1.4903e-02,
        1.0162e+00, 8.9644e-01, 4.5563e-01, 9.5179e-03, 1.2953e-01, 8.4245e-02,
        3.9632e-01, 1.6886e-01, 1.7327e-02, 1.4588e+00, 6.9767e-01, 8.0001e-01,
        3.3967e-03, 2.3751e+00, 6.8161e-01, 2.1021e-02, 2.9057e+00, 8.7416e-01,
        2.1162e-02, 3.5593e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 16:57:43 NUM_SUB: 0;----------------------------
2022-11-27 16:57:43 Epoch [30000/30000] Loss:0.004561 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:21.087118s (9.89min in total, 0.00min remains)
2022-11-27 16:57:43 NUM_SUB: 0------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 16:57:43 Testing & drawing...
2022-11-27 16:57:43 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-16-47-50/
2022-11-27 16:57:45 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-16-47-50_sub=0/
2022-11-27 16:57:45 [Loss]
2022-11-27 16:57:45 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 16:57:45 General parameter estimation: Parameter containing:
tensor([1.8705e-01, 1.0631e+00, 9.2694e-03, 2.0829e+00, 3.0742e-01, 1.4903e-02,
        1.0172e+00, 8.9644e-01, 4.5563e-01, 9.5176e-03, 1.2930e-01, 8.3998e-02,
        3.9590e-01, 1.6886e-01, 1.7315e-02, 1.4704e+00, 6.9767e-01, 8.0001e-01,
        3.1815e-03, 2.3785e+00, 6.8161e-01, 2.0997e-02, 2.9177e+00, 8.7416e-01,
        2.1130e-02, 3.5713e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 16:57:45 A: prod, degr, TonA, NonA
2022-11-27 16:57:45 [0.49378884 0.50005066 0.00052339 0.00563713]
2022-11-27 16:57:45 T: prod, degr, AonT, NonT
2022-11-27 16:57:45 [0.1648232  0.39895675 0.41429418 0.0219259 ]
2022-11-27 16:57:45 N: AonN, TonN, ATonN
2022-11-27 16:57:45 [0.00171073 0.9837323  0.01455701]
2022-11-27 16:57:45 using cpu
2022-11-27 16:57:45 epoch = 30000
2022-11-27 16:57:45 epoch_step = 1000
2022-11-27 16:57:45 model_name = SimpleNetworkAD
2022-11-27 16:57:45 now_string = 2022-11-27-16-47-50
2022-11-27 16:57:45 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_last.pt
2022-11-27 16:57:45 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_best.pt
2022-11-27 16:57:45 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-16-47-50_loss_30000.npy
2022-11-27 16:57:45 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 29900, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-16-47-50'}
2022-11-27 16:57:45 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 16:57:45 --------------------------------------------------training start--------------------------------------------------
2022-11-27 16:58:04 NUM_SUB: 1;----------------------------
2022-11-27 16:58:04 Epoch [01000/30000] Loss:0.053329 Loss_1:0.048069 Loss_2:0.001452 Loss_3:0.000000 Lr:0.000909 Time:19.327554s (0.32min in total, 9.34min remains)
2022-11-27 16:58:24 NUM_SUB: 1;----------------------------
2022-11-27 16:58:24 Epoch [02000/30000] Loss:0.046142 Loss_1:0.045318 Loss_2:0.000410 Loss_3:0.000000 Lr:0.000833 Time:19.372301s (0.65min in total, 9.03min remains)
2022-11-27 16:58:43 NUM_SUB: 1;----------------------------
2022-11-27 16:58:43 Epoch [03000/30000] Loss:0.041128 Loss_1:0.040927 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000769 Time:19.293290s (0.97min in total, 8.70min remains)
2022-11-27 16:59:02 NUM_SUB: 1;----------------------------
2022-11-27 16:59:02 Epoch [04000/30000] Loss:0.035176 Loss_1:0.034953 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000714 Time:19.332843s (1.29min in total, 8.38min remains)
2022-11-27 16:59:22 NUM_SUB: 1;----------------------------
2022-11-27 16:59:22 Epoch [05000/30000] Loss:0.027577 Loss_1:0.027380 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000667 Time:19.291112s (1.61min in total, 8.05min remains)
2022-11-27 16:59:41 NUM_SUB: 1;----------------------------
2022-11-27 16:59:41 Epoch [06000/30000] Loss:0.018169 Loss_1:0.018003 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000625 Time:19.321910s (1.93min in total, 7.73min remains)
2022-11-27 17:00:00 NUM_SUB: 1;----------------------------
2022-11-27 17:00:00 Epoch [07000/30000] Loss:0.009888 Loss_1:0.009333 Loss_2:0.000495 Loss_3:0.000000 Lr:0.000588 Time:19.403125s (2.26min in total, 7.41min remains)
2022-11-27 17:00:20 NUM_SUB: 1;----------------------------
2022-11-27 17:00:20 Epoch [08000/30000] Loss:0.004220 Loss_1:0.004119 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000556 Time:19.240554s (2.58min in total, 7.09min remains)
2022-11-27 17:00:39 NUM_SUB: 1;----------------------------
2022-11-27 17:00:39 Epoch [09000/30000] Loss:0.002193 Loss_1:0.002100 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000526 Time:19.370338s (2.90min in total, 6.77min remains)
2022-11-27 17:00:58 NUM_SUB: 1;----------------------------
2022-11-27 17:00:58 Epoch [10000/30000] Loss:0.001218 Loss_1:0.001130 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000500 Time:19.359946s (3.22min in total, 6.44min remains)
2022-11-27 17:01:19 NUM_SUB: 1;----------------------------
2022-11-27 17:01:19 Epoch [11000/30000] Loss:0.000878 Loss_1:0.000800 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000476 Time:20.115009s (3.56min in total, 6.14min remains)
2022-11-27 17:01:38 NUM_SUB: 1;----------------------------
2022-11-27 17:01:38 Epoch [12000/30000] Loss:0.000650 Loss_1:0.000598 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:19.361002s (3.88min in total, 5.82min remains)
2022-11-27 17:01:57 NUM_SUB: 1;----------------------------
2022-11-27 17:01:57 Epoch [13000/30000] Loss:0.000464 Loss_1:0.000429 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000435 Time:19.293829s (4.20min in total, 5.49min remains)
2022-11-27 17:02:17 NUM_SUB: 1;----------------------------
2022-11-27 17:02:17 Epoch [14000/30000] Loss:0.000345 Loss_1:0.000319 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:19.629448s (4.53min in total, 5.18min remains)
2022-11-27 17:02:37 NUM_SUB: 1;----------------------------
2022-11-27 17:02:37 Epoch [15000/30000] Loss:0.000309 Loss_1:0.000289 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:20.132485s (4.86min in total, 4.86min remains)
2022-11-27 17:02:57 NUM_SUB: 1;----------------------------
2022-11-27 17:02:57 Epoch [16000/30000] Loss:0.000285 Loss_1:0.000273 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:20.314754s (5.20min in total, 4.55min remains)
2022-11-27 17:03:18 NUM_SUB: 1;----------------------------
2022-11-27 17:03:18 Epoch [17000/30000] Loss:0.000272 Loss_1:0.000263 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:20.201848s (5.54min in total, 4.24min remains)
2022-11-27 17:03:38 NUM_SUB: 1;----------------------------
2022-11-27 17:03:38 Epoch [18000/30000] Loss:0.000260 Loss_1:0.000252 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:20.023804s (5.87min in total, 3.92min remains)
2022-11-27 17:03:58 NUM_SUB: 1;----------------------------
2022-11-27 17:03:58 Epoch [19000/30000] Loss:0.000243 Loss_1:0.000236 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:20.032164s (6.21min in total, 3.59min remains)
2022-11-27 17:04:18 NUM_SUB: 1;----------------------------
2022-11-27 17:04:18 Epoch [20000/30000] Loss:0.000217 Loss_1:0.000211 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.980367s (6.54min in total, 3.27min remains)
2022-11-27 17:04:38 NUM_SUB: 1;----------------------------
2022-11-27 17:04:38 Epoch [21000/30000] Loss:0.000181 Loss_1:0.000176 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.960851s (6.87min in total, 2.95min remains)
2022-11-27 17:04:57 NUM_SUB: 1;----------------------------
2022-11-27 17:04:57 Epoch [22000/30000] Loss:0.000171 Loss_1:0.000167 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.644252s (7.20min in total, 2.62min remains)
2022-11-27 17:05:17 NUM_SUB: 1;----------------------------
2022-11-27 17:05:17 Epoch [23000/30000] Loss:0.000162 Loss_1:0.000158 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.677169s (7.53min in total, 2.29min remains)
2022-11-27 17:05:37 NUM_SUB: 1;----------------------------
2022-11-27 17:05:37 Epoch [24000/30000] Loss:0.000157 Loss_1:0.000154 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.706405s (7.86min in total, 1.96min remains)
2022-11-27 17:05:56 NUM_SUB: 1;----------------------------
2022-11-27 17:05:56 Epoch [25000/30000] Loss:0.000162 Loss_1:0.000159 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.504620s (8.18min in total, 1.64min remains)
2022-11-27 17:06:16 NUM_SUB: 1;----------------------------
2022-11-27 17:06:16 Epoch [26000/30000] Loss:0.000155 Loss_1:0.000152 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.768540s (8.51min in total, 1.31min remains)
2022-11-27 17:06:35 NUM_SUB: 1;----------------------------
2022-11-27 17:06:35 Epoch [27000/30000] Loss:0.000152 Loss_1:0.000150 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.663585s (8.84min in total, 0.98min remains)
2022-11-27 17:06:55 NUM_SUB: 1;----------------------------
2022-11-27 17:06:55 Epoch [28000/30000] Loss:0.000152 Loss_1:0.000150 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.757256s (9.17min in total, 0.65min remains)
2022-11-27 17:07:15 NUM_SUB: 1;----------------------------
2022-11-27 17:07:15 Epoch [29000/30000] Loss:0.000156 Loss_1:0.000151 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.719653s (9.50min in total, 0.33min remains)
2022-11-27 17:07:33 Testing & drawing...
2022-11-27 17:07:33 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-16-47-50/
2022-11-27 17:07:34 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-16-47-50_sub=1/
2022-11-27 17:07:34 [Loss]
2022-11-27 17:07:34 NUM_SUB: 1; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 17:07:34 NUM_SUB: 1; Personalized parameter estimation: Parameter containing:
tensor([0.0160, 0.0580, 0.0102, 1.3103, 0.3074, 0.0120, 1.2627, 0.8964, 0.4556,
        0.0132, 0.0339, 0.0132, 0.8368, 0.1689, 0.0179, 1.6623, 0.6977, 0.8000,
        0.0123, 2.9423, 0.6816, 0.0225, 2.9403, 0.8742, 0.0217, 3.6509, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 17:07:36 NUM_SUB: 1;----------------------------
2022-11-27 17:07:36 Epoch [30000/30000] Loss:0.000153 Loss_1:0.000151 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:21.379031s (9.85min in total, 0.00min remains)
2022-11-27 17:07:36 NUM_SUB: 1------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 17:07:36 Testing & drawing...
2022-11-27 17:07:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-16-47-50/
2022-11-27 17:07:38 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-16-47-50_sub=1/
2022-11-27 17:07:38 [Loss]
2022-11-27 17:07:38 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 17:07:38 General parameter estimation: Parameter containing:
tensor([0.0159, 0.0578, 0.0102, 1.3101, 0.3074, 0.0120, 1.2585, 0.8964, 0.4556,
        0.0132, 0.0338, 0.0132, 0.8370, 0.1689, 0.0179, 1.6683, 0.6977, 0.8000,
        0.0123, 2.9432, 0.6816, 0.0225, 2.9409, 0.8742, 0.0217, 3.6517, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 17:07:38 A: prod, degr, TonA, NonA
2022-11-27 17:07:38 [0.4146449  0.4820638  0.03788525 0.06540602]
2022-11-27 17:07:38 T: prod, degr, AonT, NonT
2022-11-27 17:07:38 [0.43802062 0.35881588 0.12504743 0.07811609]
2022-11-27 17:07:38 N: AonN, TonN, ATonN
2022-11-27 17:07:38 [0.00710064 0.9631172  0.02978218]
2022-11-27 19:40:03 log_path: logs/20391127_200_1126_1.txt
2022-11-27 19:40:03 cuda is available: False
2022-11-27 19:40:03 
--------------------------------------------------
 NEW RUN 
--------------------------------------------------
2022-11-27 19:40:04 using cpu
2022-11-27 19:40:04 epoch = 30000
2022-11-27 19:40:04 epoch_step = 1000
2022-11-27 19:40:04 model_name = SimpleNetworkAD
2022-11-27 19:40:04 now_string = 2022-11-27-19-40-03
2022-11-27 19:40:04 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-03_last.pt
2022-11-27 19:40:04 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-03_best.pt
2022-11-27 19:40:04 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-03_loss_30000.npy
2022-11-27 19:40:04 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 29900, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-03'}
2022-11-27 19:40:04 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 19:40:04 --------------------------------------------------training start--------------------------------------------------
2022-11-27 19:40:13 log_path: logs/20391127_200_1126_1.txt
2022-11-27 19:40:13 cuda is available: False
2022-11-27 19:40:13 
--------------------------------------------------
 NEW RUN 
--------------------------------------------------
2022-11-27 19:40:14 using cpu
2022-11-27 19:40:14 epoch = 30000
2022-11-27 19:40:14 epoch_step = 1000
2022-11-27 19:40:14 model_name = SimpleNetworkAD
2022-11-27 19:40:14 now_string = 2022-11-27-19-40-13
2022-11-27 19:40:14 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 19:40:14 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 19:40:14 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 19:40:14 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 19:40:14 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 19:40:14 --------------------------------------------------training start--------------------------------------------------
2022-11-27 19:40:33 NUM_SUB: 0;----------------------------
2022-11-27 19:40:33 Epoch [01000/30000] Loss:0.024981 Loss_1:0.020060 Loss_2:0.001243 Loss_3:0.000000 Lr:0.000909 Time:18.916984s (0.32min in total, 9.14min remains)
2022-11-27 19:40:51 NUM_SUB: 0;----------------------------
2022-11-27 19:40:51 Epoch [02000/30000] Loss:0.019833 Loss_1:0.019133 Loss_2:0.000289 Loss_3:0.000000 Lr:0.000833 Time:18.430976s (0.62min in total, 8.71min remains)
2022-11-27 19:41:09 NUM_SUB: 0;----------------------------
2022-11-27 19:41:09 Epoch [03000/30000] Loss:0.018139 Loss_1:0.017989 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000769 Time:18.435959s (0.93min in total, 8.37min remains)
2022-11-27 19:41:28 NUM_SUB: 0;----------------------------
2022-11-27 19:41:28 Epoch [04000/30000] Loss:0.016505 Loss_1:0.016441 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000714 Time:18.405392s (1.24min in total, 8.04min remains)
2022-11-27 19:41:46 NUM_SUB: 0;----------------------------
2022-11-27 19:41:46 Epoch [05000/30000] Loss:0.014839 Loss_1:0.014752 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000667 Time:18.555023s (1.55min in total, 7.73min remains)
2022-11-27 19:42:05 NUM_SUB: 0;----------------------------
2022-11-27 19:42:05 Epoch [06000/30000] Loss:0.012879 Loss_1:0.012795 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000625 Time:18.667900s (1.86min in total, 7.43min remains)
2022-11-27 19:42:23 NUM_SUB: 0;----------------------------
2022-11-27 19:42:23 Epoch [07000/30000] Loss:0.010264 Loss_1:0.010168 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000588 Time:18.378945s (2.16min in total, 7.11min remains)
2022-11-27 19:42:42 NUM_SUB: 0;----------------------------
2022-11-27 19:42:42 Epoch [08000/30000] Loss:0.008010 Loss_1:0.007917 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000556 Time:18.350131s (2.47min in total, 6.79min remains)
2022-11-27 19:43:01 NUM_SUB: 0;----------------------------
2022-11-27 19:43:01 Epoch [09000/30000] Loss:0.006561 Loss_1:0.006505 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000526 Time:18.984437s (2.79min in total, 6.50min remains)
2022-11-27 19:43:19 NUM_SUB: 0;----------------------------
2022-11-27 19:43:19 Epoch [10000/30000] Loss:0.005912 Loss_1:0.005899 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000500 Time:18.529233s (3.09min in total, 6.19min remains)
2022-11-27 19:43:39 NUM_SUB: 0;----------------------------
2022-11-27 19:43:39 Epoch [11000/30000] Loss:0.005586 Loss_1:0.005580 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000476 Time:19.521400s (3.42min in total, 5.91min remains)
2022-11-27 19:43:58 NUM_SUB: 0;----------------------------
2022-11-27 19:43:58 Epoch [12000/30000] Loss:0.005278 Loss_1:0.005270 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000455 Time:18.637152s (3.73min in total, 5.60min remains)
2022-11-27 19:44:17 NUM_SUB: 0;----------------------------
2022-11-27 19:44:17 Epoch [13000/30000] Loss:0.004961 Loss_1:0.004949 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000435 Time:19.401691s (4.05min in total, 5.30min remains)
2022-11-27 19:44:36 NUM_SUB: 0;----------------------------
2022-11-27 19:44:36 Epoch [14000/30000] Loss:0.004732 Loss_1:0.004724 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000417 Time:19.325275s (4.38min in total, 5.00min remains)
2022-11-27 19:44:56 NUM_SUB: 0;----------------------------
2022-11-27 19:44:56 Epoch [15000/30000] Loss:0.004646 Loss_1:0.004639 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000400 Time:19.873043s (4.71min in total, 4.71min remains)
2022-11-27 19:45:15 NUM_SUB: 0;----------------------------
2022-11-27 19:45:15 Epoch [16000/30000] Loss:0.004619 Loss_1:0.004611 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:19.314544s (5.03min in total, 4.40min remains)
2022-11-27 19:45:34 NUM_SUB: 0;----------------------------
2022-11-27 19:45:34 Epoch [17000/30000] Loss:0.004599 Loss_1:0.004591 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:18.992184s (5.35min in total, 4.09min remains)
2022-11-27 19:45:53 NUM_SUB: 0;----------------------------
2022-11-27 19:45:53 Epoch [18000/30000] Loss:0.004579 Loss_1:0.004574 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:18.900665s (5.66min in total, 3.77min remains)
2022-11-27 19:46:12 NUM_SUB: 0;----------------------------
2022-11-27 19:46:12 Epoch [19000/30000] Loss:0.004567 Loss_1:0.004559 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:18.974697s (5.98min in total, 3.46min remains)
2022-11-27 19:46:32 NUM_SUB: 0;----------------------------
2022-11-27 19:46:32 Epoch [20000/30000] Loss:0.004562 Loss_1:0.004556 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.399748s (6.30min in total, 3.15min remains)
2022-11-27 19:46:51 NUM_SUB: 0;----------------------------
2022-11-27 19:46:51 Epoch [21000/30000] Loss:0.004562 Loss_1:0.004560 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.330027s (6.62min in total, 2.84min remains)
2022-11-27 19:47:10 NUM_SUB: 0;----------------------------
2022-11-27 19:47:10 Epoch [22000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000313 Time:19.008293s (6.94min in total, 2.52min remains)
2022-11-27 19:47:29 NUM_SUB: 0;----------------------------
2022-11-27 19:47:29 Epoch [23000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000303 Time:18.639630s (7.25min in total, 2.21min remains)
2022-11-27 19:47:47 NUM_SUB: 0;----------------------------
2022-11-27 19:47:47 Epoch [24000/30000] Loss:0.004561 Loss_1:0.004558 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:18.339317s (7.56min in total, 1.89min remains)
2022-11-27 19:48:06 NUM_SUB: 0;----------------------------
2022-11-27 19:48:06 Epoch [25000/30000] Loss:0.004561 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:18.917298s (7.87min in total, 1.57min remains)
2022-11-27 19:48:26 NUM_SUB: 0;----------------------------
2022-11-27 19:48:26 Epoch [26000/30000] Loss:0.004564 Loss_1:0.004561 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.661254s (8.20min in total, 1.26min remains)
2022-11-27 19:48:45 NUM_SUB: 0;----------------------------
2022-11-27 19:48:45 Epoch [27000/30000] Loss:0.004575 Loss_1:0.004572 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.484471s (8.52min in total, 0.95min remains)
2022-11-27 19:49:05 NUM_SUB: 0;----------------------------
2022-11-27 19:49:05 Epoch [28000/30000] Loss:0.004562 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.436309s (8.85min in total, 0.63min remains)
2022-11-27 19:49:24 NUM_SUB: 0;----------------------------
2022-11-27 19:49:24 Epoch [29000/30000] Loss:0.004561 Loss_1:0.004556 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.819295s (9.18min in total, 0.32min remains)
2022-11-27 19:49:44 NUM_SUB: 0;----------------------------
2022-11-27 19:49:44 Epoch [30000/30000] Loss:0.004561 Loss_1:0.004559 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.469513s (9.50min in total, 0.00min remains)
2022-11-27 19:49:44 Testing & drawing...
2022-11-27 19:49:44 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 19:49:46 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=0/
2022-11-27 19:49:46 [Loss]
2022-11-27 19:49:46 NUM_SUB: 0; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 19:49:46 NUM_SUB: 0; Personalized parameter estimation: Parameter containing:
tensor([1.8705e-01, 1.0631e+00, 9.2694e-03, 2.0829e+00, 3.0742e-01, 1.4903e-02,
        1.0172e+00, 8.9644e-01, 4.5563e-01, 9.5176e-03, 1.2930e-01, 8.3998e-02,
        3.9590e-01, 1.6886e-01, 1.7315e-02, 1.4704e+00, 6.9767e-01, 8.0001e-01,
        3.1815e-03, 2.3785e+00, 6.8161e-01, 2.0997e-02, 2.9177e+00, 8.7416e-01,
        2.1130e-02, 3.5713e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 19:49:46 NUM_SUB: 0------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 19:49:46 Testing & drawing...
2022-11-27 19:49:46 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 19:49:47 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=0/
2022-11-27 19:49:47 [Loss]
2022-11-27 19:49:47 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 19:49:47 General parameter estimation: Parameter containing:
tensor([1.8705e-01, 1.0631e+00, 9.2694e-03, 2.0829e+00, 3.0742e-01, 1.4903e-02,
        1.0172e+00, 8.9644e-01, 4.5563e-01, 9.5176e-03, 1.2930e-01, 8.3998e-02,
        3.9590e-01, 1.6886e-01, 1.7315e-02, 1.4704e+00, 6.9767e-01, 8.0001e-01,
        3.1815e-03, 2.3785e+00, 6.8161e-01, 2.0997e-02, 2.9177e+00, 8.7416e-01,
        2.1130e-02, 3.5713e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 19:49:47 A: prod, degr, TonA, NonA
2022-11-27 19:49:47 [0.49378884 0.50005066 0.00052339 0.00563713]
2022-11-27 19:49:47 T: prod, degr, AonT, NonT
2022-11-27 19:49:47 [0.1648232  0.39895675 0.41429418 0.0219259 ]
2022-11-27 19:49:47 N: AonN, TonN, ATonN
2022-11-27 19:49:47 [0.00171073 0.9837323  0.01455701]
2022-11-27 19:49:47 using cpu
2022-11-27 19:49:47 epoch = 30000
2022-11-27 19:49:47 epoch_step = 1000
2022-11-27 19:49:47 model_name = SimpleNetworkAD
2022-11-27 19:49:47 now_string = 2022-11-27-19-40-13
2022-11-27 19:49:47 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 19:49:47 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 19:49:47 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 19:49:47 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 19:49:47 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 19:49:47 --------------------------------------------------training start--------------------------------------------------
2022-11-27 19:50:06 NUM_SUB: 1;----------------------------
2022-11-27 19:50:06 Epoch [01000/30000] Loss:0.053329 Loss_1:0.048069 Loss_2:0.001452 Loss_3:0.000000 Lr:0.000909 Time:18.363522s (0.31min in total, 8.88min remains)
2022-11-27 19:50:24 NUM_SUB: 1;----------------------------
2022-11-27 19:50:24 Epoch [02000/30000] Loss:0.046142 Loss_1:0.045318 Loss_2:0.000410 Loss_3:0.000000 Lr:0.000833 Time:18.264223s (0.61min in total, 8.55min remains)
2022-11-27 19:50:44 NUM_SUB: 1;----------------------------
2022-11-27 19:50:44 Epoch [03000/30000] Loss:0.041128 Loss_1:0.040927 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000769 Time:19.732586s (0.94min in total, 8.45min remains)
2022-11-27 20:57:17 NUM_SUB: 1;----------------------------
2022-11-27 20:57:17 Epoch [04000/30000] Loss:0.035176 Loss_1:0.034953 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000714 Time:3993.561924s (67.50min in total, 438.74min remains)
2022-11-27 21:04:36 NUM_SUB: 1;----------------------------
2022-11-27 21:04:36 Epoch [05000/30000] Loss:0.027577 Loss_1:0.027380 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000667 Time:438.708423s (74.81min in total, 374.05min remains)
2022-11-27 21:04:55 NUM_SUB: 1;----------------------------
2022-11-27 21:04:55 Epoch [06000/30000] Loss:0.018169 Loss_1:0.018003 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000625 Time:19.084396s (75.13min in total, 300.51min remains)
2022-11-27 21:05:15 NUM_SUB: 1;----------------------------
2022-11-27 21:05:15 Epoch [07000/30000] Loss:0.009888 Loss_1:0.009333 Loss_2:0.000495 Loss_3:0.000000 Lr:0.000588 Time:19.301086s (75.45min in total, 247.91min remains)
2022-11-27 21:05:34 NUM_SUB: 1;----------------------------
2022-11-27 21:05:34 Epoch [08000/30000] Loss:0.004220 Loss_1:0.004119 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000556 Time:19.261836s (75.77min in total, 208.37min remains)
2022-11-27 21:05:52 NUM_SUB: 1;----------------------------
2022-11-27 21:05:52 Epoch [09000/30000] Loss:0.002193 Loss_1:0.002100 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000526 Time:18.584798s (76.08min in total, 177.52min remains)
2022-11-27 21:06:11 NUM_SUB: 1;----------------------------
2022-11-27 21:06:11 Epoch [10000/30000] Loss:0.001218 Loss_1:0.001130 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000500 Time:18.763444s (76.39min in total, 152.79min remains)
2022-11-27 21:06:30 NUM_SUB: 1;----------------------------
2022-11-27 21:06:30 Epoch [11000/30000] Loss:0.000878 Loss_1:0.000800 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000476 Time:18.778323s (76.71min in total, 132.49min remains)
2022-11-27 21:06:49 NUM_SUB: 1;----------------------------
2022-11-27 21:06:49 Epoch [12000/30000] Loss:0.000650 Loss_1:0.000598 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:18.678684s (77.02min in total, 115.53min remains)
2022-11-27 21:07:07 NUM_SUB: 1;----------------------------
2022-11-27 21:07:07 Epoch [13000/30000] Loss:0.000464 Loss_1:0.000429 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000435 Time:18.854952s (77.33min in total, 101.13min remains)
2022-11-27 21:07:26 NUM_SUB: 1;----------------------------
2022-11-27 21:07:26 Epoch [14000/30000] Loss:0.000345 Loss_1:0.000319 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:18.827676s (77.65min in total, 88.74min remains)
2022-11-27 21:07:45 NUM_SUB: 1;----------------------------
2022-11-27 21:07:45 Epoch [15000/30000] Loss:0.000309 Loss_1:0.000289 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:18.811034s (77.96min in total, 77.96min remains)
2022-11-27 21:08:04 NUM_SUB: 1;----------------------------
2022-11-27 21:08:04 Epoch [16000/30000] Loss:0.000285 Loss_1:0.000273 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:19.095865s (78.28min in total, 68.49min remains)
2022-11-27 21:08:23 NUM_SUB: 1;----------------------------
2022-11-27 21:08:23 Epoch [17000/30000] Loss:0.000272 Loss_1:0.000263 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:19.015561s (78.60min in total, 60.10min remains)
2022-11-27 21:08:42 NUM_SUB: 1;----------------------------
2022-11-27 21:08:42 Epoch [18000/30000] Loss:0.000260 Loss_1:0.000252 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:19.203044s (78.92min in total, 52.61min remains)
2022-11-27 21:09:01 NUM_SUB: 1;----------------------------
2022-11-27 21:09:01 Epoch [19000/30000] Loss:0.000243 Loss_1:0.000236 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:18.761794s (79.23min in total, 45.87min remains)
2022-11-27 21:09:20 NUM_SUB: 1;----------------------------
2022-11-27 21:09:20 Epoch [20000/30000] Loss:0.000217 Loss_1:0.000211 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:18.766451s (79.54min in total, 39.77min remains)
2022-11-27 21:09:39 NUM_SUB: 1;----------------------------
2022-11-27 21:09:39 Epoch [21000/30000] Loss:0.000181 Loss_1:0.000176 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:18.693797s (79.85min in total, 34.22min remains)
2022-11-27 21:09:57 NUM_SUB: 1;----------------------------
2022-11-27 21:09:57 Epoch [22000/30000] Loss:0.000171 Loss_1:0.000167 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:18.757733s (80.17min in total, 29.15min remains)
2022-11-27 21:10:16 NUM_SUB: 1;----------------------------
2022-11-27 21:10:16 Epoch [23000/30000] Loss:0.000162 Loss_1:0.000158 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.680688s (80.48min in total, 24.49min remains)
2022-11-27 21:10:34 NUM_SUB: 1;----------------------------
2022-11-27 21:10:34 Epoch [24000/30000] Loss:0.000157 Loss_1:0.000154 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.404202s (80.78min in total, 20.20min remains)
2022-11-27 21:10:53 NUM_SUB: 1;----------------------------
2022-11-27 21:10:53 Epoch [25000/30000] Loss:0.000162 Loss_1:0.000159 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:18.676773s (81.09min in total, 16.22min remains)
2022-11-27 21:11:12 NUM_SUB: 1;----------------------------
2022-11-27 21:11:12 Epoch [26000/30000] Loss:0.000155 Loss_1:0.000152 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:18.765189s (81.41min in total, 12.52min remains)
2022-11-27 21:11:31 NUM_SUB: 1;----------------------------
2022-11-27 21:11:31 Epoch [27000/30000] Loss:0.000152 Loss_1:0.000150 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.235440s (81.73min in total, 9.08min remains)
2022-11-27 21:11:50 NUM_SUB: 1;----------------------------
2022-11-27 21:11:50 Epoch [28000/30000] Loss:0.000152 Loss_1:0.000150 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.991053s (82.04min in total, 5.86min remains)
2022-11-27 21:12:09 NUM_SUB: 1;----------------------------
2022-11-27 21:12:09 Epoch [29000/30000] Loss:0.000156 Loss_1:0.000151 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.536185s (82.35min in total, 2.84min remains)
2022-11-27 21:12:27 NUM_SUB: 1;----------------------------
2022-11-27 21:12:27 Epoch [30000/30000] Loss:0.000153 Loss_1:0.000151 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.771320s (82.67min in total, 0.00min remains)
2022-11-27 21:12:27 Testing & drawing...
2022-11-27 21:12:27 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:12:29 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=1/
2022-11-27 21:12:29 [Loss]
2022-11-27 21:12:29 NUM_SUB: 1; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:12:29 NUM_SUB: 1; Personalized parameter estimation: Parameter containing:
tensor([0.0159, 0.0578, 0.0102, 1.3101, 0.3074, 0.0120, 1.2585, 0.8964, 0.4556,
        0.0132, 0.0338, 0.0132, 0.8370, 0.1689, 0.0179, 1.6683, 0.6977, 0.8000,
        0.0123, 2.9432, 0.6816, 0.0225, 2.9409, 0.8742, 0.0217, 3.6517, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:12:29 NUM_SUB: 1------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 21:12:29 Testing & drawing...
2022-11-27 21:12:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:12:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=1/
2022-11-27 21:12:31 [Loss]
2022-11-27 21:12:31 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:12:31 General parameter estimation: Parameter containing:
tensor([0.0159, 0.0578, 0.0102, 1.3101, 0.3074, 0.0120, 1.2585, 0.8964, 0.4556,
        0.0132, 0.0338, 0.0132, 0.8370, 0.1689, 0.0179, 1.6683, 0.6977, 0.8000,
        0.0123, 2.9432, 0.6816, 0.0225, 2.9409, 0.8742, 0.0217, 3.6517, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:12:31 A: prod, degr, TonA, NonA
2022-11-27 21:12:31 [0.4146449  0.4820638  0.03788525 0.06540602]
2022-11-27 21:12:31 T: prod, degr, AonT, NonT
2022-11-27 21:12:31 [0.43802062 0.35881588 0.12504743 0.07811609]
2022-11-27 21:12:31 N: AonN, TonN, ATonN
2022-11-27 21:12:31 [0.00710064 0.9631172  0.02978218]
2022-11-27 21:12:31 using cpu
2022-11-27 21:12:31 epoch = 30000
2022-11-27 21:12:31 epoch_step = 1000
2022-11-27 21:12:31 model_name = SimpleNetworkAD
2022-11-27 21:12:31 now_string = 2022-11-27-19-40-13
2022-11-27 21:12:31 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 21:12:31 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 21:12:31 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 21:12:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 21:12:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 21:12:31 --------------------------------------------------training start--------------------------------------------------
2022-11-27 21:12:50 NUM_SUB: 2;----------------------------
2022-11-27 21:12:50 Epoch [01000/30000] Loss:0.063598 Loss_1:0.058074 Loss_2:0.001571 Loss_3:0.000000 Lr:0.000909 Time:19.118254s (0.32min in total, 9.24min remains)
2022-11-27 21:13:09 NUM_SUB: 2;----------------------------
2022-11-27 21:13:09 Epoch [02000/30000] Loss:0.056844 Loss_1:0.055926 Loss_2:0.000430 Loss_3:0.000000 Lr:0.000833 Time:18.995177s (0.64min in total, 8.89min remains)
2022-11-27 21:13:29 NUM_SUB: 2;----------------------------
2022-11-27 21:13:29 Epoch [03000/30000] Loss:0.052399 Loss_1:0.052127 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000769 Time:19.557836s (0.96min in total, 8.65min remains)
2022-11-27 21:13:48 NUM_SUB: 2;----------------------------
2022-11-27 21:13:48 Epoch [04000/30000] Loss:0.047620 Loss_1:0.047270 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000714 Time:19.200560s (1.28min in total, 8.33min remains)
2022-11-27 21:14:07 NUM_SUB: 2;----------------------------
2022-11-27 21:14:07 Epoch [05000/30000] Loss:0.041001 Loss_1:0.040672 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000667 Time:18.830676s (1.60min in total, 7.98min remains)
2022-11-27 21:14:26 NUM_SUB: 2;----------------------------
2022-11-27 21:14:26 Epoch [06000/30000] Loss:0.031889 Loss_1:0.031602 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000625 Time:18.964054s (1.91min in total, 7.64min remains)
2022-11-27 21:14:45 NUM_SUB: 2;----------------------------
2022-11-27 21:14:45 Epoch [07000/30000] Loss:0.020720 Loss_1:0.020487 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000588 Time:18.887314s (2.23min in total, 7.31min remains)
2022-11-27 21:15:04 NUM_SUB: 2;----------------------------
2022-11-27 21:15:04 Epoch [08000/30000] Loss:0.010259 Loss_1:0.010081 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000556 Time:19.265606s (2.55min in total, 7.00min remains)
2022-11-27 21:15:24 NUM_SUB: 2;----------------------------
2022-11-27 21:15:24 Epoch [09000/30000] Loss:0.004261 Loss_1:0.004125 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000526 Time:19.722455s (2.88min in total, 6.71min remains)
2022-11-27 21:15:43 NUM_SUB: 2;----------------------------
2022-11-27 21:15:43 Epoch [10000/30000] Loss:0.002679 Loss_1:0.002577 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000500 Time:19.847925s (3.21min in total, 6.41min remains)
2022-11-27 21:16:03 NUM_SUB: 2;----------------------------
2022-11-27 21:16:03 Epoch [11000/30000] Loss:0.002471 Loss_1:0.002403 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:19.602686s (3.53min in total, 6.10min remains)
2022-11-27 21:16:23 NUM_SUB: 2;----------------------------
2022-11-27 21:16:23 Epoch [12000/30000] Loss:0.002338 Loss_1:0.002297 Loss_2:0.000040 Loss_3:0.000000 Lr:0.000455 Time:19.531674s (3.86min in total, 5.79min remains)
2022-11-27 21:16:42 NUM_SUB: 2;----------------------------
2022-11-27 21:16:42 Epoch [13000/30000] Loss:0.002179 Loss_1:0.002153 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000435 Time:19.653567s (4.19min in total, 5.47min remains)
2022-11-27 21:17:01 NUM_SUB: 2;----------------------------
2022-11-27 21:17:01 Epoch [14000/30000] Loss:0.001989 Loss_1:0.001973 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000417 Time:19.233794s (4.51min in total, 5.15min remains)
2022-11-27 21:17:20 NUM_SUB: 2;----------------------------
2022-11-27 21:17:20 Epoch [15000/30000] Loss:0.001816 Loss_1:0.001805 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000400 Time:18.794313s (4.82min in total, 4.82min remains)
2022-11-27 21:17:40 NUM_SUB: 2;----------------------------
2022-11-27 21:17:40 Epoch [16000/30000] Loss:0.001746 Loss_1:0.001738 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:19.332765s (5.14min in total, 4.50min remains)
2022-11-27 21:17:59 NUM_SUB: 2;----------------------------
2022-11-27 21:17:59 Epoch [17000/30000] Loss:0.001734 Loss_1:0.001727 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000370 Time:19.121700s (5.46min in total, 4.18min remains)
2022-11-27 21:18:18 NUM_SUB: 2;----------------------------
2022-11-27 21:18:18 Epoch [18000/30000] Loss:0.001730 Loss_1:0.001724 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:18.941302s (5.78min in total, 3.85min remains)
2022-11-27 21:18:38 NUM_SUB: 2;----------------------------
2022-11-27 21:18:38 Epoch [19000/30000] Loss:0.001728 Loss_1:0.001723 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000345 Time:19.899091s (6.11min in total, 3.54min remains)
2022-11-27 21:18:57 NUM_SUB: 2;----------------------------
2022-11-27 21:18:57 Epoch [20000/30000] Loss:0.001727 Loss_1:0.001723 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:19.648692s (6.44min in total, 3.22min remains)
2022-11-27 21:19:16 NUM_SUB: 2;----------------------------
2022-11-27 21:19:16 Epoch [21000/30000] Loss:0.001727 Loss_1:0.001723 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:18.959610s (6.75min in total, 2.89min remains)
2022-11-27 21:19:36 NUM_SUB: 2;----------------------------
2022-11-27 21:19:36 Epoch [22000/30000] Loss:0.001735 Loss_1:0.001731 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.614768s (7.08min in total, 2.57min remains)
2022-11-27 21:19:55 NUM_SUB: 2;----------------------------
2022-11-27 21:19:55 Epoch [23000/30000] Loss:0.001726 Loss_1:0.001723 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.265562s (7.40min in total, 2.25min remains)
2022-11-27 21:20:14 NUM_SUB: 2;----------------------------
2022-11-27 21:20:14 Epoch [24000/30000] Loss:0.001726 Loss_1:0.001722 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.170058s (7.72min in total, 1.93min remains)
2022-11-27 21:20:34 NUM_SUB: 2;----------------------------
2022-11-27 21:20:34 Epoch [25000/30000] Loss:0.001726 Loss_1:0.001722 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.562665s (8.05min in total, 1.61min remains)
2022-11-27 21:20:54 NUM_SUB: 2;----------------------------
2022-11-27 21:20:54 Epoch [26000/30000] Loss:0.001728 Loss_1:0.001726 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.864776s (8.38min in total, 1.29min remains)
2022-11-27 21:21:14 NUM_SUB: 2;----------------------------
2022-11-27 21:21:14 Epoch [27000/30000] Loss:0.001726 Loss_1:0.001723 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:20.185441s (8.71min in total, 0.97min remains)
2022-11-27 21:21:34 NUM_SUB: 2;----------------------------
2022-11-27 21:21:34 Epoch [28000/30000] Loss:0.001726 Loss_1:0.001723 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.742774s (9.04min in total, 0.65min remains)
2022-11-27 21:21:53 NUM_SUB: 2;----------------------------
2022-11-27 21:21:53 Epoch [29000/30000] Loss:0.001726 Loss_1:0.001723 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.397162s (9.37min in total, 0.32min remains)
2022-11-27 21:22:12 NUM_SUB: 2;----------------------------
2022-11-27 21:22:12 Epoch [30000/30000] Loss:0.001725 Loss_1:0.001723 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.221476s (9.69min in total, 0.00min remains)
2022-11-27 21:22:12 Testing & drawing...
2022-11-27 21:22:12 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:22:14 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=2/
2022-11-27 21:22:14 [Loss]
2022-11-27 21:22:14 NUM_SUB: 2; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:22:14 NUM_SUB: 2; Personalized parameter estimation: Parameter containing:
tensor([0.3059, 0.8419, 0.0096, 0.2024, 0.3074, 0.0344, 0.4901, 0.8964, 0.4556,
        0.1411, 0.3070, 0.0326, 0.2412, 0.1689, 0.0176, 0.2628, 0.6977, 0.8000,
        0.0124, 2.7950, 0.6816, 0.0229, 2.5632, 0.8742, 0.0216, 3.2633, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:22:14 NUM_SUB: 2------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 21:22:14 Testing & drawing...
2022-11-27 21:22:14 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:22:15 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=2/
2022-11-27 21:22:15 [Loss]
2022-11-27 21:22:15 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:22:15 General parameter estimation: Parameter containing:
tensor([0.3059, 0.8419, 0.0096, 0.2024, 0.3074, 0.0344, 0.4901, 0.8964, 0.4556,
        0.1411, 0.3070, 0.0326, 0.2412, 0.1689, 0.0176, 0.2628, 0.6977, 0.8000,
        0.0124, 2.7950, 0.6816, 0.0229, 2.5632, 0.8742, 0.0216, 3.2633, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:22:15 A: prod, degr, TonA, NonA
2022-11-27 21:22:15 [0.45062917 0.499876   0.01272938 0.03676542]
2022-11-27 21:22:15 T: prod, degr, AonT, NonT
2022-11-27 21:22:15 [0.4570028  0.40079916 0.09107389 0.05112415]
2022-11-27 21:22:15 N: AonN, TonN, ATonN
2022-11-27 21:22:15 [0.0112432  0.9436066  0.04515021]
2022-11-27 21:22:16 using cpu
2022-11-27 21:22:16 epoch = 30000
2022-11-27 21:22:16 epoch_step = 1000
2022-11-27 21:22:16 model_name = SimpleNetworkAD
2022-11-27 21:22:16 now_string = 2022-11-27-19-40-13
2022-11-27 21:22:16 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 21:22:16 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 21:22:16 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 21:22:16 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 21:22:16 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 21:22:16 --------------------------------------------------training start--------------------------------------------------
2022-11-27 21:22:35 NUM_SUB: 3;----------------------------
2022-11-27 21:22:35 Epoch [01000/30000] Loss:0.081927 Loss_1:0.076267 Loss_2:0.001792 Loss_3:0.000000 Lr:0.000909 Time:19.370346s (0.32min in total, 9.36min remains)
2022-11-27 21:22:54 NUM_SUB: 3;----------------------------
2022-11-27 21:22:54 Epoch [02000/30000] Loss:0.073862 Loss_1:0.072835 Loss_2:0.000590 Loss_3:0.000000 Lr:0.000833 Time:19.298513s (0.64min in total, 9.02min remains)
2022-11-27 21:23:14 NUM_SUB: 3;----------------------------
2022-11-27 21:23:14 Epoch [03000/30000] Loss:0.067917 Loss_1:0.067423 Loss_2:0.000271 Loss_3:0.000000 Lr:0.000769 Time:19.442635s (0.97min in total, 8.72min remains)
2022-11-27 21:23:33 NUM_SUB: 3;----------------------------
2022-11-27 21:23:33 Epoch [04000/30000] Loss:0.061075 Loss_1:0.060559 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000714 Time:19.604443s (1.30min in total, 8.42min remains)
2022-11-27 21:23:52 NUM_SUB: 3;----------------------------
2022-11-27 21:23:52 Epoch [05000/30000] Loss:0.051515 Loss_1:0.051033 Loss_2:0.000219 Loss_3:0.000000 Lr:0.000667 Time:19.049705s (1.61min in total, 8.06min remains)
2022-11-27 21:24:12 NUM_SUB: 3;----------------------------
2022-11-27 21:24:12 Epoch [06000/30000] Loss:0.038159 Loss_1:0.037739 Loss_2:0.000208 Loss_3:0.000000 Lr:0.000625 Time:19.294695s (1.93min in total, 7.74min remains)
2022-11-27 21:24:31 NUM_SUB: 3;----------------------------
2022-11-27 21:24:31 Epoch [07000/30000] Loss:0.021960 Loss_1:0.021560 Loss_2:0.000263 Loss_3:0.000000 Lr:0.000588 Time:19.668861s (2.26min in total, 7.43min remains)
2022-11-27 21:24:51 NUM_SUB: 3;----------------------------
2022-11-27 21:24:51 Epoch [08000/30000] Loss:0.009658 Loss_1:0.009372 Loss_2:0.000218 Loss_3:0.000000 Lr:0.000556 Time:19.296682s (2.58min in total, 7.11min remains)
2022-11-27 21:25:10 NUM_SUB: 3;----------------------------
2022-11-27 21:25:10 Epoch [09000/30000] Loss:0.004022 Loss_1:0.003831 Loss_2:0.000173 Loss_3:0.000000 Lr:0.000526 Time:19.386183s (2.91min in total, 6.78min remains)
2022-11-27 21:25:30 NUM_SUB: 3;----------------------------
2022-11-27 21:25:30 Epoch [10000/30000] Loss:0.002455 Loss_1:0.002310 Loss_2:0.000144 Loss_3:0.000000 Lr:0.000500 Time:19.602970s (3.23min in total, 6.47min remains)
2022-11-27 21:25:49 NUM_SUB: 3;----------------------------
2022-11-27 21:25:49 Epoch [11000/30000] Loss:0.002063 Loss_1:0.001949 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000476 Time:19.732530s (3.56min in total, 6.15min remains)
2022-11-27 21:26:09 NUM_SUB: 3;----------------------------
2022-11-27 21:26:09 Epoch [12000/30000] Loss:0.001681 Loss_1:0.001615 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000455 Time:19.393323s (3.89min in total, 5.83min remains)
2022-11-27 21:26:28 NUM_SUB: 3;----------------------------
2022-11-27 21:26:28 Epoch [13000/30000] Loss:0.001482 Loss_1:0.001430 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000435 Time:19.250189s (4.21min in total, 5.50min remains)
2022-11-27 21:26:47 NUM_SUB: 3;----------------------------
2022-11-27 21:26:47 Epoch [14000/30000] Loss:0.001432 Loss_1:0.001389 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000417 Time:19.249431s (4.53min in total, 5.17min remains)
2022-11-27 21:27:06 NUM_SUB: 3;----------------------------
2022-11-27 21:27:06 Epoch [15000/30000] Loss:0.001518 Loss_1:0.001484 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000400 Time:19.100757s (4.85min in total, 4.85min remains)
2022-11-27 21:27:26 NUM_SUB: 3;----------------------------
2022-11-27 21:27:26 Epoch [16000/30000] Loss:0.001393 Loss_1:0.001366 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000385 Time:19.556564s (5.17min in total, 4.53min remains)
2022-11-27 21:27:45 NUM_SUB: 3;----------------------------
2022-11-27 21:27:45 Epoch [17000/30000] Loss:0.001382 Loss_1:0.001358 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000370 Time:19.452336s (5.50min in total, 4.20min remains)
2022-11-27 21:28:05 NUM_SUB: 3;----------------------------
2022-11-27 21:28:05 Epoch [18000/30000] Loss:0.001371 Loss_1:0.001352 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000357 Time:19.210933s (5.82min in total, 3.88min remains)
2022-11-27 21:28:24 NUM_SUB: 3;----------------------------
2022-11-27 21:28:24 Epoch [19000/30000] Loss:0.001364 Loss_1:0.001348 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000345 Time:19.443277s (6.14min in total, 3.55min remains)
2022-11-27 21:28:43 NUM_SUB: 3;----------------------------
2022-11-27 21:28:43 Epoch [20000/30000] Loss:0.001360 Loss_1:0.001345 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000333 Time:19.344553s (6.46min in total, 3.23min remains)
2022-11-27 21:29:03 NUM_SUB: 3;----------------------------
2022-11-27 21:29:03 Epoch [21000/30000] Loss:0.001357 Loss_1:0.001344 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000323 Time:19.609009s (6.79min in total, 2.91min remains)
2022-11-27 21:29:23 NUM_SUB: 3;----------------------------
2022-11-27 21:29:23 Epoch [22000/30000] Loss:0.001355 Loss_1:0.001343 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000313 Time:19.550097s (7.12min in total, 2.59min remains)
2022-11-27 21:29:42 NUM_SUB: 3;----------------------------
2022-11-27 21:29:42 Epoch [23000/30000] Loss:0.001353 Loss_1:0.001343 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000303 Time:19.648374s (7.44min in total, 2.27min remains)
2022-11-27 21:30:02 NUM_SUB: 3;----------------------------
2022-11-27 21:30:02 Epoch [24000/30000] Loss:0.001352 Loss_1:0.001342 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000294 Time:19.612099s (7.77min in total, 1.94min remains)
2022-11-27 21:30:21 NUM_SUB: 3;----------------------------
2022-11-27 21:30:21 Epoch [25000/30000] Loss:0.001350 Loss_1:0.001341 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000286 Time:19.338211s (8.09min in total, 1.62min remains)
2022-11-27 21:30:40 NUM_SUB: 3;----------------------------
2022-11-27 21:30:40 Epoch [26000/30000] Loss:0.001349 Loss_1:0.001340 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:19.126840s (8.41min in total, 1.29min remains)
2022-11-27 21:31:00 NUM_SUB: 3;----------------------------
2022-11-27 21:31:00 Epoch [27000/30000] Loss:0.001348 Loss_1:0.001340 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000270 Time:19.936318s (8.74min in total, 0.97min remains)
2022-11-27 21:31:20 NUM_SUB: 3;----------------------------
2022-11-27 21:31:20 Epoch [28000/30000] Loss:0.001347 Loss_1:0.001339 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:19.874965s (9.07min in total, 0.65min remains)
2022-11-27 21:31:40 NUM_SUB: 3;----------------------------
2022-11-27 21:31:40 Epoch [29000/30000] Loss:0.001346 Loss_1:0.001339 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000256 Time:20.221166s (9.41min in total, 0.32min remains)
2022-11-27 21:32:00 NUM_SUB: 3;----------------------------
2022-11-27 21:32:00 Epoch [30000/30000] Loss:0.001345 Loss_1:0.001339 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:19.732251s (9.74min in total, 0.00min remains)
2022-11-27 21:32:00 Testing & drawing...
2022-11-27 21:32:00 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:32:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=3/
2022-11-27 21:32:02 [Loss]
2022-11-27 21:32:02 NUM_SUB: 3; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:32:02 NUM_SUB: 3; Personalized parameter estimation: Parameter containing:
tensor([0.0160, 0.0263, 0.0121, 1.5258, 0.3074, 0.0159, 3.2534, 0.8964, 0.4556,
        0.0136, 0.0266, 0.0143, 1.0278, 0.1689, 0.0175, 2.5252, 0.6977, 0.8000,
        0.0117, 4.4528, 0.6816, 0.0216, 3.7989, 0.8742, 0.0083, 4.2362, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:32:02 NUM_SUB: 3------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 21:32:02 Testing & drawing...
2022-11-27 21:32:02 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:32:03 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=3/
2022-11-27 21:32:03 [Loss]
2022-11-27 21:32:03 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:32:03 General parameter estimation: Parameter containing:
tensor([0.0160, 0.0263, 0.0121, 1.5258, 0.3074, 0.0159, 3.2534, 0.8964, 0.4556,
        0.0136, 0.0266, 0.0143, 1.0278, 0.1689, 0.0175, 2.5252, 0.6977, 0.8000,
        0.0117, 4.4528, 0.6816, 0.0216, 3.7989, 0.8742, 0.0083, 4.2362, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:32:03 A: prod, degr, TonA, NonA
2022-11-27 21:32:03 [0.45042816 0.47191283 0.05409728 0.02356171]
2022-11-27 21:32:03 T: prod, degr, AonT, NonT
2022-11-27 21:32:03 [0.3767017  0.46717393 0.1155144  0.04060996]
2022-11-27 21:32:03 N: AonN, TonN, ATonN
2022-11-27 21:32:03 [0.01190787 0.9693624  0.01872977]
2022-11-27 21:32:04 using cpu
2022-11-27 21:32:04 epoch = 30000
2022-11-27 21:32:04 epoch_step = 1000
2022-11-27 21:32:04 model_name = SimpleNetworkAD
2022-11-27 21:32:04 now_string = 2022-11-27-19-40-13
2022-11-27 21:32:04 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 21:32:04 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 21:32:04 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 21:32:04 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 21:32:04 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 21:32:04 --------------------------------------------------training start--------------------------------------------------
2022-11-27 21:32:23 NUM_SUB: 4;----------------------------
2022-11-27 21:32:23 Epoch [01000/30000] Loss:0.055076 Loss_1:0.049887 Loss_2:0.001507 Loss_3:0.000000 Lr:0.000909 Time:19.583248s (0.33min in total, 9.47min remains)
2022-11-27 21:32:43 NUM_SUB: 4;----------------------------
2022-11-27 21:32:43 Epoch [02000/30000] Loss:0.047406 Loss_1:0.046596 Loss_2:0.000408 Loss_3:0.000000 Lr:0.000833 Time:20.054067s (0.66min in total, 9.25min remains)
2022-11-27 21:33:03 NUM_SUB: 4;----------------------------
2022-11-27 21:33:03 Epoch [03000/30000] Loss:0.042381 Loss_1:0.042077 Loss_2:0.000130 Loss_3:0.000000 Lr:0.000769 Time:19.660450s (0.99min in total, 8.89min remains)
2022-11-27 21:33:22 NUM_SUB: 4;----------------------------
2022-11-27 21:33:22 Epoch [04000/30000] Loss:0.037313 Loss_1:0.037010 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000714 Time:19.202911s (1.31min in total, 8.50min remains)
2022-11-27 21:33:41 NUM_SUB: 4;----------------------------
2022-11-27 21:33:41 Epoch [05000/30000] Loss:0.029935 Loss_1:0.029732 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000667 Time:19.099913s (1.63min in total, 8.13min remains)
2022-11-27 21:34:00 NUM_SUB: 4;----------------------------
2022-11-27 21:34:00 Epoch [06000/30000] Loss:0.020220 Loss_1:0.020039 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000625 Time:19.156262s (1.95min in total, 7.78min remains)
2022-11-27 21:34:20 NUM_SUB: 4;----------------------------
2022-11-27 21:34:20 Epoch [07000/30000] Loss:0.010136 Loss_1:0.009992 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000588 Time:19.348200s (2.27min in total, 7.45min remains)
2022-11-27 21:34:40 NUM_SUB: 4;----------------------------
2022-11-27 21:34:40 Epoch [08000/30000] Loss:0.004181 Loss_1:0.004039 Loss_2:0.000095 Loss_3:0.000000 Lr:0.000556 Time:20.089150s (2.60min in total, 7.16min remains)
2022-11-27 21:35:00 NUM_SUB: 4;----------------------------
2022-11-27 21:35:00 Epoch [09000/30000] Loss:0.002666 Loss_1:0.002580 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000526 Time:20.300882s (2.94min in total, 6.86min remains)
2022-11-27 21:35:21 NUM_SUB: 4;----------------------------
2022-11-27 21:35:21 Epoch [10000/30000] Loss:0.002287 Loss_1:0.002244 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000500 Time:20.640111s (3.29min in total, 6.57min remains)
2022-11-27 21:35:41 NUM_SUB: 4;----------------------------
2022-11-27 21:35:41 Epoch [11000/30000] Loss:0.002604 Loss_1:0.002495 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000476 Time:20.773710s (3.63min in total, 6.27min remains)
2022-11-27 21:36:02 NUM_SUB: 4;----------------------------
2022-11-27 21:36:02 Epoch [12000/30000] Loss:0.001598 Loss_1:0.001572 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000455 Time:20.748439s (3.98min in total, 5.97min remains)
2022-11-27 21:36:23 NUM_SUB: 4;----------------------------
2022-11-27 21:36:23 Epoch [13000/30000] Loss:0.001234 Loss_1:0.001208 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000435 Time:20.608557s (4.32min in total, 5.65min remains)
2022-11-27 21:36:43 NUM_SUB: 4;----------------------------
2022-11-27 21:36:43 Epoch [14000/30000] Loss:0.001001 Loss_1:0.000977 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:20.343105s (4.66min in total, 5.33min remains)
2022-11-27 21:37:03 NUM_SUB: 4;----------------------------
2022-11-27 21:37:03 Epoch [15000/30000] Loss:0.000936 Loss_1:0.000917 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:19.400427s (4.98min in total, 4.98min remains)
2022-11-27 21:37:22 NUM_SUB: 4;----------------------------
2022-11-27 21:37:22 Epoch [16000/30000] Loss:0.000936 Loss_1:0.000909 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:19.279865s (5.31min in total, 4.64min remains)
2022-11-27 21:37:42 NUM_SUB: 4;----------------------------
2022-11-27 21:37:42 Epoch [17000/30000] Loss:0.000925 Loss_1:0.000911 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000370 Time:20.025389s (5.64min in total, 4.31min remains)
2022-11-27 21:38:02 NUM_SUB: 4;----------------------------
2022-11-27 21:38:02 Epoch [18000/30000] Loss:0.000923 Loss_1:0.000911 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:20.368072s (5.98min in total, 3.99min remains)
2022-11-27 21:38:23 NUM_SUB: 4;----------------------------
2022-11-27 21:38:23 Epoch [19000/30000] Loss:0.000948 Loss_1:0.000908 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000345 Time:20.314100s (6.32min in total, 3.66min remains)
2022-11-27 21:38:43 NUM_SUB: 4;----------------------------
2022-11-27 21:38:43 Epoch [20000/30000] Loss:0.000919 Loss_1:0.000910 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:20.608276s (6.66min in total, 3.33min remains)
2022-11-27 21:39:03 NUM_SUB: 4;----------------------------
2022-11-27 21:39:03 Epoch [21000/30000] Loss:0.000918 Loss_1:0.000910 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000323 Time:19.843211s (6.99min in total, 3.00min remains)
2022-11-27 21:39:22 NUM_SUB: 4;----------------------------
2022-11-27 21:39:22 Epoch [22000/30000] Loss:0.000922 Loss_1:0.000913 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:19.303612s (7.31min in total, 2.66min remains)
2022-11-27 21:39:41 NUM_SUB: 4;----------------------------
2022-11-27 21:39:41 Epoch [23000/30000] Loss:0.000916 Loss_1:0.000909 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:19.139977s (7.63min in total, 2.32min remains)
2022-11-27 21:40:01 NUM_SUB: 4;----------------------------
2022-11-27 21:40:01 Epoch [24000/30000] Loss:0.000915 Loss_1:0.000909 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.198797s (7.95min in total, 1.99min remains)
2022-11-27 21:40:20 NUM_SUB: 4;----------------------------
2022-11-27 21:40:20 Epoch [25000/30000] Loss:0.000914 Loss_1:0.000909 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.428761s (8.28min in total, 1.66min remains)
2022-11-27 21:40:40 NUM_SUB: 4;----------------------------
2022-11-27 21:40:40 Epoch [26000/30000] Loss:0.000914 Loss_1:0.000908 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:20.006972s (8.61min in total, 1.32min remains)
2022-11-27 21:41:00 NUM_SUB: 4;----------------------------
2022-11-27 21:41:00 Epoch [27000/30000] Loss:0.000913 Loss_1:0.000910 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.416323s (8.93min in total, 0.99min remains)
2022-11-27 21:41:19 NUM_SUB: 4;----------------------------
2022-11-27 21:41:19 Epoch [28000/30000] Loss:0.000912 Loss_1:0.000909 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.792915s (9.26min in total, 0.66min remains)
2022-11-27 21:41:38 NUM_SUB: 4;----------------------------
2022-11-27 21:41:38 Epoch [29000/30000] Loss:0.000912 Loss_1:0.000909 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.014886s (9.58min in total, 0.33min remains)
2022-11-27 21:41:57 NUM_SUB: 4;----------------------------
2022-11-27 21:41:57 Epoch [30000/30000] Loss:0.000912 Loss_1:0.000909 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.744249s (9.89min in total, 0.00min remains)
2022-11-27 21:41:57 Testing & drawing...
2022-11-27 21:41:57 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:41:59 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=4/
2022-11-27 21:41:59 [Loss]
2022-11-27 21:41:59 NUM_SUB: 4; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:41:59 NUM_SUB: 4; Personalized parameter estimation: Parameter containing:
tensor([0.1060, 0.4842, 0.0095, 0.0343, 0.3074, 0.1660, 0.8147, 0.8964, 0.4556,
        0.0099, 0.1276, 0.0937, 0.4635, 0.1689, 0.0173, 1.4302, 0.6977, 0.8000,
        0.0120, 3.4864, 0.6816, 0.0197, 3.1870, 0.8742, 0.0215, 3.9930, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:41:59 NUM_SUB: 4------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 21:41:59 Testing & drawing...
2022-11-27 21:41:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:42:00 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=4/
2022-11-27 21:42:00 [Loss]
2022-11-27 21:42:00 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:42:00 General parameter estimation: Parameter containing:
tensor([0.1060, 0.4842, 0.0095, 0.0343, 0.3074, 0.1660, 0.8147, 0.8964, 0.4556,
        0.0099, 0.1276, 0.0937, 0.4635, 0.1689, 0.0173, 1.4302, 0.6977, 0.8000,
        0.0120, 3.4864, 0.6816, 0.0197, 3.1870, 0.8742, 0.0215, 3.9930, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 21:42:00 A: prod, degr, TonA, NonA
2022-11-27 21:42:00 [0.2937982  0.49926683 0.02582695 0.181108  ]
2022-11-27 21:42:00 T: prod, degr, AonT, NonT
2022-11-27 21:42:00 [0.11321075 0.5395598  0.31312454 0.03410497]
2022-11-27 21:42:00 N: AonN, TonN, ATonN
2022-11-27 21:42:00 [0.01004839 0.9668049  0.0231467 ]
2022-11-27 21:42:00 using cpu
2022-11-27 21:42:00 epoch = 30000
2022-11-27 21:42:00 epoch_step = 1000
2022-11-27 21:42:00 model_name = SimpleNetworkAD
2022-11-27 21:42:00 now_string = 2022-11-27-19-40-13
2022-11-27 21:42:00 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 21:42:00 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 21:42:00 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 21:42:00 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 21:42:00 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 21:42:00 --------------------------------------------------training start--------------------------------------------------
2022-11-27 21:42:19 NUM_SUB: 5;----------------------------
2022-11-27 21:42:19 Epoch [01000/30000] Loss:0.086553 Loss_1:0.081341 Loss_2:0.001465 Loss_3:0.000000 Lr:0.000909 Time:18.775424s (0.31min in total, 9.07min remains)
2022-11-27 21:42:38 NUM_SUB: 5;----------------------------
2022-11-27 21:42:38 Epoch [02000/30000] Loss:0.076465 Loss_1:0.075675 Loss_2:0.000389 Loss_3:0.000000 Lr:0.000833 Time:18.955341s (0.63min in total, 8.80min remains)
2022-11-27 21:42:57 NUM_SUB: 5;----------------------------
2022-11-27 21:42:57 Epoch [03000/30000] Loss:0.067439 Loss_1:0.067127 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000769 Time:18.848450s (0.94min in total, 8.49min remains)
2022-11-27 21:43:16 NUM_SUB: 5;----------------------------
2022-11-27 21:43:16 Epoch [04000/30000] Loss:0.055956 Loss_1:0.055715 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000714 Time:18.611315s (1.25min in total, 8.15min remains)
2022-11-27 21:43:35 NUM_SUB: 5;----------------------------
2022-11-27 21:43:35 Epoch [05000/30000] Loss:0.039971 Loss_1:0.039770 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000667 Time:19.149090s (1.57min in total, 7.86min remains)
2022-11-27 21:43:53 NUM_SUB: 5;----------------------------
2022-11-27 21:43:53 Epoch [06000/30000] Loss:0.021493 Loss_1:0.021348 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000625 Time:18.665924s (1.88min in total, 7.53min remains)
2022-11-27 21:44:12 NUM_SUB: 5;----------------------------
2022-11-27 21:44:12 Epoch [07000/30000] Loss:0.008835 Loss_1:0.008757 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000588 Time:18.611944s (2.19min in total, 7.21min remains)
2022-11-27 21:44:31 NUM_SUB: 5;----------------------------
2022-11-27 21:44:31 Epoch [08000/30000] Loss:0.005535 Loss_1:0.005489 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000556 Time:19.340255s (2.52min in total, 6.92min remains)
2022-11-27 21:44:51 NUM_SUB: 5;----------------------------
2022-11-27 21:44:51 Epoch [09000/30000] Loss:0.005087 Loss_1:0.005040 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000526 Time:19.386383s (2.84min in total, 6.62min remains)
2022-11-27 21:45:10 NUM_SUB: 5;----------------------------
2022-11-27 21:45:10 Epoch [10000/30000] Loss:0.004804 Loss_1:0.004747 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000500 Time:19.095476s (3.16min in total, 6.31min remains)
2022-11-27 21:45:29 NUM_SUB: 5;----------------------------
2022-11-27 21:45:29 Epoch [11000/30000] Loss:0.004346 Loss_1:0.004293 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000476 Time:19.513163s (3.48min in total, 6.02min remains)
2022-11-27 21:45:49 NUM_SUB: 5;----------------------------
2022-11-27 21:45:49 Epoch [12000/30000] Loss:0.003585 Loss_1:0.003567 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000455 Time:19.124088s (3.80min in total, 5.70min remains)
2022-11-27 21:46:08 NUM_SUB: 5;----------------------------
2022-11-27 21:46:08 Epoch [13000/30000] Loss:0.002474 Loss_1:0.002453 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000435 Time:19.293015s (4.12min in total, 5.39min remains)
2022-11-27 21:46:27 NUM_SUB: 5;----------------------------
2022-11-27 21:46:27 Epoch [14000/30000] Loss:0.001340 Loss_1:0.001317 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:19.548633s (4.45min in total, 5.08min remains)
2022-11-27 21:46:46 NUM_SUB: 5;----------------------------
2022-11-27 21:46:46 Epoch [15000/30000] Loss:0.001095 Loss_1:0.001077 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:18.546531s (4.76min in total, 4.76min remains)
2022-11-27 21:47:05 NUM_SUB: 5;----------------------------
2022-11-27 21:47:05 Epoch [16000/30000] Loss:0.001074 Loss_1:0.001063 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:18.864530s (5.07min in total, 4.44min remains)
2022-11-27 21:47:24 NUM_SUB: 5;----------------------------
2022-11-27 21:47:24 Epoch [17000/30000] Loss:0.001052 Loss_1:0.001045 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:18.826936s (5.39min in total, 4.12min remains)
2022-11-27 21:47:43 NUM_SUB: 5;----------------------------
2022-11-27 21:47:43 Epoch [18000/30000] Loss:0.001023 Loss_1:0.001018 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:18.875916s (5.70min in total, 3.80min remains)
2022-11-27 21:48:02 NUM_SUB: 5;----------------------------
2022-11-27 21:48:02 Epoch [19000/30000] Loss:0.000981 Loss_1:0.000978 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000345 Time:19.263904s (6.02min in total, 3.49min remains)
2022-11-27 21:48:21 NUM_SUB: 5;----------------------------
2022-11-27 21:48:21 Epoch [20000/30000] Loss:0.000906 Loss_1:0.000904 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:19.347310s (6.34min in total, 3.17min remains)
2022-11-27 21:48:41 NUM_SUB: 5;----------------------------
2022-11-27 21:48:41 Epoch [21000/30000] Loss:0.000804 Loss_1:0.000803 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.380910s (6.67min in total, 2.86min remains)
2022-11-27 21:49:00 NUM_SUB: 5;----------------------------
2022-11-27 21:49:00 Epoch [22000/30000] Loss:0.000790 Loss_1:0.000789 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.325837s (6.99min in total, 2.54min remains)
2022-11-27 21:49:19 NUM_SUB: 5;----------------------------
2022-11-27 21:49:19 Epoch [23000/30000] Loss:0.000783 Loss_1:0.000782 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:18.655903s (7.30min in total, 2.22min remains)
2022-11-27 21:49:37 NUM_SUB: 5;----------------------------
2022-11-27 21:49:37 Epoch [24000/30000] Loss:0.000783 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:18.888397s (7.62min in total, 1.90min remains)
2022-11-27 21:49:56 NUM_SUB: 5;----------------------------
2022-11-27 21:49:56 Epoch [25000/30000] Loss:0.000782 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.843631s (7.93min in total, 1.59min remains)
2022-11-27 21:50:15 NUM_SUB: 5;----------------------------
2022-11-27 21:50:15 Epoch [26000/30000] Loss:0.000782 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.027867s (8.25min in total, 1.27min remains)
2022-11-27 21:50:34 NUM_SUB: 5;----------------------------
2022-11-27 21:50:34 Epoch [27000/30000] Loss:0.000782 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.920264s (8.56min in total, 0.95min remains)
2022-11-27 21:50:53 NUM_SUB: 5;----------------------------
2022-11-27 21:50:53 Epoch [28000/30000] Loss:0.000782 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:18.867184s (8.88min in total, 0.63min remains)
2022-11-27 21:51:12 NUM_SUB: 5;----------------------------
2022-11-27 21:51:12 Epoch [29000/30000] Loss:0.000782 Loss_1:0.000781 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.111355s (9.19min in total, 0.32min remains)
2022-11-27 21:51:32 NUM_SUB: 5;----------------------------
2022-11-27 21:51:32 Epoch [30000/30000] Loss:0.000783 Loss_1:0.000782 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.556544s (9.52min in total, 0.00min remains)
2022-11-27 21:51:32 Testing & drawing...
2022-11-27 21:51:32 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:51:33 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=5/
2022-11-27 21:51:33 [Loss]
2022-11-27 21:51:33 NUM_SUB: 5; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:51:33 NUM_SUB: 5; Personalized parameter estimation: Parameter containing:
tensor([3.0540e-01, 9.6282e-01, 9.4139e-03, 9.4309e-03, 3.0742e-01, 1.2548e-03,
        8.0640e-01, 8.9644e-01, 4.5563e-01, 1.4382e-02, 7.9006e-02, 7.3296e-02,
        6.4880e-01, 1.6886e-01, 1.7560e-02, 2.0953e+00, 6.9767e-01, 8.0001e-01,
        1.2519e-02, 1.1304e+00, 6.8161e-01, 2.2342e-02, 2.2856e+00, 8.7416e-01,
        2.2054e-02, 2.7800e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 21:51:33 NUM_SUB: 5------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 21:51:33 Testing & drawing...
2022-11-27 21:51:33 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 21:51:35 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=5/
2022-11-27 21:51:35 [Loss]
2022-11-27 21:51:35 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 21:51:35 General parameter estimation: Parameter containing:
tensor([3.0540e-01, 9.6282e-01, 9.4139e-03, 9.4309e-03, 3.0742e-01, 1.2548e-03,
        8.0640e-01, 8.9644e-01, 4.5563e-01, 1.4382e-02, 7.9006e-02, 7.3296e-02,
        6.4880e-01, 1.6886e-01, 1.7560e-02, 2.0953e+00, 6.9767e-01, 8.0001e-01,
        1.2519e-02, 1.1304e+00, 6.8161e-01, 2.2342e-02, 2.2856e+00, 8.7416e-01,
        2.2054e-02, 2.7800e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 21:51:35 A: prod, degr, TonA, NonA
2022-11-27 21:51:35 [0.48395467 0.50002354 0.01491102 0.00111071]
2022-11-27 21:51:35 T: prod, degr, AonT, NonT
2022-11-27 21:51:35 [0.20041889 0.3607978  0.39951655 0.03926681]
2022-11-27 21:51:35 N: AonN, TonN, ATonN
2022-11-27 21:51:35 [0.04504767 0.89974344 0.05520893]
2022-11-27 21:51:35 using cpu
2022-11-27 21:51:35 epoch = 30000
2022-11-27 21:51:35 epoch_step = 1000
2022-11-27 21:51:35 model_name = SimpleNetworkAD
2022-11-27 21:51:35 now_string = 2022-11-27-19-40-13
2022-11-27 21:51:35 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 21:51:35 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 21:51:35 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 21:51:35 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 21:51:35 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 21:51:35 --------------------------------------------------training start--------------------------------------------------
2022-11-27 21:51:54 NUM_SUB: 6;----------------------------
2022-11-27 21:51:54 Epoch [01000/30000] Loss:0.125363 Loss_1:0.119189 Loss_2:0.002360 Loss_3:0.000000 Lr:0.000909 Time:19.030356s (0.32min in total, 9.20min remains)
2022-11-27 21:52:13 NUM_SUB: 6;----------------------------
2022-11-27 21:52:13 Epoch [02000/30000] Loss:0.112872 Loss_1:0.111574 Loss_2:0.000886 Loss_3:0.000000 Lr:0.000833 Time:18.795891s (0.63min in total, 8.83min remains)
2022-11-27 21:52:32 NUM_SUB: 6;----------------------------
2022-11-27 21:52:32 Epoch [03000/30000] Loss:0.100902 Loss_1:0.100182 Loss_2:0.000397 Loss_3:0.000000 Lr:0.000769 Time:19.204218s (0.95min in total, 8.55min remains)
2022-11-27 21:52:52 NUM_SUB: 6;----------------------------
2022-11-27 21:52:52 Epoch [04000/30000] Loss:0.084694 Loss_1:0.084132 Loss_2:0.000243 Loss_3:0.000000 Lr:0.000714 Time:19.267255s (1.27min in total, 8.27min remains)
2022-11-27 21:53:10 NUM_SUB: 6;----------------------------
2022-11-27 21:53:10 Epoch [05000/30000] Loss:0.061034 Loss_1:0.060584 Loss_2:0.000162 Loss_3:0.000000 Lr:0.000667 Time:18.898235s (1.59min in total, 7.93min remains)
2022-11-27 21:53:29 NUM_SUB: 6;----------------------------
2022-11-27 21:53:29 Epoch [06000/30000] Loss:0.032257 Loss_1:0.031885 Loss_2:0.000162 Loss_3:0.000000 Lr:0.000625 Time:18.979291s (1.90min in total, 7.61min remains)
2022-11-27 21:53:48 NUM_SUB: 6;----------------------------
2022-11-27 21:53:48 Epoch [07000/30000] Loss:0.011680 Loss_1:0.011443 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000588 Time:18.727764s (2.22min in total, 7.28min remains)
2022-11-27 21:54:07 NUM_SUB: 6;----------------------------
2022-11-27 21:54:07 Epoch [08000/30000] Loss:0.005081 Loss_1:0.004937 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000556 Time:18.834766s (2.53min in total, 6.95min remains)
2022-11-27 21:54:26 NUM_SUB: 6;----------------------------
2022-11-27 21:54:26 Epoch [09000/30000] Loss:0.002794 Loss_1:0.002676 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000526 Time:19.075208s (2.85min in total, 6.64min remains)
2022-11-27 21:54:45 NUM_SUB: 6;----------------------------
2022-11-27 21:54:45 Epoch [10000/30000] Loss:0.001558 Loss_1:0.001450 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000500 Time:18.713103s (3.16min in total, 6.32min remains)
2022-11-27 21:55:04 NUM_SUB: 6;----------------------------
2022-11-27 21:55:04 Epoch [11000/30000] Loss:0.001069 Loss_1:0.000976 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000476 Time:18.849557s (3.47min in total, 6.00min remains)
2022-11-27 21:55:23 NUM_SUB: 6;----------------------------
2022-11-27 21:55:23 Epoch [12000/30000] Loss:0.000590 Loss_1:0.000542 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000455 Time:18.895391s (3.79min in total, 5.68min remains)
2022-11-27 21:55:41 NUM_SUB: 6;----------------------------
2022-11-27 21:55:41 Epoch [13000/30000] Loss:0.000242 Loss_1:0.000207 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000435 Time:18.874110s (4.10min in total, 5.36min remains)
2022-11-27 21:56:00 NUM_SUB: 6;----------------------------
2022-11-27 21:56:00 Epoch [14000/30000] Loss:0.000160 Loss_1:0.000129 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000417 Time:18.949674s (4.42min in total, 5.05min remains)
2022-11-27 21:56:19 NUM_SUB: 6;----------------------------
2022-11-27 21:56:19 Epoch [15000/30000] Loss:0.000137 Loss_1:0.000113 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000400 Time:19.087256s (4.74min in total, 4.74min remains)
2022-11-27 21:56:38 NUM_SUB: 6;----------------------------
2022-11-27 21:56:38 Epoch [16000/30000] Loss:0.000124 Loss_1:0.000106 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:18.956325s (5.05min in total, 4.42min remains)
2022-11-27 21:56:57 NUM_SUB: 6;----------------------------
2022-11-27 21:56:57 Epoch [17000/30000] Loss:0.000116 Loss_1:0.000102 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000370 Time:18.751081s (5.37min in total, 4.10min remains)
2022-11-27 21:57:16 NUM_SUB: 6;----------------------------
2022-11-27 21:57:16 Epoch [18000/30000] Loss:0.000108 Loss_1:0.000097 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:18.744754s (5.68min in total, 3.78min remains)
2022-11-27 21:57:35 NUM_SUB: 6;----------------------------
2022-11-27 21:57:35 Epoch [19000/30000] Loss:0.000097 Loss_1:0.000088 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000345 Time:19.193519s (6.00min in total, 3.47min remains)
2022-11-27 21:57:54 NUM_SUB: 6;----------------------------
2022-11-27 21:57:54 Epoch [20000/30000] Loss:0.000085 Loss_1:0.000078 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:18.943635s (6.31min in total, 3.16min remains)
2022-11-27 21:58:13 NUM_SUB: 6;----------------------------
2022-11-27 21:58:13 Epoch [21000/30000] Loss:0.000065 Loss_1:0.000060 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:19.250742s (6.63min in total, 2.84min remains)
2022-11-27 21:58:33 NUM_SUB: 6;----------------------------
2022-11-27 21:58:33 Epoch [22000/30000] Loss:0.000033 Loss_1:0.000029 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.264229s (6.96min in total, 2.53min remains)
2022-11-27 21:58:51 NUM_SUB: 6;----------------------------
2022-11-27 21:58:51 Epoch [23000/30000] Loss:0.000018 Loss_1:0.000015 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.792890s (7.27min in total, 2.21min remains)
2022-11-27 21:59:10 NUM_SUB: 6;----------------------------
2022-11-27 21:59:10 Epoch [24000/30000] Loss:0.000014 Loss_1:0.000012 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.716346s (7.58min in total, 1.90min remains)
2022-11-27 21:59:29 NUM_SUB: 6;----------------------------
2022-11-27 21:59:29 Epoch [25000/30000] Loss:0.000012 Loss_1:0.000010 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.217872s (7.90min in total, 1.58min remains)
2022-11-27 21:59:48 NUM_SUB: 6;----------------------------
2022-11-27 21:59:48 Epoch [26000/30000] Loss:0.000012 Loss_1:0.000010 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:18.959122s (8.22min in total, 1.26min remains)
2022-11-27 22:00:07 NUM_SUB: 6;----------------------------
2022-11-27 22:00:07 Epoch [27000/30000] Loss:0.000013 Loss_1:0.000011 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:18.914463s (8.53min in total, 0.95min remains)
2022-11-27 22:00:26 NUM_SUB: 6;----------------------------
2022-11-27 22:00:26 Epoch [28000/30000] Loss:0.000010 Loss_1:0.000008 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.084957s (8.85min in total, 0.63min remains)
2022-11-27 22:00:45 NUM_SUB: 6;----------------------------
2022-11-27 22:00:45 Epoch [29000/30000] Loss:0.000010 Loss_1:0.000008 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.789389s (9.16min in total, 0.32min remains)
2022-11-27 22:01:04 NUM_SUB: 6;----------------------------
2022-11-27 22:01:04 Epoch [30000/30000] Loss:0.000010 Loss_1:0.000008 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.799725s (9.48min in total, 0.00min remains)
2022-11-27 22:01:04 Testing & drawing...
2022-11-27 22:01:04 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:01:06 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=6/
2022-11-27 22:01:06 [Loss]
2022-11-27 22:01:06 NUM_SUB: 6; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:01:06 NUM_SUB: 6; Personalized parameter estimation: Parameter containing:
tensor([0.0197, 0.0302, 0.0211, 2.4539, 0.3074, 0.0164, 3.3424, 0.8964, 0.4556,
        0.0142, 0.0330, 0.0138, 0.8540, 0.1689, 0.0176, 2.4583, 0.6977, 0.8000,
        0.0120, 3.2686, 0.6816, 0.0230, 2.6650, 0.8742, 0.0197, 3.3802, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:01:06 NUM_SUB: 6------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:01:06 Testing & drawing...
2022-11-27 22:01:06 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:01:07 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=6/
2022-11-27 22:01:07 [Loss]
2022-11-27 22:01:07 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:01:07 General parameter estimation: Parameter containing:
tensor([0.0197, 0.0302, 0.0211, 2.4539, 0.3074, 0.0164, 3.3424, 0.8964, 0.4556,
        0.0142, 0.0330, 0.0138, 0.8540, 0.1689, 0.0176, 2.4583, 0.6977, 0.8000,
        0.0120, 3.2686, 0.6816, 0.0230, 2.6650, 0.8742, 0.0197, 3.3802, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:01:07 A: prod, degr, TonA, NonA
2022-11-27 22:01:07 [0.46097273 0.4784596  0.02732165 0.033246  ]
2022-11-27 22:01:07 T: prod, degr, AonT, NonT
2022-11-27 22:01:07 [0.3272062  0.51243687 0.10105817 0.05929879]
2022-11-27 22:01:07 N: AonN, TonN, ATonN
2022-11-27 22:01:07 [0.02199151 0.920134   0.05787445]
2022-11-27 22:01:07 using cpu
2022-11-27 22:01:07 epoch = 30000
2022-11-27 22:01:07 epoch_step = 1000
2022-11-27 22:01:07 model_name = SimpleNetworkAD
2022-11-27 22:01:07 now_string = 2022-11-27-19-40-13
2022-11-27 22:01:07 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:01:07 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:01:07 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:01:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:01:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:01:07 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:01:27 NUM_SUB: 7;----------------------------
2022-11-27 22:01:27 Epoch [01000/30000] Loss:0.055098 Loss_1:0.049029 Loss_2:0.002093 Loss_3:0.000000 Lr:0.000909 Time:19.342885s (0.32min in total, 9.35min remains)
2022-11-27 22:01:46 NUM_SUB: 7;----------------------------
2022-11-27 22:01:46 Epoch [02000/30000] Loss:0.047556 Loss_1:0.046358 Loss_2:0.000700 Loss_3:0.000000 Lr:0.000833 Time:19.030777s (0.64min in total, 8.95min remains)
2022-11-27 22:02:05 NUM_SUB: 7;----------------------------
2022-11-27 22:02:05 Epoch [03000/30000] Loss:0.043528 Loss_1:0.043120 Loss_2:0.000245 Loss_3:0.000000 Lr:0.000769 Time:18.989837s (0.96min in total, 8.60min remains)
2022-11-27 22:02:24 NUM_SUB: 7;----------------------------
2022-11-27 22:02:24 Epoch [04000/30000] Loss:0.038930 Loss_1:0.038538 Loss_2:0.000178 Loss_3:0.000000 Lr:0.000714 Time:19.010333s (1.27min in total, 8.27min remains)
2022-11-27 22:02:43 NUM_SUB: 7;----------------------------
2022-11-27 22:02:43 Epoch [05000/30000] Loss:0.033021 Loss_1:0.032645 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000667 Time:18.897360s (1.59min in total, 7.94min remains)
2022-11-27 22:03:02 NUM_SUB: 7;----------------------------
2022-11-27 22:03:02 Epoch [06000/30000] Loss:0.025097 Loss_1:0.024772 Loss_2:0.000149 Loss_3:0.000000 Lr:0.000625 Time:19.131527s (1.91min in total, 7.63min remains)
2022-11-27 22:03:21 NUM_SUB: 7;----------------------------
2022-11-27 22:03:21 Epoch [07000/30000] Loss:0.015895 Loss_1:0.015638 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000588 Time:19.105117s (2.23min in total, 7.31min remains)
2022-11-27 22:03:40 NUM_SUB: 7;----------------------------
2022-11-27 22:03:40 Epoch [08000/30000] Loss:0.007837 Loss_1:0.007646 Loss_2:0.000130 Loss_3:0.000000 Lr:0.000556 Time:18.987304s (2.54min in total, 6.99min remains)
2022-11-27 22:03:59 NUM_SUB: 7;----------------------------
2022-11-27 22:03:59 Epoch [09000/30000] Loss:0.003363 Loss_1:0.003218 Loss_2:0.000129 Loss_3:0.000000 Lr:0.000526 Time:18.920376s (2.86min in total, 6.67min remains)
2022-11-27 22:04:18 NUM_SUB: 7;----------------------------
2022-11-27 22:04:18 Epoch [10000/30000] Loss:0.001909 Loss_1:0.001792 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000500 Time:19.047988s (3.17min in total, 6.35min remains)
2022-11-27 22:04:38 NUM_SUB: 7;----------------------------
2022-11-27 22:04:38 Epoch [11000/30000] Loss:0.001293 Loss_1:0.001201 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000476 Time:19.829352s (3.51min in total, 6.05min remains)
2022-11-27 22:04:57 NUM_SUB: 7;----------------------------
2022-11-27 22:04:57 Epoch [12000/30000] Loss:0.000661 Loss_1:0.000609 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000455 Time:19.556222s (3.83min in total, 5.75min remains)
2022-11-27 22:05:16 NUM_SUB: 7;----------------------------
2022-11-27 22:05:16 Epoch [13000/30000] Loss:0.000243 Loss_1:0.000212 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000435 Time:18.763135s (4.14min in total, 5.42min remains)
2022-11-27 22:05:35 NUM_SUB: 7;----------------------------
2022-11-27 22:05:35 Epoch [14000/30000] Loss:0.000090 Loss_1:0.000066 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:19.410801s (4.47min in total, 5.11min remains)
2022-11-27 22:05:54 NUM_SUB: 7;----------------------------
2022-11-27 22:05:54 Epoch [15000/30000] Loss:0.000064 Loss_1:0.000045 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:18.972976s (4.78min in total, 4.78min remains)
2022-11-27 22:06:13 NUM_SUB: 7;----------------------------
2022-11-27 22:06:13 Epoch [16000/30000] Loss:0.000059 Loss_1:0.000045 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:18.862798s (5.10min in total, 4.46min remains)
2022-11-27 22:06:33 NUM_SUB: 7;----------------------------
2022-11-27 22:06:33 Epoch [17000/30000] Loss:0.000055 Loss_1:0.000045 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:19.315255s (5.42min in total, 4.14min remains)
2022-11-27 22:06:51 NUM_SUB: 7;----------------------------
2022-11-27 22:06:51 Epoch [18000/30000] Loss:0.000052 Loss_1:0.000045 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:18.774550s (5.73min in total, 3.82min remains)
2022-11-27 22:07:10 NUM_SUB: 7;----------------------------
2022-11-27 22:07:10 Epoch [19000/30000] Loss:0.000050 Loss_1:0.000045 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:18.665455s (6.04min in total, 3.50min remains)
2022-11-27 22:07:29 NUM_SUB: 7;----------------------------
2022-11-27 22:07:29 Epoch [20000/30000] Loss:0.000050 Loss_1:0.000046 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.027538s (6.36min in total, 3.18min remains)
2022-11-27 22:07:48 NUM_SUB: 7;----------------------------
2022-11-27 22:07:48 Epoch [21000/30000] Loss:0.000049 Loss_1:0.000045 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.395288s (6.68min in total, 2.86min remains)
2022-11-27 22:08:08 NUM_SUB: 7;----------------------------
2022-11-27 22:08:08 Epoch [22000/30000] Loss:0.000047 Loss_1:0.000045 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:19.055145s (7.00min in total, 2.55min remains)
2022-11-27 22:08:26 NUM_SUB: 7;----------------------------
2022-11-27 22:08:26 Epoch [23000/30000] Loss:0.000047 Loss_1:0.000045 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:18.780678s (7.31min in total, 2.23min remains)
2022-11-27 22:08:46 NUM_SUB: 7;----------------------------
2022-11-27 22:08:46 Epoch [24000/30000] Loss:0.000046 Loss_1:0.000044 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.208738s (7.64min in total, 1.91min remains)
2022-11-27 22:09:04 NUM_SUB: 7;----------------------------
2022-11-27 22:09:04 Epoch [25000/30000] Loss:0.000046 Loss_1:0.000044 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.818899s (7.95min in total, 1.59min remains)
2022-11-27 22:09:23 NUM_SUB: 7;----------------------------
2022-11-27 22:09:23 Epoch [26000/30000] Loss:0.000046 Loss_1:0.000044 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.787300s (8.26min in total, 1.27min remains)
2022-11-27 22:09:42 NUM_SUB: 7;----------------------------
2022-11-27 22:09:42 Epoch [27000/30000] Loss:0.000047 Loss_1:0.000046 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.663366s (8.57min in total, 0.95min remains)
2022-11-27 22:10:01 NUM_SUB: 7;----------------------------
2022-11-27 22:10:01 Epoch [28000/30000] Loss:0.000045 Loss_1:0.000044 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:18.896740s (8.89min in total, 0.63min remains)
2022-11-27 22:10:19 NUM_SUB: 7;----------------------------
2022-11-27 22:10:19 Epoch [29000/30000] Loss:0.000045 Loss_1:0.000044 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.708315s (9.20min in total, 0.32min remains)
2022-11-27 22:10:38 NUM_SUB: 7;----------------------------
2022-11-27 22:10:38 Epoch [30000/30000] Loss:0.000045 Loss_1:0.000044 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.883187s (9.51min in total, 0.00min remains)
2022-11-27 22:10:38 Testing & drawing...
2022-11-27 22:10:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:10:40 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=7/
2022-11-27 22:10:40 [Loss]
2022-11-27 22:10:40 NUM_SUB: 7; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:10:40 NUM_SUB: 7; Personalized parameter estimation: Parameter containing:
tensor([1.4241e-01, 2.3840e-01, 2.4635e-02, 1.3769e-38, 3.0742e-01, 1.2092e-02,
        1.5661e+00, 8.9644e-01, 4.5563e-01, 1.2947e-02, 3.6677e-02, 1.4059e-02,
        5.2511e-01, 1.6886e-01, 1.7757e-02, 1.0662e+00, 6.9767e-01, 8.0001e-01,
        1.1683e-02, 3.7570e+00, 6.8161e-01, 2.2060e-02, 3.6114e+00, 8.7416e-01,
        1.9958e-02, 4.2181e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 22:10:40 NUM_SUB: 7------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:10:40 Testing & drawing...
2022-11-27 22:10:40 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:10:42 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=7/
2022-11-27 22:10:42 [Loss]
2022-11-27 22:10:42 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:10:42 General parameter estimation: Parameter containing:
tensor([1.4241e-01, 2.3840e-01, 2.4635e-02, 1.3769e-38, 3.0742e-01, 1.2092e-02,
        1.5661e+00, 8.9644e-01, 4.5563e-01, 1.2947e-02, 3.6677e-02, 1.4059e-02,
        5.2511e-01, 1.6886e-01, 1.7757e-02, 1.0662e+00, 6.9767e-01, 8.0001e-01,
        1.1683e-02, 3.7570e+00, 6.8161e-01, 2.2060e-02, 3.6114e+00, 8.7416e-01,
        1.9958e-02, 4.2181e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 22:10:42 A: prod, degr, TonA, NonA
2022-11-27 22:10:42 [0.42245126 0.4982799  0.07307971 0.00618911]
2022-11-27 22:10:42 T: prod, degr, AonT, NonT
2022-11-27 22:10:42 [0.24476103 0.48803952 0.16593549 0.10126398]
2022-11-27 22:10:42 N: AonN, TonN, ATonN
2022-11-27 22:10:42 [0.01791293 0.93492246 0.04716463]
2022-11-27 22:10:42 using cpu
2022-11-27 22:10:42 epoch = 30000
2022-11-27 22:10:42 epoch_step = 1000
2022-11-27 22:10:42 model_name = SimpleNetworkAD
2022-11-27 22:10:42 now_string = 2022-11-27-19-40-13
2022-11-27 22:10:42 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:10:42 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:10:42 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:10:42 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:10:42 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:10:42 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:11:01 NUM_SUB: 8;----------------------------
2022-11-27 22:11:01 Epoch [01000/30000] Loss:0.039538 Loss_1:0.034399 Loss_2:0.001415 Loss_3:0.000000 Lr:0.000909 Time:19.023471s (0.32min in total, 9.19min remains)
2022-11-27 22:11:20 NUM_SUB: 8;----------------------------
2022-11-27 22:11:20 Epoch [02000/30000] Loss:0.032264 Loss_1:0.031516 Loss_2:0.000364 Loss_3:0.000000 Lr:0.000833 Time:19.387348s (0.64min in total, 8.96min remains)
2022-11-27 22:11:40 NUM_SUB: 8;----------------------------
2022-11-27 22:11:40 Epoch [03000/30000] Loss:0.027514 Loss_1:0.027370 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000769 Time:20.073459s (0.97min in total, 8.77min remains)
2022-11-27 22:11:59 NUM_SUB: 8;----------------------------
2022-11-27 22:11:59 Epoch [04000/30000] Loss:0.022324 Loss_1:0.022219 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000714 Time:19.113266s (1.29min in total, 8.41min remains)
2022-11-27 22:12:18 NUM_SUB: 8;----------------------------
2022-11-27 22:12:18 Epoch [05000/30000] Loss:0.016684 Loss_1:0.016594 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000667 Time:18.720817s (1.61min in total, 8.03min remains)
2022-11-27 22:12:37 NUM_SUB: 8;----------------------------
2022-11-27 22:12:37 Epoch [06000/30000] Loss:0.011550 Loss_1:0.011481 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000625 Time:18.798950s (1.92min in total, 7.67min remains)
2022-11-27 22:12:56 NUM_SUB: 8;----------------------------
2022-11-27 22:12:56 Epoch [07000/30000] Loss:0.008519 Loss_1:0.008464 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000588 Time:18.691587s (2.23min in total, 7.33min remains)
2022-11-27 22:13:14 NUM_SUB: 8;----------------------------
2022-11-27 22:13:14 Epoch [08000/30000] Loss:0.007260 Loss_1:0.007207 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000556 Time:18.527235s (2.54min in total, 6.98min remains)
2022-11-27 22:13:33 NUM_SUB: 8;----------------------------
2022-11-27 22:13:33 Epoch [09000/30000] Loss:0.006318 Loss_1:0.006259 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000526 Time:19.201352s (2.86min in total, 6.67min remains)
2022-11-27 22:13:52 NUM_SUB: 8;----------------------------
2022-11-27 22:13:52 Epoch [10000/30000] Loss:0.005342 Loss_1:0.005277 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000500 Time:18.585788s (3.17min in total, 6.34min remains)
2022-11-27 22:14:11 NUM_SUB: 8;----------------------------
2022-11-27 22:14:11 Epoch [11000/30000] Loss:0.004561 Loss_1:0.004499 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000476 Time:19.218839s (3.49min in total, 6.03min remains)
2022-11-27 22:14:31 NUM_SUB: 8;----------------------------
2022-11-27 22:14:31 Epoch [12000/30000] Loss:0.004106 Loss_1:0.004072 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000455 Time:19.660720s (3.82min in total, 5.73min remains)
2022-11-27 22:14:49 NUM_SUB: 8;----------------------------
2022-11-27 22:14:49 Epoch [13000/30000] Loss:0.003826 Loss_1:0.003804 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000435 Time:18.616576s (4.13min in total, 5.40min remains)
2022-11-27 22:15:08 NUM_SUB: 8;----------------------------
2022-11-27 22:15:08 Epoch [14000/30000] Loss:0.003763 Loss_1:0.003747 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:18.759622s (4.44min in total, 5.07min remains)
2022-11-27 22:15:27 NUM_SUB: 8;----------------------------
2022-11-27 22:15:27 Epoch [15000/30000] Loss:0.003744 Loss_1:0.003733 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000400 Time:18.898877s (4.75min in total, 4.75min remains)
2022-11-27 22:15:46 NUM_SUB: 8;----------------------------
2022-11-27 22:15:46 Epoch [16000/30000] Loss:0.003742 Loss_1:0.003734 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:18.660244s (5.07min in total, 4.43min remains)
2022-11-27 22:16:05 NUM_SUB: 8;----------------------------
2022-11-27 22:16:05 Epoch [17000/30000] Loss:0.003738 Loss_1:0.003731 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000370 Time:19.207930s (5.39min in total, 4.12min remains)
2022-11-27 22:16:24 NUM_SUB: 8;----------------------------
2022-11-27 22:16:24 Epoch [18000/30000] Loss:0.003735 Loss_1:0.003730 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:19.278115s (5.71min in total, 3.80min remains)
2022-11-27 22:16:43 NUM_SUB: 8;----------------------------
2022-11-27 22:16:43 Epoch [19000/30000] Loss:0.003732 Loss_1:0.003728 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000345 Time:18.899523s (6.02min in total, 3.49min remains)
2022-11-27 22:17:02 NUM_SUB: 8;----------------------------
2022-11-27 22:17:02 Epoch [20000/30000] Loss:0.003730 Loss_1:0.003727 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:18.912288s (6.34min in total, 3.17min remains)
2022-11-27 22:17:21 NUM_SUB: 8;----------------------------
2022-11-27 22:17:21 Epoch [21000/30000] Loss:0.003728 Loss_1:0.003725 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:18.938427s (6.65min in total, 2.85min remains)
2022-11-27 22:17:40 NUM_SUB: 8;----------------------------
2022-11-27 22:17:40 Epoch [22000/30000] Loss:0.003727 Loss_1:0.003724 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:18.966410s (6.97min in total, 2.53min remains)
2022-11-27 22:17:59 NUM_SUB: 8;----------------------------
2022-11-27 22:17:59 Epoch [23000/30000] Loss:0.003726 Loss_1:0.003724 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:18.882939s (7.28min in total, 2.22min remains)
2022-11-27 22:18:18 NUM_SUB: 8;----------------------------
2022-11-27 22:18:18 Epoch [24000/30000] Loss:0.003725 Loss_1:0.003723 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:18.645083s (7.59min in total, 1.90min remains)
2022-11-27 22:18:37 NUM_SUB: 8;----------------------------
2022-11-27 22:18:37 Epoch [25000/30000] Loss:0.003724 Loss_1:0.003723 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.274941s (7.92min in total, 1.58min remains)
2022-11-27 22:18:56 NUM_SUB: 8;----------------------------
2022-11-27 22:18:56 Epoch [26000/30000] Loss:0.003723 Loss_1:0.003722 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.011083s (8.23min in total, 1.27min remains)
2022-11-27 22:19:15 NUM_SUB: 8;----------------------------
2022-11-27 22:19:15 Epoch [27000/30000] Loss:0.003731 Loss_1:0.003729 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.247628s (8.55min in total, 0.95min remains)
2022-11-27 22:19:34 NUM_SUB: 8;----------------------------
2022-11-27 22:19:34 Epoch [28000/30000] Loss:0.003721 Loss_1:0.003720 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.066854s (8.87min in total, 0.63min remains)
2022-11-27 22:19:53 NUM_SUB: 8;----------------------------
2022-11-27 22:19:53 Epoch [29000/30000] Loss:0.003732 Loss_1:0.003731 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.839274s (9.19min in total, 0.32min remains)
2022-11-27 22:20:12 NUM_SUB: 8;----------------------------
2022-11-27 22:20:12 Epoch [30000/30000] Loss:0.003709 Loss_1:0.003708 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.241609s (9.51min in total, 0.00min remains)
2022-11-27 22:20:12 Testing & drawing...
2022-11-27 22:20:12 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:20:14 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=8/
2022-11-27 22:20:14 [Loss]
2022-11-27 22:20:14 NUM_SUB: 8; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:20:14 NUM_SUB: 8; Personalized parameter estimation: Parameter containing:
tensor([0.2864, 0.9643, 0.0093, 0.0047, 0.3074, 0.0119, 0.8109, 0.8964, 0.4556,
        0.0141, 0.0319, 0.0127, 0.8459, 0.1689, 0.0176, 2.3989, 0.6977, 0.8000,
        0.0121, 3.4135, 0.6816, 0.0193, 3.6444, 0.8742, 0.0210, 4.3552, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:20:14 NUM_SUB: 8------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:20:14 Testing & drawing...
2022-11-27 22:20:14 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:20:16 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=8/
2022-11-27 22:20:16 [Loss]
2022-11-27 22:20:16 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:20:16 General parameter estimation: Parameter containing:
tensor([0.2864, 0.9643, 0.0093, 0.0047, 0.3074, 0.0119, 0.8109, 0.8964, 0.4556,
        0.0141, 0.0319, 0.0127, 0.8459, 0.1689, 0.0176, 2.3989, 0.6977, 0.8000,
        0.0121, 3.4135, 0.6816, 0.0193, 3.6444, 0.8742, 0.0210, 4.3552, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:20:16 A: prod, degr, TonA, NonA
2022-11-27 22:20:16 [0.47957012 0.5000353  0.01550099 0.0048936 ]
2022-11-27 22:20:16 T: prod, degr, AonT, NonT
2022-11-27 22:20:16 [0.5008565  0.35096392 0.1258432  0.0223363 ]
2022-11-27 22:20:16 N: AonN, TonN, ATonN
2022-11-27 22:20:16 [0.00552815 0.97149885 0.02297299]
2022-11-27 22:20:16 using cpu
2022-11-27 22:20:16 epoch = 30000
2022-11-27 22:20:16 epoch_step = 1000
2022-11-27 22:20:16 model_name = SimpleNetworkAD
2022-11-27 22:20:16 now_string = 2022-11-27-19-40-13
2022-11-27 22:20:16 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:20:16 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:20:16 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:20:16 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:20:16 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:20:16 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:20:35 NUM_SUB: 9;----------------------------
2022-11-27 22:20:35 Epoch [01000/30000] Loss:0.076799 Loss_1:0.071495 Loss_2:0.001537 Loss_3:0.000000 Lr:0.000909 Time:19.170578s (0.32min in total, 9.27min remains)
2022-11-27 22:20:54 NUM_SUB: 9;----------------------------
2022-11-27 22:20:54 Epoch [02000/30000] Loss:0.067390 Loss_1:0.066571 Loss_2:0.000420 Loss_3:0.000000 Lr:0.000833 Time:19.284675s (0.64min in total, 8.97min remains)
2022-11-27 22:21:14 NUM_SUB: 9;----------------------------
2022-11-27 22:21:14 Epoch [03000/30000] Loss:0.059313 Loss_1:0.059056 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000769 Time:19.731979s (0.97min in total, 8.73min remains)
2022-11-27 22:21:33 NUM_SUB: 9;----------------------------
2022-11-27 22:21:33 Epoch [04000/30000] Loss:0.049544 Loss_1:0.049321 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000714 Time:19.439180s (1.29min in total, 8.41min remains)
2022-11-27 22:21:52 NUM_SUB: 9;----------------------------
2022-11-27 22:21:52 Epoch [05000/30000] Loss:0.036603 Loss_1:0.036406 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000667 Time:18.866002s (1.61min in total, 8.04min remains)
2022-11-27 22:22:11 NUM_SUB: 9;----------------------------
2022-11-27 22:22:11 Epoch [06000/30000] Loss:0.022453 Loss_1:0.022298 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000625 Time:19.041210s (1.93min in total, 7.70min remains)
2022-11-27 22:22:30 NUM_SUB: 9;----------------------------
2022-11-27 22:22:30 Epoch [07000/30000] Loss:0.013224 Loss_1:0.013130 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000588 Time:19.014099s (2.24min in total, 7.37min remains)
2022-11-27 22:22:49 NUM_SUB: 9;----------------------------
2022-11-27 22:22:49 Epoch [08000/30000] Loss:0.010061 Loss_1:0.009992 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000556 Time:19.064127s (2.56min in total, 7.04min remains)
2022-11-27 22:23:08 NUM_SUB: 9;----------------------------
2022-11-27 22:23:08 Epoch [09000/30000] Loss:0.009187 Loss_1:0.009119 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000526 Time:19.069523s (2.88min in total, 6.72min remains)
2022-11-27 22:23:28 NUM_SUB: 9;----------------------------
2022-11-27 22:23:28 Epoch [10000/30000] Loss:0.008770 Loss_1:0.008674 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000500 Time:19.204962s (3.20min in total, 6.40min remains)
2022-11-27 22:23:47 NUM_SUB: 9;----------------------------
2022-11-27 22:23:47 Epoch [11000/30000] Loss:0.008345 Loss_1:0.008280 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000476 Time:19.068865s (3.52min in total, 6.07min remains)
2022-11-27 22:24:06 NUM_SUB: 9;----------------------------
2022-11-27 22:24:06 Epoch [12000/30000] Loss:0.007870 Loss_1:0.007842 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000455 Time:19.105908s (3.83min in total, 5.75min remains)
2022-11-27 22:24:25 NUM_SUB: 9;----------------------------
2022-11-27 22:24:25 Epoch [13000/30000] Loss:0.007560 Loss_1:0.007537 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000435 Time:18.997671s (4.15min in total, 5.43min remains)
2022-11-27 22:24:44 NUM_SUB: 9;----------------------------
2022-11-27 22:24:44 Epoch [14000/30000] Loss:0.007457 Loss_1:0.007434 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000417 Time:18.872516s (4.47min in total, 5.10min remains)
2022-11-27 22:25:03 NUM_SUB: 9;----------------------------
2022-11-27 22:25:03 Epoch [15000/30000] Loss:0.007422 Loss_1:0.007411 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000400 Time:18.874083s (4.78min in total, 4.78min remains)
2022-11-27 22:25:21 NUM_SUB: 9;----------------------------
2022-11-27 22:25:21 Epoch [16000/30000] Loss:0.007376 Loss_1:0.007363 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:18.913786s (5.10min in total, 4.46min remains)
2022-11-27 22:25:40 NUM_SUB: 9;----------------------------
2022-11-27 22:25:40 Epoch [17000/30000] Loss:0.007303 Loss_1:0.007294 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000370 Time:18.993232s (5.41min in total, 4.14min remains)
2022-11-27 22:25:59 NUM_SUB: 9;----------------------------
2022-11-27 22:25:59 Epoch [18000/30000] Loss:0.007158 Loss_1:0.007153 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000357 Time:19.022782s (5.73min in total, 3.82min remains)
2022-11-27 22:26:19 NUM_SUB: 9;----------------------------
2022-11-27 22:26:19 Epoch [19000/30000] Loss:0.006916 Loss_1:0.006912 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000345 Time:19.068280s (6.05min in total, 3.50min remains)
2022-11-27 22:26:38 NUM_SUB: 9;----------------------------
2022-11-27 22:26:38 Epoch [20000/30000] Loss:0.006850 Loss_1:0.006846 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.177307s (6.37min in total, 3.18min remains)
2022-11-27 22:26:57 NUM_SUB: 9;----------------------------
2022-11-27 22:26:57 Epoch [21000/30000] Loss:0.006843 Loss_1:0.006839 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:18.859481s (6.68min in total, 2.86min remains)
2022-11-27 22:27:16 NUM_SUB: 9;----------------------------
2022-11-27 22:27:16 Epoch [22000/30000] Loss:0.006841 Loss_1:0.006836 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.070366s (7.00min in total, 2.55min remains)
2022-11-27 22:27:35 NUM_SUB: 9;----------------------------
2022-11-27 22:27:35 Epoch [23000/30000] Loss:0.006840 Loss_1:0.006832 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.074557s (7.32min in total, 2.23min remains)
2022-11-27 22:27:54 NUM_SUB: 9;----------------------------
2022-11-27 22:27:54 Epoch [24000/30000] Loss:0.006837 Loss_1:0.006833 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.338105s (7.64min in total, 1.91min remains)
2022-11-27 22:28:13 NUM_SUB: 9;----------------------------
2022-11-27 22:28:13 Epoch [25000/30000] Loss:0.006837 Loss_1:0.006828 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.297913s (7.96min in total, 1.59min remains)
2022-11-27 22:28:32 NUM_SUB: 9;----------------------------
2022-11-27 22:28:32 Epoch [26000/30000] Loss:0.006835 Loss_1:0.006828 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.075843s (8.28min in total, 1.27min remains)
2022-11-27 22:28:52 NUM_SUB: 9;----------------------------
2022-11-27 22:28:52 Epoch [27000/30000] Loss:0.006834 Loss_1:0.006830 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.117065s (8.60min in total, 0.96min remains)
2022-11-27 22:29:11 NUM_SUB: 9;----------------------------
2022-11-27 22:29:11 Epoch [28000/30000] Loss:0.006833 Loss_1:0.006830 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.278759s (8.92min in total, 0.64min remains)
2022-11-27 22:29:30 NUM_SUB: 9;----------------------------
2022-11-27 22:29:30 Epoch [29000/30000] Loss:0.006832 Loss_1:0.006826 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.222370s (9.24min in total, 0.32min remains)
2022-11-27 22:29:49 NUM_SUB: 9;----------------------------
2022-11-27 22:29:49 Epoch [30000/30000] Loss:0.006883 Loss_1:0.006878 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.034707s (9.56min in total, 0.00min remains)
2022-11-27 22:29:49 Testing & drawing...
2022-11-27 22:29:49 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:29:51 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=9/
2022-11-27 22:29:51 [Loss]
2022-11-27 22:29:51 NUM_SUB: 9; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:29:51 NUM_SUB: 9; Personalized parameter estimation: Parameter containing:
tensor([0.3457, 0.9471, 0.0099, 0.0062, 0.3074, 0.0129, 2.2118, 0.8964, 0.4556,
        0.0144, 0.1591, 0.1248, 0.4984, 0.1689, 0.0176, 1.3014, 0.6977, 0.8000,
        0.0123, 2.8830, 0.6816, 0.0228, 1.4294, 0.8742, 0.0215, 2.8698, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:29:51 NUM_SUB: 9------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:29:51 Testing & drawing...
2022-11-27 22:29:51 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:29:52 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=9/
2022-11-27 22:29:52 [Loss]
2022-11-27 22:29:52 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:29:52 General parameter estimation: Parameter containing:
tensor([0.3457, 0.9471, 0.0099, 0.0062, 0.3074, 0.0129, 2.2118, 0.8964, 0.4556,
        0.0144, 0.1591, 0.1248, 0.4984, 0.1689, 0.0176, 1.3014, 0.6977, 0.8000,
        0.0123, 2.8830, 0.6816, 0.0228, 1.4294, 0.8742, 0.0215, 2.8698, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:29:52 A: prod, degr, TonA, NonA
2022-11-27 22:29:52 [0.48385677 0.50001186 0.013878   0.00225341]
2022-11-27 22:29:52 T: prod, degr, AonT, NonT
2022-11-27 22:29:52 [0.10436092 0.43556145 0.42526758 0.03481002]
2022-11-27 22:29:52 N: AonN, TonN, ATonN
2022-11-27 22:29:52 [0.00971193 0.9452841  0.045004  ]
2022-11-27 22:29:53 using cpu
2022-11-27 22:29:53 epoch = 30000
2022-11-27 22:29:53 epoch_step = 1000
2022-11-27 22:29:53 model_name = SimpleNetworkAD
2022-11-27 22:29:53 now_string = 2022-11-27-19-40-13
2022-11-27 22:29:53 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:29:53 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:29:53 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:29:53 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:29:53 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:29:53 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:30:11 NUM_SUB: 10;----------------------------
2022-11-27 22:30:11 Epoch [01000/30000] Loss:0.064139 Loss_1:0.058559 Loss_2:0.001767 Loss_3:0.000000 Lr:0.000909 Time:18.849403s (0.31min in total, 9.11min remains)
2022-11-27 22:30:30 NUM_SUB: 10;----------------------------
2022-11-27 22:30:30 Epoch [02000/30000] Loss:0.056437 Loss_1:0.055471 Loss_2:0.000558 Loss_3:0.000000 Lr:0.000833 Time:18.826960s (0.63min in total, 8.79min remains)
2022-11-27 22:30:49 NUM_SUB: 10;----------------------------
2022-11-27 22:30:49 Epoch [03000/30000] Loss:0.051231 Loss_1:0.050883 Loss_2:0.000177 Loss_3:0.000000 Lr:0.000769 Time:18.687535s (0.94min in total, 8.45min remains)
2022-11-27 22:31:08 NUM_SUB: 10;----------------------------
2022-11-27 22:31:08 Epoch [04000/30000] Loss:0.045697 Loss_1:0.045347 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000714 Time:18.723907s (1.25min in total, 8.13min remains)
2022-11-27 22:31:27 NUM_SUB: 10;----------------------------
2022-11-27 22:31:27 Epoch [05000/30000] Loss:0.037909 Loss_1:0.037589 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000667 Time:18.927889s (1.57min in total, 7.83min remains)
2022-11-27 22:31:45 NUM_SUB: 10;----------------------------
2022-11-27 22:31:45 Epoch [06000/30000] Loss:0.027559 Loss_1:0.027277 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000625 Time:18.776962s (1.88min in total, 7.52min remains)
2022-11-27 22:32:04 NUM_SUB: 10;----------------------------
2022-11-27 22:32:04 Epoch [07000/30000] Loss:0.016121 Loss_1:0.015890 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000588 Time:18.518855s (2.19min in total, 7.19min remains)
2022-11-27 22:32:23 NUM_SUB: 10;----------------------------
2022-11-27 22:32:23 Epoch [08000/30000] Loss:0.007742 Loss_1:0.007552 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000556 Time:18.902129s (2.50min in total, 6.89min remains)
2022-11-27 22:32:41 NUM_SUB: 10;----------------------------
2022-11-27 22:32:41 Epoch [09000/30000] Loss:0.004154 Loss_1:0.003981 Loss_2:0.000166 Loss_3:0.000000 Lr:0.000526 Time:18.662666s (2.81min in total, 6.57min remains)
2022-11-27 22:33:00 NUM_SUB: 10;----------------------------
2022-11-27 22:33:00 Epoch [10000/30000] Loss:0.003139 Loss_1:0.002942 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000500 Time:18.599638s (3.12min in total, 6.25min remains)
2022-11-27 22:33:20 NUM_SUB: 10;----------------------------
2022-11-27 22:33:20 Epoch [11000/30000] Loss:0.002317 Loss_1:0.002197 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000476 Time:19.579215s (3.45min in total, 5.96min remains)
2022-11-27 22:33:39 NUM_SUB: 10;----------------------------
2022-11-27 22:33:39 Epoch [12000/30000] Loss:0.001656 Loss_1:0.001587 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000455 Time:19.601587s (3.78min in total, 5.67min remains)
2022-11-27 22:33:58 NUM_SUB: 10;----------------------------
2022-11-27 22:33:58 Epoch [13000/30000] Loss:0.001364 Loss_1:0.001313 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000435 Time:19.065344s (4.10min in total, 5.36min remains)
2022-11-27 22:34:17 NUM_SUB: 10;----------------------------
2022-11-27 22:34:17 Epoch [14000/30000] Loss:0.001285 Loss_1:0.001248 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000417 Time:19.145529s (4.41min in total, 5.05min remains)
2022-11-27 22:34:36 NUM_SUB: 10;----------------------------
2022-11-27 22:34:36 Epoch [15000/30000] Loss:0.001219 Loss_1:0.001195 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000400 Time:18.710973s (4.73min in total, 4.73min remains)
2022-11-27 22:34:55 NUM_SUB: 10;----------------------------
2022-11-27 22:34:55 Epoch [16000/30000] Loss:0.001155 Loss_1:0.001136 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:18.650809s (5.04min in total, 4.41min remains)
2022-11-27 22:35:14 NUM_SUB: 10;----------------------------
2022-11-27 22:35:14 Epoch [17000/30000] Loss:0.001105 Loss_1:0.001090 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:19.113849s (5.36min in total, 4.10min remains)
2022-11-27 22:35:34 NUM_SUB: 10;----------------------------
2022-11-27 22:35:34 Epoch [18000/30000] Loss:0.001089 Loss_1:0.001077 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:19.872288s (5.69min in total, 3.79min remains)
2022-11-27 22:35:52 NUM_SUB: 10;----------------------------
2022-11-27 22:35:52 Epoch [19000/30000] Loss:0.001084 Loss_1:0.001075 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:18.631596s (6.00min in total, 3.47min remains)
2022-11-27 22:36:11 NUM_SUB: 10;----------------------------
2022-11-27 22:36:11 Epoch [20000/30000] Loss:0.001082 Loss_1:0.001074 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:18.650259s (6.31min in total, 3.15min remains)
2022-11-27 22:36:30 NUM_SUB: 10;----------------------------
2022-11-27 22:36:30 Epoch [21000/30000] Loss:0.001080 Loss_1:0.001074 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:18.876970s (6.62min in total, 2.84min remains)
2022-11-27 22:36:49 NUM_SUB: 10;----------------------------
2022-11-27 22:36:49 Epoch [22000/30000] Loss:0.001079 Loss_1:0.001074 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:18.678834s (6.93min in total, 2.52min remains)
2022-11-27 22:37:07 NUM_SUB: 10;----------------------------
2022-11-27 22:37:07 Epoch [23000/30000] Loss:0.001080 Loss_1:0.001076 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:18.593189s (7.24min in total, 2.20min remains)
2022-11-27 22:37:27 NUM_SUB: 10;----------------------------
2022-11-27 22:37:27 Epoch [24000/30000] Loss:0.001077 Loss_1:0.001073 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:19.568515s (7.57min in total, 1.89min remains)
2022-11-27 22:37:47 NUM_SUB: 10;----------------------------
2022-11-27 22:37:47 Epoch [25000/30000] Loss:0.001077 Loss_1:0.001073 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.885743s (7.90min in total, 1.58min remains)
2022-11-27 22:38:05 NUM_SUB: 10;----------------------------
2022-11-27 22:38:05 Epoch [26000/30000] Loss:0.001077 Loss_1:0.001072 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:18.554462s (8.21min in total, 1.26min remains)
2022-11-27 22:38:24 NUM_SUB: 10;----------------------------
2022-11-27 22:38:24 Epoch [27000/30000] Loss:0.001075 Loss_1:0.001073 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.042560s (8.53min in total, 0.95min remains)
2022-11-27 22:38:43 NUM_SUB: 10;----------------------------
2022-11-27 22:38:43 Epoch [28000/30000] Loss:0.001075 Loss_1:0.001072 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.898523s (8.84min in total, 0.63min remains)
2022-11-27 22:39:02 NUM_SUB: 10;----------------------------
2022-11-27 22:39:02 Epoch [29000/30000] Loss:0.001077 Loss_1:0.001074 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.595020s (9.15min in total, 0.32min remains)
2022-11-27 22:39:21 NUM_SUB: 10;----------------------------
2022-11-27 22:39:21 Epoch [30000/30000] Loss:0.001078 Loss_1:0.001076 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.847632s (9.47min in total, 0.00min remains)
2022-11-27 22:39:21 Testing & drawing...
2022-11-27 22:39:21 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:39:22 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=10/
2022-11-27 22:39:22 [Loss]
2022-11-27 22:39:22 NUM_SUB: 10; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:39:22 NUM_SUB: 10; Personalized parameter estimation: Parameter containing:
tensor([0.0149, 0.0369, 0.0267, 1.0283, 0.3074, 0.0124, 2.1659, 0.8964, 0.4556,
        0.0139, 0.0274, 0.0141, 0.9719, 0.1689, 0.0170, 2.9558, 0.6977, 0.8000,
        0.0114, 4.6289, 0.6816, 0.0216, 4.0478, 0.8742, 0.0194, 4.8988, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:39:22 NUM_SUB: 10------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:39:22 Testing & drawing...
2022-11-27 22:39:22 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:39:24 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=10/
2022-11-27 22:39:24 [Loss]
2022-11-27 22:39:24 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:39:24 General parameter estimation: Parameter containing:
tensor([0.0149, 0.0369, 0.0267, 1.0283, 0.3074, 0.0124, 2.1659, 0.8964, 0.4556,
        0.0139, 0.0274, 0.0141, 0.9719, 0.1689, 0.0170, 2.9558, 0.6977, 0.8000,
        0.0114, 4.6289, 0.6816, 0.0216, 4.0478, 0.8742, 0.0194, 4.8988, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:39:24 A: prod, degr, TonA, NonA
2022-11-27 22:39:24 [0.3363505  0.48928574 0.15432829 0.02003551]
2022-11-27 22:39:24 T: prod, degr, AonT, NonT
2022-11-27 22:39:24 [0.4007449  0.46641013 0.11325253 0.01959245]
2022-11-27 22:39:24 N: AonN, TonN, ATonN
2022-11-27 22:39:24 [0.00900894 0.96321654 0.02777453]
2022-11-27 22:39:24 using cpu
2022-11-27 22:39:24 epoch = 30000
2022-11-27 22:39:24 epoch_step = 1000
2022-11-27 22:39:24 model_name = SimpleNetworkAD
2022-11-27 22:39:24 now_string = 2022-11-27-19-40-13
2022-11-27 22:39:24 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:39:24 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:39:24 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:39:24 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:39:24 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:39:24 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:39:43 NUM_SUB: 11;----------------------------
2022-11-27 22:39:43 Epoch [01000/30000] Loss:0.015659 Loss_1:0.009597 Loss_2:0.002246 Loss_3:0.000000 Lr:0.000909 Time:18.775469s (0.31min in total, 9.07min remains)
2022-11-27 22:40:02 NUM_SUB: 11;----------------------------
2022-11-27 22:40:02 Epoch [02000/30000] Loss:0.010540 Loss_1:0.009297 Loss_2:0.000821 Loss_3:0.000000 Lr:0.000833 Time:18.716575s (0.62min in total, 8.75min remains)
2022-11-27 22:40:21 NUM_SUB: 11;----------------------------
2022-11-27 22:40:21 Epoch [03000/30000] Loss:0.009042 Loss_1:0.008631 Loss_2:0.000346 Loss_3:0.000000 Lr:0.000769 Time:18.973644s (0.94min in total, 8.47min remains)
2022-11-27 22:40:40 NUM_SUB: 11;----------------------------
2022-11-27 22:40:40 Epoch [04000/30000] Loss:0.007012 Loss_1:0.006565 Loss_2:0.000422 Loss_3:0.000000 Lr:0.000714 Time:19.388974s (1.26min in total, 8.22min remains)
2022-11-27 22:40:59 NUM_SUB: 11;----------------------------
2022-11-27 22:40:59 Epoch [05000/30000] Loss:0.005347 Loss_1:0.005090 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000667 Time:18.951767s (1.58min in total, 7.90min remains)
2022-11-27 22:41:18 NUM_SUB: 11;----------------------------
2022-11-27 22:41:18 Epoch [06000/30000] Loss:0.004307 Loss_1:0.004116 Loss_2:0.000160 Loss_3:0.000000 Lr:0.000625 Time:19.419523s (1.90min in total, 7.62min remains)
2022-11-27 22:41:38 NUM_SUB: 11;----------------------------
2022-11-27 22:41:38 Epoch [07000/30000] Loss:0.003293 Loss_1:0.003132 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000588 Time:19.477576s (2.23min in total, 7.32min remains)
2022-11-27 22:41:57 NUM_SUB: 11;----------------------------
2022-11-27 22:41:57 Epoch [08000/30000] Loss:0.002255 Loss_1:0.002127 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000556 Time:19.217906s (2.55min in total, 7.01min remains)
2022-11-27 22:42:16 NUM_SUB: 11;----------------------------
2022-11-27 22:42:16 Epoch [09000/30000] Loss:0.001446 Loss_1:0.001339 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000526 Time:19.146526s (2.87min in total, 6.69min remains)
2022-11-27 22:42:36 NUM_SUB: 11;----------------------------
2022-11-27 22:42:36 Epoch [10000/30000] Loss:0.001019 Loss_1:0.000930 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000500 Time:19.351457s (3.19min in total, 6.38min remains)
2022-11-27 22:42:55 NUM_SUB: 11;----------------------------
2022-11-27 22:42:55 Epoch [11000/30000] Loss:0.000866 Loss_1:0.000793 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000476 Time:19.174715s (3.51min in total, 6.06min remains)
2022-11-27 22:43:14 NUM_SUB: 11;----------------------------
2022-11-27 22:43:14 Epoch [12000/30000] Loss:0.000764 Loss_1:0.000708 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000455 Time:18.884818s (3.82min in total, 5.74min remains)
2022-11-27 22:43:33 NUM_SUB: 11;----------------------------
2022-11-27 22:43:33 Epoch [13000/30000] Loss:0.000648 Loss_1:0.000610 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000435 Time:19.094829s (4.14min in total, 5.42min remains)
2022-11-27 22:43:52 NUM_SUB: 11;----------------------------
2022-11-27 22:43:52 Epoch [14000/30000] Loss:0.000549 Loss_1:0.000521 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:18.930476s (4.46min in total, 5.10min remains)
2022-11-27 22:44:10 NUM_SUB: 11;----------------------------
2022-11-27 22:44:10 Epoch [15000/30000] Loss:0.000464 Loss_1:0.000443 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000400 Time:18.813648s (4.77min in total, 4.77min remains)
2022-11-27 22:44:30 NUM_SUB: 11;----------------------------
2022-11-27 22:44:30 Epoch [16000/30000] Loss:0.000380 Loss_1:0.000362 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:19.238064s (5.09min in total, 4.46min remains)
2022-11-27 22:44:49 NUM_SUB: 11;----------------------------
2022-11-27 22:44:49 Epoch [17000/30000] Loss:0.000334 Loss_1:0.000319 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:18.897595s (5.41min in total, 4.14min remains)
2022-11-27 22:45:07 NUM_SUB: 11;----------------------------
2022-11-27 22:45:07 Epoch [18000/30000] Loss:0.000328 Loss_1:0.000315 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:18.844030s (5.72min in total, 3.81min remains)
2022-11-27 22:45:27 NUM_SUB: 11;----------------------------
2022-11-27 22:45:27 Epoch [19000/30000] Loss:0.000326 Loss_1:0.000315 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.232848s (6.04min in total, 3.50min remains)
2022-11-27 22:45:46 NUM_SUB: 11;----------------------------
2022-11-27 22:45:46 Epoch [20000/30000] Loss:0.000325 Loss_1:0.000315 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:19.381301s (6.37min in total, 3.18min remains)
2022-11-27 22:46:05 NUM_SUB: 11;----------------------------
2022-11-27 22:46:05 Epoch [21000/30000] Loss:0.000324 Loss_1:0.000315 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000323 Time:18.906897s (6.68min in total, 2.86min remains)
2022-11-27 22:46:24 NUM_SUB: 11;----------------------------
2022-11-27 22:46:24 Epoch [22000/30000] Loss:0.000325 Loss_1:0.000316 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:19.250488s (7.00min in total, 2.55min remains)
2022-11-27 22:46:43 NUM_SUB: 11;----------------------------
2022-11-27 22:46:43 Epoch [23000/30000] Loss:0.000323 Loss_1:0.000314 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000303 Time:19.091005s (7.32min in total, 2.23min remains)
2022-11-27 22:47:03 NUM_SUB: 11;----------------------------
2022-11-27 22:47:03 Epoch [24000/30000] Loss:0.000322 Loss_1:0.000314 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000294 Time:20.069642s (7.65min in total, 1.91min remains)
2022-11-27 22:47:23 NUM_SUB: 11;----------------------------
2022-11-27 22:47:23 Epoch [25000/30000] Loss:0.000322 Loss_1:0.000314 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000286 Time:19.411335s (7.98min in total, 1.60min remains)
2022-11-27 22:47:42 NUM_SUB: 11;----------------------------
2022-11-27 22:47:42 Epoch [26000/30000] Loss:0.000322 Loss_1:0.000314 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:19.065723s (8.30min in total, 1.28min remains)
2022-11-27 22:48:01 NUM_SUB: 11;----------------------------
2022-11-27 22:48:01 Epoch [27000/30000] Loss:0.000321 Loss_1:0.000314 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000270 Time:19.445856s (8.62min in total, 0.96min remains)
2022-11-27 22:48:20 NUM_SUB: 11;----------------------------
2022-11-27 22:48:20 Epoch [28000/30000] Loss:0.000321 Loss_1:0.000314 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000263 Time:19.121782s (8.94min in total, 0.64min remains)
2022-11-27 22:48:40 NUM_SUB: 11;----------------------------
2022-11-27 22:48:40 Epoch [29000/30000] Loss:0.000320 Loss_1:0.000314 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000256 Time:19.834134s (9.27min in total, 0.32min remains)
2022-11-27 22:49:01 NUM_SUB: 11;----------------------------
2022-11-27 22:49:01 Epoch [30000/30000] Loss:0.000320 Loss_1:0.000314 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:20.480097s (9.61min in total, 0.00min remains)
2022-11-27 22:49:01 Testing & drawing...
2022-11-27 22:49:01 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:49:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=11/
2022-11-27 22:49:02 [Loss]
2022-11-27 22:49:02 NUM_SUB: 11; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:49:02 NUM_SUB: 11; Personalized parameter estimation: Parameter containing:
tensor([0.0160, 0.0206, 0.0227, 2.5242, 0.3074, 0.0148, 2.8781, 0.8964, 0.4556,
        0.0136, 0.1505, 0.1248, 0.5314, 0.1689, 0.0177, 0.6564, 0.6977, 0.8000,
        0.0107, 4.8368, 0.6816, 0.0226, 3.6208, 0.8742, 0.0183, 4.8202, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:49:02 NUM_SUB: 11------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:49:02 Testing & drawing...
2022-11-27 22:49:02 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:49:04 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=11/
2022-11-27 22:49:04 [Loss]
2022-11-27 22:49:04 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:49:04 General parameter estimation: Parameter containing:
tensor([0.0160, 0.0206, 0.0227, 2.5242, 0.3074, 0.0148, 2.8781, 0.8964, 0.4556,
        0.0136, 0.1505, 0.1248, 0.5314, 0.1689, 0.0177, 0.6564, 0.6977, 0.8000,
        0.0107, 4.8368, 0.6816, 0.0226, 3.6208, 0.8742, 0.0183, 4.8202, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:49:04 A: prod, degr, TonA, NonA
2022-11-27 22:49:04 [0.51081645 0.46427628 0.02043562 0.00447166]
2022-11-27 22:49:04 T: prod, degr, AonT, NonT
2022-11-27 22:49:04 [0.07985906 0.61906093 0.28492504 0.01615492]
2022-11-27 22:49:04 N: AonN, TonN, ATonN
2022-11-27 22:49:04 [0.01164458 0.9614349  0.0269205 ]
2022-11-27 22:49:04 using cpu
2022-11-27 22:49:04 epoch = 30000
2022-11-27 22:49:04 epoch_step = 1000
2022-11-27 22:49:04 model_name = SimpleNetworkAD
2022-11-27 22:49:04 now_string = 2022-11-27-19-40-13
2022-11-27 22:49:04 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:49:04 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:49:04 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:49:04 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:49:04 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:49:04 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:49:24 NUM_SUB: 12;----------------------------
2022-11-27 22:49:24 Epoch [01000/30000] Loss:0.020181 Loss_1:0.014418 Loss_2:0.001989 Loss_3:0.000000 Lr:0.000909 Time:19.301251s (0.32min in total, 9.33min remains)
2022-11-27 22:49:42 NUM_SUB: 12;----------------------------
2022-11-27 22:49:42 Epoch [02000/30000] Loss:0.014820 Loss_1:0.013704 Loss_2:0.000703 Loss_3:0.000000 Lr:0.000833 Time:18.814910s (0.64min in total, 8.89min remains)
2022-11-27 22:50:02 NUM_SUB: 12;----------------------------
2022-11-27 22:50:02 Epoch [03000/30000] Loss:0.013013 Loss_1:0.012670 Loss_2:0.000284 Loss_3:0.000000 Lr:0.000769 Time:19.161165s (0.95min in total, 8.59min remains)
2022-11-27 22:50:21 NUM_SUB: 12;----------------------------
2022-11-27 22:50:21 Epoch [04000/30000] Loss:0.011396 Loss_1:0.011173 Loss_2:0.000216 Loss_3:0.000000 Lr:0.000714 Time:19.052119s (1.27min in total, 8.27min remains)
2022-11-27 22:50:40 NUM_SUB: 12;----------------------------
2022-11-27 22:50:40 Epoch [05000/30000] Loss:0.009575 Loss_1:0.009299 Loss_2:0.000249 Loss_3:0.000000 Lr:0.000667 Time:18.901109s (1.59min in total, 7.94min remains)
2022-11-27 22:50:58 NUM_SUB: 12;----------------------------
2022-11-27 22:50:58 Epoch [06000/30000] Loss:0.007450 Loss_1:0.007228 Loss_2:0.000195 Loss_3:0.000000 Lr:0.000625 Time:18.809808s (1.90min in total, 7.60min remains)
2022-11-27 22:51:17 NUM_SUB: 12;----------------------------
2022-11-27 22:51:17 Epoch [07000/30000] Loss:0.004853 Loss_1:0.004643 Loss_2:0.000191 Loss_3:0.000000 Lr:0.000588 Time:18.655933s (2.21min in total, 7.27min remains)
2022-11-27 22:51:37 NUM_SUB: 12;----------------------------
2022-11-27 22:51:37 Epoch [08000/30000] Loss:0.002512 Loss_1:0.002392 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000556 Time:19.760892s (2.54min in total, 6.99min remains)
2022-11-27 22:51:56 NUM_SUB: 12;----------------------------
2022-11-27 22:51:56 Epoch [09000/30000] Loss:0.001332 Loss_1:0.001243 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000526 Time:19.220156s (2.86min in total, 6.68min remains)
2022-11-27 22:52:15 NUM_SUB: 12;----------------------------
2022-11-27 22:52:15 Epoch [10000/30000] Loss:0.000953 Loss_1:0.000881 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000500 Time:19.486348s (3.19min in total, 6.37min remains)
2022-11-27 22:52:34 NUM_SUB: 12;----------------------------
2022-11-27 22:52:34 Epoch [11000/30000] Loss:0.000840 Loss_1:0.000760 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000476 Time:18.984571s (3.50min in total, 6.05min remains)
2022-11-27 22:52:54 NUM_SUB: 12;----------------------------
2022-11-27 22:52:54 Epoch [12000/30000] Loss:0.000709 Loss_1:0.000657 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000455 Time:19.279331s (3.82min in total, 5.74min remains)
2022-11-27 22:53:14 NUM_SUB: 12;----------------------------
2022-11-27 22:53:14 Epoch [13000/30000] Loss:0.000593 Loss_1:0.000567 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000435 Time:19.987338s (4.16min in total, 5.44min remains)
2022-11-27 22:53:33 NUM_SUB: 12;----------------------------
2022-11-27 22:53:33 Epoch [14000/30000] Loss:0.000501 Loss_1:0.000481 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:19.277136s (4.48min in total, 5.12min remains)
2022-11-27 22:53:52 NUM_SUB: 12;----------------------------
2022-11-27 22:53:52 Epoch [15000/30000] Loss:0.000468 Loss_1:0.000451 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:18.879662s (4.79min in total, 4.79min remains)
2022-11-27 22:54:11 NUM_SUB: 12;----------------------------
2022-11-27 22:54:11 Epoch [16000/30000] Loss:0.000447 Loss_1:0.000434 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:18.740843s (5.11min in total, 4.47min remains)
2022-11-27 22:54:30 NUM_SUB: 12;----------------------------
2022-11-27 22:54:30 Epoch [17000/30000] Loss:0.000436 Loss_1:0.000425 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000370 Time:18.905184s (5.42min in total, 4.15min remains)
2022-11-27 22:54:48 NUM_SUB: 12;----------------------------
2022-11-27 22:54:48 Epoch [18000/30000] Loss:0.000432 Loss_1:0.000423 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:18.803770s (5.73min in total, 3.82min remains)
2022-11-27 22:55:07 NUM_SUB: 12;----------------------------
2022-11-27 22:55:07 Epoch [19000/30000] Loss:0.000430 Loss_1:0.000422 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:18.996118s (6.05min in total, 3.50min remains)
2022-11-27 22:55:27 NUM_SUB: 12;----------------------------
2022-11-27 22:55:27 Epoch [20000/30000] Loss:0.000431 Loss_1:0.000422 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:19.393901s (6.37min in total, 3.19min remains)
2022-11-27 22:55:46 NUM_SUB: 12;----------------------------
2022-11-27 22:55:46 Epoch [21000/30000] Loss:0.000428 Loss_1:0.000421 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000323 Time:19.069934s (6.69min in total, 2.87min remains)
2022-11-27 22:56:05 NUM_SUB: 12;----------------------------
2022-11-27 22:56:05 Epoch [22000/30000] Loss:0.000427 Loss_1:0.000421 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:18.801607s (7.01min in total, 2.55min remains)
2022-11-27 22:56:23 NUM_SUB: 12;----------------------------
2022-11-27 22:56:23 Epoch [23000/30000] Loss:0.000426 Loss_1:0.000420 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:18.555967s (7.31min in total, 2.23min remains)
2022-11-27 22:56:43 NUM_SUB: 12;----------------------------
2022-11-27 22:56:43 Epoch [24000/30000] Loss:0.000425 Loss_1:0.000419 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.965866s (7.65min in total, 1.91min remains)
2022-11-27 22:57:02 NUM_SUB: 12;----------------------------
2022-11-27 22:57:02 Epoch [25000/30000] Loss:0.000621 Loss_1:0.000448 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.230860s (7.97min in total, 1.59min remains)
2022-11-27 22:57:21 NUM_SUB: 12;----------------------------
2022-11-27 22:57:21 Epoch [26000/30000] Loss:0.000422 Loss_1:0.000417 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:18.558018s (8.28min in total, 1.27min remains)
2022-11-27 22:57:40 NUM_SUB: 12;----------------------------
2022-11-27 22:57:40 Epoch [27000/30000] Loss:0.000420 Loss_1:0.000415 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000270 Time:18.778505s (8.59min in total, 0.95min remains)
2022-11-27 22:57:59 NUM_SUB: 12;----------------------------
2022-11-27 22:57:59 Epoch [28000/30000] Loss:0.000417 Loss_1:0.000412 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:18.974882s (8.91min in total, 0.64min remains)
2022-11-27 22:58:18 NUM_SUB: 12;----------------------------
2022-11-27 22:58:18 Epoch [29000/30000] Loss:0.000412 Loss_1:0.000407 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000256 Time:19.089668s (9.22min in total, 0.32min remains)
2022-11-27 22:58:38 NUM_SUB: 12;----------------------------
2022-11-27 22:58:38 Epoch [30000/30000] Loss:0.000410 Loss_1:0.000404 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:20.132769s (9.56min in total, 0.00min remains)
2022-11-27 22:58:38 Testing & drawing...
2022-11-27 22:58:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:58:40 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=12/
2022-11-27 22:58:40 [Loss]
2022-11-27 22:58:40 NUM_SUB: 12; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:58:40 NUM_SUB: 12; Personalized parameter estimation: Parameter containing:
tensor([0.0157, 0.0296, 0.0253, 0.8841, 0.3074, 0.0148, 1.1460, 0.8964, 0.4556,
        0.0137, 0.1127, 0.0688, 0.4974, 0.1689, 0.0176, 0.9660, 0.6977, 0.8000,
        0.0118, 4.1080, 0.6816, 0.0228, 2.7905, 0.8742, 0.0203, 4.0491, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:58:40 NUM_SUB: 12------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 22:58:40 Testing & drawing...
2022-11-27 22:58:40 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 22:58:41 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=12/
2022-11-27 22:58:41 [Loss]
2022-11-27 22:58:41 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 22:58:41 General parameter estimation: Parameter containing:
tensor([0.0157, 0.0296, 0.0253, 0.8841, 0.3074, 0.0148, 1.1460, 0.8964, 0.4556,
        0.0137, 0.1127, 0.0688, 0.4974, 0.1689, 0.0176, 0.9660, 0.6977, 0.8000,
        0.0118, 4.1080, 0.6816, 0.0228, 2.7905, 0.8742, 0.0203, 4.0491, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 22:58:41 A: prod, degr, TonA, NonA
2022-11-27 22:58:41 [0.36553222 0.4745989  0.08934455 0.07052429]
2022-11-27 22:58:41 T: prod, degr, AonT, NonT
2022-11-27 22:58:41 [0.11481337 0.6428703  0.2037563  0.03856004]
2022-11-27 22:58:41 N: AonN, TonN, ATonN
2022-11-27 22:58:41 [0.0170777  0.9443627  0.03855966]
2022-11-27 22:58:41 using cpu
2022-11-27 22:58:41 epoch = 30000
2022-11-27 22:58:41 epoch_step = 1000
2022-11-27 22:58:41 model_name = SimpleNetworkAD
2022-11-27 22:58:41 now_string = 2022-11-27-19-40-13
2022-11-27 22:58:41 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 22:58:41 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 22:58:41 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 22:58:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 22:58:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 22:58:41 --------------------------------------------------training start--------------------------------------------------
2022-11-27 22:59:01 NUM_SUB: 13;----------------------------
2022-11-27 22:59:01 Epoch [01000/30000] Loss:0.084433 Loss_1:0.079232 Loss_2:0.001508 Loss_3:0.000000 Lr:0.000909 Time:19.210082s (0.32min in total, 9.28min remains)
2022-11-27 22:59:19 NUM_SUB: 13;----------------------------
2022-11-27 22:59:19 Epoch [02000/30000] Loss:0.072958 Loss_1:0.072143 Loss_2:0.000446 Loss_3:0.000000 Lr:0.000833 Time:18.733654s (0.63min in total, 8.85min remains)
2022-11-27 22:59:38 NUM_SUB: 13;----------------------------
2022-11-27 22:59:38 Epoch [03000/30000] Loss:0.062665 Loss_1:0.062206 Loss_2:0.000178 Loss_3:0.000000 Lr:0.000769 Time:18.851460s (0.95min in total, 8.52min remains)
2022-11-27 22:59:58 NUM_SUB: 13;----------------------------
2022-11-27 22:59:58 Epoch [04000/30000] Loss:0.049703 Loss_1:0.049346 Loss_2:0.000122 Loss_3:0.000000 Lr:0.000714 Time:19.951834s (1.28min in total, 8.31min remains)
2022-11-27 23:00:18 NUM_SUB: 13;----------------------------
2022-11-27 23:00:18 Epoch [05000/30000] Loss:0.033024 Loss_1:0.032736 Loss_2:0.000115 Loss_3:0.000000 Lr:0.000667 Time:20.218904s (1.62min in total, 8.08min remains)
2022-11-27 23:00:39 NUM_SUB: 13;----------------------------
2022-11-27 23:00:39 Epoch [06000/30000] Loss:0.016658 Loss_1:0.016453 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000625 Time:20.438423s (1.96min in total, 7.83min remains)
2022-11-27 23:00:58 NUM_SUB: 13;----------------------------
2022-11-27 23:00:58 Epoch [07000/30000] Loss:0.008117 Loss_1:0.007986 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000588 Time:19.202344s (2.28min in total, 7.48min remains)
2022-11-27 23:01:18 NUM_SUB: 13;----------------------------
2022-11-27 23:01:18 Epoch [08000/30000] Loss:0.006075 Loss_1:0.005964 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000556 Time:19.630150s (2.60min in total, 7.16min remains)
2022-11-27 23:01:37 NUM_SUB: 13;----------------------------
2022-11-27 23:01:37 Epoch [09000/30000] Loss:0.005113 Loss_1:0.004999 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000526 Time:19.031468s (2.92min in total, 6.82min remains)
2022-11-27 23:01:56 NUM_SUB: 13;----------------------------
2022-11-27 23:01:56 Epoch [10000/30000] Loss:0.004213 Loss_1:0.004116 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000500 Time:18.895187s (3.24min in total, 6.47min remains)
2022-11-27 23:02:15 NUM_SUB: 13;----------------------------
2022-11-27 23:02:15 Epoch [11000/30000] Loss:0.003489 Loss_1:0.003426 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000476 Time:18.865005s (3.55min in total, 6.13min remains)
2022-11-27 23:02:33 NUM_SUB: 13;----------------------------
2022-11-27 23:02:33 Epoch [12000/30000] Loss:0.002981 Loss_1:0.002951 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000455 Time:18.959681s (3.87min in total, 5.80min remains)
2022-11-27 23:02:53 NUM_SUB: 13;----------------------------
2022-11-27 23:02:53 Epoch [13000/30000] Loss:0.002725 Loss_1:0.002703 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000435 Time:19.387356s (4.19min in total, 5.48min remains)
2022-11-27 23:03:12 NUM_SUB: 13;----------------------------
2022-11-27 23:03:12 Epoch [14000/30000] Loss:0.002611 Loss_1:0.002594 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000417 Time:19.277925s (4.51min in total, 5.16min remains)
2022-11-27 23:03:31 NUM_SUB: 13;----------------------------
2022-11-27 23:03:31 Epoch [15000/30000] Loss:0.002537 Loss_1:0.002525 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000400 Time:19.268487s (4.83min in total, 4.83min remains)
2022-11-27 23:03:50 NUM_SUB: 13;----------------------------
2022-11-27 23:03:50 Epoch [16000/30000] Loss:0.002426 Loss_1:0.002417 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000385 Time:18.563201s (5.14min in total, 4.50min remains)
2022-11-27 23:04:09 NUM_SUB: 13;----------------------------
2022-11-27 23:04:09 Epoch [17000/30000] Loss:0.002351 Loss_1:0.002344 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:18.990625s (5.46min in total, 4.17min remains)
2022-11-27 23:04:28 NUM_SUB: 13;----------------------------
2022-11-27 23:04:28 Epoch [18000/30000] Loss:0.002327 Loss_1:0.002321 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:19.022715s (5.78min in total, 3.85min remains)
2022-11-27 23:04:47 NUM_SUB: 13;----------------------------
2022-11-27 23:04:47 Epoch [19000/30000] Loss:0.002324 Loss_1:0.002319 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:19.069263s (6.09min in total, 3.53min remains)
2022-11-27 23:05:06 NUM_SUB: 13;----------------------------
2022-11-27 23:05:06 Epoch [20000/30000] Loss:0.002321 Loss_1:0.002316 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.210224s (6.41min in total, 3.21min remains)
2022-11-27 23:05:25 NUM_SUB: 13;----------------------------
2022-11-27 23:05:25 Epoch [21000/30000] Loss:0.002317 Loss_1:0.002313 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:18.932036s (6.73min in total, 2.88min remains)
2022-11-27 23:05:44 NUM_SUB: 13;----------------------------
2022-11-27 23:05:44 Epoch [22000/30000] Loss:0.002313 Loss_1:0.002309 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.620130s (7.04min in total, 2.56min remains)
2022-11-27 23:06:03 NUM_SUB: 13;----------------------------
2022-11-27 23:06:03 Epoch [23000/30000] Loss:0.002305 Loss_1:0.002302 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.739208s (7.35min in total, 2.24min remains)
2022-11-27 23:06:21 NUM_SUB: 13;----------------------------
2022-11-27 23:06:21 Epoch [24000/30000] Loss:0.002299 Loss_1:0.002297 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.677477s (7.66min in total, 1.92min remains)
2022-11-27 23:06:40 NUM_SUB: 13;----------------------------
2022-11-27 23:06:40 Epoch [25000/30000] Loss:0.002285 Loss_1:0.002282 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.865482s (7.98min in total, 1.60min remains)
2022-11-27 23:06:59 NUM_SUB: 13;----------------------------
2022-11-27 23:06:59 Epoch [26000/30000] Loss:0.002275 Loss_1:0.002272 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.817239s (8.29min in total, 1.28min remains)
2022-11-27 23:07:18 NUM_SUB: 13;----------------------------
2022-11-27 23:07:18 Epoch [27000/30000] Loss:0.002266 Loss_1:0.002259 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.975933s (8.61min in total, 0.96min remains)
2022-11-27 23:07:37 NUM_SUB: 13;----------------------------
2022-11-27 23:07:37 Epoch [28000/30000] Loss:0.002251 Loss_1:0.002250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.018402s (8.92min in total, 0.64min remains)
2022-11-27 23:07:56 NUM_SUB: 13;----------------------------
2022-11-27 23:07:56 Epoch [29000/30000] Loss:0.002243 Loss_1:0.002242 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.840149s (9.24min in total, 0.32min remains)
2022-11-27 23:08:15 NUM_SUB: 13;----------------------------
2022-11-27 23:08:15 Epoch [30000/30000] Loss:0.002238 Loss_1:0.002236 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.956829s (9.55min in total, 0.00min remains)
2022-11-27 23:08:15 Testing & drawing...
2022-11-27 23:08:15 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:08:16 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=13/
2022-11-27 23:08:16 [Loss]
2022-11-27 23:08:16 NUM_SUB: 13; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:08:16 NUM_SUB: 13; Personalized parameter estimation: Parameter containing:
tensor([0.0043, 0.0243, 0.0096, 0.6365, 0.3074, 0.0147, 2.8995, 0.8964, 0.4556,
        0.0145, 0.1280, 0.1219, 0.6411, 0.1689, 0.0175, 1.0656, 0.6977, 0.8000,
        0.0123, 3.4769, 0.6816, 0.0209, 3.4134, 0.8742, 0.0214, 4.1723, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:08:16 NUM_SUB: 13------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:08:16 Testing & drawing...
2022-11-27 23:08:16 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:08:18 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=13/
2022-11-27 23:08:18 [Loss]
2022-11-27 23:08:18 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:08:18 General parameter estimation: Parameter containing:
tensor([0.0043, 0.0243, 0.0096, 0.6365, 0.3074, 0.0147, 2.8995, 0.8964, 0.4556,
        0.0145, 0.1280, 0.1219, 0.6411, 0.1689, 0.0175, 1.0656, 0.6977, 0.8000,
        0.0123, 3.4769, 0.6816, 0.0209, 3.4134, 0.8742, 0.0214, 4.1723, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:08:18 A: prod, degr, TonA, NonA
2022-11-27 23:08:18 [0.26920703 0.4795749  0.20711654 0.04410153]
2022-11-27 23:08:18 T: prod, degr, AonT, NonT
2022-11-27 23:08:18 [0.1442771  0.39996725 0.40876597 0.04698967]
2022-11-27 23:08:18 N: AonN, TonN, ATonN
2022-11-27 23:08:18 [0.00556202 0.97323084 0.02120716]
2022-11-27 23:08:18 using cpu
2022-11-27 23:08:18 epoch = 30000
2022-11-27 23:08:18 epoch_step = 1000
2022-11-27 23:08:18 model_name = SimpleNetworkAD
2022-11-27 23:08:18 now_string = 2022-11-27-19-40-13
2022-11-27 23:08:18 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:08:18 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:08:18 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:08:18 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:08:18 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:08:18 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:08:38 NUM_SUB: 14;----------------------------
2022-11-27 23:08:38 Epoch [01000/30000] Loss:0.051829 Loss_1:0.045968 Loss_2:0.002188 Loss_3:0.000000 Lr:0.000909 Time:19.472858s (0.32min in total, 9.41min remains)
2022-11-27 23:08:57 NUM_SUB: 14;----------------------------
2022-11-27 23:08:57 Epoch [02000/30000] Loss:0.042192 Loss_1:0.041078 Loss_2:0.000755 Loss_3:0.000000 Lr:0.000833 Time:19.225128s (0.64min in total, 9.03min remains)
2022-11-27 23:09:17 NUM_SUB: 14;----------------------------
2022-11-27 23:09:17 Epoch [03000/30000] Loss:0.035477 Loss_1:0.034930 Loss_2:0.000274 Loss_3:0.000000 Lr:0.000769 Time:19.719739s (0.97min in total, 8.76min remains)
2022-11-27 23:09:36 NUM_SUB: 14;----------------------------
2022-11-27 23:09:36 Epoch [04000/30000] Loss:0.028212 Loss_1:0.027787 Loss_2:0.000208 Loss_3:0.000000 Lr:0.000714 Time:19.262183s (1.29min in total, 8.42min remains)
2022-11-27 23:09:55 NUM_SUB: 14;----------------------------
2022-11-27 23:09:55 Epoch [05000/30000] Loss:0.019228 Loss_1:0.018882 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000667 Time:18.639212s (1.61min in total, 8.03min remains)
2022-11-27 23:10:14 NUM_SUB: 14;----------------------------
2022-11-27 23:10:14 Epoch [06000/30000] Loss:0.010110 Loss_1:0.009849 Loss_2:0.000184 Loss_3:0.000000 Lr:0.000625 Time:19.091333s (1.92min in total, 7.69min remains)
2022-11-27 23:10:33 NUM_SUB: 14;----------------------------
2022-11-27 23:10:33 Epoch [07000/30000] Loss:0.004299 Loss_1:0.004105 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000588 Time:18.998637s (2.24min in total, 7.36min remains)
2022-11-27 23:10:52 NUM_SUB: 14;----------------------------
2022-11-27 23:10:52 Epoch [08000/30000] Loss:0.002419 Loss_1:0.002248 Loss_2:0.000169 Loss_3:0.000000 Lr:0.000556 Time:18.994686s (2.56min in total, 7.03min remains)
2022-11-27 23:11:11 NUM_SUB: 14;----------------------------
2022-11-27 23:11:11 Epoch [09000/30000] Loss:0.001708 Loss_1:0.001552 Loss_2:0.000155 Loss_3:0.000000 Lr:0.000526 Time:19.013934s (2.87min in total, 6.71min remains)
2022-11-27 23:11:30 NUM_SUB: 14;----------------------------
2022-11-27 23:11:30 Epoch [10000/30000] Loss:0.001124 Loss_1:0.000978 Loss_2:0.000147 Loss_3:0.000000 Lr:0.000500 Time:19.049746s (3.19min in total, 6.38min remains)
2022-11-27 23:11:49 NUM_SUB: 14;----------------------------
2022-11-27 23:11:49 Epoch [11000/30000] Loss:0.000633 Loss_1:0.000552 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000476 Time:18.828867s (3.51min in total, 6.05min remains)
2022-11-27 23:12:08 NUM_SUB: 14;----------------------------
2022-11-27 23:12:08 Epoch [12000/30000] Loss:0.000364 Loss_1:0.000310 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000455 Time:19.004540s (3.82min in total, 5.73min remains)
2022-11-27 23:12:27 NUM_SUB: 14;----------------------------
2022-11-27 23:12:27 Epoch [13000/30000] Loss:0.000272 Loss_1:0.000234 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000435 Time:19.092141s (4.14min in total, 5.41min remains)
2022-11-27 23:12:45 NUM_SUB: 14;----------------------------
2022-11-27 23:12:45 Epoch [14000/30000] Loss:0.000233 Loss_1:0.000207 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:18.812204s (4.45min in total, 5.09min remains)
2022-11-27 23:13:04 NUM_SUB: 14;----------------------------
2022-11-27 23:13:04 Epoch [15000/30000] Loss:0.000195 Loss_1:0.000177 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000400 Time:18.645120s (4.76min in total, 4.76min remains)
2022-11-27 23:13:24 NUM_SUB: 14;----------------------------
2022-11-27 23:13:24 Epoch [16000/30000] Loss:0.000155 Loss_1:0.000142 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:19.748063s (5.09min in total, 4.46min remains)
2022-11-27 23:13:43 NUM_SUB: 14;----------------------------
2022-11-27 23:13:43 Epoch [17000/30000] Loss:0.000119 Loss_1:0.000109 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:18.862847s (5.41min in total, 4.14min remains)
2022-11-27 23:14:01 NUM_SUB: 14;----------------------------
2022-11-27 23:14:01 Epoch [18000/30000] Loss:0.000139 Loss_1:0.000131 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:18.725948s (5.72min in total, 3.81min remains)
2022-11-27 23:14:20 NUM_SUB: 14;----------------------------
2022-11-27 23:14:20 Epoch [19000/30000] Loss:0.000087 Loss_1:0.000081 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:18.978112s (6.04min in total, 3.49min remains)
2022-11-27 23:14:39 NUM_SUB: 14;----------------------------
2022-11-27 23:14:39 Epoch [20000/30000] Loss:0.000084 Loss_1:0.000079 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:18.934883s (6.35min in total, 3.18min remains)
2022-11-27 23:14:59 NUM_SUB: 14;----------------------------
2022-11-27 23:14:59 Epoch [21000/30000] Loss:0.000082 Loss_1:0.000079 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.402170s (6.68min in total, 2.86min remains)
2022-11-27 23:15:18 NUM_SUB: 14;----------------------------
2022-11-27 23:15:18 Epoch [22000/30000] Loss:0.000386 Loss_1:0.000384 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.682451s (7.00min in total, 2.55min remains)
2022-11-27 23:15:38 NUM_SUB: 14;----------------------------
2022-11-27 23:15:38 Epoch [23000/30000] Loss:0.000079 Loss_1:0.000077 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.735647s (7.33min in total, 2.23min remains)
2022-11-27 23:15:58 NUM_SUB: 14;----------------------------
2022-11-27 23:15:58 Epoch [24000/30000] Loss:0.000078 Loss_1:0.000076 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:20.236490s (7.67min in total, 1.92min remains)
2022-11-27 23:16:18 NUM_SUB: 14;----------------------------
2022-11-27 23:16:18 Epoch [25000/30000] Loss:0.000076 Loss_1:0.000075 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.814169s (8.00min in total, 1.60min remains)
2022-11-27 23:16:37 NUM_SUB: 14;----------------------------
2022-11-27 23:16:37 Epoch [26000/30000] Loss:0.000080 Loss_1:0.000078 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.958935s (8.32min in total, 1.28min remains)
2022-11-27 23:16:57 NUM_SUB: 14;----------------------------
2022-11-27 23:16:57 Epoch [27000/30000] Loss:0.000075 Loss_1:0.000074 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.686242s (8.64min in total, 0.96min remains)
2022-11-27 23:17:16 NUM_SUB: 14;----------------------------
2022-11-27 23:17:16 Epoch [28000/30000] Loss:0.000075 Loss_1:0.000074 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.255116s (8.96min in total, 0.64min remains)
2022-11-27 23:17:35 NUM_SUB: 14;----------------------------
2022-11-27 23:17:35 Epoch [29000/30000] Loss:0.000074 Loss_1:0.000073 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.078607s (9.28min in total, 0.32min remains)
2022-11-27 23:17:54 NUM_SUB: 14;----------------------------
2022-11-27 23:17:54 Epoch [30000/30000] Loss:0.000074 Loss_1:0.000073 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.972087s (9.60min in total, 0.00min remains)
2022-11-27 23:17:54 Testing & drawing...
2022-11-27 23:17:54 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:17:56 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=14/
2022-11-27 23:17:56 [Loss]
2022-11-27 23:17:56 NUM_SUB: 14; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:17:56 NUM_SUB: 14; Personalized parameter estimation: Parameter containing:
tensor([1.2110e-02, 1.8178e-02, 6.1046e-02, 1.4188e+00, 3.0742e-01, 1.5255e-02,
        1.5222e+00, 8.9644e-01, 4.5563e-01, 1.4778e-02, 1.6257e-01, 1.4131e-01,
        5.6741e-01, 1.6886e-01, 1.7611e-02, 8.1936e-01, 6.9767e-01, 8.0001e-01,
        4.5970e-03, 5.0347e+00, 6.8161e-01, 2.2630e-02, 3.5275e+00, 8.7416e-01,
        1.6464e-02, 5.0025e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 23:17:56 NUM_SUB: 14------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:17:56 Testing & drawing...
2022-11-27 23:17:56 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:17:57 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=14/
2022-11-27 23:17:57 [Loss]
2022-11-27 23:17:57 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:17:57 General parameter estimation: Parameter containing:
tensor([1.2110e-02, 1.8178e-02, 6.1046e-02, 1.4188e+00, 3.0742e-01, 1.5255e-02,
        1.5222e+00, 8.9644e-01, 4.5563e-01, 1.4778e-02, 1.6257e-01, 1.4131e-01,
        5.6741e-01, 1.6886e-01, 1.7611e-02, 8.1936e-01, 6.9767e-01, 8.0001e-01,
        4.5970e-03, 5.0347e+00, 6.8161e-01, 2.2630e-02, 3.5275e+00, 8.7416e-01,
        1.6464e-02, 5.0025e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-27 23:17:57 A: prod, degr, TonA, NonA
2022-11-27 23:17:57 [0.34023955 0.48666498 0.12962586 0.04346964]
2022-11-27 23:17:57 T: prod, degr, AonT, NonT
2022-11-27 23:17:57 [0.06686838 0.70041585 0.21040949 0.0223063 ]
2022-11-27 23:17:57 N: AonN, TonN, ATonN
2022-11-27 23:17:57 [0.0080706  0.95756924 0.03436017]
2022-11-27 23:17:58 using cpu
2022-11-27 23:17:58 epoch = 30000
2022-11-27 23:17:58 epoch_step = 1000
2022-11-27 23:17:58 model_name = SimpleNetworkAD
2022-11-27 23:17:58 now_string = 2022-11-27-19-40-13
2022-11-27 23:17:58 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:17:58 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:17:58 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:17:58 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:17:58 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:17:58 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:18:17 NUM_SUB: 15;----------------------------
2022-11-27 23:18:17 Epoch [01000/30000] Loss:0.042766 Loss_1:0.036939 Loss_2:0.001947 Loss_3:0.000000 Lr:0.000909 Time:19.146999s (0.32min in total, 9.25min remains)
2022-11-27 23:18:36 NUM_SUB: 15;----------------------------
2022-11-27 23:18:36 Epoch [02000/30000] Loss:0.036054 Loss_1:0.034968 Loss_2:0.000638 Loss_3:0.000000 Lr:0.000833 Time:19.128173s (0.64min in total, 8.93min remains)
2022-11-27 23:18:55 NUM_SUB: 15;----------------------------
2022-11-27 23:18:55 Epoch [03000/30000] Loss:0.032178 Loss_1:0.031861 Loss_2:0.000222 Loss_3:0.000000 Lr:0.000769 Time:19.487796s (0.96min in total, 8.67min remains)
2022-11-27 23:19:15 NUM_SUB: 15;----------------------------
2022-11-27 23:19:15 Epoch [04000/30000] Loss:0.028419 Loss_1:0.028091 Loss_2:0.000150 Loss_3:0.000000 Lr:0.000714 Time:19.273714s (1.28min in total, 8.35min remains)
2022-11-27 23:19:34 NUM_SUB: 15;----------------------------
2022-11-27 23:19:34 Epoch [05000/30000] Loss:0.023464 Loss_1:0.023160 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000667 Time:19.365666s (1.61min in total, 8.03min remains)
2022-11-27 23:19:53 NUM_SUB: 15;----------------------------
2022-11-27 23:19:53 Epoch [06000/30000] Loss:0.016984 Loss_1:0.016723 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000625 Time:18.950186s (1.92min in total, 7.69min remains)
2022-11-27 23:20:13 NUM_SUB: 15;----------------------------
2022-11-27 23:20:13 Epoch [07000/30000] Loss:0.009833 Loss_1:0.009589 Loss_2:0.000155 Loss_3:0.000000 Lr:0.000588 Time:20.465989s (2.26min in total, 7.44min remains)
2022-11-27 23:20:34 NUM_SUB: 15;----------------------------
2022-11-27 23:20:34 Epoch [08000/30000] Loss:0.004055 Loss_1:0.003889 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000556 Time:20.137065s (2.60min in total, 7.15min remains)
2022-11-27 23:20:53 NUM_SUB: 15;----------------------------
2022-11-27 23:20:53 Epoch [09000/30000] Loss:0.001413 Loss_1:0.001278 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000526 Time:19.572255s (2.93min in total, 6.83min remains)
2022-11-27 23:21:13 NUM_SUB: 15;----------------------------
2022-11-27 23:21:13 Epoch [10000/30000] Loss:0.000629 Loss_1:0.000519 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000500 Time:19.329068s (3.25min in total, 6.50min remains)
2022-11-27 23:21:32 NUM_SUB: 15;----------------------------
2022-11-27 23:21:32 Epoch [11000/30000] Loss:0.000629 Loss_1:0.000520 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000476 Time:19.487369s (3.57min in total, 6.17min remains)
2022-11-27 23:21:51 NUM_SUB: 15;----------------------------
2022-11-27 23:21:51 Epoch [12000/30000] Loss:0.000474 Loss_1:0.000405 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000455 Time:19.093328s (3.89min in total, 5.84min remains)
2022-11-27 23:22:11 NUM_SUB: 15;----------------------------
2022-11-27 23:22:11 Epoch [13000/30000] Loss:0.000411 Loss_1:0.000368 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000435 Time:19.617512s (4.22min in total, 5.52min remains)
2022-11-27 23:22:30 NUM_SUB: 15;----------------------------
2022-11-27 23:22:30 Epoch [14000/30000] Loss:0.000385 Loss_1:0.000353 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000417 Time:19.242159s (4.54min in total, 5.19min remains)
2022-11-27 23:22:49 NUM_SUB: 15;----------------------------
2022-11-27 23:22:49 Epoch [15000/30000] Loss:0.000347 Loss_1:0.000323 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000400 Time:18.712710s (4.85min in total, 4.85min remains)
2022-11-27 23:23:08 NUM_SUB: 15;----------------------------
2022-11-27 23:23:08 Epoch [16000/30000] Loss:0.000318 Loss_1:0.000298 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:19.749513s (5.18min in total, 4.53min remains)
2022-11-27 23:23:28 NUM_SUB: 15;----------------------------
2022-11-27 23:23:28 Epoch [17000/30000] Loss:0.000271 Loss_1:0.000254 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:19.550115s (5.51min in total, 4.21min remains)
2022-11-27 23:23:47 NUM_SUB: 15;----------------------------
2022-11-27 23:23:47 Epoch [18000/30000] Loss:0.000239 Loss_1:0.000229 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:18.823289s (5.82min in total, 3.88min remains)
2022-11-27 23:24:06 NUM_SUB: 15;----------------------------
2022-11-27 23:24:06 Epoch [19000/30000] Loss:0.000227 Loss_1:0.000220 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.503128s (6.14min in total, 3.56min remains)
2022-11-27 23:24:26 NUM_SUB: 15;----------------------------
2022-11-27 23:24:26 Epoch [20000/30000] Loss:0.000225 Loss_1:0.000221 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.598105s (6.47min in total, 3.24min remains)
2022-11-27 23:24:45 NUM_SUB: 15;----------------------------
2022-11-27 23:24:45 Epoch [21000/30000] Loss:0.000222 Loss_1:0.000219 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:18.912909s (6.79min in total, 2.91min remains)
2022-11-27 23:25:04 NUM_SUB: 15;----------------------------
2022-11-27 23:25:04 Epoch [22000/30000] Loss:0.000223 Loss_1:0.000220 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:19.178330s (7.11min in total, 2.58min remains)
2022-11-27 23:25:23 NUM_SUB: 15;----------------------------
2022-11-27 23:25:23 Epoch [23000/30000] Loss:0.000222 Loss_1:0.000220 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.227183s (7.43min in total, 2.26min remains)
2022-11-27 23:25:43 NUM_SUB: 15;----------------------------
2022-11-27 23:25:43 Epoch [24000/30000] Loss:0.000220 Loss_1:0.000218 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.378553s (7.75min in total, 1.94min remains)
2022-11-27 23:26:01 NUM_SUB: 15;----------------------------
2022-11-27 23:26:01 Epoch [25000/30000] Loss:0.000226 Loss_1:0.000224 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.870361s (8.06min in total, 1.61min remains)
2022-11-27 23:26:21 NUM_SUB: 15;----------------------------
2022-11-27 23:26:21 Epoch [26000/30000] Loss:0.000227 Loss_1:0.000226 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.176182s (8.38min in total, 1.29min remains)
2022-11-27 23:26:41 NUM_SUB: 15;----------------------------
2022-11-27 23:26:41 Epoch [27000/30000] Loss:0.000220 Loss_1:0.000219 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.994954s (8.72min in total, 0.97min remains)
2022-11-27 23:27:00 NUM_SUB: 15;----------------------------
2022-11-27 23:27:00 Epoch [28000/30000] Loss:0.000222 Loss_1:0.000221 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.697064s (9.05min in total, 0.65min remains)
2022-11-27 23:27:20 NUM_SUB: 15;----------------------------
2022-11-27 23:27:20 Epoch [29000/30000] Loss:0.000224 Loss_1:0.000223 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.398255s (9.37min in total, 0.32min remains)
2022-11-27 23:27:39 NUM_SUB: 15;----------------------------
2022-11-27 23:27:39 Epoch [30000/30000] Loss:0.000219 Loss_1:0.000218 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.541729s (9.69min in total, 0.00min remains)
2022-11-27 23:27:39 Testing & drawing...
2022-11-27 23:27:39 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:27:41 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=15/
2022-11-27 23:27:41 [Loss]
2022-11-27 23:27:41 NUM_SUB: 15; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:27:41 NUM_SUB: 15; Personalized parameter estimation: Parameter containing:
tensor([0.0176, 0.0313, 0.0228, 1.6585, 0.3074, 0.0099, 1.4911, 0.8964, 0.4556,
        0.0127, 0.0395, 0.0111, 0.6028, 0.1689, 0.0175, 1.4358, 0.6977, 0.8000,
        0.0114, 4.6008, 0.6816, 0.0226, 3.6641, 0.8742, 0.0191, 4.6857, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:27:41 NUM_SUB: 15------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:27:41 Testing & drawing...
2022-11-27 23:27:41 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:27:43 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=15/
2022-11-27 23:27:43 [Loss]
2022-11-27 23:27:43 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:27:43 General parameter estimation: Parameter containing:
tensor([0.0176, 0.0313, 0.0228, 1.6585, 0.3074, 0.0099, 1.4911, 0.8964, 0.4556,
        0.0127, 0.0395, 0.0111, 0.6028, 0.1689, 0.0175, 1.4358, 0.6977, 0.8000,
        0.0114, 4.6008, 0.6816, 0.0226, 3.6641, 0.8742, 0.0191, 4.6857, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:27:43 A: prod, degr, TonA, NonA
2022-11-27 23:27:43 [0.440634   0.48861268 0.0430813  0.02767203]
2022-11-27 23:27:43 T: prod, degr, AonT, NonT
2022-11-27 23:27:43 [0.29066432 0.5643546  0.0970429  0.04793819]
2022-11-27 23:27:43 N: AonN, TonN, ATonN
2022-11-27 23:27:43 [0.01000964 0.9647114  0.02527892]
2022-11-27 23:27:43 using cpu
2022-11-27 23:27:43 epoch = 30000
2022-11-27 23:27:43 epoch_step = 1000
2022-11-27 23:27:43 model_name = SimpleNetworkAD
2022-11-27 23:27:43 now_string = 2022-11-27-19-40-13
2022-11-27 23:27:43 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:27:43 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:27:43 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:27:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:27:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:27:43 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:28:02 NUM_SUB: 16;----------------------------
2022-11-27 23:28:02 Epoch [01000/30000] Loss:0.023974 Loss_1:0.018353 Loss_2:0.001758 Loss_3:0.000000 Lr:0.000909 Time:19.592929s (0.33min in total, 9.47min remains)
2022-11-27 23:28:22 NUM_SUB: 16;----------------------------
2022-11-27 23:28:22 Epoch [02000/30000] Loss:0.018755 Loss_1:0.017790 Loss_2:0.000524 Loss_3:0.000000 Lr:0.000833 Time:19.517889s (0.65min in total, 9.13min remains)
2022-11-27 23:28:41 NUM_SUB: 16;----------------------------
2022-11-27 23:28:41 Epoch [03000/30000] Loss:0.016949 Loss_1:0.016714 Loss_2:0.000153 Loss_3:0.000000 Lr:0.000769 Time:19.149103s (0.97min in total, 8.74min remains)
2022-11-27 23:29:00 NUM_SUB: 16;----------------------------
2022-11-27 23:29:00 Epoch [04000/30000] Loss:0.015323 Loss_1:0.015177 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000714 Time:19.014600s (1.29min in total, 8.37min remains)
2022-11-27 23:29:20 NUM_SUB: 16;----------------------------
2022-11-27 23:29:20 Epoch [05000/30000] Loss:0.013401 Loss_1:0.013236 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000667 Time:19.494449s (1.61min in total, 8.06min remains)
2022-11-27 23:29:39 NUM_SUB: 16;----------------------------
2022-11-27 23:29:39 Epoch [06000/30000] Loss:0.011122 Loss_1:0.010971 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000625 Time:19.475733s (1.94min in total, 7.75min remains)
2022-11-27 23:29:58 NUM_SUB: 16;----------------------------
2022-11-27 23:29:58 Epoch [07000/30000] Loss:0.008522 Loss_1:0.008390 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000588 Time:19.339352s (2.26min in total, 7.43min remains)
2022-11-27 23:30:18 NUM_SUB: 16;----------------------------
2022-11-27 23:30:18 Epoch [08000/30000] Loss:0.006031 Loss_1:0.005906 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000556 Time:19.156621s (2.58min in total, 7.09min remains)
2022-11-27 23:30:37 NUM_SUB: 16;----------------------------
2022-11-27 23:30:37 Epoch [09000/30000] Loss:0.004096 Loss_1:0.003925 Loss_2:0.000155 Loss_3:0.000000 Lr:0.000526 Time:19.135217s (2.90min in total, 6.76min remains)
2022-11-27 23:30:55 NUM_SUB: 16;----------------------------
2022-11-27 23:30:55 Epoch [10000/30000] Loss:0.002697 Loss_1:0.002595 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000500 Time:18.774052s (3.21min in total, 6.42min remains)
2022-11-27 23:31:15 NUM_SUB: 16;----------------------------
2022-11-27 23:31:15 Epoch [11000/30000] Loss:0.002316 Loss_1:0.002231 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000476 Time:19.477704s (3.54min in total, 6.11min remains)
2022-11-27 23:31:34 NUM_SUB: 16;----------------------------
2022-11-27 23:31:34 Epoch [12000/30000] Loss:0.002164 Loss_1:0.002097 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000455 Time:19.366319s (3.86min in total, 5.79min remains)
2022-11-27 23:31:53 NUM_SUB: 16;----------------------------
2022-11-27 23:31:53 Epoch [13000/30000] Loss:0.001977 Loss_1:0.001933 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000435 Time:18.857983s (4.17min in total, 5.46min remains)
2022-11-27 23:32:13 NUM_SUB: 16;----------------------------
2022-11-27 23:32:13 Epoch [14000/30000] Loss:0.001837 Loss_1:0.001799 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:19.634836s (4.50min in total, 5.14min remains)
2022-11-27 23:32:32 NUM_SUB: 16;----------------------------
2022-11-27 23:32:32 Epoch [15000/30000] Loss:0.001777 Loss_1:0.001745 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000400 Time:19.314877s (4.82min in total, 4.82min remains)
2022-11-27 23:32:51 NUM_SUB: 16;----------------------------
2022-11-27 23:32:51 Epoch [16000/30000] Loss:0.001748 Loss_1:0.001720 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000385 Time:18.989863s (5.14min in total, 4.50min remains)
2022-11-27 23:33:10 NUM_SUB: 16;----------------------------
2022-11-27 23:33:10 Epoch [17000/30000] Loss:0.001728 Loss_1:0.001705 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000370 Time:18.865961s (5.45min in total, 4.17min remains)
2022-11-27 23:33:30 NUM_SUB: 16;----------------------------
2022-11-27 23:33:30 Epoch [18000/30000] Loss:0.001709 Loss_1:0.001688 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000357 Time:19.660255s (5.78min in total, 3.85min remains)
2022-11-27 23:33:49 NUM_SUB: 16;----------------------------
2022-11-27 23:33:49 Epoch [19000/30000] Loss:0.001690 Loss_1:0.001672 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000345 Time:19.683063s (6.11min in total, 3.54min remains)
2022-11-27 23:34:08 NUM_SUB: 16;----------------------------
2022-11-27 23:34:08 Epoch [20000/30000] Loss:0.001675 Loss_1:0.001659 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000333 Time:18.848093s (6.42min in total, 3.21min remains)
2022-11-27 23:34:28 NUM_SUB: 16;----------------------------
2022-11-27 23:34:28 Epoch [21000/30000] Loss:0.001663 Loss_1:0.001649 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000323 Time:20.101823s (6.76min in total, 2.90min remains)
2022-11-27 23:34:48 NUM_SUB: 16;----------------------------
2022-11-27 23:34:48 Epoch [22000/30000] Loss:0.001654 Loss_1:0.001642 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000313 Time:20.089083s (7.09min in total, 2.58min remains)
2022-11-27 23:35:09 NUM_SUB: 16;----------------------------
2022-11-27 23:35:09 Epoch [23000/30000] Loss:0.001645 Loss_1:0.001633 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000303 Time:20.418488s (7.43min in total, 2.26min remains)
2022-11-27 23:35:30 NUM_SUB: 16;----------------------------
2022-11-27 23:35:30 Epoch [24000/30000] Loss:0.001654 Loss_1:0.001645 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000294 Time:20.838624s (7.78min in total, 1.95min remains)
2022-11-27 23:35:49 NUM_SUB: 16;----------------------------
2022-11-27 23:35:49 Epoch [25000/30000] Loss:0.001627 Loss_1:0.001617 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000286 Time:19.447656s (8.10min in total, 1.62min remains)
2022-11-27 23:36:08 NUM_SUB: 16;----------------------------
2022-11-27 23:36:08 Epoch [26000/30000] Loss:0.001621 Loss_1:0.001611 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000278 Time:19.263414s (8.43min in total, 1.30min remains)
2022-11-27 23:36:28 NUM_SUB: 16;----------------------------
2022-11-27 23:36:28 Epoch [27000/30000] Loss:0.001610 Loss_1:0.001602 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000270 Time:19.388894s (8.75min in total, 0.97min remains)
2022-11-27 23:36:47 NUM_SUB: 16;----------------------------
2022-11-27 23:36:47 Epoch [28000/30000] Loss:0.001619 Loss_1:0.001592 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:19.515116s (9.07min in total, 0.65min remains)
2022-11-27 23:37:06 NUM_SUB: 16;----------------------------
2022-11-27 23:37:06 Epoch [29000/30000] Loss:0.001591 Loss_1:0.001585 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000256 Time:18.900536s (9.39min in total, 0.32min remains)
2022-11-27 23:37:27 NUM_SUB: 16;----------------------------
2022-11-27 23:37:27 Epoch [30000/30000] Loss:0.001580 Loss_1:0.001575 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:20.760204s (9.74min in total, 0.00min remains)
2022-11-27 23:37:27 Testing & drawing...
2022-11-27 23:37:27 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:37:29 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=16/
2022-11-27 23:37:29 [Loss]
2022-11-27 23:37:29 NUM_SUB: 16; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:37:29 NUM_SUB: 16; Personalized parameter estimation: Parameter containing:
tensor([0.0664, 0.2780, 0.0086, 0.7180, 0.3074, 0.4948, 0.8560, 0.8964, 0.4556,
        0.0137, 0.0335, 0.0130, 0.8587, 0.1689, 0.0177, 1.1748, 0.6977, 0.8000,
        0.0113, 4.4319, 0.6816, 0.0224, 3.8217, 0.8742, 0.0201, 4.6908, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:37:29 NUM_SUB: 16------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:37:29 Testing & drawing...
2022-11-27 23:37:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:37:30 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=16/
2022-11-27 23:37:30 [Loss]
2022-11-27 23:37:30 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:37:30 General parameter estimation: Parameter containing:
tensor([0.0664, 0.2780, 0.0086, 0.7180, 0.3074, 0.4948, 0.8560, 0.8964, 0.4556,
        0.0137, 0.0335, 0.0130, 0.8587, 0.1689, 0.0177, 1.1748, 0.6977, 0.8000,
        0.0113, 4.4319, 0.6816, 0.0224, 3.8217, 0.8742, 0.0201, 4.6908, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:37:30 A: prod, degr, TonA, NonA
2022-11-27 23:37:30 [0.2136033  0.49884745 0.00992326 0.277626  ]
2022-11-27 23:37:30 T: prod, degr, AonT, NonT
2022-11-27 23:37:30 [0.3610657  0.49514532 0.09648457 0.04730441]
2022-11-27 23:37:30 N: AonN, TonN, ATonN
2022-11-27 23:37:30 [0.00849191 0.9658569  0.02565118]
2022-11-27 23:37:30 using cpu
2022-11-27 23:37:30 epoch = 30000
2022-11-27 23:37:30 epoch_step = 1000
2022-11-27 23:37:30 model_name = SimpleNetworkAD
2022-11-27 23:37:30 now_string = 2022-11-27-19-40-13
2022-11-27 23:37:30 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:37:30 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:37:30 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:37:30 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:37:30 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:37:30 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:37:50 NUM_SUB: 17;----------------------------
2022-11-27 23:37:50 Epoch [01000/30000] Loss:0.096187 Loss_1:0.090548 Loss_2:0.001870 Loss_3:0.000000 Lr:0.000909 Time:19.936720s (0.33min in total, 9.64min remains)
2022-11-27 23:38:10 NUM_SUB: 17;----------------------------
2022-11-27 23:38:10 Epoch [02000/30000] Loss:0.084990 Loss_1:0.083912 Loss_2:0.000665 Loss_3:0.000000 Lr:0.000833 Time:19.508782s (0.66min in total, 9.20min remains)
2022-11-27 23:38:29 NUM_SUB: 17;----------------------------
2022-11-27 23:38:29 Epoch [03000/30000] Loss:0.074417 Loss_1:0.073883 Loss_2:0.000307 Loss_3:0.000000 Lr:0.000769 Time:19.116174s (0.98min in total, 8.78min remains)
2022-11-27 23:38:48 NUM_SUB: 17;----------------------------
2022-11-27 23:38:48 Epoch [04000/30000] Loss:0.060172 Loss_1:0.059619 Loss_2:0.000351 Loss_3:0.000000 Lr:0.000714 Time:19.113084s (1.29min in total, 8.42min remains)
2022-11-27 23:39:07 NUM_SUB: 17;----------------------------
2022-11-27 23:39:07 Epoch [05000/30000] Loss:0.040798 Loss_1:0.040386 Loss_2:0.000246 Loss_3:0.000000 Lr:0.000667 Time:19.040305s (1.61min in total, 8.06min remains)
2022-11-27 23:39:26 NUM_SUB: 17;----------------------------
2022-11-27 23:39:26 Epoch [06000/30000] Loss:0.018767 Loss_1:0.018482 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000625 Time:19.325251s (1.93min in total, 7.74min remains)
2022-11-27 23:39:45 NUM_SUB: 17;----------------------------
2022-11-27 23:39:45 Epoch [07000/30000] Loss:0.004588 Loss_1:0.004423 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000588 Time:19.022704s (2.25min in total, 7.40min remains)
2022-11-27 23:40:05 NUM_SUB: 17;----------------------------
2022-11-27 23:40:05 Epoch [08000/30000] Loss:0.001254 Loss_1:0.001170 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000556 Time:19.758304s (2.58min in total, 7.10min remains)
2022-11-27 23:40:25 NUM_SUB: 17;----------------------------
2022-11-27 23:40:25 Epoch [09000/30000] Loss:0.000926 Loss_1:0.000865 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000526 Time:19.657679s (2.91min in total, 6.79min remains)
2022-11-27 23:40:44 NUM_SUB: 17;----------------------------
2022-11-27 23:40:44 Epoch [10000/30000] Loss:0.000771 Loss_1:0.000713 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000500 Time:19.430033s (3.23min in total, 6.46min remains)
2022-11-27 23:41:04 NUM_SUB: 17;----------------------------
2022-11-27 23:41:04 Epoch [11000/30000] Loss:0.000633 Loss_1:0.000576 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000476 Time:19.418164s (3.56min in total, 6.14min remains)
2022-11-27 23:41:23 NUM_SUB: 17;----------------------------
2022-11-27 23:41:23 Epoch [12000/30000] Loss:0.000449 Loss_1:0.000411 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000455 Time:19.351493s (3.88min in total, 5.82min remains)
2022-11-27 23:41:42 NUM_SUB: 17;----------------------------
2022-11-27 23:41:42 Epoch [13000/30000] Loss:0.000246 Loss_1:0.000224 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000435 Time:19.125953s (4.20min in total, 5.49min remains)
2022-11-27 23:42:02 NUM_SUB: 17;----------------------------
2022-11-27 23:42:02 Epoch [14000/30000] Loss:0.000109 Loss_1:0.000092 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000417 Time:19.452521s (4.52min in total, 5.17min remains)
2022-11-27 23:42:21 NUM_SUB: 17;----------------------------
2022-11-27 23:42:21 Epoch [15000/30000] Loss:0.000068 Loss_1:0.000052 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000400 Time:19.573900s (4.85min in total, 4.85min remains)
2022-11-27 23:42:41 NUM_SUB: 17;----------------------------
2022-11-27 23:42:41 Epoch [16000/30000] Loss:0.000076 Loss_1:0.000064 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:19.429946s (5.17min in total, 4.52min remains)
2022-11-27 23:43:00 NUM_SUB: 17;----------------------------
2022-11-27 23:43:00 Epoch [17000/30000] Loss:0.000055 Loss_1:0.000046 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.210333s (5.49min in total, 4.20min remains)
2022-11-27 23:43:20 NUM_SUB: 17;----------------------------
2022-11-27 23:43:20 Epoch [18000/30000] Loss:0.000052 Loss_1:0.000045 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:19.883082s (5.82min in total, 3.88min remains)
2022-11-27 23:43:40 NUM_SUB: 17;----------------------------
2022-11-27 23:43:40 Epoch [19000/30000] Loss:0.000049 Loss_1:0.000043 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.867188s (6.15min in total, 3.56min remains)
2022-11-27 23:44:00 NUM_SUB: 17;----------------------------
2022-11-27 23:44:00 Epoch [20000/30000] Loss:0.000049 Loss_1:0.000043 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:19.865565s (6.49min in total, 3.24min remains)
2022-11-27 23:44:19 NUM_SUB: 17;----------------------------
2022-11-27 23:44:19 Epoch [21000/30000] Loss:0.000044 Loss_1:0.000039 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:19.723025s (6.81min in total, 2.92min remains)
2022-11-27 23:44:39 NUM_SUB: 17;----------------------------
2022-11-27 23:44:39 Epoch [22000/30000] Loss:0.000041 Loss_1:0.000036 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:19.628375s (7.14min in total, 2.60min remains)
2022-11-27 23:44:58 NUM_SUB: 17;----------------------------
2022-11-27 23:44:58 Epoch [23000/30000] Loss:0.000039 Loss_1:0.000034 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:19.391186s (7.46min in total, 2.27min remains)
2022-11-27 23:45:18 NUM_SUB: 17;----------------------------
2022-11-27 23:45:18 Epoch [24000/30000] Loss:0.000037 Loss_1:0.000033 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:19.543297s (7.79min in total, 1.95min remains)
2022-11-27 23:45:38 NUM_SUB: 17;----------------------------
2022-11-27 23:45:38 Epoch [25000/30000] Loss:0.000036 Loss_1:0.000032 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.746809s (8.12min in total, 1.62min remains)
2022-11-27 23:45:57 NUM_SUB: 17;----------------------------
2022-11-27 23:45:57 Epoch [26000/30000] Loss:0.000036 Loss_1:0.000032 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.487468s (8.44min in total, 1.30min remains)
2022-11-27 23:46:17 NUM_SUB: 17;----------------------------
2022-11-27 23:46:17 Epoch [27000/30000] Loss:0.000036 Loss_1:0.000032 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.519286s (8.77min in total, 0.97min remains)
2022-11-27 23:46:36 NUM_SUB: 17;----------------------------
2022-11-27 23:46:36 Epoch [28000/30000] Loss:0.000035 Loss_1:0.000032 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.694959s (9.10min in total, 0.65min remains)
2022-11-27 23:46:56 NUM_SUB: 17;----------------------------
2022-11-27 23:46:56 Epoch [29000/30000] Loss:0.000035 Loss_1:0.000032 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.494572s (9.42min in total, 0.32min remains)
2022-11-27 23:47:15 NUM_SUB: 17;----------------------------
2022-11-27 23:47:15 Epoch [30000/30000] Loss:0.000035 Loss_1:0.000032 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:19.482284s (9.75min in total, 0.00min remains)
2022-11-27 23:47:15 Testing & drawing...
2022-11-27 23:47:15 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:47:17 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=17/
2022-11-27 23:47:17 [Loss]
2022-11-27 23:47:17 NUM_SUB: 17; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:47:17 NUM_SUB: 17; Personalized parameter estimation: Parameter containing:
tensor([0.0138, 0.0298, 0.0111, 0.6049, 0.3074, 0.0166, 3.3058, 0.8964, 0.4556,
        0.0139, 0.1491, 0.1350, 0.6264, 0.1689, 0.0178, 0.8711, 0.6977, 0.8000,
        0.0117, 4.2442, 0.6816, 0.0219, 3.3340, 0.8742, 0.0192, 4.3738, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:47:17 NUM_SUB: 17------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:47:17 Testing & drawing...
2022-11-27 23:47:17 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:47:19 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=17/
2022-11-27 23:47:19 [Loss]
2022-11-27 23:47:19 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:47:19 General parameter estimation: Parameter containing:
tensor([0.0138, 0.0298, 0.0111, 0.6049, 0.3074, 0.0166, 3.3058, 0.8964, 0.4556,
        0.0139, 0.1491, 0.1350, 0.6264, 0.1689, 0.0178, 0.8711, 0.6977, 0.8000,
        0.0117, 4.2442, 0.6816, 0.0219, 3.3340, 0.8742, 0.0192, 4.3738, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:47:19 A: prod, degr, TonA, NonA
2022-11-27 23:47:19 [0.3996098  0.48107934 0.09408972 0.02522115]
2022-11-27 23:47:19 T: prod, degr, AonT, NonT
2022-11-27 23:47:19 [0.09895755 0.5836399  0.261563   0.05583963]
2022-11-27 23:47:19 N: AonN, TonN, ATonN
2022-11-27 23:47:19 [0.01074655 0.96451366 0.02473981]
2022-11-27 23:47:19 using cpu
2022-11-27 23:47:19 epoch = 30000
2022-11-27 23:47:19 epoch_step = 1000
2022-11-27 23:47:19 model_name = SimpleNetworkAD
2022-11-27 23:47:19 now_string = 2022-11-27-19-40-13
2022-11-27 23:47:19 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:47:19 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:47:19 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:47:19 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:47:19 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:47:19 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:47:38 NUM_SUB: 18;----------------------------
2022-11-27 23:47:38 Epoch [01000/30000] Loss:0.062870 Loss_1:0.057379 Loss_2:0.001630 Loss_3:0.000000 Lr:0.000909 Time:19.576612s (0.33min in total, 9.46min remains)
2022-11-27 23:47:58 NUM_SUB: 18;----------------------------
2022-11-27 23:47:58 Epoch [02000/30000] Loss:0.055848 Loss_1:0.054956 Loss_2:0.000460 Loss_3:0.000000 Lr:0.000833 Time:19.401986s (0.65min in total, 9.10min remains)
2022-11-27 23:48:17 NUM_SUB: 18;----------------------------
2022-11-27 23:48:17 Epoch [03000/30000] Loss:0.051232 Loss_1:0.050966 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000769 Time:19.497802s (0.97min in total, 8.77min remains)
2022-11-27 23:48:36 NUM_SUB: 18;----------------------------
2022-11-27 23:48:36 Epoch [04000/30000] Loss:0.046404 Loss_1:0.046092 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000714 Time:18.949481s (1.29min in total, 8.39min remains)
2022-11-27 23:48:55 NUM_SUB: 18;----------------------------
2022-11-27 23:48:55 Epoch [05000/30000] Loss:0.039609 Loss_1:0.039316 Loss_2:0.000073 Loss_3:0.000000 Lr:0.000667 Time:19.229137s (1.61min in total, 8.06min remains)
2022-11-27 23:49:15 NUM_SUB: 18;----------------------------
2022-11-27 23:49:15 Epoch [06000/30000] Loss:0.030286 Loss_1:0.030030 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000625 Time:19.460712s (1.94min in total, 7.74min remains)
2022-11-27 23:49:35 NUM_SUB: 18;----------------------------
2022-11-27 23:49:35 Epoch [07000/30000] Loss:0.019114 Loss_1:0.018907 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000588 Time:19.589693s (2.26min in total, 7.43min remains)
2022-11-27 23:49:54 NUM_SUB: 18;----------------------------
2022-11-27 23:49:54 Epoch [08000/30000] Loss:0.009360 Loss_1:0.009194 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000556 Time:19.409097s (2.59min in total, 7.11min remains)
2022-11-27 23:50:13 NUM_SUB: 18;----------------------------
2022-11-27 23:50:13 Epoch [09000/30000] Loss:0.004200 Loss_1:0.004064 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000526 Time:18.741134s (2.90min in total, 6.76min remains)
2022-11-27 23:50:32 NUM_SUB: 18;----------------------------
2022-11-27 23:50:32 Epoch [10000/30000] Loss:0.002706 Loss_1:0.002591 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000500 Time:19.536821s (3.22min in total, 6.45min remains)
2022-11-27 23:50:52 NUM_SUB: 18;----------------------------
2022-11-27 23:50:52 Epoch [11000/30000] Loss:0.002352 Loss_1:0.002261 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000476 Time:19.515563s (3.55min in total, 6.13min remains)
2022-11-27 23:51:11 NUM_SUB: 18;----------------------------
2022-11-27 23:51:11 Epoch [12000/30000] Loss:0.002005 Loss_1:0.001953 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:19.368722s (3.87min in total, 5.81min remains)
2022-11-27 23:51:31 NUM_SUB: 18;----------------------------
2022-11-27 23:51:31 Epoch [13000/30000] Loss:0.001595 Loss_1:0.001529 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000435 Time:19.614104s (4.20min in total, 5.49min remains)
2022-11-27 23:51:50 NUM_SUB: 18;----------------------------
2022-11-27 23:51:50 Epoch [14000/30000] Loss:0.001408 Loss_1:0.001339 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000417 Time:19.282644s (4.52min in total, 5.17min remains)
2022-11-27 23:52:09 NUM_SUB: 18;----------------------------
2022-11-27 23:52:09 Epoch [15000/30000] Loss:0.001245 Loss_1:0.001185 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000400 Time:18.857484s (4.83min in total, 4.83min remains)
2022-11-27 23:52:29 NUM_SUB: 18;----------------------------
2022-11-27 23:52:29 Epoch [16000/30000] Loss:0.001174 Loss_1:0.001123 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000385 Time:19.921674s (5.17min in total, 4.52min remains)
2022-11-27 23:52:48 NUM_SUB: 18;----------------------------
2022-11-27 23:52:48 Epoch [17000/30000] Loss:0.001093 Loss_1:0.001072 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000370 Time:19.570810s (5.49min in total, 4.20min remains)
2022-11-27 23:53:08 NUM_SUB: 18;----------------------------
2022-11-27 23:53:08 Epoch [18000/30000] Loss:0.001050 Loss_1:0.001034 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000357 Time:19.538559s (5.82min in total, 3.88min remains)
2022-11-27 23:53:27 NUM_SUB: 18;----------------------------
2022-11-27 23:53:27 Epoch [19000/30000] Loss:0.001044 Loss_1:0.001032 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.562314s (6.14min in total, 3.56min remains)
2022-11-27 23:53:47 NUM_SUB: 18;----------------------------
2022-11-27 23:53:47 Epoch [20000/30000] Loss:0.001055 Loss_1:0.001047 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:19.317967s (6.47min in total, 3.23min remains)
2022-11-27 23:54:06 NUM_SUB: 18;----------------------------
2022-11-27 23:54:06 Epoch [21000/30000] Loss:0.001036 Loss_1:0.001030 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:18.956905s (6.78min in total, 2.91min remains)
2022-11-27 23:54:25 NUM_SUB: 18;----------------------------
2022-11-27 23:54:25 Epoch [22000/30000] Loss:0.001033 Loss_1:0.001029 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.431232s (7.11min in total, 2.58min remains)
2022-11-27 23:54:45 NUM_SUB: 18;----------------------------
2022-11-27 23:54:45 Epoch [23000/30000] Loss:0.001032 Loss_1:0.001028 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.990528s (7.44min in total, 2.26min remains)
2022-11-27 23:55:05 NUM_SUB: 18;----------------------------
2022-11-27 23:55:05 Epoch [24000/30000] Loss:0.001044 Loss_1:0.001042 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.519104s (7.76min in total, 1.94min remains)
2022-11-27 23:55:24 NUM_SUB: 18;----------------------------
2022-11-27 23:55:24 Epoch [25000/30000] Loss:0.001033 Loss_1:0.001030 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.108422s (8.08min in total, 1.62min remains)
2022-11-27 23:55:43 NUM_SUB: 18;----------------------------
2022-11-27 23:55:43 Epoch [26000/30000] Loss:0.001034 Loss_1:0.001032 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.095714s (8.40min in total, 1.29min remains)
2022-11-27 23:56:02 NUM_SUB: 18;----------------------------
2022-11-27 23:56:02 Epoch [27000/30000] Loss:0.001030 Loss_1:0.001027 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:18.991834s (8.72min in total, 0.97min remains)
2022-11-27 23:56:21 NUM_SUB: 18;----------------------------
2022-11-27 23:56:21 Epoch [28000/30000] Loss:0.001031 Loss_1:0.001029 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.911683s (9.03min in total, 0.65min remains)
2022-11-27 23:56:40 NUM_SUB: 18;----------------------------
2022-11-27 23:56:40 Epoch [29000/30000] Loss:0.001029 Loss_1:0.001027 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.120513s (9.35min in total, 0.32min remains)
2022-11-27 23:56:59 NUM_SUB: 18;----------------------------
2022-11-27 23:56:59 Epoch [30000/30000] Loss:0.001030 Loss_1:0.001028 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.732034s (9.66min in total, 0.00min remains)
2022-11-27 23:56:59 Testing & drawing...
2022-11-27 23:56:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:57:00 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=18/
2022-11-27 23:57:00 [Loss]
2022-11-27 23:57:00 NUM_SUB: 18; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:57:00 NUM_SUB: 18; Personalized parameter estimation: Parameter containing:
tensor([0.0134, 0.0400, 0.0109, 0.8614, 0.3074, 0.0094, 1.3643, 0.8964, 0.4556,
        0.0134, 0.0264, 0.0139, 0.9841, 0.1689, 0.0093, 2.2098, 0.6977, 0.8000,
        0.0117, 4.2945, 0.6816, 0.0208, 4.0936, 0.8742, 0.0198, 4.8446, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:57:00 NUM_SUB: 18------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-27 23:57:00 Testing & drawing...
2022-11-27 23:57:00 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-27 23:57:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=18/
2022-11-27 23:57:02 [Loss]
2022-11-27 23:57:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-27 23:57:02 General parameter estimation: Parameter containing:
tensor([0.0134, 0.0400, 0.0109, 0.8614, 0.3074, 0.0094, 1.3643, 0.8964, 0.4556,
        0.0134, 0.0264, 0.0139, 0.9841, 0.1689, 0.0093, 2.2098, 0.6977, 0.8000,
        0.0117, 4.2945, 0.6816, 0.0208, 4.0936, 0.8742, 0.0198, 4.8446, 0.9527,
        0.0362], requires_grad=True);
2022-11-27 23:57:02 A: prod, degr, TonA, NonA
2022-11-27 23:57:02 [0.35974225 0.49650073 0.10345667 0.04030038]
2022-11-27 23:57:02 T: prod, degr, AonT, NonT
2022-11-27 23:57:02 [0.44293344 0.40111744 0.13539249 0.02055665]
2022-11-27 23:57:02 N: AonN, TonN, ATonN
2022-11-27 23:57:02 [0.0067192  0.9675097  0.02577107]
2022-11-27 23:57:02 using cpu
2022-11-27 23:57:02 epoch = 30000
2022-11-27 23:57:02 epoch_step = 1000
2022-11-27 23:57:02 model_name = SimpleNetworkAD
2022-11-27 23:57:02 now_string = 2022-11-27-19-40-13
2022-11-27 23:57:02 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-27 23:57:02 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-27 23:57:02 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-27 23:57:02 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-27 23:57:02 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-27 23:57:02 --------------------------------------------------training start--------------------------------------------------
2022-11-27 23:57:21 NUM_SUB: 19;----------------------------
2022-11-27 23:57:21 Epoch [01000/30000] Loss:0.020681 Loss_1:0.014255 Loss_2:0.002548 Loss_3:0.000000 Lr:0.000909 Time:18.994911s (0.32min in total, 9.18min remains)
2022-11-27 23:57:40 NUM_SUB: 19;----------------------------
2022-11-27 23:57:40 Epoch [02000/30000] Loss:0.015383 Loss_1:0.013953 Loss_2:0.000983 Loss_3:0.000000 Lr:0.000833 Time:19.075042s (0.63min in total, 8.88min remains)
2022-11-27 23:57:59 NUM_SUB: 19;----------------------------
2022-11-27 23:57:59 Epoch [03000/30000] Loss:0.013722 Loss_1:0.013280 Loss_2:0.000352 Loss_3:0.000000 Lr:0.000769 Time:18.813120s (0.95min in total, 8.53min remains)
2022-11-27 23:58:18 NUM_SUB: 19;----------------------------
2022-11-27 23:58:18 Epoch [04000/30000] Loss:0.012581 Loss_1:0.012349 Loss_2:0.000157 Loss_3:0.000000 Lr:0.000714 Time:19.243892s (1.27min in total, 8.25min remains)
2022-11-27 23:58:38 NUM_SUB: 19;----------------------------
2022-11-27 23:58:38 Epoch [05000/30000] Loss:0.011346 Loss_1:0.011136 Loss_2:0.000128 Loss_3:0.000000 Lr:0.000667 Time:19.397963s (1.59min in total, 7.96min remains)
2022-11-27 23:58:57 NUM_SUB: 19;----------------------------
2022-11-27 23:58:57 Epoch [06000/30000] Loss:0.009709 Loss_1:0.009526 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000625 Time:19.033319s (1.91min in total, 7.64min remains)
2022-11-27 23:59:17 NUM_SUB: 19;----------------------------
2022-11-27 23:59:17 Epoch [07000/30000] Loss:0.007671 Loss_1:0.007511 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000588 Time:19.978766s (2.24min in total, 7.37min remains)
2022-11-27 23:59:36 NUM_SUB: 19;----------------------------
2022-11-27 23:59:36 Epoch [08000/30000] Loss:0.005328 Loss_1:0.005197 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000556 Time:19.503931s (2.57min in total, 7.06min remains)
2022-11-27 23:59:55 NUM_SUB: 19;----------------------------
2022-11-27 23:59:55 Epoch [09000/30000] Loss:0.003204 Loss_1:0.003093 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000526 Time:18.869026s (2.88min in total, 6.72min remains)
2022-11-28 00:00:15 NUM_SUB: 19;----------------------------
2022-11-28 00:00:15 Epoch [10000/30000] Loss:0.002079 Loss_1:0.001981 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000500 Time:20.511894s (3.22min in total, 6.45min remains)
2022-11-28 00:00:36 NUM_SUB: 19;----------------------------
2022-11-28 00:00:36 Epoch [11000/30000] Loss:0.001692 Loss_1:0.001603 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000476 Time:20.515506s (3.57min in total, 6.16min remains)
2022-11-28 00:00:55 NUM_SUB: 19;----------------------------
2022-11-28 00:00:55 Epoch [12000/30000] Loss:0.001268 Loss_1:0.001215 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000455 Time:18.873728s (3.88min in total, 5.82min remains)
2022-11-28 00:01:14 NUM_SUB: 19;----------------------------
2022-11-28 00:01:14 Epoch [13000/30000] Loss:0.000697 Loss_1:0.000663 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:18.903355s (4.20min in total, 5.49min remains)
2022-11-28 00:01:33 NUM_SUB: 19;----------------------------
2022-11-28 00:01:33 Epoch [14000/30000] Loss:0.000346 Loss_1:0.000316 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:19.077599s (4.51min in total, 5.16min remains)
2022-11-28 00:01:52 NUM_SUB: 19;----------------------------
2022-11-28 00:01:52 Epoch [15000/30000] Loss:0.000251 Loss_1:0.000229 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000400 Time:19.241299s (4.83min in total, 4.83min remains)
2022-11-28 00:02:11 NUM_SUB: 19;----------------------------
2022-11-28 00:02:11 Epoch [16000/30000] Loss:0.000195 Loss_1:0.000179 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:18.967464s (5.15min in total, 4.51min remains)
2022-11-28 00:02:30 NUM_SUB: 19;----------------------------
2022-11-28 00:02:30 Epoch [17000/30000] Loss:0.000176 Loss_1:0.000149 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000370 Time:19.285250s (5.47min in total, 4.18min remains)
2022-11-28 00:02:49 NUM_SUB: 19;----------------------------
2022-11-28 00:02:49 Epoch [18000/30000] Loss:0.000151 Loss_1:0.000142 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:18.716534s (5.78min in total, 3.86min remains)
2022-11-28 00:03:08 NUM_SUB: 19;----------------------------
2022-11-28 00:03:08 Epoch [19000/30000] Loss:0.000149 Loss_1:0.000142 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:19.251618s (6.10min in total, 3.53min remains)
2022-11-28 00:03:27 NUM_SUB: 19;----------------------------
2022-11-28 00:03:27 Epoch [20000/30000] Loss:0.000148 Loss_1:0.000142 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:19.144029s (6.42min in total, 3.21min remains)
2022-11-28 00:03:46 NUM_SUB: 19;----------------------------
2022-11-28 00:03:46 Epoch [21000/30000] Loss:0.000147 Loss_1:0.000142 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:18.576471s (6.73min in total, 2.89min remains)
2022-11-28 00:04:05 NUM_SUB: 19;----------------------------
2022-11-28 00:04:05 Epoch [22000/30000] Loss:0.000146 Loss_1:0.000142 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:18.808510s (7.05min in total, 2.56min remains)
2022-11-28 00:04:24 NUM_SUB: 19;----------------------------
2022-11-28 00:04:24 Epoch [23000/30000] Loss:0.000146 Loss_1:0.000142 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.824899s (7.36min in total, 2.24min remains)
2022-11-28 00:04:42 NUM_SUB: 19;----------------------------
2022-11-28 00:04:42 Epoch [24000/30000] Loss:0.000145 Loss_1:0.000142 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.651022s (7.67min in total, 1.92min remains)
2022-11-28 00:05:01 NUM_SUB: 19;----------------------------
2022-11-28 00:05:01 Epoch [25000/30000] Loss:0.000149 Loss_1:0.000146 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.144117s (7.99min in total, 1.60min remains)
2022-11-28 00:05:21 NUM_SUB: 19;----------------------------
2022-11-28 00:05:21 Epoch [26000/30000] Loss:0.000145 Loss_1:0.000142 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.174232s (8.31min in total, 1.28min remains)
2022-11-28 00:05:40 NUM_SUB: 19;----------------------------
2022-11-28 00:05:40 Epoch [27000/30000] Loss:0.000145 Loss_1:0.000142 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:18.944945s (8.63min in total, 0.96min remains)
2022-11-28 00:05:58 NUM_SUB: 19;----------------------------
2022-11-28 00:05:58 Epoch [28000/30000] Loss:0.000144 Loss_1:0.000142 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.774597s (8.94min in total, 0.64min remains)
2022-11-28 00:06:17 NUM_SUB: 19;----------------------------
2022-11-28 00:06:17 Epoch [29000/30000] Loss:0.000144 Loss_1:0.000142 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.527023s (9.25min in total, 0.32min remains)
2022-11-28 00:06:36 NUM_SUB: 19;----------------------------
2022-11-28 00:06:36 Epoch [30000/30000] Loss:0.000144 Loss_1:0.000142 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.978912s (9.56min in total, 0.00min remains)
2022-11-28 00:06:36 Testing & drawing...
2022-11-28 00:06:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:06:37 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=19/
2022-11-28 00:06:37 [Loss]
2022-11-28 00:06:38 NUM_SUB: 19; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:06:38 NUM_SUB: 19; Personalized parameter estimation: Parameter containing:
tensor([0.0201, 0.0345, 0.0095, 1.2355, 0.3074, 0.0123, 2.5815, 0.8964, 0.4556,
        0.0140, 0.0430, 0.0135, 0.8303, 0.1689, 0.0179, 0.4056, 0.6977, 0.8000,
        0.0118, 4.0397, 0.6816, 0.0221, 3.5972, 0.8742, 0.0201, 4.3587, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:06:38 NUM_SUB: 19------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:06:38 Testing & drawing...
2022-11-28 00:06:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:06:39 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=19/
2022-11-28 00:06:39 [Loss]
2022-11-28 00:06:39 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:06:39 General parameter estimation: Parameter containing:
tensor([0.0201, 0.0345, 0.0095, 1.2355, 0.3074, 0.0123, 2.5815, 0.8964, 0.4556,
        0.0140, 0.0430, 0.0135, 0.8303, 0.1689, 0.0179, 0.4056, 0.6977, 0.8000,
        0.0118, 4.0397, 0.6816, 0.0221, 3.5972, 0.8742, 0.0201, 4.3587, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:06:39 A: prod, degr, TonA, NonA
2022-11-28 00:06:39 [0.47037953 0.47410658 0.04547241 0.01004152]
2022-11-28 00:06:39 T: prod, degr, AonT, NonT
2022-11-28 00:06:39 [0.26125732 0.46586683 0.08875191 0.18412393]
2022-11-28 00:06:39 N: AonN, TonN, ATonN
2022-11-28 00:06:39 [0.01186162 0.95195776 0.03618064]
2022-11-28 00:06:39 using cpu
2022-11-28 00:06:39 epoch = 30000
2022-11-28 00:06:39 epoch_step = 1000
2022-11-28 00:06:39 model_name = SimpleNetworkAD
2022-11-28 00:06:39 now_string = 2022-11-27-19-40-13
2022-11-28 00:06:39 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:06:39 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:06:39 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:06:39 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:06:39 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:06:39 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:06:58 NUM_SUB: 20;----------------------------
2022-11-28 00:06:58 Epoch [01000/30000] Loss:0.113783 Loss_1:0.108189 Loss_2:0.001591 Loss_3:0.000000 Lr:0.000909 Time:18.609324s (0.31min in total, 8.99min remains)
2022-11-28 00:07:17 NUM_SUB: 20;----------------------------
2022-11-28 00:07:17 Epoch [02000/30000] Loss:0.105707 Loss_1:0.104711 Loss_2:0.000440 Loss_3:0.000000 Lr:0.000833 Time:18.866171s (0.62min in total, 8.74min remains)
2022-11-28 00:07:36 NUM_SUB: 20;----------------------------
2022-11-28 00:07:36 Epoch [03000/30000] Loss:0.099236 Loss_1:0.098745 Loss_2:0.000100 Loss_3:0.000000 Lr:0.000769 Time:18.945009s (0.94min in total, 8.46min remains)
2022-11-28 00:07:54 NUM_SUB: 20;----------------------------
2022-11-28 00:07:54 Epoch [04000/30000] Loss:0.090903 Loss_1:0.090331 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000714 Time:18.616817s (1.25min in total, 8.13min remains)
2022-11-28 00:08:13 NUM_SUB: 20;----------------------------
2022-11-28 00:08:13 Epoch [05000/30000] Loss:0.078657 Loss_1:0.078120 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000667 Time:18.697741s (1.56min in total, 7.81min remains)
2022-11-28 00:08:32 NUM_SUB: 20;----------------------------
2022-11-28 00:08:32 Epoch [06000/30000] Loss:0.060429 Loss_1:0.059946 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000625 Time:18.867289s (1.88min in total, 7.51min remains)
2022-11-28 00:08:51 NUM_SUB: 20;----------------------------
2022-11-28 00:08:51 Epoch [07000/30000] Loss:0.035016 Loss_1:0.034602 Loss_2:0.000144 Loss_3:0.000000 Lr:0.000588 Time:18.631003s (2.19min in total, 7.19min remains)
2022-11-28 00:09:09 NUM_SUB: 20;----------------------------
2022-11-28 00:09:09 Epoch [08000/30000] Loss:0.010859 Loss_1:0.010071 Loss_2:0.000673 Loss_3:0.000000 Lr:0.000556 Time:18.542188s (2.50min in total, 6.87min remains)
2022-11-28 00:09:28 NUM_SUB: 20;----------------------------
2022-11-28 00:09:28 Epoch [09000/30000] Loss:0.000840 Loss_1:0.000619 Loss_2:0.000206 Loss_3:0.000000 Lr:0.000526 Time:18.843229s (2.81min in total, 6.56min remains)
2022-11-28 00:09:47 NUM_SUB: 20;----------------------------
2022-11-28 00:09:47 Epoch [10000/30000] Loss:0.000199 Loss_1:0.000055 Loss_2:0.000145 Loss_3:0.000000 Lr:0.000500 Time:19.404749s (3.13min in total, 6.27min remains)
2022-11-28 00:10:06 NUM_SUB: 20;----------------------------
2022-11-28 00:10:06 Epoch [11000/30000] Loss:0.000129 Loss_1:0.000036 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000476 Time:18.746682s (3.45min in total, 5.95min remains)
2022-11-28 00:10:25 NUM_SUB: 20;----------------------------
2022-11-28 00:10:25 Epoch [12000/30000] Loss:0.000086 Loss_1:0.000025 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000455 Time:18.959640s (3.76min in total, 5.64min remains)
2022-11-28 00:10:44 NUM_SUB: 20;----------------------------
2022-11-28 00:10:44 Epoch [13000/30000] Loss:0.000062 Loss_1:0.000020 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000435 Time:18.876342s (4.08min in total, 5.33min remains)
2022-11-28 00:11:03 NUM_SUB: 20;----------------------------
2022-11-28 00:11:03 Epoch [14000/30000] Loss:0.000048 Loss_1:0.000017 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:18.626759s (4.39min in total, 5.01min remains)
2022-11-28 00:11:22 NUM_SUB: 20;----------------------------
2022-11-28 00:11:22 Epoch [15000/30000] Loss:0.000037 Loss_1:0.000015 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000400 Time:18.888493s (4.70min in total, 4.70min remains)
2022-11-28 00:11:41 NUM_SUB: 20;----------------------------
2022-11-28 00:11:41 Epoch [16000/30000] Loss:0.000032 Loss_1:0.000015 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:19.242373s (5.02min in total, 4.40min remains)
2022-11-28 00:12:00 NUM_SUB: 20;----------------------------
2022-11-28 00:12:00 Epoch [17000/30000] Loss:0.000024 Loss_1:0.000012 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:18.882010s (5.34min in total, 4.08min remains)
2022-11-28 00:12:19 NUM_SUB: 20;----------------------------
2022-11-28 00:12:19 Epoch [18000/30000] Loss:0.000021 Loss_1:0.000012 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:19.351709s (5.66min in total, 3.77min remains)
2022-11-28 00:12:38 NUM_SUB: 20;----------------------------
2022-11-28 00:12:38 Epoch [19000/30000] Loss:0.000019 Loss_1:0.000012 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:18.962248s (5.98min in total, 3.46min remains)
2022-11-28 00:12:57 NUM_SUB: 20;----------------------------
2022-11-28 00:12:57 Epoch [20000/30000] Loss:0.000017 Loss_1:0.000012 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.168543s (6.30min in total, 3.15min remains)
2022-11-28 00:13:16 NUM_SUB: 20;----------------------------
2022-11-28 00:13:16 Epoch [21000/30000] Loss:0.000016 Loss_1:0.000012 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:18.950938s (6.61min in total, 2.83min remains)
2022-11-28 00:13:35 NUM_SUB: 20;----------------------------
2022-11-28 00:13:35 Epoch [22000/30000] Loss:0.000015 Loss_1:0.000012 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.807794s (6.93min in total, 2.52min remains)
2022-11-28 00:13:54 NUM_SUB: 20;----------------------------
2022-11-28 00:13:54 Epoch [23000/30000] Loss:0.000014 Loss_1:0.000011 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.347828s (7.25min in total, 2.21min remains)
2022-11-28 00:14:13 NUM_SUB: 20;----------------------------
2022-11-28 00:14:13 Epoch [24000/30000] Loss:0.000014 Loss_1:0.000011 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.816719s (7.56min in total, 1.89min remains)
2022-11-28 00:14:32 NUM_SUB: 20;----------------------------
2022-11-28 00:14:32 Epoch [25000/30000] Loss:0.000013 Loss_1:0.000011 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.793646s (7.87min in total, 1.57min remains)
2022-11-28 00:14:51 NUM_SUB: 20;----------------------------
2022-11-28 00:14:51 Epoch [26000/30000] Loss:0.000019 Loss_1:0.000017 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:18.846846s (8.19min in total, 1.26min remains)
2022-11-28 00:15:09 NUM_SUB: 20;----------------------------
2022-11-28 00:15:09 Epoch [27000/30000] Loss:0.000013 Loss_1:0.000011 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.694083s (8.50min in total, 0.94min remains)
2022-11-28 00:15:29 NUM_SUB: 20;----------------------------
2022-11-28 00:15:29 Epoch [28000/30000] Loss:0.000013 Loss_1:0.000012 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.121575s (8.82min in total, 0.63min remains)
2022-11-28 00:15:48 NUM_SUB: 20;----------------------------
2022-11-28 00:15:48 Epoch [29000/30000] Loss:0.000012 Loss_1:0.000011 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.235245s (9.14min in total, 0.32min remains)
2022-11-28 00:16:07 NUM_SUB: 20;----------------------------
2022-11-28 00:16:07 Epoch [30000/30000] Loss:0.000012 Loss_1:0.000011 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.369082s (9.46min in total, 0.00min remains)
2022-11-28 00:16:07 Testing & drawing...
2022-11-28 00:16:07 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:16:09 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=20/
2022-11-28 00:16:09 [Loss]
2022-11-28 00:16:09 NUM_SUB: 20; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:16:09 NUM_SUB: 20; Personalized parameter estimation: Parameter containing:
tensor([0.3388, 0.8995, 0.0101, 0.1465, 0.3074, 0.0527, 0.7732, 0.8964, 0.4556,
        0.0087, 0.0322, 0.0152, 0.2438, 0.1689, 0.0176, 0.6246, 0.6977, 0.8000,
        0.0121, 4.0443, 0.6816, 0.0113, 4.2793, 0.8742, 0.0191, 5.0663, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:16:09 NUM_SUB: 20------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:16:09 Testing & drawing...
2022-11-28 00:16:09 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:16:10 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=20/
2022-11-28 00:16:10 [Loss]
2022-11-28 00:16:10 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:16:10 General parameter estimation: Parameter containing:
tensor([0.3388, 0.8995, 0.0101, 0.1465, 0.3074, 0.0527, 0.7732, 0.8964, 0.4556,
        0.0087, 0.0322, 0.0152, 0.2438, 0.1689, 0.0176, 0.6246, 0.6977, 0.8000,
        0.0121, 4.0443, 0.6816, 0.0113, 4.2793, 0.8742, 0.0191, 5.0663, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:16:10 A: prod, degr, TonA, NonA
2022-11-28 00:16:10 [0.45952505 0.4999045  0.01335702 0.02721342]
2022-11-28 00:16:10 T: prod, degr, AonT, NonT
2022-11-28 00:16:10 [0.19494958 0.29565012 0.31880078 0.19059952]
2022-11-28 00:16:10 N: AonN, TonN, ATonN
2022-11-28 00:16:10 [0.01039462 0.9250116  0.06459381]
2022-11-28 00:16:11 using cpu
2022-11-28 00:16:11 epoch = 30000
2022-11-28 00:16:11 epoch_step = 1000
2022-11-28 00:16:11 model_name = SimpleNetworkAD
2022-11-28 00:16:11 now_string = 2022-11-27-19-40-13
2022-11-28 00:16:11 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:16:11 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:16:11 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:16:11 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:16:11 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:16:11 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:16:30 NUM_SUB: 21;----------------------------
2022-11-28 00:16:30 Epoch [01000/30000] Loss:0.081490 Loss_1:0.076041 Loss_2:0.001771 Loss_3:0.000000 Lr:0.000909 Time:19.322726s (0.32min in total, 9.34min remains)
2022-11-28 00:16:49 NUM_SUB: 21;----------------------------
2022-11-28 00:16:49 Epoch [02000/30000] Loss:0.069896 Loss_1:0.068892 Loss_2:0.000653 Loss_3:0.000000 Lr:0.000833 Time:19.171850s (0.64min in total, 8.98min remains)
2022-11-28 00:17:09 NUM_SUB: 21;----------------------------
2022-11-28 00:17:09 Epoch [03000/30000] Loss:0.059815 Loss_1:0.059173 Loss_2:0.000357 Loss_3:0.000000 Lr:0.000769 Time:19.722858s (0.97min in total, 8.73min remains)
2022-11-28 00:17:29 NUM_SUB: 21;----------------------------
2022-11-28 00:17:29 Epoch [04000/30000] Loss:0.047272 Loss_1:0.046692 Loss_2:0.000342 Loss_3:0.000000 Lr:0.000714 Time:20.095896s (1.31min in total, 8.48min remains)
2022-11-28 00:17:48 NUM_SUB: 21;----------------------------
2022-11-28 00:17:48 Epoch [05000/30000] Loss:0.031620 Loss_1:0.031181 Loss_2:0.000268 Loss_3:0.000000 Lr:0.000667 Time:19.506334s (1.63min in total, 8.15min remains)
2022-11-28 00:18:08 NUM_SUB: 21;----------------------------
2022-11-28 00:18:08 Epoch [06000/30000] Loss:0.016706 Loss_1:0.016447 Loss_2:0.000169 Loss_3:0.000000 Lr:0.000625 Time:19.156581s (1.95min in total, 7.80min remains)
2022-11-28 00:18:27 NUM_SUB: 21;----------------------------
2022-11-28 00:18:27 Epoch [07000/30000] Loss:0.008703 Loss_1:0.008562 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000588 Time:19.342316s (2.27min in total, 7.47min remains)
2022-11-28 00:18:46 NUM_SUB: 21;----------------------------
2022-11-28 00:18:46 Epoch [08000/30000] Loss:0.005805 Loss_1:0.005711 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000556 Time:19.419423s (2.60min in total, 7.14min remains)
2022-11-28 00:19:06 NUM_SUB: 21;----------------------------
2022-11-28 00:19:06 Epoch [09000/30000] Loss:0.003696 Loss_1:0.003592 Loss_2:0.000103 Loss_3:0.000000 Lr:0.000526 Time:19.162679s (2.92min in total, 6.80min remains)
2022-11-28 00:19:25 NUM_SUB: 21;----------------------------
2022-11-28 00:19:25 Epoch [10000/30000] Loss:0.002040 Loss_1:0.001929 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000500 Time:19.535023s (3.24min in total, 6.48min remains)
2022-11-28 00:19:45 NUM_SUB: 21;----------------------------
2022-11-28 00:19:45 Epoch [11000/30000] Loss:0.001124 Loss_1:0.001047 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000476 Time:19.504452s (3.57min in total, 6.16min remains)
2022-11-28 00:20:04 NUM_SUB: 21;----------------------------
2022-11-28 00:20:04 Epoch [12000/30000] Loss:0.000673 Loss_1:0.000630 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000455 Time:18.956154s (3.88min in total, 5.82min remains)
2022-11-28 00:20:23 NUM_SUB: 21;----------------------------
2022-11-28 00:20:23 Epoch [13000/30000] Loss:0.000527 Loss_1:0.000498 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:19.082577s (4.20min in total, 5.49min remains)
2022-11-28 00:20:42 NUM_SUB: 21;----------------------------
2022-11-28 00:20:42 Epoch [14000/30000] Loss:0.000478 Loss_1:0.000454 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:19.002467s (4.52min in total, 5.16min remains)
2022-11-28 00:21:00 NUM_SUB: 21;----------------------------
2022-11-28 00:21:00 Epoch [15000/30000] Loss:0.000440 Loss_1:0.000420 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:18.522633s (4.83min in total, 4.83min remains)
2022-11-28 00:21:19 NUM_SUB: 21;----------------------------
2022-11-28 00:21:19 Epoch [16000/30000] Loss:0.000418 Loss_1:0.000402 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:19.224821s (5.15min in total, 4.50min remains)
2022-11-28 00:21:38 NUM_SUB: 21;----------------------------
2022-11-28 00:21:38 Epoch [17000/30000] Loss:0.000407 Loss_1:0.000395 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000370 Time:18.989989s (5.46min in total, 4.18min remains)
2022-11-28 00:21:57 NUM_SUB: 21;----------------------------
2022-11-28 00:21:57 Epoch [18000/30000] Loss:0.000402 Loss_1:0.000392 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:18.929973s (5.78min in total, 3.85min remains)
2022-11-28 00:22:16 NUM_SUB: 21;----------------------------
2022-11-28 00:22:16 Epoch [19000/30000] Loss:0.000398 Loss_1:0.000389 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:18.998338s (6.09min in total, 3.53min remains)
2022-11-28 00:22:35 NUM_SUB: 21;----------------------------
2022-11-28 00:22:35 Epoch [20000/30000] Loss:0.000394 Loss_1:0.000387 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:19.230014s (6.41min in total, 3.21min remains)
2022-11-28 00:22:54 NUM_SUB: 21;----------------------------
2022-11-28 00:22:54 Epoch [21000/30000] Loss:0.000390 Loss_1:0.000383 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:18.747254s (6.73min in total, 2.88min remains)
2022-11-28 00:23:13 NUM_SUB: 21;----------------------------
2022-11-28 00:23:13 Epoch [22000/30000] Loss:0.000386 Loss_1:0.000381 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:18.759385s (7.04min in total, 2.56min remains)
2022-11-28 00:23:32 NUM_SUB: 21;----------------------------
2022-11-28 00:23:32 Epoch [23000/30000] Loss:0.000385 Loss_1:0.000380 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:18.987283s (7.36min in total, 2.24min remains)
2022-11-28 00:23:51 NUM_SUB: 21;----------------------------
2022-11-28 00:23:51 Epoch [24000/30000] Loss:0.000384 Loss_1:0.000379 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.707982s (7.67min in total, 1.92min remains)
2022-11-28 00:24:10 NUM_SUB: 21;----------------------------
2022-11-28 00:24:10 Epoch [25000/30000] Loss:0.000382 Loss_1:0.000377 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:18.826907s (7.98min in total, 1.60min remains)
2022-11-28 00:24:28 NUM_SUB: 21;----------------------------
2022-11-28 00:24:28 Epoch [26000/30000] Loss:0.000381 Loss_1:0.000376 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:18.930533s (8.30min in total, 1.28min remains)
2022-11-28 00:24:47 NUM_SUB: 21;----------------------------
2022-11-28 00:24:47 Epoch [27000/30000] Loss:0.000380 Loss_1:0.000376 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:18.834799s (8.61min in total, 0.96min remains)
2022-11-28 00:25:06 NUM_SUB: 21;----------------------------
2022-11-28 00:25:06 Epoch [28000/30000] Loss:0.000379 Loss_1:0.000375 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:18.785527s (8.92min in total, 0.64min remains)
2022-11-28 00:25:25 NUM_SUB: 21;----------------------------
2022-11-28 00:25:25 Epoch [29000/30000] Loss:0.000378 Loss_1:0.000375 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.239315s (9.25min in total, 0.32min remains)
2022-11-28 00:25:45 NUM_SUB: 21;----------------------------
2022-11-28 00:25:45 Epoch [30000/30000] Loss:0.000378 Loss_1:0.000375 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:19.526889s (9.57min in total, 0.00min remains)
2022-11-28 00:25:45 Testing & drawing...
2022-11-28 00:25:45 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:25:46 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=21/
2022-11-28 00:25:46 [Loss]
2022-11-28 00:25:47 NUM_SUB: 21; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:25:47 NUM_SUB: 21; Personalized parameter estimation: Parameter containing:
tensor([0.0165, 0.0420, 0.0105, 1.0974, 0.3074, 0.0173, 3.6084, 0.8964, 0.4556,
        0.0145, 0.0306, 0.0138, 0.9156, 0.1689, 0.0173, 2.9800, 0.6977, 0.8000,
        0.0099, 4.1062, 0.6816, 0.0220, 3.9004, 0.8742, 0.0169, 4.6350, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:25:47 NUM_SUB: 21------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:25:47 Testing & drawing...
2022-11-28 00:25:47 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:25:48 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=21/
2022-11-28 00:25:48 [Loss]
2022-11-28 00:25:48 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:25:48 General parameter estimation: Parameter containing:
tensor([0.0165, 0.0420, 0.0105, 1.0974, 0.3074, 0.0173, 3.6084, 0.8964, 0.4556,
        0.0145, 0.0306, 0.0138, 0.9156, 0.1689, 0.0173, 2.9800, 0.6977, 0.8000,
        0.0099, 4.1062, 0.6816, 0.0220, 3.9004, 0.8742, 0.0169, 4.6350, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:25:48 A: prod, degr, TonA, NonA
2022-11-28 00:25:48 [0.4463503  0.48238838 0.05917896 0.01208237]
2022-11-28 00:25:48 T: prod, degr, AonT, NonT
2022-11-28 00:25:48 [0.45312953 0.40826067 0.11825923 0.02035057]
2022-11-28 00:25:48 N: AonN, TonN, ATonN
2022-11-28 00:25:48 [0.0053171  0.97547054 0.01921239]
2022-11-28 00:25:48 using cpu
2022-11-28 00:25:48 epoch = 30000
2022-11-28 00:25:48 epoch_step = 1000
2022-11-28 00:25:48 model_name = SimpleNetworkAD
2022-11-28 00:25:48 now_string = 2022-11-27-19-40-13
2022-11-28 00:25:48 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:25:48 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:25:48 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:25:48 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:25:48 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:25:48 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:26:08 NUM_SUB: 22;----------------------------
2022-11-28 00:26:08 Epoch [01000/30000] Loss:0.021682 Loss_1:0.016542 Loss_2:0.001464 Loss_3:0.000000 Lr:0.000909 Time:19.172796s (0.32min in total, 9.27min remains)
2022-11-28 00:26:27 NUM_SUB: 22;----------------------------
2022-11-28 00:26:27 Epoch [02000/30000] Loss:0.016076 Loss_1:0.015321 Loss_2:0.000394 Loss_3:0.000000 Lr:0.000833 Time:19.157727s (0.64min in total, 8.94min remains)
2022-11-28 00:26:45 NUM_SUB: 22;----------------------------
2022-11-28 00:26:45 Epoch [03000/30000] Loss:0.013897 Loss_1:0.013742 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000769 Time:18.674255s (0.95min in total, 8.55min remains)
2022-11-28 00:27:05 NUM_SUB: 22;----------------------------
2022-11-28 00:27:05 Epoch [04000/30000] Loss:0.011854 Loss_1:0.011785 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000714 Time:19.704033s (1.28min in total, 8.31min remains)
2022-11-28 00:27:24 NUM_SUB: 22;----------------------------
2022-11-28 00:27:24 Epoch [05000/30000] Loss:0.009872 Loss_1:0.009787 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000667 Time:18.701450s (1.59min in total, 7.95min remains)
2022-11-28 00:27:43 NUM_SUB: 22;----------------------------
2022-11-28 00:27:43 Epoch [06000/30000] Loss:0.007872 Loss_1:0.007801 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000625 Time:19.086382s (1.91min in total, 7.63min remains)
2022-11-28 00:28:02 NUM_SUB: 22;----------------------------
2022-11-28 00:28:02 Epoch [07000/30000] Loss:0.006243 Loss_1:0.006179 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000588 Time:19.154601s (2.23min in total, 7.32min remains)
2022-11-28 00:28:21 NUM_SUB: 22;----------------------------
2022-11-28 00:28:21 Epoch [08000/30000] Loss:0.005114 Loss_1:0.005047 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000556 Time:18.899665s (2.54min in total, 6.99min remains)
2022-11-28 00:28:40 NUM_SUB: 22;----------------------------
2022-11-28 00:28:40 Epoch [09000/30000] Loss:0.004181 Loss_1:0.004096 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000526 Time:19.298719s (2.86min in total, 6.68min remains)
2022-11-28 00:28:59 NUM_SUB: 22;----------------------------
2022-11-28 00:28:59 Epoch [10000/30000] Loss:0.003343 Loss_1:0.003250 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000500 Time:18.713985s (3.18min in total, 6.35min remains)
2022-11-28 00:29:18 NUM_SUB: 22;----------------------------
2022-11-28 00:29:18 Epoch [11000/30000] Loss:0.002693 Loss_1:0.002630 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000476 Time:18.863127s (3.49min in total, 6.03min remains)
2022-11-28 00:29:37 NUM_SUB: 22;----------------------------
2022-11-28 00:29:37 Epoch [12000/30000] Loss:0.002335 Loss_1:0.002298 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000455 Time:19.387410s (3.81min in total, 5.72min remains)
2022-11-28 00:29:57 NUM_SUB: 22;----------------------------
2022-11-28 00:29:57 Epoch [13000/30000] Loss:0.002221 Loss_1:0.002192 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000435 Time:19.418599s (4.14min in total, 5.41min remains)
2022-11-28 00:30:15 NUM_SUB: 22;----------------------------
2022-11-28 00:30:15 Epoch [14000/30000] Loss:0.002194 Loss_1:0.002176 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:18.782607s (4.45min in total, 5.09min remains)
2022-11-28 00:30:34 NUM_SUB: 22;----------------------------
2022-11-28 00:30:34 Epoch [15000/30000] Loss:0.002174 Loss_1:0.002159 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:18.905213s (4.77min in total, 4.77min remains)
2022-11-28 00:30:53 NUM_SUB: 22;----------------------------
2022-11-28 00:30:53 Epoch [16000/30000] Loss:0.002159 Loss_1:0.002149 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:18.824212s (5.08min in total, 4.44min remains)
2022-11-28 00:31:12 NUM_SUB: 22;----------------------------
2022-11-28 00:31:12 Epoch [17000/30000] Loss:0.002145 Loss_1:0.002138 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:18.997968s (5.40min in total, 4.13min remains)
2022-11-28 00:31:31 NUM_SUB: 22;----------------------------
2022-11-28 00:31:31 Epoch [18000/30000] Loss:0.002128 Loss_1:0.002122 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:18.946994s (5.71min in total, 3.81min remains)
2022-11-28 00:31:50 NUM_SUB: 22;----------------------------
2022-11-28 00:31:50 Epoch [19000/30000] Loss:0.002104 Loss_1:0.002098 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:18.760484s (6.02min in total, 3.49min remains)
2022-11-28 00:32:09 NUM_SUB: 22;----------------------------
2022-11-28 00:32:09 Epoch [20000/30000] Loss:0.002060 Loss_1:0.002055 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.244462s (6.35min in total, 3.17min remains)
2022-11-28 00:32:29 NUM_SUB: 22;----------------------------
2022-11-28 00:32:29 Epoch [21000/30000] Loss:0.001989 Loss_1:0.001984 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:19.725583s (6.67min in total, 2.86min remains)
2022-11-28 00:32:48 NUM_SUB: 22;----------------------------
2022-11-28 00:32:48 Epoch [22000/30000] Loss:0.001916 Loss_1:0.001912 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.192979s (6.99min in total, 2.54min remains)
2022-11-28 00:33:07 NUM_SUB: 22;----------------------------
2022-11-28 00:33:07 Epoch [23000/30000] Loss:0.001864 Loss_1:0.001859 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:18.763651s (7.31min in total, 2.22min remains)
2022-11-28 00:33:26 NUM_SUB: 22;----------------------------
2022-11-28 00:33:26 Epoch [24000/30000] Loss:0.001777 Loss_1:0.001772 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.234254s (7.63min in total, 1.91min remains)
2022-11-28 00:33:45 NUM_SUB: 22;----------------------------
2022-11-28 00:33:45 Epoch [25000/30000] Loss:0.001638 Loss_1:0.001632 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:18.718259s (7.94min in total, 1.59min remains)
2022-11-28 00:34:04 NUM_SUB: 22;----------------------------
2022-11-28 00:34:04 Epoch [26000/30000] Loss:0.001579 Loss_1:0.001573 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:19.395302s (8.26min in total, 1.27min remains)
2022-11-28 00:34:24 NUM_SUB: 22;----------------------------
2022-11-28 00:34:24 Epoch [27000/30000] Loss:0.001534 Loss_1:0.001527 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000270 Time:19.614262s (8.59min in total, 0.95min remains)
2022-11-28 00:34:43 NUM_SUB: 22;----------------------------
2022-11-28 00:34:43 Epoch [28000/30000] Loss:0.001462 Loss_1:0.001455 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:19.141085s (8.91min in total, 0.64min remains)
2022-11-28 00:35:02 NUM_SUB: 22;----------------------------
2022-11-28 00:35:02 Epoch [29000/30000] Loss:0.001365 Loss_1:0.001358 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000256 Time:19.391791s (9.23min in total, 0.32min remains)
2022-11-28 00:35:22 NUM_SUB: 22;----------------------------
2022-11-28 00:35:22 Epoch [30000/30000] Loss:0.001296 Loss_1:0.001289 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000250 Time:19.237466s (9.55min in total, 0.00min remains)
2022-11-28 00:35:22 Testing & drawing...
2022-11-28 00:35:22 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:35:23 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=22/
2022-11-28 00:35:23 [Loss]
2022-11-28 00:35:23 NUM_SUB: 22; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:35:23 NUM_SUB: 22; Personalized parameter estimation: Parameter containing:
tensor([0.0132, 0.0376, 0.0100, 1.1014, 0.3074, 0.0119, 2.2214, 0.8964, 0.4556,
        0.0146, 0.1013, 0.1016, 0.6758, 0.1689, 0.0176, 1.3169, 0.6977, 0.8000,
        0.0109, 3.5216, 0.6816, 0.0223, 3.4231, 0.8742, 0.0171, 4.1330, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:35:23 NUM_SUB: 22------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:35:23 Testing & drawing...
2022-11-28 00:35:23 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:35:25 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=22/
2022-11-28 00:35:25 [Loss]
2022-11-28 00:35:25 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:35:25 General parameter estimation: Parameter containing:
tensor([0.0132, 0.0376, 0.0100, 1.1014, 0.3074, 0.0119, 2.2214, 0.8964, 0.4556,
        0.0146, 0.1013, 0.1016, 0.6758, 0.1689, 0.0176, 1.3169, 0.6977, 0.8000,
        0.0109, 3.5216, 0.6816, 0.0223, 3.4231, 0.8742, 0.0171, 4.1330, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:35:25 A: prod, degr, TonA, NonA
2022-11-28 00:35:25 [0.47356287 0.46194384 0.0525973  0.011896  ]
2022-11-28 00:35:25 T: prod, degr, AonT, NonT
2022-11-28 00:35:25 [0.17969668 0.42414308 0.37991112 0.0162491 ]
2022-11-28 00:35:25 N: AonN, TonN, ATonN
2022-11-28 00:35:25 [0.00546783 0.9778471  0.01668505]
2022-11-28 00:35:25 using cpu
2022-11-28 00:35:25 epoch = 30000
2022-11-28 00:35:25 epoch_step = 1000
2022-11-28 00:35:25 model_name = SimpleNetworkAD
2022-11-28 00:35:25 now_string = 2022-11-27-19-40-13
2022-11-28 00:35:25 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:35:25 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:35:25 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:35:25 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:35:25 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:35:25 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:35:44 NUM_SUB: 23;----------------------------
2022-11-28 00:35:44 Epoch [01000/30000] Loss:0.029531 Loss_1:0.023701 Loss_2:0.002085 Loss_3:0.000000 Lr:0.000909 Time:18.528908s (0.31min in total, 8.96min remains)
2022-11-28 00:36:03 NUM_SUB: 23;----------------------------
2022-11-28 00:36:03 Epoch [02000/30000] Loss:0.023304 Loss_1:0.022201 Loss_2:0.000712 Loss_3:0.000000 Lr:0.000833 Time:19.014120s (0.63min in total, 8.76min remains)
2022-11-28 00:36:21 NUM_SUB: 23;----------------------------
2022-11-28 00:36:21 Epoch [03000/30000] Loss:0.020233 Loss_1:0.019900 Loss_2:0.000286 Loss_3:0.000000 Lr:0.000769 Time:18.509302s (0.93min in total, 8.41min remains)
2022-11-28 00:36:41 NUM_SUB: 23;----------------------------
2022-11-28 00:36:41 Epoch [04000/30000] Loss:0.017739 Loss_1:0.017489 Loss_2:0.000185 Loss_3:0.000000 Lr:0.000714 Time:19.631985s (1.26min in total, 8.20min remains)
2022-11-28 00:37:00 NUM_SUB: 23;----------------------------
2022-11-28 00:37:00 Epoch [05000/30000] Loss:0.014834 Loss_1:0.014623 Loss_2:0.000150 Loss_3:0.000000 Lr:0.000667 Time:19.263214s (1.58min in total, 7.91min remains)
2022-11-28 00:37:20 NUM_SUB: 23;----------------------------
2022-11-28 00:37:20 Epoch [06000/30000] Loss:0.011140 Loss_1:0.010970 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000625 Time:19.733950s (1.91min in total, 7.65min remains)
2022-11-28 00:37:39 NUM_SUB: 23;----------------------------
2022-11-28 00:37:39 Epoch [07000/30000] Loss:0.007091 Loss_1:0.006945 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000588 Time:19.553326s (2.24min in total, 7.35min remains)
2022-11-28 00:37:58 NUM_SUB: 23;----------------------------
2022-11-28 00:37:58 Epoch [08000/30000] Loss:0.003863 Loss_1:0.003743 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000556 Time:18.944088s (2.55min in total, 7.02min remains)
2022-11-28 00:38:17 NUM_SUB: 23;----------------------------
2022-11-28 00:38:17 Epoch [09000/30000] Loss:0.002372 Loss_1:0.002262 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000526 Time:19.128835s (2.87min in total, 6.70min remains)
2022-11-28 00:38:37 NUM_SUB: 23;----------------------------
2022-11-28 00:38:37 Epoch [10000/30000] Loss:0.001820 Loss_1:0.001713 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000500 Time:19.184748s (3.19min in total, 6.38min remains)
2022-11-28 00:38:56 NUM_SUB: 23;----------------------------
2022-11-28 00:38:56 Epoch [11000/30000] Loss:0.001325 Loss_1:0.001242 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000476 Time:18.988391s (3.51min in total, 6.06min remains)
2022-11-28 00:39:15 NUM_SUB: 23;----------------------------
2022-11-28 00:39:15 Epoch [12000/30000] Loss:0.000704 Loss_1:0.000661 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000455 Time:18.888828s (3.82min in total, 5.73min remains)
2022-11-28 00:39:34 NUM_SUB: 23;----------------------------
2022-11-28 00:39:34 Epoch [13000/30000] Loss:0.000232 Loss_1:0.000199 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000435 Time:19.079019s (4.14min in total, 5.42min remains)
2022-11-28 00:39:52 NUM_SUB: 23;----------------------------
2022-11-28 00:39:52 Epoch [14000/30000] Loss:0.000084 Loss_1:0.000059 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:18.793985s (4.45min in total, 5.09min remains)
2022-11-28 00:40:11 NUM_SUB: 23;----------------------------
2022-11-28 00:40:11 Epoch [15000/30000] Loss:0.000066 Loss_1:0.000048 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:18.811827s (4.77min in total, 4.77min remains)
2022-11-28 00:40:30 NUM_SUB: 23;----------------------------
2022-11-28 00:40:30 Epoch [16000/30000] Loss:0.000074 Loss_1:0.000059 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:19.098756s (5.09min in total, 4.45min remains)
2022-11-28 00:40:49 NUM_SUB: 23;----------------------------
2022-11-28 00:40:49 Epoch [17000/30000] Loss:0.000051 Loss_1:0.000041 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:18.695911s (5.40min in total, 4.13min remains)
2022-11-28 00:41:08 NUM_SUB: 23;----------------------------
2022-11-28 00:41:08 Epoch [18000/30000] Loss:0.000046 Loss_1:0.000038 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:19.471452s (5.72min in total, 3.81min remains)
2022-11-28 00:41:28 NUM_SUB: 23;----------------------------
2022-11-28 00:41:28 Epoch [19000/30000] Loss:0.000042 Loss_1:0.000035 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:19.378079s (6.05min in total, 3.50min remains)
2022-11-28 00:41:47 NUM_SUB: 23;----------------------------
2022-11-28 00:41:47 Epoch [20000/30000] Loss:0.000040 Loss_1:0.000033 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:18.982892s (6.36min in total, 3.18min remains)
2022-11-28 00:42:06 NUM_SUB: 23;----------------------------
2022-11-28 00:42:06 Epoch [21000/30000] Loss:0.000043 Loss_1:0.000038 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:19.168014s (6.68min in total, 2.86min remains)
2022-11-28 00:42:25 NUM_SUB: 23;----------------------------
2022-11-28 00:42:25 Epoch [22000/30000] Loss:0.000035 Loss_1:0.000030 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:18.657302s (6.99min in total, 2.54min remains)
2022-11-28 00:42:44 NUM_SUB: 23;----------------------------
2022-11-28 00:42:44 Epoch [23000/30000] Loss:0.000033 Loss_1:0.000029 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:19.039721s (7.31min in total, 2.22min remains)
2022-11-28 00:43:03 NUM_SUB: 23;----------------------------
2022-11-28 00:43:03 Epoch [24000/30000] Loss:0.000032 Loss_1:0.000027 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.881521s (7.62min in total, 1.91min remains)
2022-11-28 00:43:22 NUM_SUB: 23;----------------------------
2022-11-28 00:43:22 Epoch [25000/30000] Loss:0.000030 Loss_1:0.000026 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.565333s (7.95min in total, 1.59min remains)
2022-11-28 00:43:42 NUM_SUB: 23;----------------------------
2022-11-28 00:43:42 Epoch [26000/30000] Loss:0.000029 Loss_1:0.000025 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.638692s (8.28min in total, 1.27min remains)
2022-11-28 00:44:00 NUM_SUB: 23;----------------------------
2022-11-28 00:44:00 Epoch [27000/30000] Loss:0.000029 Loss_1:0.000025 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:18.565568s (8.59min in total, 0.95min remains)
2022-11-28 00:44:19 NUM_SUB: 23;----------------------------
2022-11-28 00:44:19 Epoch [28000/30000] Loss:0.000026 Loss_1:0.000022 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:18.758465s (8.90min in total, 0.64min remains)
2022-11-28 00:44:38 NUM_SUB: 23;----------------------------
2022-11-28 00:44:38 Epoch [29000/30000] Loss:0.000025 Loss_1:0.000021 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.223929s (9.22min in total, 0.32min remains)
2022-11-28 00:44:57 NUM_SUB: 23;----------------------------
2022-11-28 00:44:57 Epoch [30000/30000] Loss:0.000046 Loss_1:0.000042 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:18.594367s (9.53min in total, 0.00min remains)
2022-11-28 00:44:57 Testing & drawing...
2022-11-28 00:44:57 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:44:59 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=23/
2022-11-28 00:44:59 [Loss]
2022-11-28 00:44:59 NUM_SUB: 23; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:44:59 NUM_SUB: 23; Personalized parameter estimation: Parameter containing:
tensor([0.0187, 0.0317, 0.0147, 0.7868, 0.3074, 0.0109, 1.8154, 0.8964, 0.4556,
        0.0145, 0.1096, 0.1030, 0.6542, 0.1689, 0.0176, 0.9765, 0.6977, 0.8000,
        0.0115, 4.4548, 0.6816, 0.0216, 3.5395, 0.8742, 0.0135, 4.4764, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:44:59 NUM_SUB: 23------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:44:59 Testing & drawing...
2022-11-28 00:44:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:45:00 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=23/
2022-11-28 00:45:00 [Loss]
2022-11-28 00:45:00 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:45:00 General parameter estimation: Parameter containing:
tensor([0.0187, 0.0317, 0.0147, 0.7868, 0.3074, 0.0109, 1.8154, 0.8964, 0.4556,
        0.0145, 0.1096, 0.1030, 0.6542, 0.1689, 0.0176, 0.9765, 0.6977, 0.8000,
        0.0115, 4.4548, 0.6816, 0.0216, 3.5395, 0.8742, 0.0135, 4.4764, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:45:00 A: prod, degr, TonA, NonA
2022-11-28 00:45:00 [0.42658946 0.46738392 0.0850699  0.02095675]
2022-11-28 00:45:00 T: prod, degr, AonT, NonT
2022-11-28 00:45:00 [0.11952045 0.5770909  0.26917744 0.0342112 ]
2022-11-28 00:45:00 N: AonN, TonN, ATonN
2022-11-28 00:45:00 [0.0128866  0.9646018  0.02251155]
2022-11-28 00:45:01 using cpu
2022-11-28 00:45:01 epoch = 30000
2022-11-28 00:45:01 epoch_step = 1000
2022-11-28 00:45:01 model_name = SimpleNetworkAD
2022-11-28 00:45:01 now_string = 2022-11-27-19-40-13
2022-11-28 00:45:01 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:45:01 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:45:01 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:45:01 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:45:01 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:45:01 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:45:19 NUM_SUB: 24;----------------------------
2022-11-28 00:45:19 Epoch [01000/30000] Loss:0.087243 Loss_1:0.081036 Loss_2:0.002571 Loss_3:0.000000 Lr:0.000909 Time:18.875599s (0.31min in total, 9.12min remains)
2022-11-28 00:45:38 NUM_SUB: 24;----------------------------
2022-11-28 00:45:38 Epoch [02000/30000] Loss:0.077730 Loss_1:0.076392 Loss_2:0.001003 Loss_3:0.000000 Lr:0.000833 Time:18.996334s (0.63min in total, 8.84min remains)
2022-11-28 00:45:57 NUM_SUB: 24;----------------------------
2022-11-28 00:45:57 Epoch [03000/30000] Loss:0.070214 Loss_1:0.069504 Loss_2:0.000503 Loss_3:0.000000 Lr:0.000769 Time:18.680825s (0.94min in total, 8.48min remains)
2022-11-28 00:46:16 NUM_SUB: 24;----------------------------
2022-11-28 00:46:16 Epoch [04000/30000] Loss:0.060518 Loss_1:0.059964 Loss_2:0.000332 Loss_3:0.000000 Lr:0.000714 Time:18.730828s (1.25min in total, 8.16min remains)
2022-11-28 00:46:35 NUM_SUB: 24;----------------------------
2022-11-28 00:46:35 Epoch [05000/30000] Loss:0.048758 Loss_1:0.048351 Loss_2:0.000212 Loss_3:0.000000 Lr:0.000667 Time:18.833262s (1.57min in total, 7.84min remains)
2022-11-28 00:46:53 NUM_SUB: 24;----------------------------
2022-11-28 00:46:53 Epoch [06000/30000] Loss:0.033039 Loss_1:0.032692 Loss_2:0.000209 Loss_3:0.000000 Lr:0.000625 Time:18.756420s (1.88min in total, 7.53min remains)
2022-11-28 00:47:13 NUM_SUB: 24;----------------------------
2022-11-28 00:47:13 Epoch [07000/30000] Loss:0.017142 Loss_1:0.016873 Loss_2:0.000200 Loss_3:0.000000 Lr:0.000588 Time:19.353157s (2.20min in total, 7.24min remains)
2022-11-28 00:47:32 NUM_SUB: 24;----------------------------
2022-11-28 00:47:32 Epoch [08000/30000] Loss:0.008995 Loss_1:0.008788 Loss_2:0.000189 Loss_3:0.000000 Lr:0.000556 Time:19.252579s (2.52min in total, 6.94min remains)
2022-11-28 00:47:51 NUM_SUB: 24;----------------------------
2022-11-28 00:47:51 Epoch [09000/30000] Loss:0.006727 Loss_1:0.006536 Loss_2:0.000189 Loss_3:0.000000 Lr:0.000526 Time:19.049737s (2.84min in total, 6.63min remains)
2022-11-28 00:48:10 NUM_SUB: 24;----------------------------
2022-11-28 00:48:10 Epoch [10000/30000] Loss:0.004920 Loss_1:0.004797 Loss_2:0.000122 Loss_3:0.000000 Lr:0.000500 Time:18.952544s (3.16min in total, 6.32min remains)
2022-11-28 00:48:29 NUM_SUB: 24;----------------------------
2022-11-28 00:48:29 Epoch [11000/30000] Loss:0.002584 Loss_1:0.002503 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000476 Time:19.265091s (3.48min in total, 6.01min remains)
2022-11-28 00:48:49 NUM_SUB: 24;----------------------------
2022-11-28 00:48:49 Epoch [12000/30000] Loss:0.000718 Loss_1:0.000648 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000455 Time:19.244325s (3.80min in total, 5.70min remains)
2022-11-28 00:49:08 NUM_SUB: 24;----------------------------
2022-11-28 00:49:08 Epoch [13000/30000] Loss:0.000344 Loss_1:0.000291 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000435 Time:19.167919s (4.12min in total, 5.39min remains)
2022-11-28 00:49:27 NUM_SUB: 24;----------------------------
2022-11-28 00:49:27 Epoch [14000/30000] Loss:0.000321 Loss_1:0.000282 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000417 Time:19.316835s (4.44min in total, 5.08min remains)
2022-11-28 00:49:46 NUM_SUB: 24;----------------------------
2022-11-28 00:49:46 Epoch [15000/30000] Loss:0.000309 Loss_1:0.000280 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000400 Time:19.112683s (4.76min in total, 4.76min remains)
2022-11-28 00:50:05 NUM_SUB: 24;----------------------------
2022-11-28 00:50:05 Epoch [16000/30000] Loss:0.000300 Loss_1:0.000277 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000385 Time:19.283710s (5.08min in total, 4.45min remains)
2022-11-28 00:50:24 NUM_SUB: 24;----------------------------
2022-11-28 00:50:24 Epoch [17000/30000] Loss:0.000298 Loss_1:0.000278 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000370 Time:18.911751s (5.40min in total, 4.13min remains)
2022-11-28 00:50:43 NUM_SUB: 24;----------------------------
2022-11-28 00:50:43 Epoch [18000/30000] Loss:0.000289 Loss_1:0.000273 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000357 Time:19.060959s (5.71min in total, 3.81min remains)
2022-11-28 00:51:03 NUM_SUB: 24;----------------------------
2022-11-28 00:51:03 Epoch [19000/30000] Loss:0.000285 Loss_1:0.000272 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000345 Time:19.231038s (6.03min in total, 3.49min remains)
2022-11-28 00:51:21 NUM_SUB: 24;----------------------------
2022-11-28 00:51:21 Epoch [20000/30000] Loss:0.000283 Loss_1:0.000271 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:18.795837s (6.35min in total, 3.17min remains)
2022-11-28 00:51:41 NUM_SUB: 24;----------------------------
2022-11-28 00:51:41 Epoch [21000/30000] Loss:0.000281 Loss_1:0.000271 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000323 Time:19.266052s (6.67min in total, 2.86min remains)
2022-11-28 00:52:00 NUM_SUB: 24;----------------------------
2022-11-28 00:52:00 Epoch [22000/30000] Loss:0.000299 Loss_1:0.000291 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:18.824118s (6.98min in total, 2.54min remains)
2022-11-28 00:52:19 NUM_SUB: 24;----------------------------
2022-11-28 00:52:19 Epoch [23000/30000] Loss:0.000279 Loss_1:0.000271 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000303 Time:19.850455s (7.31min in total, 2.23min remains)
2022-11-28 00:52:39 NUM_SUB: 24;----------------------------
2022-11-28 00:52:39 Epoch [24000/30000] Loss:0.000279 Loss_1:0.000272 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:19.337289s (7.64min in total, 1.91min remains)
2022-11-28 00:52:58 NUM_SUB: 24;----------------------------
2022-11-28 00:52:58 Epoch [25000/30000] Loss:0.000277 Loss_1:0.000271 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000286 Time:19.376184s (7.96min in total, 1.59min remains)
2022-11-28 00:53:17 NUM_SUB: 24;----------------------------
2022-11-28 00:53:17 Epoch [26000/30000] Loss:0.000276 Loss_1:0.000271 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:19.061115s (8.28min in total, 1.27min remains)
2022-11-28 00:53:36 NUM_SUB: 24;----------------------------
2022-11-28 00:53:36 Epoch [27000/30000] Loss:0.000285 Loss_1:0.000280 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000270 Time:19.347419s (8.60min in total, 0.96min remains)
2022-11-28 00:53:55 NUM_SUB: 24;----------------------------
2022-11-28 00:53:55 Epoch [28000/30000] Loss:0.000275 Loss_1:0.000270 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:18.984295s (8.92min in total, 0.64min remains)
2022-11-28 00:54:15 NUM_SUB: 24;----------------------------
2022-11-28 00:54:15 Epoch [29000/30000] Loss:0.000275 Loss_1:0.000270 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.483282s (9.24min in total, 0.32min remains)
2022-11-28 00:54:35 NUM_SUB: 24;----------------------------
2022-11-28 00:54:35 Epoch [30000/30000] Loss:0.000279 Loss_1:0.000274 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.555024s (9.57min in total, 0.00min remains)
2022-11-28 00:54:35 Testing & drawing...
2022-11-28 00:54:35 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:54:36 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=24/
2022-11-28 00:54:36 [Loss]
2022-11-28 00:54:36 NUM_SUB: 24; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:54:36 NUM_SUB: 24; Personalized parameter estimation: Parameter containing:
tensor([0.0203, 0.0456, 0.0331, 0.2587, 0.3074, 0.0152, 2.6063, 0.8964, 0.4556,
        0.0154, 0.0956, 0.1013, 0.7034, 0.1689, 0.0176, 2.1415, 0.6977, 0.8000,
        0.0083, 4.8451, 0.6816, 0.0220, 3.8422, 0.8742, 0.0177, 5.0233, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:54:36 NUM_SUB: 24------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 00:54:36 Testing & drawing...
2022-11-28 00:54:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 00:54:38 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=24/
2022-11-28 00:54:38 [Loss]
2022-11-28 00:54:38 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 00:54:38 General parameter estimation: Parameter containing:
tensor([0.0203, 0.0456, 0.0331, 0.2587, 0.3074, 0.0152, 2.6063, 0.8964, 0.4556,
        0.0154, 0.0956, 0.1013, 0.7034, 0.1689, 0.0176, 2.1415, 0.6977, 0.8000,
        0.0083, 4.8451, 0.6816, 0.0220, 3.8422, 0.8742, 0.0177, 5.0233, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 00:54:38 A: prod, degr, TonA, NonA
2022-11-28 00:54:38 [0.2258416  0.48846394 0.27055106 0.01514341]
2022-11-28 00:54:38 T: prod, degr, AonT, NonT
2022-11-28 00:54:38 [0.10940026 0.6445053  0.23050457 0.01558986]
2022-11-28 00:54:38 N: AonN, TonN, ATonN
2022-11-28 00:54:38 [0.01611843 0.94276893 0.04111264]
2022-11-28 00:54:38 using cpu
2022-11-28 00:54:38 epoch = 30000
2022-11-28 00:54:38 epoch_step = 1000
2022-11-28 00:54:38 model_name = SimpleNetworkAD
2022-11-28 00:54:38 now_string = 2022-11-27-19-40-13
2022-11-28 00:54:38 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 00:54:38 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 00:54:38 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 00:54:38 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 00:54:38 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 00:54:38 --------------------------------------------------training start--------------------------------------------------
2022-11-28 00:54:57 NUM_SUB: 25;----------------------------
2022-11-28 00:54:57 Epoch [01000/30000] Loss:0.066330 Loss_1:0.060559 Loss_2:0.001872 Loss_3:0.000000 Lr:0.000909 Time:19.137243s (0.32min in total, 9.25min remains)
2022-11-28 00:55:17 NUM_SUB: 25;----------------------------
2022-11-28 00:55:17 Epoch [02000/30000] Loss:0.056670 Loss_1:0.055580 Loss_2:0.000626 Loss_3:0.000000 Lr:0.000833 Time:19.366044s (0.64min in total, 8.98min remains)
2022-11-28 00:55:36 NUM_SUB: 25;----------------------------
2022-11-28 00:55:36 Epoch [03000/30000] Loss:0.049918 Loss_1:0.049547 Loss_2:0.000220 Loss_3:0.000000 Lr:0.000769 Time:19.737722s (0.97min in total, 8.74min remains)
2022-11-28 00:55:56 NUM_SUB: 25;----------------------------
2022-11-28 00:55:56 Epoch [04000/30000] Loss:0.042484 Loss_1:0.042120 Loss_2:0.000155 Loss_3:0.000000 Lr:0.000714 Time:19.821427s (1.30min in total, 8.46min remains)
2022-11-28 00:56:15 NUM_SUB: 25;----------------------------
2022-11-28 00:56:15 Epoch [05000/30000] Loss:0.032596 Loss_1:0.032263 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000667 Time:19.024953s (1.62min in total, 8.09min remains)
2022-11-28 00:56:35 NUM_SUB: 25;----------------------------
2022-11-28 00:56:35 Epoch [06000/30000] Loss:0.020840 Loss_1:0.020570 Loss_2:0.000121 Loss_3:0.000000 Lr:0.000625 Time:19.380559s (1.94min in total, 7.76min remains)
2022-11-28 00:56:54 NUM_SUB: 25;----------------------------
2022-11-28 00:56:54 Epoch [07000/30000] Loss:0.010938 Loss_1:0.010738 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000588 Time:19.239793s (2.26min in total, 7.43min remains)
2022-11-28 00:57:12 NUM_SUB: 25;----------------------------
2022-11-28 00:57:12 Epoch [08000/30000] Loss:0.006178 Loss_1:0.006031 Loss_2:0.000100 Loss_3:0.000000 Lr:0.000556 Time:18.596293s (2.57min in total, 7.07min remains)
2022-11-28 00:57:32 NUM_SUB: 25;----------------------------
2022-11-28 00:57:32 Epoch [09000/30000] Loss:0.004241 Loss_1:0.004123 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000526 Time:19.237740s (2.89min in total, 6.75min remains)
2022-11-28 00:57:50 NUM_SUB: 25;----------------------------
2022-11-28 00:57:50 Epoch [10000/30000] Loss:0.003347 Loss_1:0.003252 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000500 Time:18.829619s (3.21min in total, 6.41min remains)
2022-11-28 00:58:09 NUM_SUB: 25;----------------------------
2022-11-28 00:58:09 Epoch [11000/30000] Loss:0.003136 Loss_1:0.003065 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000476 Time:18.715141s (3.52min in total, 6.08min remains)
2022-11-28 00:58:28 NUM_SUB: 25;----------------------------
2022-11-28 00:58:28 Epoch [12000/30000] Loss:0.003101 Loss_1:0.003051 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:18.967945s (3.83min in total, 5.75min remains)
2022-11-28 00:58:47 NUM_SUB: 25;----------------------------
2022-11-28 00:58:47 Epoch [13000/30000] Loss:0.003081 Loss_1:0.003048 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000435 Time:18.443255s (4.14min in total, 5.42min remains)
2022-11-28 00:59:06 NUM_SUB: 25;----------------------------
2022-11-28 00:59:06 Epoch [14000/30000] Loss:0.003068 Loss_1:0.003045 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000417 Time:18.941957s (4.46min in total, 5.09min remains)
2022-11-28 00:59:24 NUM_SUB: 25;----------------------------
2022-11-28 00:59:24 Epoch [15000/30000] Loss:0.003058 Loss_1:0.003043 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000400 Time:18.950310s (4.77min in total, 4.77min remains)
2022-11-28 00:59:43 NUM_SUB: 25;----------------------------
2022-11-28 00:59:43 Epoch [16000/30000] Loss:0.003052 Loss_1:0.003041 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:18.944659s (5.09min in total, 4.45min remains)
2022-11-28 01:00:02 NUM_SUB: 25;----------------------------
2022-11-28 01:00:02 Epoch [17000/30000] Loss:0.003048 Loss_1:0.003040 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:18.817954s (5.40min in total, 4.13min remains)
2022-11-28 01:00:20 NUM_SUB: 25;----------------------------
2022-11-28 01:00:20 Epoch [18000/30000] Loss:0.003048 Loss_1:0.003037 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:18.247539s (5.71min in total, 3.80min remains)
2022-11-28 01:00:39 NUM_SUB: 25;----------------------------
2022-11-28 01:00:39 Epoch [19000/30000] Loss:0.003059 Loss_1:0.003034 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000345 Time:18.497147s (6.02min in total, 3.48min remains)
2022-11-28 01:00:57 NUM_SUB: 25;----------------------------
2022-11-28 01:00:57 Epoch [20000/30000] Loss:0.003038 Loss_1:0.003034 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:18.413822s (6.32min in total, 3.16min remains)
2022-11-28 01:01:16 NUM_SUB: 25;----------------------------
2022-11-28 01:01:16 Epoch [21000/30000] Loss:0.003033 Loss_1:0.003030 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:18.355705s (6.63min in total, 2.84min remains)
2022-11-28 01:01:34 NUM_SUB: 25;----------------------------
2022-11-28 01:01:34 Epoch [22000/30000] Loss:0.003027 Loss_1:0.003024 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:18.326813s (6.93min in total, 2.52min remains)
2022-11-28 01:01:53 NUM_SUB: 25;----------------------------
2022-11-28 01:01:53 Epoch [23000/30000] Loss:0.003018 Loss_1:0.003017 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:18.492858s (7.24min in total, 2.20min remains)
2022-11-28 01:02:12 NUM_SUB: 25;----------------------------
2022-11-28 01:02:12 Epoch [24000/30000] Loss:0.003007 Loss_1:0.003005 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.428973s (7.57min in total, 1.89min remains)
2022-11-28 01:02:31 NUM_SUB: 25;----------------------------
2022-11-28 01:02:31 Epoch [25000/30000] Loss:0.002999 Loss_1:0.002996 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:18.497350s (7.87min in total, 1.57min remains)
2022-11-28 01:02:49 NUM_SUB: 25;----------------------------
2022-11-28 01:02:49 Epoch [26000/30000] Loss:0.002997 Loss_1:0.002997 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:18.397879s (8.18min in total, 1.26min remains)
2022-11-28 01:03:07 NUM_SUB: 25;----------------------------
2022-11-28 01:03:07 Epoch [27000/30000] Loss:0.002997 Loss_1:0.002996 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:18.530960s (8.49min in total, 0.94min remains)
2022-11-28 01:03:26 NUM_SUB: 25;----------------------------
2022-11-28 01:03:26 Epoch [28000/30000] Loss:0.002997 Loss_1:0.002996 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:18.420635s (8.80min in total, 0.63min remains)
2022-11-28 01:03:44 NUM_SUB: 25;----------------------------
2022-11-28 01:03:44 Epoch [29000/30000] Loss:0.002997 Loss_1:0.002995 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.521511s (9.11min in total, 0.31min remains)
2022-11-28 01:04:03 NUM_SUB: 25;----------------------------
2022-11-28 01:04:03 Epoch [30000/30000] Loss:0.002997 Loss_1:0.002996 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.407316s (9.41min in total, 0.00min remains)
2022-11-28 01:04:03 Testing & drawing...
2022-11-28 01:04:03 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:04:04 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=25/
2022-11-28 01:04:04 [Loss]
2022-11-28 01:04:04 NUM_SUB: 25; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:04:04 NUM_SUB: 25; Personalized parameter estimation: Parameter containing:
tensor([1.7801e-01, 3.1388e-01, 2.4142e-02, 3.7396e-02, 3.0742e-01, 9.2203e-03,
        8.9099e-01, 8.9644e-01, 4.5563e-01, 1.1442e-02, 7.1596e-02, 2.7409e-02,
        3.3293e-01, 1.6886e-01, 1.7575e-02, 1.0633e+00, 6.9767e-01, 8.0001e-01,
        2.1426e-03, 3.7529e+00, 6.8161e-01, 2.2859e-02, 3.1099e+00, 8.7416e-01,
        8.5664e-03, 3.6422e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 01:04:04 NUM_SUB: 25------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:04:04 Testing & drawing...
2022-11-28 01:04:04 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:04:06 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=25/
2022-11-28 01:04:06 [Loss]
2022-11-28 01:04:06 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:04:06 General parameter estimation: Parameter containing:
tensor([1.7801e-01, 3.1388e-01, 2.4142e-02, 3.7396e-02, 3.0742e-01, 9.2203e-03,
        8.9099e-01, 8.9644e-01, 4.5563e-01, 1.1442e-02, 7.1596e-02, 2.7409e-02,
        3.3293e-01, 1.6886e-01, 1.7575e-02, 1.0633e+00, 6.9767e-01, 8.0001e-01,
        2.1426e-03, 3.7529e+00, 6.8161e-01, 2.2859e-02, 3.1099e+00, 8.7416e-01,
        8.5664e-03, 3.6422e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 01:04:06 A: prod, degr, TonA, NonA
2022-11-28 01:04:06 [0.43509245 0.49874592 0.05865096 0.00751068]
2022-11-28 01:04:06 T: prod, degr, AonT, NonT
2022-11-28 01:04:06 [0.14125964 0.57449436 0.22787666 0.05636932]
2022-11-28 01:04:06 N: AonN, TonN, ATonN
2022-11-28 01:04:06 [0.00300596 0.97768545 0.01930864]
2022-11-28 01:04:06 using cpu
2022-11-28 01:04:06 epoch = 30000
2022-11-28 01:04:06 epoch_step = 1000
2022-11-28 01:04:06 model_name = SimpleNetworkAD
2022-11-28 01:04:06 now_string = 2022-11-27-19-40-13
2022-11-28 01:04:06 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:04:06 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:04:06 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:04:06 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:04:06 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:04:06 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:04:25 NUM_SUB: 26;----------------------------
2022-11-28 01:04:25 Epoch [01000/30000] Loss:0.153862 Loss_1:0.147848 Loss_2:0.001988 Loss_3:0.000000 Lr:0.000909 Time:18.987663s (0.32min in total, 9.18min remains)
2022-11-28 01:04:44 NUM_SUB: 26;----------------------------
2022-11-28 01:04:44 Epoch [02000/30000] Loss:0.140302 Loss_1:0.139115 Loss_2:0.000635 Loss_3:0.000000 Lr:0.000833 Time:18.801392s (0.63min in total, 8.82min remains)
2022-11-28 01:05:03 NUM_SUB: 26;----------------------------
2022-11-28 01:05:03 Epoch [03000/30000] Loss:0.125794 Loss_1:0.125117 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000769 Time:18.596883s (0.94min in total, 8.46min remains)
2022-11-28 01:05:21 NUM_SUB: 26;----------------------------
2022-11-28 01:05:21 Epoch [04000/30000] Loss:0.106167 Loss_1:0.105462 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000714 Time:18.767711s (1.25min in total, 8.14min remains)
2022-11-28 01:05:40 NUM_SUB: 26;----------------------------
2022-11-28 01:05:40 Epoch [05000/30000] Loss:0.078055 Loss_1:0.077435 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000667 Time:19.043196s (1.57min in total, 7.85min remains)
2022-11-28 01:05:59 NUM_SUB: 26;----------------------------
2022-11-28 01:05:59 Epoch [06000/30000] Loss:0.044724 Loss_1:0.044240 Loss_2:0.000146 Loss_3:0.000000 Lr:0.000625 Time:18.498702s (1.88min in total, 7.51min remains)
2022-11-28 01:06:18 NUM_SUB: 26;----------------------------
2022-11-28 01:06:18 Epoch [07000/30000] Loss:0.019323 Loss_1:0.018998 Loss_2:0.000165 Loss_3:0.000000 Lr:0.000588 Time:18.968618s (2.19min in total, 7.21min remains)
2022-11-28 01:06:37 NUM_SUB: 26;----------------------------
2022-11-28 01:06:37 Epoch [08000/30000] Loss:0.007584 Loss_1:0.007357 Loss_2:0.000183 Loss_3:0.000000 Lr:0.000556 Time:19.004696s (2.51min in total, 6.91min remains)
2022-11-28 01:06:56 NUM_SUB: 26;----------------------------
2022-11-28 01:06:56 Epoch [09000/30000] Loss:0.003739 Loss_1:0.003566 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000526 Time:19.076442s (2.83min in total, 6.60min remains)
2022-11-28 01:07:15 NUM_SUB: 26;----------------------------
2022-11-28 01:07:15 Epoch [10000/30000] Loss:0.001877 Loss_1:0.001737 Loss_2:0.000140 Loss_3:0.000000 Lr:0.000500 Time:18.968427s (3.15min in total, 6.29min remains)
2022-11-28 01:07:34 NUM_SUB: 26;----------------------------
2022-11-28 01:07:34 Epoch [11000/30000] Loss:0.000545 Loss_1:0.000463 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000476 Time:18.634059s (3.46min in total, 5.97min remains)
2022-11-28 01:07:52 NUM_SUB: 26;----------------------------
2022-11-28 01:07:52 Epoch [12000/30000] Loss:0.000117 Loss_1:0.000071 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000455 Time:18.803196s (3.77min in total, 5.65min remains)
2022-11-28 01:08:12 NUM_SUB: 26;----------------------------
2022-11-28 01:08:12 Epoch [13000/30000] Loss:0.000039 Loss_1:0.000004 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000435 Time:19.180256s (4.09min in total, 5.35min remains)
2022-11-28 01:08:30 NUM_SUB: 26;----------------------------
2022-11-28 01:08:30 Epoch [14000/30000] Loss:0.000026 Loss_1:0.000000 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:18.848279s (4.40min in total, 5.03min remains)
2022-11-28 01:08:49 NUM_SUB: 26;----------------------------
2022-11-28 01:08:49 Epoch [15000/30000] Loss:0.000019 Loss_1:0.000000 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:18.878929s (4.72min in total, 4.72min remains)
2022-11-28 01:09:08 NUM_SUB: 26;----------------------------
2022-11-28 01:09:08 Epoch [16000/30000] Loss:0.000014 Loss_1:0.000000 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:18.942561s (5.03min in total, 4.40min remains)
2022-11-28 01:09:27 NUM_SUB: 26;----------------------------
2022-11-28 01:09:27 Epoch [17000/30000] Loss:0.000010 Loss_1:0.000000 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:19.184029s (5.35min in total, 4.09min remains)
2022-11-28 01:09:47 NUM_SUB: 26;----------------------------
2022-11-28 01:09:47 Epoch [18000/30000] Loss:0.000008 Loss_1:0.000000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:19.109253s (5.67min in total, 3.78min remains)
2022-11-28 01:10:06 NUM_SUB: 26;----------------------------
2022-11-28 01:10:06 Epoch [19000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.090654s (5.99min in total, 3.47min remains)
2022-11-28 01:10:25 NUM_SUB: 26;----------------------------
2022-11-28 01:10:25 Epoch [20000/30000] Loss:0.000005 Loss_1:0.000000 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.354840s (6.31min in total, 3.16min remains)
2022-11-28 01:10:44 NUM_SUB: 26;----------------------------
2022-11-28 01:10:44 Epoch [21000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.488699s (6.64min in total, 2.84min remains)
2022-11-28 01:11:04 NUM_SUB: 26;----------------------------
2022-11-28 01:11:04 Epoch [22000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.378453s (6.96min in total, 2.53min remains)
2022-11-28 01:11:23 NUM_SUB: 26;----------------------------
2022-11-28 01:11:23 Epoch [23000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.181435s (7.28min in total, 2.22min remains)
2022-11-28 01:11:42 NUM_SUB: 26;----------------------------
2022-11-28 01:11:42 Epoch [24000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.268002s (7.60min in total, 1.90min remains)
2022-11-28 01:12:01 NUM_SUB: 26;----------------------------
2022-11-28 01:12:01 Epoch [25000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.897702s (7.92min in total, 1.58min remains)
2022-11-28 01:12:21 NUM_SUB: 26;----------------------------
2022-11-28 01:12:21 Epoch [26000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.428227s (8.24min in total, 1.27min remains)
2022-11-28 01:12:40 NUM_SUB: 26;----------------------------
2022-11-28 01:12:40 Epoch [27000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.272786s (8.56min in total, 0.95min remains)
2022-11-28 01:12:59 NUM_SUB: 26;----------------------------
2022-11-28 01:12:59 Epoch [28000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:18.756760s (8.87min in total, 0.63min remains)
2022-11-28 01:13:18 NUM_SUB: 26;----------------------------
2022-11-28 01:13:18 Epoch [29000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.132770s (9.19min in total, 0.32min remains)
2022-11-28 01:13:37 NUM_SUB: 26;----------------------------
2022-11-28 01:13:37 Epoch [30000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.928123s (9.51min in total, 0.00min remains)
2022-11-28 01:13:37 Testing & drawing...
2022-11-28 01:13:37 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:13:38 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=26/
2022-11-28 01:13:38 [Loss]
2022-11-28 01:13:38 NUM_SUB: 26; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:13:38 NUM_SUB: 26; Personalized parameter estimation: Parameter containing:
tensor([0.3595, 0.9260, 0.0231, 0.1385, 0.3074, 0.4672, 0.6528, 0.8964, 0.4556,
        0.0141, 0.0387, 0.0151, 0.5214, 0.1689, 0.0178, 1.3488, 0.6977, 0.8000,
        0.0118, 3.6261, 0.6816, 0.0229, 3.5028, 0.8742, 0.0199, 4.0298, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:13:38 NUM_SUB: 26------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:13:38 Testing & drawing...
2022-11-28 01:13:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:13:40 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=26/
2022-11-28 01:13:40 [Loss]
2022-11-28 01:13:40 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:13:40 General parameter estimation: Parameter containing:
tensor([0.3595, 0.9260, 0.0231, 0.1385, 0.3074, 0.4672, 0.6528, 0.8964, 0.4556,
        0.0141, 0.0387, 0.0151, 0.5214, 0.1689, 0.0178, 1.3488, 0.6977, 0.8000,
        0.0118, 3.6261, 0.6816, 0.0229, 3.5028, 0.8742, 0.0199, 4.0298, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:13:40 A: prod, degr, TonA, NonA
2022-11-28 01:13:40 [0.25735268 0.49968582 0.01596543 0.22699606]
2022-11-28 01:13:40 T: prod, degr, AonT, NonT
2022-11-28 01:13:40 [0.23765549 0.49150744 0.16848725 0.1023498 ]
2022-11-28 01:13:40 N: AonN, TonN, ATonN
2022-11-28 01:13:40 [0.02092314 0.92423    0.05484688]
2022-11-28 01:13:40 using cpu
2022-11-28 01:13:40 epoch = 30000
2022-11-28 01:13:40 epoch_step = 1000
2022-11-28 01:13:40 model_name = SimpleNetworkAD
2022-11-28 01:13:40 now_string = 2022-11-27-19-40-13
2022-11-28 01:13:40 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:13:40 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:13:40 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:13:40 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:13:40 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:13:40 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:13:59 NUM_SUB: 27;----------------------------
2022-11-28 01:13:59 Epoch [01000/30000] Loss:0.130120 Loss_1:0.124037 Loss_2:0.001955 Loss_3:0.000000 Lr:0.000909 Time:19.166820s (0.32min in total, 9.26min remains)
2022-11-28 01:14:19 NUM_SUB: 27;----------------------------
2022-11-28 01:14:19 Epoch [02000/30000] Loss:0.119047 Loss_1:0.117714 Loss_2:0.000691 Loss_3:0.000000 Lr:0.000833 Time:19.256948s (0.64min in total, 8.97min remains)
2022-11-28 01:14:38 NUM_SUB: 27;----------------------------
2022-11-28 01:14:38 Epoch [03000/30000] Loss:0.110749 Loss_1:0.110039 Loss_2:0.000222 Loss_3:0.000000 Lr:0.000769 Time:19.501190s (0.97min in total, 8.69min remains)
2022-11-28 01:14:58 NUM_SUB: 27;----------------------------
2022-11-28 01:14:58 Epoch [04000/30000] Loss:0.100023 Loss_1:0.099251 Loss_2:0.000180 Loss_3:0.000000 Lr:0.000714 Time:19.442458s (1.29min in total, 8.38min remains)
2022-11-28 01:15:17 NUM_SUB: 27;----------------------------
2022-11-28 01:15:17 Epoch [05000/30000] Loss:0.084549 Loss_1:0.083847 Loss_2:0.000170 Loss_3:0.000000 Lr:0.000667 Time:19.140667s (1.61min in total, 8.04min remains)
2022-11-28 01:15:37 NUM_SUB: 27;----------------------------
2022-11-28 01:15:37 Epoch [06000/30000] Loss:0.062361 Loss_1:0.061760 Loss_2:0.000173 Loss_3:0.000000 Lr:0.000625 Time:19.923874s (1.94min in total, 7.76min remains)
2022-11-28 01:15:56 NUM_SUB: 27;----------------------------
2022-11-28 01:15:56 Epoch [07000/30000] Loss:0.033998 Loss_1:0.033528 Loss_2:0.000196 Loss_3:0.000000 Lr:0.000588 Time:19.276508s (2.26min in total, 7.43min remains)
2022-11-28 01:16:16 NUM_SUB: 27;----------------------------
2022-11-28 01:16:16 Epoch [08000/30000] Loss:0.010058 Loss_1:0.009724 Loss_2:0.000239 Loss_3:0.000000 Lr:0.000556 Time:19.640325s (2.59min in total, 7.13min remains)
2022-11-28 01:16:35 NUM_SUB: 27;----------------------------
2022-11-28 01:16:35 Epoch [09000/30000] Loss:0.003143 Loss_1:0.002908 Loss_2:0.000227 Loss_3:0.000000 Lr:0.000526 Time:19.531403s (2.92min in total, 6.81min remains)
2022-11-28 01:16:55 NUM_SUB: 27;----------------------------
2022-11-28 01:16:55 Epoch [10000/30000] Loss:0.002363 Loss_1:0.002196 Loss_2:0.000166 Loss_3:0.000000 Lr:0.000500 Time:19.407532s (3.24min in total, 6.49min remains)
2022-11-28 01:17:14 NUM_SUB: 27;----------------------------
2022-11-28 01:17:14 Epoch [11000/30000] Loss:0.001738 Loss_1:0.001629 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000476 Time:19.559148s (3.57min in total, 6.17min remains)
2022-11-28 01:17:34 NUM_SUB: 27;----------------------------
2022-11-28 01:17:34 Epoch [12000/30000] Loss:0.001404 Loss_1:0.001322 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000455 Time:19.258569s (3.89min in total, 5.84min remains)
2022-11-28 01:17:53 NUM_SUB: 27;----------------------------
2022-11-28 01:17:53 Epoch [13000/30000] Loss:0.001172 Loss_1:0.001127 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000435 Time:19.112129s (4.21min in total, 5.50min remains)
2022-11-28 01:18:12 NUM_SUB: 27;----------------------------
2022-11-28 01:18:12 Epoch [14000/30000] Loss:0.001196 Loss_1:0.001161 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:18.920539s (4.52min in total, 5.17min remains)
2022-11-28 01:18:32 NUM_SUB: 27;----------------------------
2022-11-28 01:18:32 Epoch [15000/30000] Loss:0.001145 Loss_1:0.001121 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000400 Time:20.069824s (4.86min in total, 4.86min remains)
2022-11-28 01:18:52 NUM_SUB: 27;----------------------------
2022-11-28 01:18:52 Epoch [16000/30000] Loss:0.001138 Loss_1:0.001121 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:20.324255s (5.20min in total, 4.55min remains)
2022-11-28 01:19:13 NUM_SUB: 27;----------------------------
2022-11-28 01:19:13 Epoch [17000/30000] Loss:0.001134 Loss_1:0.001121 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:20.717912s (5.54min in total, 4.24min remains)
2022-11-28 01:19:32 NUM_SUB: 27;----------------------------
2022-11-28 01:19:32 Epoch [18000/30000] Loss:0.001131 Loss_1:0.001121 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:19.532685s (5.87min in total, 3.91min remains)
2022-11-28 01:19:51 NUM_SUB: 27;----------------------------
2022-11-28 01:19:51 Epoch [19000/30000] Loss:0.001133 Loss_1:0.001126 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:18.856007s (6.18min in total, 3.58min remains)
2022-11-28 01:20:11 NUM_SUB: 27;----------------------------
2022-11-28 01:20:11 Epoch [20000/30000] Loss:0.001127 Loss_1:0.001122 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.465770s (6.51min in total, 3.25min remains)
2022-11-28 01:20:30 NUM_SUB: 27;----------------------------
2022-11-28 01:20:30 Epoch [21000/30000] Loss:0.001125 Loss_1:0.001121 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.447755s (6.83min in total, 2.93min remains)
2022-11-28 01:20:49 NUM_SUB: 27;----------------------------
2022-11-28 01:20:49 Epoch [22000/30000] Loss:0.001125 Loss_1:0.001120 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.589950s (7.14min in total, 2.60min remains)
2022-11-28 01:21:08 NUM_SUB: 27;----------------------------
2022-11-28 01:21:08 Epoch [23000/30000] Loss:0.001124 Loss_1:0.001121 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.129352s (7.46min in total, 2.27min remains)
2022-11-28 01:21:27 NUM_SUB: 27;----------------------------
2022-11-28 01:21:27 Epoch [24000/30000] Loss:0.001123 Loss_1:0.001121 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.760705s (7.77min in total, 1.94min remains)
2022-11-28 01:21:46 NUM_SUB: 27;----------------------------
2022-11-28 01:21:46 Epoch [25000/30000] Loss:0.001123 Loss_1:0.001120 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.292302s (8.09min in total, 1.62min remains)
2022-11-28 01:22:05 NUM_SUB: 27;----------------------------
2022-11-28 01:22:05 Epoch [26000/30000] Loss:0.001123 Loss_1:0.001121 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.074288s (8.41min in total, 1.29min remains)
2022-11-28 01:22:24 NUM_SUB: 27;----------------------------
2022-11-28 01:22:24 Epoch [27000/30000] Loss:0.001122 Loss_1:0.001121 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.047854s (8.73min in total, 0.97min remains)
2022-11-28 01:22:43 NUM_SUB: 27;----------------------------
2022-11-28 01:22:43 Epoch [28000/30000] Loss:0.001122 Loss_1:0.001120 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.374263s (9.05min in total, 0.65min remains)
2022-11-28 01:23:03 NUM_SUB: 27;----------------------------
2022-11-28 01:23:03 Epoch [29000/30000] Loss:0.001122 Loss_1:0.001121 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.248542s (9.37min in total, 0.32min remains)
2022-11-28 01:23:22 NUM_SUB: 27;----------------------------
2022-11-28 01:23:22 Epoch [30000/30000] Loss:0.001122 Loss_1:0.001121 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.978994s (9.69min in total, 0.00min remains)
2022-11-28 01:23:22 Testing & drawing...
2022-11-28 01:23:22 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:23:23 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=27/
2022-11-28 01:23:23 [Loss]
2022-11-28 01:23:23 NUM_SUB: 27; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:23:23 NUM_SUB: 27; Personalized parameter estimation: Parameter containing:
tensor([1.8349e-01, 3.1053e-01, 2.4619e-02, 5.9317e-37, 3.0742e-01, 1.1513e-02,
        2.0242e+00, 8.9644e-01, 4.5563e-01, 1.1304e-02, 3.9500e-02, 1.5144e-02,
        2.5071e-01, 1.6886e-01, 1.7756e-02, 5.0030e-01, 6.9767e-01, 8.0001e-01,
        1.1606e-02, 4.1170e+00, 6.8161e-01, 1.9156e-02, 3.9019e+00, 8.7416e-01,
        1.9779e-02, 4.6012e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 01:23:23 NUM_SUB: 27------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:23:23 Testing & drawing...
2022-11-28 01:23:23 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:23:25 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=27/
2022-11-28 01:23:25 [Loss]
2022-11-28 01:23:25 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:23:25 General parameter estimation: Parameter containing:
tensor([1.8349e-01, 3.1053e-01, 2.4619e-02, 5.9317e-37, 3.0742e-01, 1.1513e-02,
        2.0242e+00, 8.9644e-01, 4.5563e-01, 1.1304e-02, 3.9500e-02, 1.5144e-02,
        2.5071e-01, 1.6886e-01, 1.7756e-02, 5.0030e-01, 6.9767e-01, 8.0001e-01,
        1.1606e-02, 4.1170e+00, 6.8161e-01, 1.9156e-02, 3.9019e+00, 8.7416e-01,
        1.9779e-02, 4.6012e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 01:23:25 A: prod, degr, TonA, NonA
2022-11-28 01:23:25 [0.43896785 0.49842152 0.05889592 0.00371467]
2022-11-28 01:23:25 T: prod, degr, AonT, NonT
2022-11-28 01:23:25 [0.17587525 0.41220132 0.21917646 0.19274697]
2022-11-28 01:23:25 N: AonN, TonN, ATonN
2022-11-28 01:23:25 [0.0150495  0.9272573  0.05769319]
2022-11-28 01:23:25 using cpu
2022-11-28 01:23:25 epoch = 30000
2022-11-28 01:23:25 epoch_step = 1000
2022-11-28 01:23:25 model_name = SimpleNetworkAD
2022-11-28 01:23:25 now_string = 2022-11-27-19-40-13
2022-11-28 01:23:25 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:23:25 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:23:25 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:23:25 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:23:25 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:23:25 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:23:45 NUM_SUB: 28;----------------------------
2022-11-28 01:23:45 Epoch [01000/30000] Loss:0.070226 Loss_1:0.064920 Loss_2:0.001651 Loss_3:0.000000 Lr:0.000909 Time:19.575247s (0.33min in total, 9.46min remains)
2022-11-28 01:24:04 NUM_SUB: 28;----------------------------
2022-11-28 01:24:04 Epoch [02000/30000] Loss:0.061692 Loss_1:0.060801 Loss_2:0.000521 Loss_3:0.000000 Lr:0.000833 Time:18.956575s (0.64min in total, 8.99min remains)
2022-11-28 01:24:23 NUM_SUB: 28;----------------------------
2022-11-28 01:24:23 Epoch [03000/30000] Loss:0.055077 Loss_1:0.054759 Loss_2:0.000218 Loss_3:0.000000 Lr:0.000769 Time:19.496871s (0.97min in total, 8.70min remains)
2022-11-28 01:24:42 NUM_SUB: 28;----------------------------
2022-11-28 01:24:42 Epoch [04000/30000] Loss:0.047215 Loss_1:0.046898 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000714 Time:19.249421s (1.29min in total, 8.37min remains)
2022-11-28 01:25:01 NUM_SUB: 28;----------------------------
2022-11-28 01:25:01 Epoch [05000/30000] Loss:0.036438 Loss_1:0.036093 Loss_2:0.000235 Loss_3:0.000000 Lr:0.000667 Time:18.740897s (1.60min in total, 8.00min remains)
2022-11-28 01:25:20 NUM_SUB: 28;----------------------------
2022-11-28 01:25:20 Epoch [06000/30000] Loss:0.024173 Loss_1:0.022875 Loss_2:0.000218 Loss_3:0.000000 Lr:0.000625 Time:18.997944s (1.92min in total, 7.67min remains)
2022-11-28 01:25:39 NUM_SUB: 28;----------------------------
2022-11-28 01:25:39 Epoch [07000/30000] Loss:0.011556 Loss_1:0.011276 Loss_2:0.000237 Loss_3:0.000000 Lr:0.000588 Time:18.882755s (2.23min in total, 7.33min remains)
2022-11-28 01:25:58 NUM_SUB: 28;----------------------------
2022-11-28 01:25:58 Epoch [08000/30000] Loss:0.006884 Loss_1:0.006678 Loss_2:0.000193 Loss_3:0.000000 Lr:0.000556 Time:18.788569s (2.54min in total, 7.00min remains)
2022-11-28 01:26:17 NUM_SUB: 28;----------------------------
2022-11-28 01:26:17 Epoch [09000/30000] Loss:0.005826 Loss_1:0.005691 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000526 Time:18.868977s (2.86min in total, 6.67min remains)
2022-11-28 01:26:36 NUM_SUB: 28;----------------------------
2022-11-28 01:26:36 Epoch [10000/30000] Loss:0.005030 Loss_1:0.004967 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000500 Time:19.264074s (3.18min in total, 6.36min remains)
2022-11-28 01:26:55 NUM_SUB: 28;----------------------------
2022-11-28 01:26:55 Epoch [11000/30000] Loss:0.004112 Loss_1:0.004070 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000476 Time:18.760831s (3.49min in total, 6.03min remains)
2022-11-28 01:27:14 NUM_SUB: 28;----------------------------
2022-11-28 01:27:14 Epoch [12000/30000] Loss:0.003157 Loss_1:0.003124 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000455 Time:19.280151s (3.81min in total, 5.72min remains)
2022-11-28 01:27:34 NUM_SUB: 28;----------------------------
2022-11-28 01:27:34 Epoch [13000/30000] Loss:0.002570 Loss_1:0.002537 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:19.486982s (4.14min in total, 5.41min remains)
2022-11-28 01:27:52 NUM_SUB: 28;----------------------------
2022-11-28 01:27:52 Epoch [14000/30000] Loss:0.002453 Loss_1:0.002424 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:18.605492s (4.45min in total, 5.09min remains)
2022-11-28 01:28:11 NUM_SUB: 28;----------------------------
2022-11-28 01:28:11 Epoch [15000/30000] Loss:0.002432 Loss_1:0.002409 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000400 Time:18.829169s (4.76min in total, 4.76min remains)
2022-11-28 01:28:30 NUM_SUB: 28;----------------------------
2022-11-28 01:28:30 Epoch [16000/30000] Loss:0.002422 Loss_1:0.002405 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:18.853300s (5.08min in total, 4.44min remains)
2022-11-28 01:28:49 NUM_SUB: 28;----------------------------
2022-11-28 01:28:49 Epoch [17000/30000] Loss:0.002417 Loss_1:0.002402 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:18.789310s (5.39min in total, 4.12min remains)
2022-11-28 01:29:08 NUM_SUB: 28;----------------------------
2022-11-28 01:29:08 Epoch [18000/30000] Loss:0.002414 Loss_1:0.002401 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:18.987693s (5.71min in total, 3.80min remains)
2022-11-28 01:29:27 NUM_SUB: 28;----------------------------
2022-11-28 01:29:27 Epoch [19000/30000] Loss:0.002431 Loss_1:0.002394 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:19.029723s (6.02min in total, 3.49min remains)
2022-11-28 01:29:46 NUM_SUB: 28;----------------------------
2022-11-28 01:29:46 Epoch [20000/30000] Loss:0.002407 Loss_1:0.002396 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:19.508897s (6.35min in total, 3.17min remains)
2022-11-28 01:30:05 NUM_SUB: 28;----------------------------
2022-11-28 01:30:05 Epoch [21000/30000] Loss:0.002404 Loss_1:0.002394 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000323 Time:19.076366s (6.67min in total, 2.86min remains)
2022-11-28 01:30:25 NUM_SUB: 28;----------------------------
2022-11-28 01:30:25 Epoch [22000/30000] Loss:0.002400 Loss_1:0.002391 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:19.726414s (7.00min in total, 2.54min remains)
2022-11-28 01:30:44 NUM_SUB: 28;----------------------------
2022-11-28 01:30:44 Epoch [23000/30000] Loss:0.002399 Loss_1:0.002392 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:19.121951s (7.31min in total, 2.23min remains)
2022-11-28 01:31:03 NUM_SUB: 28;----------------------------
2022-11-28 01:31:03 Epoch [24000/30000] Loss:0.002450 Loss_1:0.002445 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.730628s (7.63min in total, 1.91min remains)
2022-11-28 01:31:22 NUM_SUB: 28;----------------------------
2022-11-28 01:31:22 Epoch [25000/30000] Loss:0.002380 Loss_1:0.002375 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:19.346528s (7.95min in total, 1.59min remains)
2022-11-28 01:31:41 NUM_SUB: 28;----------------------------
2022-11-28 01:31:41 Epoch [26000/30000] Loss:0.002378 Loss_1:0.002372 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.011858s (8.27min in total, 1.27min remains)
2022-11-28 01:32:00 NUM_SUB: 28;----------------------------
2022-11-28 01:32:00 Epoch [27000/30000] Loss:0.002386 Loss_1:0.002373 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:18.844375s (8.58min in total, 0.95min remains)
2022-11-28 01:32:19 NUM_SUB: 28;----------------------------
2022-11-28 01:32:19 Epoch [28000/30000] Loss:0.002377 Loss_1:0.002370 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:18.733282s (8.89min in total, 0.64min remains)
2022-11-28 01:32:39 NUM_SUB: 28;----------------------------
2022-11-28 01:32:39 Epoch [29000/30000] Loss:0.002376 Loss_1:0.002370 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.835534s (9.22min in total, 0.32min remains)
2022-11-28 01:32:57 NUM_SUB: 28;----------------------------
2022-11-28 01:32:57 Epoch [30000/30000] Loss:0.002375 Loss_1:0.002370 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:18.809852s (9.54min in total, 0.00min remains)
2022-11-28 01:32:57 Testing & drawing...
2022-11-28 01:32:57 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:32:59 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=28/
2022-11-28 01:32:59 [Loss]
2022-11-28 01:32:59 NUM_SUB: 28; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:32:59 NUM_SUB: 28; Personalized parameter estimation: Parameter containing:
tensor([0.0165, 0.0423, 0.0189, 0.4841, 0.3074, 0.0161, 3.4439, 0.8964, 0.4556,
        0.0151, 0.1490, 0.1331, 0.5459, 0.1689, 0.0175, 2.3134, 0.6977, 0.8000,
        0.0120, 4.0106, 0.6816, 0.0215, 3.2765, 0.8742, 0.0045, 3.9570, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:32:59 NUM_SUB: 28------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:32:59 Testing & drawing...
2022-11-28 01:32:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:33:01 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=28/
2022-11-28 01:33:01 [Loss]
2022-11-28 01:33:01 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:33:01 General parameter estimation: Parameter containing:
tensor([0.0165, 0.0423, 0.0189, 0.4841, 0.3074, 0.0161, 3.4439, 0.8964, 0.4556,
        0.0151, 0.1490, 0.1331, 0.5459, 0.1689, 0.0175, 2.3134, 0.6977, 0.8000,
        0.0120, 4.0106, 0.6816, 0.0215, 3.2765, 0.8742, 0.0045, 3.9570, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:33:01 A: prod, degr, TonA, NonA
2022-11-28 01:33:01 [0.3656254  0.4796944  0.14179687 0.01288336]
2022-11-28 01:33:01 T: prod, degr, AonT, NonT
2022-11-28 01:33:01 [0.11815193 0.58522385 0.28614345 0.01048074]
2022-11-28 01:33:01 N: AonN, TonN, ATonN
2022-11-28 01:33:01 [0.01279507 0.97978467 0.00742029]
2022-11-28 01:33:01 using cpu
2022-11-28 01:33:01 epoch = 30000
2022-11-28 01:33:01 epoch_step = 1000
2022-11-28 01:33:01 model_name = SimpleNetworkAD
2022-11-28 01:33:01 now_string = 2022-11-27-19-40-13
2022-11-28 01:33:01 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:33:01 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:33:01 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:33:01 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:33:01 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:33:01 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:33:20 NUM_SUB: 29;----------------------------
2022-11-28 01:33:20 Epoch [01000/30000] Loss:0.214342 Loss_1:0.208646 Loss_2:0.001780 Loss_3:0.000000 Lr:0.000909 Time:18.687120s (0.31min in total, 9.03min remains)
2022-11-28 01:33:39 NUM_SUB: 29;----------------------------
2022-11-28 01:33:39 Epoch [02000/30000] Loss:0.199807 Loss_1:0.198719 Loss_2:0.000570 Loss_3:0.000000 Lr:0.000833 Time:19.538631s (0.64min in total, 8.92min remains)
2022-11-28 01:33:58 NUM_SUB: 29;----------------------------
2022-11-28 01:33:58 Epoch [03000/30000] Loss:0.185526 Loss_1:0.184594 Loss_2:0.000167 Loss_3:0.000000 Lr:0.000769 Time:19.224961s (0.96min in total, 8.62min remains)
2022-11-28 01:34:17 NUM_SUB: 29;----------------------------
2022-11-28 01:34:17 Epoch [04000/30000] Loss:0.165065 Loss_1:0.164172 Loss_2:0.000126 Loss_3:0.000000 Lr:0.000714 Time:18.793515s (1.27min in total, 8.26min remains)
2022-11-28 01:34:36 NUM_SUB: 29;----------------------------
2022-11-28 01:34:36 Epoch [05000/30000] Loss:0.133780 Loss_1:0.132961 Loss_2:0.000140 Loss_3:0.000000 Lr:0.000667 Time:19.082236s (1.59min in total, 7.94min remains)
2022-11-28 01:34:55 NUM_SUB: 29;----------------------------
2022-11-28 01:34:55 Epoch [06000/30000] Loss:0.089261 Loss_1:0.088553 Loss_2:0.000176 Loss_3:0.000000 Lr:0.000625 Time:18.644694s (1.90min in total, 7.60min remains)
2022-11-28 01:35:14 NUM_SUB: 29;----------------------------
2022-11-28 01:35:14 Epoch [07000/30000] Loss:0.041506 Loss_1:0.040926 Loss_2:0.000251 Loss_3:0.000000 Lr:0.000588 Time:18.842369s (2.21min in total, 7.27min remains)
2022-11-28 01:35:33 NUM_SUB: 29;----------------------------
2022-11-28 01:35:33 Epoch [08000/30000] Loss:0.013244 Loss_1:0.012824 Loss_2:0.000306 Loss_3:0.000000 Lr:0.000556 Time:18.895385s (2.53min in total, 6.95min remains)
2022-11-28 01:35:51 NUM_SUB: 29;----------------------------
2022-11-28 01:35:51 Epoch [09000/30000] Loss:0.007697 Loss_1:0.007404 Loss_2:0.000269 Loss_3:0.000000 Lr:0.000526 Time:18.830067s (2.84min in total, 6.63min remains)
2022-11-28 01:36:10 NUM_SUB: 29;----------------------------
2022-11-28 01:36:10 Epoch [10000/30000] Loss:0.007317 Loss_1:0.007117 Loss_2:0.000189 Loss_3:0.000000 Lr:0.000500 Time:18.896428s (3.16min in total, 6.31min remains)
2022-11-28 01:36:29 NUM_SUB: 29;----------------------------
2022-11-28 01:36:29 Epoch [11000/30000] Loss:0.007170 Loss_1:0.007036 Loss_2:0.000129 Loss_3:0.000000 Lr:0.000476 Time:18.746666s (3.47min in total, 5.99min remains)
2022-11-28 01:36:49 NUM_SUB: 29;----------------------------
2022-11-28 01:36:49 Epoch [12000/30000] Loss:0.007069 Loss_1:0.006971 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000455 Time:19.609792s (3.80min in total, 5.70min remains)
2022-11-28 01:37:09 NUM_SUB: 29;----------------------------
2022-11-28 01:37:09 Epoch [13000/30000] Loss:0.007000 Loss_1:0.006930 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000435 Time:19.853630s (4.13min in total, 5.40min remains)
2022-11-28 01:37:28 NUM_SUB: 29;----------------------------
2022-11-28 01:37:28 Epoch [14000/30000] Loss:0.006973 Loss_1:0.006904 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000417 Time:19.065032s (4.45min in total, 5.08min remains)
2022-11-28 01:37:47 NUM_SUB: 29;----------------------------
2022-11-28 01:37:47 Epoch [15000/30000] Loss:0.006932 Loss_1:0.006896 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000400 Time:19.131635s (4.76min in total, 4.76min remains)
2022-11-28 01:38:05 NUM_SUB: 29;----------------------------
2022-11-28 01:38:05 Epoch [16000/30000] Loss:0.006916 Loss_1:0.006885 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000385 Time:18.700629s (5.08min in total, 4.44min remains)
2022-11-28 01:38:25 NUM_SUB: 29;----------------------------
2022-11-28 01:38:25 Epoch [17000/30000] Loss:0.006906 Loss_1:0.006882 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000370 Time:19.775690s (5.41min in total, 4.13min remains)
2022-11-28 01:38:44 NUM_SUB: 29;----------------------------
2022-11-28 01:38:44 Epoch [18000/30000] Loss:0.006899 Loss_1:0.006879 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:19.205644s (5.73min in total, 3.82min remains)
2022-11-28 01:39:04 NUM_SUB: 29;----------------------------
2022-11-28 01:39:04 Epoch [19000/30000] Loss:0.006894 Loss_1:0.006877 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000345 Time:19.345941s (6.05min in total, 3.50min remains)
2022-11-28 01:39:23 NUM_SUB: 29;----------------------------
2022-11-28 01:39:23 Epoch [20000/30000] Loss:0.006890 Loss_1:0.006875 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:19.255657s (6.37min in total, 3.18min remains)
2022-11-28 01:39:42 NUM_SUB: 29;----------------------------
2022-11-28 01:39:42 Epoch [21000/30000] Loss:0.006887 Loss_1:0.006875 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000323 Time:19.081357s (6.69min in total, 2.87min remains)
2022-11-28 01:40:01 NUM_SUB: 29;----------------------------
2022-11-28 01:40:01 Epoch [22000/30000] Loss:0.006885 Loss_1:0.006874 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:18.947237s (7.00min in total, 2.55min remains)
2022-11-28 01:40:20 NUM_SUB: 29;----------------------------
2022-11-28 01:40:20 Epoch [23000/30000] Loss:0.006883 Loss_1:0.006873 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:19.086783s (7.32min in total, 2.23min remains)
2022-11-28 01:40:39 NUM_SUB: 29;----------------------------
2022-11-28 01:40:39 Epoch [24000/30000] Loss:0.006882 Loss_1:0.006874 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.085430s (7.64min in total, 1.91min remains)
2022-11-28 01:40:58 NUM_SUB: 29;----------------------------
2022-11-28 01:40:58 Epoch [25000/30000] Loss:0.006880 Loss_1:0.006872 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.248460s (7.96min in total, 1.59min remains)
2022-11-28 01:41:18 NUM_SUB: 29;----------------------------
2022-11-28 01:41:18 Epoch [26000/30000] Loss:0.006879 Loss_1:0.006871 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:20.018948s (8.29min in total, 1.28min remains)
2022-11-28 01:41:38 NUM_SUB: 29;----------------------------
2022-11-28 01:41:38 Epoch [27000/30000] Loss:0.006877 Loss_1:0.006871 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.145290s (8.61min in total, 0.96min remains)
2022-11-28 01:41:57 NUM_SUB: 29;----------------------------
2022-11-28 01:41:57 Epoch [28000/30000] Loss:0.006877 Loss_1:0.006868 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.215372s (8.93min in total, 0.64min remains)
2022-11-28 01:42:16 NUM_SUB: 29;----------------------------
2022-11-28 01:42:16 Epoch [29000/30000] Loss:0.006876 Loss_1:0.006868 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.990402s (9.25min in total, 0.32min remains)
2022-11-28 01:42:35 NUM_SUB: 29;----------------------------
2022-11-28 01:42:35 Epoch [30000/30000] Loss:0.006874 Loss_1:0.006868 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.131315s (9.57min in total, 0.00min remains)
2022-11-28 01:42:35 Testing & drawing...
2022-11-28 01:42:35 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:42:37 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=29/
2022-11-28 01:42:37 [Loss]
2022-11-28 01:42:37 NUM_SUB: 29; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:42:37 NUM_SUB: 29; Personalized parameter estimation: Parameter containing:
tensor([0.0151, 0.0902, 0.0106, 1.3899, 0.3074, 0.1326, 1.6478, 0.8964, 0.4556,
        0.0085, 0.0388, 0.0151, 0.2279, 0.1689, 0.0176, 0.5905, 0.6977, 0.8000,
        0.0095, 4.5445, 0.6816, 0.0218, 4.4345, 0.8742, 0.0145, 5.0800, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:42:37 NUM_SUB: 29------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:42:37 Testing & drawing...
2022-11-28 01:42:37 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:42:38 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=29/
2022-11-28 01:42:38 [Loss]
2022-11-28 01:42:38 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:42:38 General parameter estimation: Parameter containing:
tensor([0.0151, 0.0902, 0.0106, 1.3899, 0.3074, 0.1326, 1.6478, 0.8964, 0.4556,
        0.0085, 0.0388, 0.0151, 0.2279, 0.1689, 0.0176, 0.5905, 0.6977, 0.8000,
        0.0095, 4.5445, 0.6816, 0.0218, 4.4345, 0.8742, 0.0145, 5.0800, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:42:38 A: prod, degr, TonA, NonA
2022-11-28 01:42:38 [0.14882202 0.49674678 0.03064237 0.32378882]
2022-11-28 01:42:38 T: prod, degr, AonT, NonT
2022-11-28 01:42:38 [0.1482481  0.38096234 0.249214   0.22157557]
2022-11-28 01:42:38 N: AonN, TonN, ATonN
2022-11-28 01:42:38 [0.00656986 0.9655482  0.02788186]
2022-11-28 01:42:38 using cpu
2022-11-28 01:42:38 epoch = 30000
2022-11-28 01:42:38 epoch_step = 1000
2022-11-28 01:42:38 model_name = SimpleNetworkAD
2022-11-28 01:42:38 now_string = 2022-11-27-19-40-13
2022-11-28 01:42:38 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:42:38 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:42:38 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:42:38 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:42:38 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:42:38 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:42:58 NUM_SUB: 30;----------------------------
2022-11-28 01:42:58 Epoch [01000/30000] Loss:0.039280 Loss_1:0.033268 Loss_2:0.002101 Loss_3:0.000000 Lr:0.000909 Time:19.101448s (0.32min in total, 9.23min remains)
2022-11-28 01:43:16 NUM_SUB: 30;----------------------------
2022-11-28 01:43:16 Epoch [02000/30000] Loss:0.033210 Loss_1:0.031909 Loss_2:0.000836 Loss_3:0.000000 Lr:0.000833 Time:18.988957s (0.63min in total, 8.89min remains)
2022-11-28 01:43:36 NUM_SUB: 30;----------------------------
2022-11-28 01:43:36 Epoch [03000/30000] Loss:0.029628 Loss_1:0.029074 Loss_2:0.000450 Loss_3:0.000000 Lr:0.000769 Time:19.128592s (0.95min in total, 8.58min remains)
2022-11-28 01:43:55 NUM_SUB: 30;----------------------------
2022-11-28 01:43:55 Epoch [04000/30000] Loss:0.026287 Loss_1:0.025829 Loss_2:0.000317 Loss_3:0.000000 Lr:0.000714 Time:19.180726s (1.27min in total, 8.28min remains)
2022-11-28 01:44:14 NUM_SUB: 30;----------------------------
2022-11-28 01:44:14 Epoch [05000/30000] Loss:0.022625 Loss_1:0.022191 Loss_2:0.000286 Loss_3:0.000000 Lr:0.000667 Time:18.784554s (1.59min in total, 7.93min remains)
2022-11-28 01:44:33 NUM_SUB: 30;----------------------------
2022-11-28 01:44:33 Epoch [06000/30000] Loss:0.017958 Loss_1:0.017679 Loss_2:0.000151 Loss_3:0.000000 Lr:0.000625 Time:19.270226s (1.91min in total, 7.63min remains)
2022-11-28 01:44:52 NUM_SUB: 30;----------------------------
2022-11-28 01:44:52 Epoch [07000/30000] Loss:0.012612 Loss_1:0.012385 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000588 Time:18.761993s (2.22min in total, 7.30min remains)
2022-11-28 01:45:11 NUM_SUB: 30;----------------------------
2022-11-28 01:45:11 Epoch [08000/30000] Loss:0.007472 Loss_1:0.007295 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000556 Time:19.123251s (2.54min in total, 6.98min remains)
2022-11-28 01:45:30 NUM_SUB: 30;----------------------------
2022-11-28 01:45:30 Epoch [09000/30000] Loss:0.004138 Loss_1:0.004008 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000526 Time:19.345675s (2.86min in total, 6.68min remains)
2022-11-28 01:45:49 NUM_SUB: 30;----------------------------
2022-11-28 01:45:49 Epoch [10000/30000] Loss:0.002850 Loss_1:0.002750 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000500 Time:18.709209s (3.17min in total, 6.35min remains)
2022-11-28 01:46:08 NUM_SUB: 30;----------------------------
2022-11-28 01:46:08 Epoch [11000/30000] Loss:0.002569 Loss_1:0.002487 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000476 Time:19.235216s (3.49min in total, 6.04min remains)
2022-11-28 01:46:27 NUM_SUB: 30;----------------------------
2022-11-28 01:46:27 Epoch [12000/30000] Loss:0.002429 Loss_1:0.002365 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000455 Time:19.300508s (3.82min in total, 5.72min remains)
2022-11-28 01:46:46 NUM_SUB: 30;----------------------------
2022-11-28 01:46:46 Epoch [13000/30000] Loss:0.002189 Loss_1:0.002154 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000435 Time:18.638876s (4.13min in total, 5.40min remains)
2022-11-28 01:47:05 NUM_SUB: 30;----------------------------
2022-11-28 01:47:05 Epoch [14000/30000] Loss:0.001990 Loss_1:0.001961 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:19.287992s (4.45min in total, 5.08min remains)
2022-11-28 01:47:24 NUM_SUB: 30;----------------------------
2022-11-28 01:47:24 Epoch [15000/30000] Loss:0.001873 Loss_1:0.001848 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000400 Time:19.051832s (4.77min in total, 4.77min remains)
2022-11-28 01:47:44 NUM_SUB: 30;----------------------------
2022-11-28 01:47:44 Epoch [16000/30000] Loss:0.001792 Loss_1:0.001772 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:19.329226s (5.09min in total, 4.45min remains)
2022-11-28 01:48:03 NUM_SUB: 30;----------------------------
2022-11-28 01:48:03 Epoch [17000/30000] Loss:0.001741 Loss_1:0.001724 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000370 Time:19.179785s (5.41min in total, 4.13min remains)
2022-11-28 01:48:22 NUM_SUB: 30;----------------------------
2022-11-28 01:48:22 Epoch [18000/30000] Loss:0.001729 Loss_1:0.001715 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:19.434933s (5.73min in total, 3.82min remains)
2022-11-28 01:48:41 NUM_SUB: 30;----------------------------
2022-11-28 01:48:41 Epoch [19000/30000] Loss:0.001726 Loss_1:0.001713 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000345 Time:18.821321s (6.04min in total, 3.50min remains)
2022-11-28 01:49:00 NUM_SUB: 30;----------------------------
2022-11-28 01:49:00 Epoch [20000/30000] Loss:0.001728 Loss_1:0.001718 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:18.883076s (6.36min in total, 3.18min remains)
2022-11-28 01:49:19 NUM_SUB: 30;----------------------------
2022-11-28 01:49:19 Epoch [21000/30000] Loss:0.001722 Loss_1:0.001713 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000323 Time:18.796222s (6.67min in total, 2.86min remains)
2022-11-28 01:49:38 NUM_SUB: 30;----------------------------
2022-11-28 01:49:38 Epoch [22000/30000] Loss:0.001722 Loss_1:0.001714 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:19.677058s (7.00min in total, 2.55min remains)
2022-11-28 01:49:57 NUM_SUB: 30;----------------------------
2022-11-28 01:49:57 Epoch [23000/30000] Loss:0.001721 Loss_1:0.001714 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:18.887070s (7.32min in total, 2.23min remains)
2022-11-28 01:50:16 NUM_SUB: 30;----------------------------
2022-11-28 01:50:16 Epoch [24000/30000] Loss:0.001720 Loss_1:0.001714 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.746672s (7.63min in total, 1.91min remains)
2022-11-28 01:50:35 NUM_SUB: 30;----------------------------
2022-11-28 01:50:35 Epoch [25000/30000] Loss:0.001719 Loss_1:0.001713 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:19.074551s (7.95min in total, 1.59min remains)
2022-11-28 01:50:54 NUM_SUB: 30;----------------------------
2022-11-28 01:50:54 Epoch [26000/30000] Loss:0.001718 Loss_1:0.001712 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:18.834695s (8.26min in total, 1.27min remains)
2022-11-28 01:51:13 NUM_SUB: 30;----------------------------
2022-11-28 01:51:13 Epoch [27000/30000] Loss:0.001717 Loss_1:0.001712 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:19.059591s (8.58min in total, 0.95min remains)
2022-11-28 01:51:32 NUM_SUB: 30;----------------------------
2022-11-28 01:51:32 Epoch [28000/30000] Loss:0.001715 Loss_1:0.001711 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:19.363068s (8.90min in total, 0.64min remains)
2022-11-28 01:51:51 NUM_SUB: 30;----------------------------
2022-11-28 01:51:51 Epoch [29000/30000] Loss:0.001715 Loss_1:0.001711 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:18.505761s (9.21min in total, 0.32min remains)
2022-11-28 01:52:10 NUM_SUB: 30;----------------------------
2022-11-28 01:52:10 Epoch [30000/30000] Loss:0.001713 Loss_1:0.001710 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:18.787012s (9.52min in total, 0.00min remains)
2022-11-28 01:52:10 Testing & drawing...
2022-11-28 01:52:10 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:52:11 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=30/
2022-11-28 01:52:11 [Loss]
2022-11-28 01:52:11 NUM_SUB: 30; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:52:11 NUM_SUB: 30; Personalized parameter estimation: Parameter containing:
tensor([0.0191, 0.0370, 0.0225, 1.2191, 0.3074, 0.0147, 3.1856, 0.8964, 0.4556,
        0.0136, 0.0275, 0.0132, 0.9581, 0.1689, 0.0175, 2.5331, 0.6977, 0.8000,
        0.0115, 4.5760, 0.6816, 0.0221, 3.9101, 0.8742, 0.0083, 4.3815, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:52:11 NUM_SUB: 30------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 01:52:11 Testing & drawing...
2022-11-28 01:52:11 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 01:52:13 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=30/
2022-11-28 01:52:13 [Loss]
2022-11-28 01:52:13 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 01:52:13 General parameter estimation: Parameter containing:
tensor([0.0191, 0.0370, 0.0225, 1.2191, 0.3074, 0.0147, 3.1856, 0.8964, 0.4556,
        0.0136, 0.0275, 0.0132, 0.9581, 0.1689, 0.0175, 2.5331, 0.6977, 0.8000,
        0.0115, 4.5760, 0.6816, 0.0221, 3.9101, 0.8742, 0.0083, 4.3815, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 01:52:13 A: prod, degr, TonA, NonA
2022-11-28 01:52:13 [0.42025477 0.47871143 0.09389719 0.00713663]
2022-11-28 01:52:13 T: prod, degr, AonT, NonT
2022-11-28 01:52:13 [0.40006977 0.47622144 0.10601923 0.01768958]
2022-11-28 01:52:13 N: AonN, TonN, ATonN
2022-11-28 01:52:13 [0.00946853 0.976016   0.01451552]
2022-11-28 01:52:13 using cpu
2022-11-28 01:52:13 epoch = 30000
2022-11-28 01:52:13 epoch_step = 1000
2022-11-28 01:52:13 model_name = SimpleNetworkAD
2022-11-28 01:52:13 now_string = 2022-11-27-19-40-13
2022-11-28 01:52:13 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 01:52:13 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 01:52:13 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 01:52:13 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 01:52:13 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 01:52:13 --------------------------------------------------training start--------------------------------------------------
2022-11-28 01:52:32 NUM_SUB: 31;----------------------------
2022-11-28 01:52:32 Epoch [01000/30000] Loss:0.009569 Loss_1:0.004432 Loss_2:0.001375 Loss_3:0.000000 Lr:0.000909 Time:19.302715s (0.32min in total, 9.33min remains)
2022-11-28 01:52:52 NUM_SUB: 31;----------------------------
2022-11-28 01:52:52 Epoch [02000/30000] Loss:0.005001 Loss_1:0.004253 Loss_2:0.000350 Loss_3:0.000000 Lr:0.000833 Time:19.935107s (0.65min in total, 9.16min remains)
2022-11-28 01:53:12 NUM_SUB: 31;----------------------------
2022-11-28 01:53:12 Epoch [03000/30000] Loss:0.004139 Loss_1:0.003993 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000769 Time:19.937202s (0.99min in total, 8.88min remains)
2022-11-28 01:53:32 NUM_SUB: 31;----------------------------
2022-11-28 01:53:32 Epoch [04000/30000] Loss:0.003703 Loss_1:0.003649 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000714 Time:20.029868s (1.32min in total, 8.58min remains)
2022-11-28 01:53:52 NUM_SUB: 31;----------------------------
2022-11-28 01:53:52 Epoch [05000/30000] Loss:0.003262 Loss_1:0.003210 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000667 Time:19.244568s (1.64min in total, 8.20min remains)
2022-11-28 01:54:11 NUM_SUB: 31;----------------------------
2022-11-28 01:54:11 Epoch [06000/30000] Loss:0.002707 Loss_1:0.002657 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000625 Time:18.970231s (1.96min in total, 7.83min remains)
2022-11-28 01:54:30 NUM_SUB: 31;----------------------------
2022-11-28 01:54:30 Epoch [07000/30000] Loss:0.002068 Loss_1:0.002022 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000588 Time:19.437188s (2.28min in total, 7.49min remains)
2022-11-28 01:54:49 NUM_SUB: 31;----------------------------
2022-11-28 01:54:49 Epoch [08000/30000] Loss:0.001445 Loss_1:0.001401 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000556 Time:19.024080s (2.60min in total, 7.14min remains)
2022-11-28 01:55:08 NUM_SUB: 31;----------------------------
2022-11-28 01:55:08 Epoch [09000/30000] Loss:0.000976 Loss_1:0.000929 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000526 Time:18.757477s (2.91min in total, 6.79min remains)
2022-11-28 01:55:27 NUM_SUB: 31;----------------------------
2022-11-28 01:55:27 Epoch [10000/30000] Loss:0.000700 Loss_1:0.000649 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000500 Time:19.095695s (3.23min in total, 6.46min remains)
2022-11-28 01:55:46 NUM_SUB: 31;----------------------------
2022-11-28 01:55:46 Epoch [11000/30000] Loss:0.000491 Loss_1:0.000443 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000476 Time:19.236926s (3.55min in total, 6.13min remains)
2022-11-28 01:56:05 NUM_SUB: 31;----------------------------
2022-11-28 01:56:05 Epoch [12000/30000] Loss:0.000268 Loss_1:0.000249 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000455 Time:19.171002s (3.87min in total, 5.80min remains)
2022-11-28 01:56:24 NUM_SUB: 31;----------------------------
2022-11-28 01:56:24 Epoch [13000/30000] Loss:0.000130 Loss_1:0.000118 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000435 Time:19.099211s (4.19min in total, 5.48min remains)
2022-11-28 01:56:43 NUM_SUB: 31;----------------------------
2022-11-28 01:56:43 Epoch [14000/30000] Loss:0.000090 Loss_1:0.000082 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000417 Time:18.871706s (4.50min in total, 5.15min remains)
2022-11-28 01:57:02 NUM_SUB: 31;----------------------------
2022-11-28 01:57:02 Epoch [15000/30000] Loss:0.000085 Loss_1:0.000079 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000400 Time:18.701421s (4.81min in total, 4.81min remains)
2022-11-28 01:57:22 NUM_SUB: 31;----------------------------
2022-11-28 01:57:22 Epoch [16000/30000] Loss:0.000083 Loss_1:0.000078 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000385 Time:19.781426s (5.14min in total, 4.50min remains)
2022-11-28 01:57:41 NUM_SUB: 31;----------------------------
2022-11-28 01:57:41 Epoch [17000/30000] Loss:0.000081 Loss_1:0.000078 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:19.365188s (5.47min in total, 4.18min remains)
2022-11-28 01:58:00 NUM_SUB: 31;----------------------------
2022-11-28 01:58:00 Epoch [18000/30000] Loss:0.000081 Loss_1:0.000078 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:18.716455s (5.78min in total, 3.85min remains)
2022-11-28 01:58:19 NUM_SUB: 31;----------------------------
2022-11-28 01:58:19 Epoch [19000/30000] Loss:0.000080 Loss_1:0.000078 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:18.931018s (6.09min in total, 3.53min remains)
2022-11-28 01:58:38 NUM_SUB: 31;----------------------------
2022-11-28 01:58:38 Epoch [20000/30000] Loss:0.000080 Loss_1:0.000078 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.316446s (6.42min in total, 3.21min remains)
2022-11-28 01:58:57 NUM_SUB: 31;----------------------------
2022-11-28 01:58:57 Epoch [21000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.337232s (6.74min in total, 2.89min remains)
2022-11-28 01:59:16 NUM_SUB: 31;----------------------------
2022-11-28 01:59:16 Epoch [22000/30000] Loss:0.000079 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:18.874001s (7.05min in total, 2.56min remains)
2022-11-28 01:59:35 NUM_SUB: 31;----------------------------
2022-11-28 01:59:35 Epoch [23000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000303 Time:18.936463s (7.37min in total, 2.24min remains)
2022-11-28 01:59:54 NUM_SUB: 31;----------------------------
2022-11-28 01:59:54 Epoch [24000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:19.018750s (7.69min in total, 1.92min remains)
2022-11-28 02:00:13 NUM_SUB: 31;----------------------------
2022-11-28 02:00:13 Epoch [25000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:19.015454s (8.00min in total, 1.60min remains)
2022-11-28 02:00:32 NUM_SUB: 31;----------------------------
2022-11-28 02:00:32 Epoch [26000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:18.828882s (8.32min in total, 1.28min remains)
2022-11-28 02:00:51 NUM_SUB: 31;----------------------------
2022-11-28 02:00:51 Epoch [27000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.080181s (8.63min in total, 0.96min remains)
2022-11-28 02:01:10 NUM_SUB: 31;----------------------------
2022-11-28 02:01:10 Epoch [28000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:18.650476s (8.94min in total, 0.64min remains)
2022-11-28 02:01:29 NUM_SUB: 31;----------------------------
2022-11-28 02:01:29 Epoch [29000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.220590s (9.27min in total, 0.32min remains)
2022-11-28 02:01:48 NUM_SUB: 31;----------------------------
2022-11-28 02:01:48 Epoch [30000/30000] Loss:0.000079 Loss_1:0.000078 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.880220s (9.58min in total, 0.00min remains)
2022-11-28 02:01:48 Testing & drawing...
2022-11-28 02:01:48 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:01:49 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=31/
2022-11-28 02:01:49 [Loss]
2022-11-28 02:01:50 NUM_SUB: 31; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:01:50 NUM_SUB: 31; Personalized parameter estimation: Parameter containing:
tensor([2.5342e-01, 1.0041e+00, 9.2704e-03, 8.3557e-37, 3.0742e-01, 1.3669e-02,
        1.1687e+00, 8.9644e-01, 4.5563e-01, 1.4053e-02, 1.0859e-01, 7.5842e-02,
        5.0939e-01, 1.6886e-01, 1.7592e-02, 5.4386e-01, 6.9767e-01, 8.0001e-01,
        1.2544e-02, 2.7043e+00, 6.8161e-01, 2.1695e-02, 3.0098e+00, 8.7416e-01,
        2.0877e-02, 3.6435e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:01:50 NUM_SUB: 31------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:01:50 Testing & drawing...
2022-11-28 02:01:50 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:01:51 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=31/
2022-11-28 02:01:51 [Loss]
2022-11-28 02:01:51 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:01:51 General parameter estimation: Parameter containing:
tensor([2.5342e-01, 1.0041e+00, 9.2704e-03, 8.3557e-37, 3.0742e-01, 1.3669e-02,
        1.1687e+00, 8.9644e-01, 4.5563e-01, 1.4053e-02, 1.0859e-01, 7.5842e-02,
        5.0939e-01, 1.6886e-01, 1.7592e-02, 5.4386e-01, 6.9767e-01, 8.0001e-01,
        1.2544e-02, 2.7043e+00, 6.8161e-01, 2.1695e-02, 3.0098e+00, 8.7416e-01,
        2.0877e-02, 3.6435e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:01:51 A: prod, degr, TonA, NonA
2022-11-28 02:01:51 [0.48175296 0.5000047  0.01762311 0.00061924]
2022-11-28 02:01:51 T: prod, degr, AonT, NonT
2022-11-28 02:01:51 [0.19342123 0.39147863 0.39181733 0.02328283]
2022-11-28 02:01:51 N: AonN, TonN, ATonN
2022-11-28 02:01:51 [0.00623673 0.97460765 0.01915561]
2022-11-28 02:01:51 using cpu
2022-11-28 02:01:51 epoch = 30000
2022-11-28 02:01:51 epoch_step = 1000
2022-11-28 02:01:51 model_name = SimpleNetworkAD
2022-11-28 02:01:51 now_string = 2022-11-27-19-40-13
2022-11-28 02:01:51 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:01:51 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:01:51 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:01:51 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:01:51 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:01:51 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:02:10 NUM_SUB: 32;----------------------------
2022-11-28 02:02:10 Epoch [01000/30000] Loss:0.072375 Loss_1:0.067098 Loss_2:0.001431 Loss_3:0.000000 Lr:0.000909 Time:18.762442s (0.31min in total, 9.07min remains)
2022-11-28 02:02:29 NUM_SUB: 32;----------------------------
2022-11-28 02:02:29 Epoch [02000/30000] Loss:0.064779 Loss_1:0.063977 Loss_2:0.000373 Loss_3:0.000000 Lr:0.000833 Time:19.253970s (0.63min in total, 8.87min remains)
2022-11-28 02:02:48 NUM_SUB: 32;----------------------------
2022-11-28 02:02:48 Epoch [03000/30000] Loss:0.059423 Loss_1:0.059124 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000769 Time:18.945522s (0.95min in total, 8.54min remains)
2022-11-28 02:03:08 NUM_SUB: 32;----------------------------
2022-11-28 02:03:08 Epoch [04000/30000] Loss:0.053593 Loss_1:0.053257 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000714 Time:19.173131s (1.27min in total, 8.25min remains)
2022-11-28 02:03:27 NUM_SUB: 32;----------------------------
2022-11-28 02:03:27 Epoch [05000/30000] Loss:0.045555 Loss_1:0.045253 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000667 Time:19.257372s (1.59min in total, 7.95min remains)
2022-11-28 02:03:46 NUM_SUB: 32;----------------------------
2022-11-28 02:03:46 Epoch [06000/30000] Loss:0.035233 Loss_1:0.034986 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000625 Time:19.209153s (1.91min in total, 7.64min remains)
2022-11-28 02:04:06 NUM_SUB: 32;----------------------------
2022-11-28 02:04:06 Epoch [07000/30000] Loss:0.024389 Loss_1:0.024204 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000588 Time:19.881848s (2.24min in total, 7.36min remains)
2022-11-28 02:04:25 NUM_SUB: 32;----------------------------
2022-11-28 02:04:25 Epoch [08000/30000] Loss:0.016782 Loss_1:0.016643 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000556 Time:19.566336s (2.57min in total, 7.06min remains)
2022-11-28 02:04:45 NUM_SUB: 32;----------------------------
2022-11-28 02:04:45 Epoch [09000/30000] Loss:0.013610 Loss_1:0.013487 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000526 Time:19.228044s (2.89min in total, 6.74min remains)
2022-11-28 02:05:04 NUM_SUB: 32;----------------------------
2022-11-28 02:05:04 Epoch [10000/30000] Loss:0.012692 Loss_1:0.012567 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000500 Time:19.048292s (3.21min in total, 6.41min remains)
2022-11-28 02:05:23 NUM_SUB: 32;----------------------------
2022-11-28 02:05:23 Epoch [11000/30000] Loss:0.011934 Loss_1:0.011851 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000476 Time:19.250660s (3.53min in total, 6.09min remains)
2022-11-28 02:05:42 NUM_SUB: 32;----------------------------
2022-11-28 02:05:42 Epoch [12000/30000] Loss:0.011238 Loss_1:0.011192 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000455 Time:19.201991s (3.85min in total, 5.77min remains)
2022-11-28 02:06:01 NUM_SUB: 32;----------------------------
2022-11-28 02:06:01 Epoch [13000/30000] Loss:0.010986 Loss_1:0.010949 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000435 Time:19.218181s (4.17min in total, 5.45min remains)
2022-11-28 02:06:20 NUM_SUB: 32;----------------------------
2022-11-28 02:06:20 Epoch [14000/30000] Loss:0.010907 Loss_1:0.010881 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:19.007262s (4.48min in total, 5.12min remains)
2022-11-28 02:06:40 NUM_SUB: 32;----------------------------
2022-11-28 02:06:40 Epoch [15000/30000] Loss:0.010825 Loss_1:0.010805 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:19.271311s (4.81min in total, 4.81min remains)
2022-11-28 02:06:59 NUM_SUB: 32;----------------------------
2022-11-28 02:06:59 Epoch [16000/30000] Loss:0.010745 Loss_1:0.010723 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:19.138154s (5.12min in total, 4.48min remains)
2022-11-28 02:07:18 NUM_SUB: 32;----------------------------
2022-11-28 02:07:18 Epoch [17000/30000] Loss:0.010714 Loss_1:0.010700 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:18.859068s (5.44min in total, 4.16min remains)
2022-11-28 02:07:37 NUM_SUB: 32;----------------------------
2022-11-28 02:07:37 Epoch [18000/30000] Loss:0.010709 Loss_1:0.010699 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:19.408141s (5.76min in total, 3.84min remains)
2022-11-28 02:07:56 NUM_SUB: 32;----------------------------
2022-11-28 02:07:56 Epoch [19000/30000] Loss:0.010708 Loss_1:0.010699 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:18.929227s (6.08min in total, 3.52min remains)
2022-11-28 02:08:15 NUM_SUB: 32;----------------------------
2022-11-28 02:08:15 Epoch [20000/30000] Loss:0.010707 Loss_1:0.010701 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.107690s (6.40min in total, 3.20min remains)
2022-11-28 02:08:34 NUM_SUB: 32;----------------------------
2022-11-28 02:08:34 Epoch [21000/30000] Loss:0.010705 Loss_1:0.010697 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.133409s (6.71min in total, 2.88min remains)
2022-11-28 02:08:53 NUM_SUB: 32;----------------------------
2022-11-28 02:08:53 Epoch [22000/30000] Loss:0.010704 Loss_1:0.010696 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:18.995380s (7.03min in total, 2.56min remains)
2022-11-28 02:09:12 NUM_SUB: 32;----------------------------
2022-11-28 02:09:12 Epoch [23000/30000] Loss:0.010704 Loss_1:0.010693 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.036620s (7.35min in total, 2.24min remains)
2022-11-28 02:09:31 NUM_SUB: 32;----------------------------
2022-11-28 02:09:31 Epoch [24000/30000] Loss:0.010703 Loss_1:0.010692 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.017783s (7.67min in total, 1.92min remains)
2022-11-28 02:09:51 NUM_SUB: 32;----------------------------
2022-11-28 02:09:51 Epoch [25000/30000] Loss:0.010703 Loss_1:0.010698 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.357634s (7.99min in total, 1.60min remains)
2022-11-28 02:10:10 NUM_SUB: 32;----------------------------
2022-11-28 02:10:10 Epoch [26000/30000] Loss:0.010702 Loss_1:0.010694 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.202401s (8.31min in total, 1.28min remains)
2022-11-28 02:10:29 NUM_SUB: 32;----------------------------
2022-11-28 02:10:29 Epoch [27000/30000] Loss:0.010703 Loss_1:0.010691 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.400178s (8.63min in total, 0.96min remains)
2022-11-28 02:10:49 NUM_SUB: 32;----------------------------
2022-11-28 02:10:49 Epoch [28000/30000] Loss:0.010703 Loss_1:0.010689 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.364822s (8.95min in total, 0.64min remains)
2022-11-28 02:11:08 NUM_SUB: 32;----------------------------
2022-11-28 02:11:08 Epoch [29000/30000] Loss:0.010702 Loss_1:0.010691 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.247123s (9.28min in total, 0.32min remains)
2022-11-28 02:11:27 NUM_SUB: 32;----------------------------
2022-11-28 02:11:27 Epoch [30000/30000] Loss:0.010733 Loss_1:0.010725 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.529449s (9.60min in total, 0.00min remains)
2022-11-28 02:11:27 Testing & drawing...
2022-11-28 02:11:27 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:11:29 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=32/
2022-11-28 02:11:29 [Loss]
2022-11-28 02:11:29 NUM_SUB: 32; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:11:29 NUM_SUB: 32; Personalized parameter estimation: Parameter containing:
tensor([2.7855e-01, 9.6206e-01, 9.4823e-03, 1.4482e-01, 3.0742e-01, 1.3535e-02,
        6.7402e-01, 8.9644e-01, 4.5563e-01, 1.4332e-02, 2.6912e-02, 1.4283e-02,
        9.8741e-01, 1.6886e-01, 2.4770e-03, 2.5523e+00, 6.9767e-01, 8.0001e-01,
        1.2333e-02, 3.7016e+00, 6.8161e-01, 2.1835e-02, 4.0726e+00, 8.7416e-01,
        2.0299e-02, 4.7469e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:11:29 NUM_SUB: 32------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:11:29 Testing & drawing...
2022-11-28 02:11:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:11:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=32/
2022-11-28 02:11:31 [Loss]
2022-11-28 02:11:31 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:11:31 General parameter estimation: Parameter containing:
tensor([2.7855e-01, 9.6206e-01, 9.4823e-03, 1.4482e-01, 3.0742e-01, 1.3535e-02,
        6.7402e-01, 8.9644e-01, 4.5563e-01, 1.4332e-02, 2.6912e-02, 1.4283e-02,
        9.8741e-01, 1.6886e-01, 2.4770e-03, 2.5523e+00, 6.9767e-01, 8.0001e-01,
        1.2333e-02, 3.7016e+00, 6.8161e-01, 2.1835e-02, 4.0726e+00, 8.7416e-01,
        2.0299e-02, 4.7469e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:11:31 A: prod, degr, TonA, NonA
2022-11-28 02:11:31 [0.4753649  0.5000194  0.01529646 0.0093193 ]
2022-11-28 02:11:31 T: prod, degr, AonT, NonT
2022-11-28 02:11:31 [0.5368548  0.30701238 0.15195543 0.00417739]
2022-11-28 02:11:31 N: AonN, TonN, ATonN
2022-11-28 02:11:31 [0.00399775 0.97524256 0.02075972]
2022-11-28 02:11:31 using cpu
2022-11-28 02:11:31 epoch = 30000
2022-11-28 02:11:31 epoch_step = 1000
2022-11-28 02:11:31 model_name = SimpleNetworkAD
2022-11-28 02:11:31 now_string = 2022-11-27-19-40-13
2022-11-28 02:11:31 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:11:31 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:11:31 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:11:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:11:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:11:31 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:11:50 NUM_SUB: 33;----------------------------
2022-11-28 02:11:50 Epoch [01000/30000] Loss:0.044760 Loss_1:0.038738 Loss_2:0.002105 Loss_3:0.000000 Lr:0.000909 Time:19.281374s (0.32min in total, 9.32min remains)
2022-11-28 02:12:09 NUM_SUB: 33;----------------------------
2022-11-28 02:12:09 Epoch [02000/30000] Loss:0.038114 Loss_1:0.036894 Loss_2:0.000754 Loss_3:0.000000 Lr:0.000833 Time:19.099270s (0.64min in total, 8.96min remains)
2022-11-28 02:12:29 NUM_SUB: 33;----------------------------
2022-11-28 02:12:29 Epoch [03000/30000] Loss:0.034166 Loss_1:0.033741 Loss_2:0.000312 Loss_3:0.000000 Lr:0.000769 Time:20.064425s (0.97min in total, 8.77min remains)
2022-11-28 02:12:49 NUM_SUB: 33;----------------------------
2022-11-28 02:12:49 Epoch [04000/30000] Loss:0.030154 Loss_1:0.029760 Loss_2:0.000199 Loss_3:0.000000 Lr:0.000714 Time:19.499144s (1.30min in total, 8.44min remains)
2022-11-28 02:13:08 NUM_SUB: 33;----------------------------
2022-11-28 02:13:08 Epoch [05000/30000] Loss:0.024879 Loss_1:0.024527 Loss_2:0.000164 Loss_3:0.000000 Lr:0.000667 Time:18.980261s (1.62min in total, 8.08min remains)
2022-11-28 02:13:27 NUM_SUB: 33;----------------------------
2022-11-28 02:13:27 Epoch [06000/30000] Loss:0.018143 Loss_1:0.017855 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000625 Time:19.628111s (1.94min in total, 7.77min remains)
2022-11-28 02:13:47 NUM_SUB: 33;----------------------------
2022-11-28 02:13:47 Epoch [07000/30000] Loss:0.010576 Loss_1:0.010344 Loss_2:0.000125 Loss_3:0.000000 Lr:0.000588 Time:19.237019s (2.26min in total, 7.44min remains)
2022-11-28 02:14:06 NUM_SUB: 33;----------------------------
2022-11-28 02:14:06 Epoch [08000/30000] Loss:0.004340 Loss_1:0.004164 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000556 Time:19.206514s (2.58min in total, 7.10min remains)
2022-11-28 02:14:25 NUM_SUB: 33;----------------------------
2022-11-28 02:14:25 Epoch [09000/30000] Loss:0.001210 Loss_1:0.001078 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000526 Time:19.419388s (2.91min in total, 6.78min remains)
2022-11-28 02:14:44 NUM_SUB: 33;----------------------------
2022-11-28 02:14:44 Epoch [10000/30000] Loss:0.000279 Loss_1:0.000184 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000500 Time:18.933230s (3.22min in total, 6.45min remains)
2022-11-28 02:15:03 NUM_SUB: 33;----------------------------
2022-11-28 02:15:03 Epoch [11000/30000] Loss:0.000134 Loss_1:0.000067 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000476 Time:19.140618s (3.54min in total, 6.12min remains)
2022-11-28 02:15:23 NUM_SUB: 33;----------------------------
2022-11-28 02:15:23 Epoch [12000/30000] Loss:0.000100 Loss_1:0.000055 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000455 Time:19.186657s (3.86min in total, 5.79min remains)
2022-11-28 02:15:42 NUM_SUB: 33;----------------------------
2022-11-28 02:15:42 Epoch [13000/30000] Loss:0.000075 Loss_1:0.000045 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:19.300949s (4.18min in total, 5.47min remains)
2022-11-28 02:16:01 NUM_SUB: 33;----------------------------
2022-11-28 02:16:01 Epoch [14000/30000] Loss:0.000056 Loss_1:0.000035 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000417 Time:19.548503s (4.51min in total, 5.15min remains)
2022-11-28 02:16:21 NUM_SUB: 33;----------------------------
2022-11-28 02:16:21 Epoch [15000/30000] Loss:0.000040 Loss_1:0.000025 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:19.461512s (4.83min in total, 4.83min remains)
2022-11-28 02:16:40 NUM_SUB: 33;----------------------------
2022-11-28 02:16:40 Epoch [16000/30000] Loss:0.000028 Loss_1:0.000017 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:19.182863s (5.15min in total, 4.51min remains)
2022-11-28 02:16:59 NUM_SUB: 33;----------------------------
2022-11-28 02:16:59 Epoch [17000/30000] Loss:0.000018 Loss_1:0.000009 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.117358s (5.47min in total, 4.18min remains)
2022-11-28 02:17:18 NUM_SUB: 33;----------------------------
2022-11-28 02:17:18 Epoch [18000/30000] Loss:0.000011 Loss_1:0.000004 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:18.883469s (5.79min in total, 3.86min remains)
2022-11-28 02:17:38 NUM_SUB: 33;----------------------------
2022-11-28 02:17:38 Epoch [19000/30000] Loss:0.000007 Loss_1:0.000001 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:20.176472s (6.12min in total, 3.54min remains)
2022-11-28 02:17:58 NUM_SUB: 33;----------------------------
2022-11-28 02:17:58 Epoch [20000/30000] Loss:0.000005 Loss_1:0.000000 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.871417s (6.45min in total, 3.23min remains)
2022-11-28 02:18:17 NUM_SUB: 33;----------------------------
2022-11-28 02:18:17 Epoch [21000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.200132s (6.77min in total, 2.90min remains)
2022-11-28 02:18:37 NUM_SUB: 33;----------------------------
2022-11-28 02:18:37 Epoch [22000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.444518s (7.10min in total, 2.58min remains)
2022-11-28 02:18:56 NUM_SUB: 33;----------------------------
2022-11-28 02:18:56 Epoch [23000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.016742s (7.42min in total, 2.26min remains)
2022-11-28 02:19:15 NUM_SUB: 33;----------------------------
2022-11-28 02:19:15 Epoch [24000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.948346s (7.73min in total, 1.93min remains)
2022-11-28 02:19:34 NUM_SUB: 33;----------------------------
2022-11-28 02:19:34 Epoch [25000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.051012s (8.05min in total, 1.61min remains)
2022-11-28 02:19:53 NUM_SUB: 33;----------------------------
2022-11-28 02:19:53 Epoch [26000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:18.898767s (8.36min in total, 1.29min remains)
2022-11-28 02:20:12 NUM_SUB: 33;----------------------------
2022-11-28 02:20:12 Epoch [27000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:18.937442s (8.68min in total, 0.96min remains)
2022-11-28 02:20:31 NUM_SUB: 33;----------------------------
2022-11-28 02:20:31 Epoch [28000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.058069s (9.00min in total, 0.64min remains)
2022-11-28 02:20:50 NUM_SUB: 33;----------------------------
2022-11-28 02:20:50 Epoch [29000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.943974s (9.31min in total, 0.32min remains)
2022-11-28 02:21:09 NUM_SUB: 33;----------------------------
2022-11-28 02:21:09 Epoch [30000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.974721s (9.63min in total, 0.00min remains)
2022-11-28 02:21:09 Testing & drawing...
2022-11-28 02:21:09 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:21:10 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=33/
2022-11-28 02:21:10 [Loss]
2022-11-28 02:21:10 NUM_SUB: 33; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:21:10 NUM_SUB: 33; Personalized parameter estimation: Parameter containing:
tensor([0.0154, 0.0252, 0.0109, 2.7788, 0.3074, 0.0146, 2.9801, 0.8964, 0.4556,
        0.0112, 0.0752, 0.0286, 0.2462, 0.1689, 0.0155, 1.1168, 0.6977, 0.8000,
        0.0116, 4.3916, 0.6816, 0.0222, 3.5461, 0.8742, 0.0199, 4.5252, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:21:10 NUM_SUB: 33------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:21:10 Testing & drawing...
2022-11-28 02:21:10 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:21:12 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=33/
2022-11-28 02:21:12 [Loss]
2022-11-28 02:21:12 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:21:12 General parameter estimation: Parameter containing:
tensor([0.0154, 0.0252, 0.0109, 2.7788, 0.3074, 0.0146, 2.9801, 0.8964, 0.4556,
        0.0112, 0.0752, 0.0286, 0.2462, 0.1689, 0.0155, 1.1168, 0.6977, 0.8000,
        0.0116, 4.3916, 0.6816, 0.0222, 3.5461, 0.8742, 0.0199, 4.5252, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:21:12 A: prod, degr, TonA, NonA
2022-11-28 02:21:12 [0.49202862 0.47987378 0.01074232 0.01735529]
2022-11-28 02:21:12 T: prod, degr, AonT, NonT
2022-11-28 02:21:12 [0.13605538 0.5441483  0.27945834 0.04033798]
2022-11-28 02:21:12 N: AonN, TonN, ATonN
2022-11-28 02:21:12 [0.01038146 0.961804   0.02781463]
2022-11-28 02:21:12 using cpu
2022-11-28 02:21:12 epoch = 30000
2022-11-28 02:21:12 epoch_step = 1000
2022-11-28 02:21:12 model_name = SimpleNetworkAD
2022-11-28 02:21:12 now_string = 2022-11-27-19-40-13
2022-11-28 02:21:12 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:21:12 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:21:12 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:21:12 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:21:12 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:21:12 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:21:31 NUM_SUB: 34;----------------------------
2022-11-28 02:21:31 Epoch [01000/30000] Loss:0.202021 Loss_1:0.195923 Loss_2:0.001859 Loss_3:0.000000 Lr:0.000909 Time:19.121320s (0.32min in total, 9.24min remains)
2022-11-28 02:21:50 NUM_SUB: 34;----------------------------
2022-11-28 02:21:50 Epoch [02000/30000] Loss:0.190580 Loss_1:0.189228 Loss_2:0.000565 Loss_3:0.000000 Lr:0.000833 Time:18.827844s (0.63min in total, 8.85min remains)
2022-11-28 02:22:09 NUM_SUB: 34;----------------------------
2022-11-28 02:22:09 Epoch [03000/30000] Loss:0.178711 Loss_1:0.177815 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000769 Time:18.734577s (0.94min in total, 8.50min remains)
2022-11-28 02:22:28 NUM_SUB: 34;----------------------------
2022-11-28 02:22:28 Epoch [04000/30000] Loss:0.161607 Loss_1:0.160671 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000714 Time:18.769144s (1.26min in total, 8.17min remains)
2022-11-28 02:22:47 NUM_SUB: 34;----------------------------
2022-11-28 02:22:47 Epoch [05000/30000] Loss:0.135739 Loss_1:0.134864 Loss_2:0.000121 Loss_3:0.000000 Lr:0.000667 Time:18.978716s (1.57min in total, 7.87min remains)
2022-11-28 02:23:06 NUM_SUB: 34;----------------------------
2022-11-28 02:23:06 Epoch [06000/30000] Loss:0.096759 Loss_1:0.095996 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000625 Time:19.269825s (1.90min in total, 7.58min remains)
2022-11-28 02:23:25 NUM_SUB: 34;----------------------------
2022-11-28 02:23:25 Epoch [07000/30000] Loss:0.046334 Loss_1:0.045736 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000588 Time:18.797343s (2.21min in total, 7.26min remains)
2022-11-28 02:23:44 NUM_SUB: 34;----------------------------
2022-11-28 02:23:44 Epoch [08000/30000] Loss:0.012977 Loss_1:0.012583 Loss_2:0.000282 Loss_3:0.000000 Lr:0.000556 Time:19.002516s (2.53min in total, 6.94min remains)
2022-11-28 02:24:02 NUM_SUB: 34;----------------------------
2022-11-28 02:24:02 Epoch [09000/30000] Loss:0.006397 Loss_1:0.006147 Loss_2:0.000230 Loss_3:0.000000 Lr:0.000526 Time:18.542105s (2.83min in total, 6.61min remains)
2022-11-28 02:24:21 NUM_SUB: 34;----------------------------
2022-11-28 02:24:21 Epoch [10000/30000] Loss:0.003026 Loss_1:0.002859 Loss_2:0.000158 Loss_3:0.000000 Lr:0.000500 Time:19.201008s (3.15min in total, 6.31min remains)
2022-11-28 02:24:40 NUM_SUB: 34;----------------------------
2022-11-28 02:24:40 Epoch [11000/30000] Loss:0.000980 Loss_1:0.000872 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000476 Time:18.712053s (3.47min in total, 5.99min remains)
2022-11-28 02:24:59 NUM_SUB: 34;----------------------------
2022-11-28 02:24:59 Epoch [12000/30000] Loss:0.000579 Loss_1:0.000507 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000455 Time:19.122902s (3.78min in total, 5.68min remains)
2022-11-28 02:25:18 NUM_SUB: 34;----------------------------
2022-11-28 02:25:18 Epoch [13000/30000] Loss:0.000447 Loss_1:0.000391 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000435 Time:18.868803s (4.10min in total, 5.36min remains)
2022-11-28 02:25:37 NUM_SUB: 34;----------------------------
2022-11-28 02:25:37 Epoch [14000/30000] Loss:0.000335 Loss_1:0.000293 Loss_2:0.000040 Loss_3:0.000000 Lr:0.000417 Time:19.379519s (4.42min in total, 5.05min remains)
2022-11-28 02:25:56 NUM_SUB: 34;----------------------------
2022-11-28 02:25:56 Epoch [15000/30000] Loss:0.000261 Loss_1:0.000229 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000400 Time:18.931367s (4.74min in total, 4.74min remains)
2022-11-28 02:26:15 NUM_SUB: 34;----------------------------
2022-11-28 02:26:15 Epoch [16000/30000] Loss:0.000218 Loss_1:0.000191 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000385 Time:18.840660s (5.05min in total, 4.42min remains)
2022-11-28 02:26:35 NUM_SUB: 34;----------------------------
2022-11-28 02:26:35 Epoch [17000/30000] Loss:0.000190 Loss_1:0.000168 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000370 Time:19.519713s (5.38min in total, 4.11min remains)
2022-11-28 02:26:54 NUM_SUB: 34;----------------------------
2022-11-28 02:26:54 Epoch [18000/30000] Loss:0.000174 Loss_1:0.000154 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000357 Time:19.586857s (5.70min in total, 3.80min remains)
2022-11-28 02:27:13 NUM_SUB: 34;----------------------------
2022-11-28 02:27:13 Epoch [19000/30000] Loss:0.000167 Loss_1:0.000150 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000345 Time:18.954754s (6.02min in total, 3.49min remains)
2022-11-28 02:27:33 NUM_SUB: 34;----------------------------
2022-11-28 02:27:33 Epoch [20000/30000] Loss:0.000167 Loss_1:0.000150 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000333 Time:19.352209s (6.34min in total, 3.17min remains)
2022-11-28 02:27:52 NUM_SUB: 34;----------------------------
2022-11-28 02:27:52 Epoch [21000/30000] Loss:0.000160 Loss_1:0.000146 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000323 Time:19.004542s (6.66min in total, 2.85min remains)
2022-11-28 02:28:11 NUM_SUB: 34;----------------------------
2022-11-28 02:28:11 Epoch [22000/30000] Loss:0.000163 Loss_1:0.000148 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000313 Time:19.199616s (6.98min in total, 2.54min remains)
2022-11-28 02:28:30 NUM_SUB: 34;----------------------------
2022-11-28 02:28:30 Epoch [23000/30000] Loss:0.000157 Loss_1:0.000145 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000303 Time:19.228067s (7.30min in total, 2.22min remains)
2022-11-28 02:28:50 NUM_SUB: 34;----------------------------
2022-11-28 02:28:50 Epoch [24000/30000] Loss:0.000156 Loss_1:0.000145 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000294 Time:19.487974s (7.62min in total, 1.91min remains)
2022-11-28 02:29:09 NUM_SUB: 34;----------------------------
2022-11-28 02:29:09 Epoch [25000/30000] Loss:0.000155 Loss_1:0.000144 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000286 Time:19.660226s (7.95min in total, 1.59min remains)
2022-11-28 02:29:29 NUM_SUB: 34;----------------------------
2022-11-28 02:29:29 Epoch [26000/30000] Loss:0.000154 Loss_1:0.000144 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000278 Time:19.617824s (8.28min in total, 1.27min remains)
2022-11-28 02:29:48 NUM_SUB: 34;----------------------------
2022-11-28 02:29:48 Epoch [27000/30000] Loss:0.000153 Loss_1:0.000144 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000270 Time:18.984569s (8.60min in total, 0.96min remains)
2022-11-28 02:30:07 NUM_SUB: 34;----------------------------
2022-11-28 02:30:07 Epoch [28000/30000] Loss:0.000153 Loss_1:0.000145 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000263 Time:19.152691s (8.91min in total, 0.64min remains)
2022-11-28 02:30:26 NUM_SUB: 34;----------------------------
2022-11-28 02:30:26 Epoch [29000/30000] Loss:0.000152 Loss_1:0.000144 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000256 Time:19.226702s (9.24min in total, 0.32min remains)
2022-11-28 02:30:46 NUM_SUB: 34;----------------------------
2022-11-28 02:30:46 Epoch [30000/30000] Loss:0.000151 Loss_1:0.000144 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000250 Time:19.677856s (9.56min in total, 0.00min remains)
2022-11-28 02:30:46 Testing & drawing...
2022-11-28 02:30:46 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:30:48 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=34/
2022-11-28 02:30:48 [Loss]
2022-11-28 02:30:48 NUM_SUB: 34; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:30:48 NUM_SUB: 34; Personalized parameter estimation: Parameter containing:
tensor([0.2001, 0.4631, 0.0160, 0.3458, 0.3074, 0.0946, 0.4997, 0.8964, 0.4556,
        0.1280, 0.1548, 0.0102, 0.2315, 0.1689, 0.0176, 0.1244, 0.6977, 0.8000,
        0.0118, 4.0589, 0.6816, 0.0229, 3.6090, 0.8742, 0.0204, 4.3744, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:30:48 NUM_SUB: 34------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:30:48 Testing & drawing...
2022-11-28 02:30:48 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:30:49 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=34/
2022-11-28 02:30:49 [Loss]
2022-11-28 02:30:49 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:30:49 General parameter estimation: Parameter containing:
tensor([0.2001, 0.4631, 0.0160, 0.3458, 0.3074, 0.0946, 0.4997, 0.8964, 0.4556,
        0.1280, 0.1548, 0.0102, 0.2315, 0.1689, 0.0176, 0.1244, 0.6977, 0.8000,
        0.0118, 4.0589, 0.6816, 0.0229, 3.6090, 0.8742, 0.0204, 4.3744, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:30:49 A: prod, degr, TonA, NonA
2022-11-28 02:30:49 [0.35180384 0.49966702 0.02520098 0.12332816]
2022-11-28 02:30:49 T: prod, degr, AonT, NonT
2022-11-28 02:30:49 [0.512141   0.38024566 0.03869971 0.06891362]
2022-11-28 02:30:49 N: AonN, TonN, ATonN
2022-11-28 02:30:49 [0.01107959 0.9316163  0.05730411]
2022-11-28 02:30:49 using cpu
2022-11-28 02:30:49 epoch = 30000
2022-11-28 02:30:49 epoch_step = 1000
2022-11-28 02:30:49 model_name = SimpleNetworkAD
2022-11-28 02:30:49 now_string = 2022-11-27-19-40-13
2022-11-28 02:30:49 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:30:49 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:30:49 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:30:49 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:30:49 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:30:49 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:31:09 NUM_SUB: 35;----------------------------
2022-11-28 02:31:09 Epoch [01000/30000] Loss:0.125612 Loss_1:0.119827 Loss_2:0.001819 Loss_3:0.000000 Lr:0.000909 Time:19.515234s (0.33min in total, 9.43min remains)
2022-11-28 02:31:28 NUM_SUB: 35;----------------------------
2022-11-28 02:31:28 Epoch [02000/30000] Loss:0.114435 Loss_1:0.113359 Loss_2:0.000550 Loss_3:0.000000 Lr:0.000833 Time:18.971529s (0.64min in total, 8.98min remains)
2022-11-28 02:31:47 NUM_SUB: 35;----------------------------
2022-11-28 02:31:47 Epoch [03000/30000] Loss:0.103230 Loss_1:0.102749 Loss_2:0.000142 Loss_3:0.000000 Lr:0.000769 Time:19.141044s (0.96min in total, 8.64min remains)
2022-11-28 02:32:06 NUM_SUB: 35;----------------------------
2022-11-28 02:32:06 Epoch [04000/30000] Loss:0.088275 Loss_1:0.087722 Loss_2:0.000105 Loss_3:0.000000 Lr:0.000714 Time:18.855249s (1.27min in total, 8.29min remains)
2022-11-28 02:32:25 NUM_SUB: 35;----------------------------
2022-11-28 02:32:25 Epoch [05000/30000] Loss:0.067373 Loss_1:0.066877 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000667 Time:19.267352s (1.60min in total, 7.98min remains)
2022-11-28 02:32:44 NUM_SUB: 35;----------------------------
2022-11-28 02:32:44 Epoch [06000/30000] Loss:0.041471 Loss_1:0.041064 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000625 Time:19.032295s (1.91min in total, 7.65min remains)
2022-11-28 02:33:04 NUM_SUB: 35;----------------------------
2022-11-28 02:33:04 Epoch [07000/30000] Loss:0.018059 Loss_1:0.017759 Loss_2:0.000142 Loss_3:0.000000 Lr:0.000588 Time:19.478999s (2.24min in total, 7.35min remains)
2022-11-28 02:33:23 NUM_SUB: 35;----------------------------
2022-11-28 02:33:23 Epoch [08000/30000] Loss:0.005437 Loss_1:0.005216 Loss_2:0.000171 Loss_3:0.000000 Lr:0.000556 Time:19.708076s (2.57min in total, 7.06min remains)
2022-11-28 02:33:42 NUM_SUB: 35;----------------------------
2022-11-28 02:33:42 Epoch [09000/30000] Loss:0.001912 Loss_1:0.001751 Loss_2:0.000156 Loss_3:0.000000 Lr:0.000526 Time:18.965936s (2.88min in total, 6.73min remains)
2022-11-28 02:34:02 NUM_SUB: 35;----------------------------
2022-11-28 02:34:02 Epoch [10000/30000] Loss:0.000715 Loss_1:0.000607 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000500 Time:19.178893s (3.20min in total, 6.40min remains)
2022-11-28 02:34:20 NUM_SUB: 35;----------------------------
2022-11-28 02:34:20 Epoch [11000/30000] Loss:0.000201 Loss_1:0.000137 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:18.838353s (3.52min in total, 6.07min remains)
2022-11-28 02:34:40 NUM_SUB: 35;----------------------------
2022-11-28 02:34:40 Epoch [12000/30000] Loss:0.000122 Loss_1:0.000083 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:19.529697s (3.84min in total, 5.76min remains)
2022-11-28 02:34:59 NUM_SUB: 35;----------------------------
2022-11-28 02:34:59 Epoch [13000/30000] Loss:0.000104 Loss_1:0.000079 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000435 Time:19.107384s (4.16min in total, 5.44min remains)
2022-11-28 02:35:18 NUM_SUB: 35;----------------------------
2022-11-28 02:35:18 Epoch [14000/30000] Loss:0.000096 Loss_1:0.000079 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:19.114780s (4.48min in total, 5.12min remains)
2022-11-28 02:35:37 NUM_SUB: 35;----------------------------
2022-11-28 02:35:37 Epoch [15000/30000] Loss:0.000091 Loss_1:0.000079 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000400 Time:19.251920s (4.80min in total, 4.80min remains)
2022-11-28 02:35:56 NUM_SUB: 35;----------------------------
2022-11-28 02:35:56 Epoch [16000/30000] Loss:0.000088 Loss_1:0.000079 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000385 Time:19.021187s (5.12min in total, 4.48min remains)
2022-11-28 02:36:15 NUM_SUB: 35;----------------------------
2022-11-28 02:36:15 Epoch [17000/30000] Loss:0.000085 Loss_1:0.000079 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:19.063022s (5.43min in total, 4.16min remains)
2022-11-28 02:36:35 NUM_SUB: 35;----------------------------
2022-11-28 02:36:35 Epoch [18000/30000] Loss:0.000084 Loss_1:0.000079 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:19.459558s (5.76min in total, 3.84min remains)
2022-11-28 02:36:54 NUM_SUB: 35;----------------------------
2022-11-28 02:36:54 Epoch [19000/30000] Loss:0.000082 Loss_1:0.000079 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000345 Time:19.160121s (6.08min in total, 3.52min remains)
2022-11-28 02:37:14 NUM_SUB: 35;----------------------------
2022-11-28 02:37:14 Epoch [20000/30000] Loss:0.000081 Loss_1:0.000079 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:19.832282s (6.41min in total, 3.20min remains)
2022-11-28 02:37:33 NUM_SUB: 35;----------------------------
2022-11-28 02:37:33 Epoch [21000/30000] Loss:0.000081 Loss_1:0.000079 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:19.527993s (6.73min in total, 2.89min remains)
2022-11-28 02:37:52 NUM_SUB: 35;----------------------------
2022-11-28 02:37:52 Epoch [22000/30000] Loss:0.000081 Loss_1:0.000078 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:19.078054s (7.05min in total, 2.56min remains)
2022-11-28 02:38:12 NUM_SUB: 35;----------------------------
2022-11-28 02:38:12 Epoch [23000/30000] Loss:0.000080 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.348703s (7.37min in total, 2.24min remains)
2022-11-28 02:38:31 NUM_SUB: 35;----------------------------
2022-11-28 02:38:31 Epoch [24000/30000] Loss:0.000080 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.493462s (7.70min in total, 1.92min remains)
2022-11-28 02:38:50 NUM_SUB: 35;----------------------------
2022-11-28 02:38:50 Epoch [25000/30000] Loss:0.000080 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.853987s (8.01min in total, 1.60min remains)
2022-11-28 02:39:09 NUM_SUB: 35;----------------------------
2022-11-28 02:39:09 Epoch [26000/30000] Loss:0.000080 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.909983s (8.33min in total, 1.28min remains)
2022-11-28 02:39:28 NUM_SUB: 35;----------------------------
2022-11-28 02:39:28 Epoch [27000/30000] Loss:0.000079 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.832561s (8.64min in total, 0.96min remains)
2022-11-28 02:39:47 NUM_SUB: 35;----------------------------
2022-11-28 02:39:47 Epoch [28000/30000] Loss:0.000079 Loss_1:0.000079 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.143983s (8.96min in total, 0.64min remains)
2022-11-28 02:40:06 NUM_SUB: 35;----------------------------
2022-11-28 02:40:06 Epoch [29000/30000] Loss:0.000084 Loss_1:0.000083 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.542688s (9.27min in total, 0.32min remains)
2022-11-28 02:40:25 NUM_SUB: 35;----------------------------
2022-11-28 02:40:25 Epoch [30000/30000] Loss:0.000079 Loss_1:0.000079 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.774819s (9.60min in total, 0.00min remains)
2022-11-28 02:40:25 Testing & drawing...
2022-11-28 02:40:25 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:40:27 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=35/
2022-11-28 02:40:27 [Loss]
2022-11-28 02:40:27 NUM_SUB: 35; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:40:27 NUM_SUB: 35; Personalized parameter estimation: Parameter containing:
tensor([4.5374e-01, 8.2298e-01, 1.1757e-02, 1.4838e-01, 3.0742e-01, 1.3364e-04,
        7.8162e-01, 8.9644e-01, 4.5563e-01, 9.7601e-03, 4.9557e-02, 1.4782e-02,
        2.5628e-01, 1.6886e-01, 1.7589e-02, 4.6520e-01, 6.9767e-01, 8.0001e-01,
        1.2138e-02, 3.2129e+00, 6.8161e-01, 2.2965e-02, 3.2674e+00, 8.7416e-01,
        1.9941e-02, 3.8122e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:40:27 NUM_SUB: 35------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:40:27 Testing & drawing...
2022-11-28 02:40:27 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:40:29 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=35/
2022-11-28 02:40:29 [Loss]
2022-11-28 02:40:29 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:40:29 General parameter estimation: Parameter containing:
tensor([4.5374e-01, 8.2298e-01, 1.1757e-02, 1.4838e-01, 3.0742e-01, 1.3364e-04,
        7.8162e-01, 8.9644e-01, 4.5563e-01, 9.7601e-03, 4.9557e-02, 1.4782e-02,
        2.5628e-01, 1.6886e-01, 1.7589e-02, 4.6520e-01, 6.9767e-01, 8.0001e-01,
        1.2138e-02, 3.2129e+00, 6.8161e-01, 2.2965e-02, 3.2674e+00, 8.7416e-01,
        1.9941e-02, 3.8122e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:40:29 A: prod, degr, TonA, NonA
2022-11-28 02:40:29 [4.8782426e-01 4.9999756e-01 1.2104020e-02 7.4163298e-05]
2022-11-28 02:40:29 T: prod, degr, AonT, NonT
2022-11-28 02:40:29 [0.15281552 0.4384656  0.20436569 0.20435318]
2022-11-28 02:40:29 N: AonN, TonN, ATonN
2022-11-28 02:40:29 [0.01573351 0.93809974 0.0461668 ]
2022-11-28 02:40:29 using cpu
2022-11-28 02:40:29 epoch = 30000
2022-11-28 02:40:29 epoch_step = 1000
2022-11-28 02:40:29 model_name = SimpleNetworkAD
2022-11-28 02:40:29 now_string = 2022-11-27-19-40-13
2022-11-28 02:40:29 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:40:29 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:40:29 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:40:29 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:40:29 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:40:29 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:40:48 NUM_SUB: 36;----------------------------
2022-11-28 02:40:48 Epoch [01000/30000] Loss:0.177219 Loss_1:0.170904 Loss_2:0.002214 Loss_3:0.000000 Lr:0.000909 Time:19.135530s (0.32min in total, 9.25min remains)
2022-11-28 02:41:07 NUM_SUB: 36;----------------------------
2022-11-28 02:41:07 Epoch [02000/30000] Loss:0.165894 Loss_1:0.164495 Loss_2:0.000747 Loss_3:0.000000 Lr:0.000833 Time:18.736769s (0.63min in total, 8.84min remains)
2022-11-28 02:41:27 NUM_SUB: 36;----------------------------
2022-11-28 02:41:27 Epoch [03000/30000] Loss:0.154556 Loss_1:0.153783 Loss_2:0.000211 Loss_3:0.000000 Lr:0.000769 Time:19.745091s (0.96min in total, 8.64min remains)
2022-11-28 02:41:46 NUM_SUB: 36;----------------------------
2022-11-28 02:41:46 Epoch [04000/30000] Loss:0.138976 Loss_1:0.138096 Loss_2:0.000215 Loss_3:0.000000 Lr:0.000714 Time:19.594757s (1.29min in total, 8.36min remains)
2022-11-28 02:42:05 NUM_SUB: 36;----------------------------
2022-11-28 02:42:05 Epoch [05000/30000] Loss:0.116360 Loss_1:0.115504 Loss_2:0.000249 Loss_3:0.000000 Lr:0.000667 Time:18.594796s (1.60min in total, 7.98min remains)
2022-11-28 02:42:24 NUM_SUB: 36;----------------------------
2022-11-28 02:42:24 Epoch [06000/30000] Loss:0.084400 Loss_1:0.083645 Loss_2:0.000248 Loss_3:0.000000 Lr:0.000625 Time:19.405731s (1.92min in total, 7.68min remains)
2022-11-28 02:42:43 NUM_SUB: 36;----------------------------
2022-11-28 02:42:43 Epoch [07000/30000] Loss:0.043980 Loss_1:0.043342 Loss_2:0.000293 Loss_3:0.000000 Lr:0.000588 Time:18.634971s (2.23min in total, 7.33min remains)
2022-11-28 02:43:02 NUM_SUB: 36;----------------------------
2022-11-28 02:43:02 Epoch [08000/30000] Loss:0.011963 Loss_1:0.011495 Loss_2:0.000329 Loss_3:0.000000 Lr:0.000556 Time:18.905914s (2.55min in total, 7.00min remains)
2022-11-28 02:43:21 NUM_SUB: 36;----------------------------
2022-11-28 02:43:21 Epoch [09000/30000] Loss:0.004816 Loss_1:0.004508 Loss_2:0.000279 Loss_3:0.000000 Lr:0.000526 Time:18.935080s (2.86min in total, 6.68min remains)
2022-11-28 02:43:39 NUM_SUB: 36;----------------------------
2022-11-28 02:43:39 Epoch [10000/30000] Loss:0.003904 Loss_1:0.003700 Loss_2:0.000192 Loss_3:0.000000 Lr:0.000500 Time:18.850480s (3.18min in total, 6.35min remains)
2022-11-28 02:43:58 NUM_SUB: 36;----------------------------
2022-11-28 02:43:58 Epoch [11000/30000] Loss:0.003228 Loss_1:0.003097 Loss_2:0.000125 Loss_3:0.000000 Lr:0.000476 Time:19.002784s (3.49min in total, 6.03min remains)
2022-11-28 02:44:17 NUM_SUB: 36;----------------------------
2022-11-28 02:44:17 Epoch [12000/30000] Loss:0.002826 Loss_1:0.002741 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000455 Time:18.856682s (3.81min in total, 5.71min remains)
2022-11-28 02:44:37 NUM_SUB: 36;----------------------------
2022-11-28 02:44:37 Epoch [13000/30000] Loss:0.002634 Loss_1:0.002573 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000435 Time:19.789493s (4.14min in total, 5.41min remains)
2022-11-28 02:44:56 NUM_SUB: 36;----------------------------
2022-11-28 02:44:56 Epoch [14000/30000] Loss:0.002491 Loss_1:0.002445 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000417 Time:18.991855s (4.45min in total, 5.09min remains)
2022-11-28 02:45:15 NUM_SUB: 36;----------------------------
2022-11-28 02:45:15 Epoch [15000/30000] Loss:0.002374 Loss_1:0.002340 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000400 Time:19.145585s (4.77min in total, 4.77min remains)
2022-11-28 02:45:35 NUM_SUB: 36;----------------------------
2022-11-28 02:45:35 Epoch [16000/30000] Loss:0.002271 Loss_1:0.002245 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000385 Time:19.917455s (5.10min in total, 4.47min remains)
2022-11-28 02:45:55 NUM_SUB: 36;----------------------------
2022-11-28 02:45:55 Epoch [17000/30000] Loss:0.002163 Loss_1:0.002144 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000370 Time:19.544590s (5.43min in total, 4.15min remains)
2022-11-28 02:46:14 NUM_SUB: 36;----------------------------
2022-11-28 02:46:14 Epoch [18000/30000] Loss:0.002004 Loss_1:0.001989 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:19.005014s (5.75min in total, 3.83min remains)
2022-11-28 02:46:33 NUM_SUB: 36;----------------------------
2022-11-28 02:46:33 Epoch [19000/30000] Loss:0.001875 Loss_1:0.001863 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.295392s (6.07min in total, 3.51min remains)
2022-11-28 02:46:52 NUM_SUB: 36;----------------------------
2022-11-28 02:46:52 Epoch [20000/30000] Loss:0.001851 Loss_1:0.001841 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:18.818999s (6.38min in total, 3.19min remains)
2022-11-28 02:47:11 NUM_SUB: 36;----------------------------
2022-11-28 02:47:11 Epoch [21000/30000] Loss:0.001848 Loss_1:0.001840 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000323 Time:19.614158s (6.71min in total, 2.88min remains)
2022-11-28 02:47:31 NUM_SUB: 36;----------------------------
2022-11-28 02:47:31 Epoch [22000/30000] Loss:0.001846 Loss_1:0.001838 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:19.680707s (7.04min in total, 2.56min remains)
2022-11-28 02:47:51 NUM_SUB: 36;----------------------------
2022-11-28 02:47:51 Epoch [23000/30000] Loss:0.001845 Loss_1:0.001839 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:19.463131s (7.36min in total, 2.24min remains)
2022-11-28 02:48:10 NUM_SUB: 36;----------------------------
2022-11-28 02:48:10 Epoch [24000/30000] Loss:0.001844 Loss_1:0.001839 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.428272s (7.69min in total, 1.92min remains)
2022-11-28 02:48:29 NUM_SUB: 36;----------------------------
2022-11-28 02:48:29 Epoch [25000/30000] Loss:0.001844 Loss_1:0.001839 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:19.250946s (8.01min in total, 1.60min remains)
2022-11-28 02:48:48 NUM_SUB: 36;----------------------------
2022-11-28 02:48:48 Epoch [26000/30000] Loss:0.001845 Loss_1:0.001841 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.137320s (8.33min in total, 1.28min remains)
2022-11-28 02:49:07 NUM_SUB: 36;----------------------------
2022-11-28 02:49:07 Epoch [27000/30000] Loss:0.001844 Loss_1:0.001839 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:18.916688s (8.64min in total, 0.96min remains)
2022-11-28 02:49:27 NUM_SUB: 36;----------------------------
2022-11-28 02:49:27 Epoch [28000/30000] Loss:0.001843 Loss_1:0.001839 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:19.404239s (8.96min in total, 0.64min remains)
2022-11-28 02:49:46 NUM_SUB: 36;----------------------------
2022-11-28 02:49:46 Epoch [29000/30000] Loss:0.001843 Loss_1:0.001837 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.434052s (9.29min in total, 0.32min remains)
2022-11-28 02:50:05 NUM_SUB: 36;----------------------------
2022-11-28 02:50:05 Epoch [30000/30000] Loss:0.001843 Loss_1:0.001839 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.217318s (9.61min in total, 0.00min remains)
2022-11-28 02:50:05 Testing & drawing...
2022-11-28 02:50:05 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:50:07 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=36/
2022-11-28 02:50:07 [Loss]
2022-11-28 02:50:07 NUM_SUB: 36; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:50:07 NUM_SUB: 36; Personalized parameter estimation: Parameter containing:
tensor([0.0136, 0.0400, 0.0250, 0.5137, 0.3074, 0.0127, 0.7435, 0.8964, 0.4556,
        0.1335, 0.1640, 0.0139, 0.2254, 0.1689, 0.0176, 0.0772, 0.6977, 0.8000,
        0.0106, 4.6653, 0.6816, 0.0224, 3.8364, 0.8742, 0.0110, 4.5686, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:50:07 NUM_SUB: 36------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:50:07 Testing & drawing...
2022-11-28 02:50:07 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:50:09 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=36/
2022-11-28 02:50:09 [Loss]
2022-11-28 02:50:09 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:50:09 General parameter estimation: Parameter containing:
tensor([0.0136, 0.0400, 0.0250, 0.5137, 0.3074, 0.0127, 0.7435, 0.8964, 0.4556,
        0.1335, 0.1640, 0.0139, 0.2254, 0.1689, 0.0176, 0.0772, 0.6977, 0.8000,
        0.0106, 4.6653, 0.6816, 0.0224, 3.8364, 0.8742, 0.0110, 4.5686, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 02:50:09 A: prod, degr, TonA, NonA
2022-11-28 02:50:09 [0.17515185 0.48833522 0.25511745 0.08139549]
2022-11-28 02:50:09 T: prod, degr, AonT, NonT
2022-11-28 02:50:09 [0.41747546 0.48673218 0.04149596 0.05429643]
2022-11-28 02:50:09 N: AonN, TonN, ATonN
2022-11-28 02:50:09 [0.01835073 0.9415969  0.04005235]
2022-11-28 02:50:09 using cpu
2022-11-28 02:50:09 epoch = 30000
2022-11-28 02:50:09 epoch_step = 1000
2022-11-28 02:50:09 model_name = SimpleNetworkAD
2022-11-28 02:50:09 now_string = 2022-11-27-19-40-13
2022-11-28 02:50:09 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:50:09 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:50:09 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:50:09 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:50:09 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:50:09 --------------------------------------------------training start--------------------------------------------------
2022-11-28 02:50:28 NUM_SUB: 37;----------------------------
2022-11-28 02:50:28 Epoch [01000/30000] Loss:0.052893 Loss_1:0.047503 Loss_2:0.001556 Loss_3:0.000000 Lr:0.000909 Time:19.054149s (0.32min in total, 9.21min remains)
2022-11-28 02:50:47 NUM_SUB: 37;----------------------------
2022-11-28 02:50:47 Epoch [02000/30000] Loss:0.046343 Loss_1:0.045499 Loss_2:0.000425 Loss_3:0.000000 Lr:0.000833 Time:18.969125s (0.63min in total, 8.87min remains)
2022-11-28 02:51:06 NUM_SUB: 37;----------------------------
2022-11-28 02:51:06 Epoch [03000/30000] Loss:0.042404 Loss_1:0.042192 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000769 Time:18.915266s (0.95min in total, 8.54min remains)
2022-11-28 02:51:25 NUM_SUB: 37;----------------------------
2022-11-28 02:51:25 Epoch [04000/30000] Loss:0.037797 Loss_1:0.037577 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000714 Time:19.012598s (1.27min in total, 8.23min remains)
2022-11-28 02:51:44 NUM_SUB: 37;----------------------------
2022-11-28 02:51:44 Epoch [05000/30000] Loss:0.031864 Loss_1:0.031640 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000667 Time:18.918348s (1.58min in total, 7.91min remains)
2022-11-28 02:52:03 NUM_SUB: 37;----------------------------
2022-11-28 02:52:03 Epoch [06000/30000] Loss:0.024167 Loss_1:0.023967 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000625 Time:19.081593s (1.90min in total, 7.60min remains)
2022-11-28 02:52:23 NUM_SUB: 37;----------------------------
2022-11-28 02:52:23 Epoch [07000/30000] Loss:0.015483 Loss_1:0.015305 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000588 Time:19.607895s (2.23min in total, 7.31min remains)
2022-11-28 02:52:42 NUM_SUB: 37;----------------------------
2022-11-28 02:52:42 Epoch [08000/30000] Loss:0.007684 Loss_1:0.007527 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000556 Time:19.180138s (2.55min in total, 7.00min remains)
2022-11-28 02:53:01 NUM_SUB: 37;----------------------------
2022-11-28 02:53:01 Epoch [09000/30000] Loss:0.002491 Loss_1:0.002342 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000526 Time:19.155542s (2.87min in total, 6.69min remains)
2022-11-28 02:53:20 NUM_SUB: 37;----------------------------
2022-11-28 02:53:20 Epoch [10000/30000] Loss:0.000705 Loss_1:0.000584 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000500 Time:18.970566s (3.18min in total, 6.36min remains)
2022-11-28 02:53:40 NUM_SUB: 37;----------------------------
2022-11-28 02:53:40 Epoch [11000/30000] Loss:0.000495 Loss_1:0.000414 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000476 Time:19.835610s (3.51min in total, 6.07min remains)
2022-11-28 02:53:59 NUM_SUB: 37;----------------------------
2022-11-28 02:53:59 Epoch [12000/30000] Loss:0.000438 Loss_1:0.000387 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:19.380012s (3.83min in total, 5.75min remains)
2022-11-28 02:54:18 NUM_SUB: 37;----------------------------
2022-11-28 02:54:18 Epoch [13000/30000] Loss:0.000405 Loss_1:0.000370 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:19.211742s (4.16min in total, 5.43min remains)
2022-11-28 02:54:37 NUM_SUB: 37;----------------------------
2022-11-28 02:54:37 Epoch [14000/30000] Loss:0.000384 Loss_1:0.000358 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:19.103883s (4.47min in total, 5.11min remains)
2022-11-28 02:54:57 NUM_SUB: 37;----------------------------
2022-11-28 02:54:57 Epoch [15000/30000] Loss:0.000372 Loss_1:0.000351 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000400 Time:19.182641s (4.79min in total, 4.79min remains)
2022-11-28 02:55:16 NUM_SUB: 37;----------------------------
2022-11-28 02:55:16 Epoch [16000/30000] Loss:0.000362 Loss_1:0.000346 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:19.048397s (5.11min in total, 4.47min remains)
2022-11-28 02:55:35 NUM_SUB: 37;----------------------------
2022-11-28 02:55:35 Epoch [17000/30000] Loss:0.000496 Loss_1:0.000466 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000370 Time:19.186544s (5.43min in total, 4.15min remains)
2022-11-28 02:55:54 NUM_SUB: 37;----------------------------
2022-11-28 02:55:54 Epoch [18000/30000] Loss:0.000344 Loss_1:0.000333 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:19.071506s (5.75min in total, 3.83min remains)
2022-11-28 02:56:13 NUM_SUB: 37;----------------------------
2022-11-28 02:56:13 Epoch [19000/30000] Loss:0.000332 Loss_1:0.000321 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000345 Time:18.789931s (6.06min in total, 3.51min remains)
2022-11-28 02:56:32 NUM_SUB: 37;----------------------------
2022-11-28 02:56:32 Epoch [20000/30000] Loss:0.000318 Loss_1:0.000306 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:19.109104s (6.38min in total, 3.19min remains)
2022-11-28 02:56:51 NUM_SUB: 37;----------------------------
2022-11-28 02:56:51 Epoch [21000/30000] Loss:0.000312 Loss_1:0.000283 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000323 Time:19.011056s (6.70min in total, 2.87min remains)
2022-11-28 02:57:10 NUM_SUB: 37;----------------------------
2022-11-28 02:57:10 Epoch [22000/30000] Loss:0.000273 Loss_1:0.000258 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000313 Time:18.794625s (7.01min in total, 2.55min remains)
2022-11-28 02:57:29 NUM_SUB: 37;----------------------------
2022-11-28 02:57:29 Epoch [23000/30000] Loss:0.000266 Loss_1:0.000251 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000303 Time:19.628686s (7.34min in total, 2.23min remains)
2022-11-28 02:57:48 NUM_SUB: 37;----------------------------
2022-11-28 02:57:48 Epoch [24000/30000] Loss:0.000260 Loss_1:0.000248 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000294 Time:19.052335s (7.65min in total, 1.91min remains)
2022-11-28 02:58:07 NUM_SUB: 37;----------------------------
2022-11-28 02:58:07 Epoch [25000/30000] Loss:0.000255 Loss_1:0.000246 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000286 Time:18.884932s (7.97min in total, 1.59min remains)
2022-11-28 02:58:27 NUM_SUB: 37;----------------------------
2022-11-28 02:58:27 Epoch [26000/30000] Loss:0.000251 Loss_1:0.000244 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:19.648216s (8.30min in total, 1.28min remains)
2022-11-28 02:58:46 NUM_SUB: 37;----------------------------
2022-11-28 02:58:46 Epoch [27000/30000] Loss:0.000247 Loss_1:0.000241 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000270 Time:19.196570s (8.62min in total, 0.96min remains)
2022-11-28 02:59:06 NUM_SUB: 37;----------------------------
2022-11-28 02:59:06 Epoch [28000/30000] Loss:0.000251 Loss_1:0.000246 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:19.929346s (8.95min in total, 0.64min remains)
2022-11-28 02:59:25 NUM_SUB: 37;----------------------------
2022-11-28 02:59:25 Epoch [29000/30000] Loss:0.000244 Loss_1:0.000241 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.309747s (9.27min in total, 0.32min remains)
2022-11-28 02:59:44 NUM_SUB: 37;----------------------------
2022-11-28 02:59:44 Epoch [30000/30000] Loss:0.000241 Loss_1:0.000239 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.139138s (9.59min in total, 0.00min remains)
2022-11-28 02:59:44 Testing & drawing...
2022-11-28 02:59:44 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:59:46 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=37/
2022-11-28 02:59:46 [Loss]
2022-11-28 02:59:46 NUM_SUB: 37; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:59:46 NUM_SUB: 37; Personalized parameter estimation: Parameter containing:
tensor([1.2333e-02, 1.6987e-01, 1.1730e-02, 5.4791e-09, 3.0742e-01, 1.6420e-01,
        8.2795e-01, 8.9644e-01, 4.5563e-01, 1.2894e-02, 3.2737e-02, 1.4132e-02,
        5.8404e-01, 1.6886e-01, 1.7470e-02, 1.8145e+00, 6.9767e-01, 8.0001e-01,
        1.2092e-02, 3.8207e+00, 6.8161e-01, 2.1898e-02, 3.7330e+00, 8.7416e-01,
        2.0948e-02, 4.4691e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:59:46 NUM_SUB: 37------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 02:59:46 Testing & drawing...
2022-11-28 02:59:46 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 02:59:48 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=37/
2022-11-28 02:59:48 [Loss]
2022-11-28 02:59:48 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 02:59:48 General parameter estimation: Parameter containing:
tensor([1.2333e-02, 1.6987e-01, 1.1730e-02, 5.4791e-09, 3.0742e-01, 1.6420e-01,
        8.2795e-01, 8.9644e-01, 4.5563e-01, 1.2894e-02, 3.2737e-02, 1.4132e-02,
        5.8404e-01, 1.6886e-01, 1.7470e-02, 1.8145e+00, 6.9767e-01, 8.0001e-01,
        1.2092e-02, 3.8207e+00, 6.8161e-01, 2.1898e-02, 3.7330e+00, 8.7416e-01,
        2.0948e-02, 4.4691e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 02:59:48 A: prod, degr, TonA, NonA
2022-11-28 02:59:48 [0.08396818 0.49676    0.07985906 0.33941275]
2022-11-28 02:59:48 T: prod, degr, AonT, NonT
2022-11-28 02:59:48 [0.35412255 0.3891869  0.215391   0.04129957]
2022-11-28 02:59:48 N: AonN, TonN, ATonN
2022-11-28 02:59:48 [0.00743339 0.96267974 0.0298869 ]
2022-11-28 02:59:48 using cpu
2022-11-28 02:59:48 epoch = 30000
2022-11-28 02:59:48 epoch_step = 1000
2022-11-28 02:59:48 model_name = SimpleNetworkAD
2022-11-28 02:59:48 now_string = 2022-11-27-19-40-13
2022-11-28 02:59:48 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 02:59:48 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 02:59:48 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 02:59:48 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 02:59:48 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 02:59:48 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:00:07 NUM_SUB: 38;----------------------------
2022-11-28 03:00:07 Epoch [01000/30000] Loss:0.064347 Loss_1:0.058850 Loss_2:0.001674 Loss_3:0.000000 Lr:0.000909 Time:19.514249s (0.33min in total, 9.43min remains)
2022-11-28 03:00:27 NUM_SUB: 38;----------------------------
2022-11-28 03:00:27 Epoch [02000/30000] Loss:0.056203 Loss_1:0.055255 Loss_2:0.000521 Loss_3:0.000000 Lr:0.000833 Time:19.617846s (0.65min in total, 9.13min remains)
2022-11-28 03:00:46 NUM_SUB: 38;----------------------------
2022-11-28 03:00:46 Epoch [03000/30000] Loss:0.049920 Loss_1:0.049589 Loss_2:0.000208 Loss_3:0.000000 Lr:0.000769 Time:19.020914s (0.97min in total, 8.72min remains)
2022-11-28 03:01:05 NUM_SUB: 38;----------------------------
2022-11-28 03:01:05 Epoch [04000/30000] Loss:0.042609 Loss_1:0.042310 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000714 Time:19.126397s (1.29min in total, 8.37min remains)
2022-11-28 03:01:25 NUM_SUB: 38;----------------------------
2022-11-28 03:01:25 Epoch [05000/30000] Loss:0.032543 Loss_1:0.032255 Loss_2:0.000142 Loss_3:0.000000 Lr:0.000667 Time:19.811939s (1.62min in total, 8.09min remains)
2022-11-28 03:01:44 NUM_SUB: 38;----------------------------
2022-11-28 03:01:44 Epoch [06000/30000] Loss:0.020154 Loss_1:0.019907 Loss_2:0.000134 Loss_3:0.000000 Lr:0.000625 Time:19.057089s (1.94min in total, 7.74min remains)
2022-11-28 03:02:03 NUM_SUB: 38;----------------------------
2022-11-28 03:02:03 Epoch [07000/30000] Loss:0.009236 Loss_1:0.009048 Loss_2:0.000120 Loss_3:0.000000 Lr:0.000588 Time:19.041922s (2.25min in total, 7.40min remains)
2022-11-28 03:02:22 NUM_SUB: 38;----------------------------
2022-11-28 03:02:22 Epoch [08000/30000] Loss:0.004309 Loss_1:0.004158 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000556 Time:18.921540s (2.57min in total, 7.06min remains)
2022-11-28 03:02:41 NUM_SUB: 38;----------------------------
2022-11-28 03:02:41 Epoch [09000/30000] Loss:0.002892 Loss_1:0.002738 Loss_2:0.000120 Loss_3:0.000000 Lr:0.000526 Time:19.342437s (2.89min in total, 6.75min remains)
2022-11-28 03:03:00 NUM_SUB: 38;----------------------------
2022-11-28 03:03:00 Epoch [10000/30000] Loss:0.002098 Loss_1:0.002004 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000500 Time:18.539767s (3.20min in total, 6.40min remains)
2022-11-28 03:03:20 NUM_SUB: 38;----------------------------
2022-11-28 03:03:20 Epoch [11000/30000] Loss:0.001659 Loss_1:0.001586 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000476 Time:19.756153s (3.53min in total, 6.10min remains)
2022-11-28 03:03:40 NUM_SUB: 38;----------------------------
2022-11-28 03:03:40 Epoch [12000/30000] Loss:0.001286 Loss_1:0.001233 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:20.046479s (3.86min in total, 5.80min remains)
2022-11-28 03:03:59 NUM_SUB: 38;----------------------------
2022-11-28 03:03:59 Epoch [13000/30000] Loss:0.000871 Loss_1:0.000840 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000435 Time:19.382015s (4.19min in total, 5.47min remains)
2022-11-28 03:04:19 NUM_SUB: 38;----------------------------
2022-11-28 03:04:19 Epoch [14000/30000] Loss:0.000542 Loss_1:0.000517 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:19.982911s (4.52min in total, 5.17min remains)
2022-11-28 03:04:38 NUM_SUB: 38;----------------------------
2022-11-28 03:04:38 Epoch [15000/30000] Loss:0.000410 Loss_1:0.000391 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000400 Time:18.891707s (4.83min in total, 4.83min remains)
2022-11-28 03:04:57 NUM_SUB: 38;----------------------------
2022-11-28 03:04:57 Epoch [16000/30000] Loss:0.000389 Loss_1:0.000374 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:19.117456s (5.15min in total, 4.51min remains)
2022-11-28 03:05:16 NUM_SUB: 38;----------------------------
2022-11-28 03:05:16 Epoch [17000/30000] Loss:0.000382 Loss_1:0.000369 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:18.520381s (5.46min in total, 4.18min remains)
2022-11-28 03:05:35 NUM_SUB: 38;----------------------------
2022-11-28 03:05:35 Epoch [18000/30000] Loss:0.000373 Loss_1:0.000363 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:19.544860s (5.79min in total, 3.86min remains)
2022-11-28 03:05:55 NUM_SUB: 38;----------------------------
2022-11-28 03:05:55 Epoch [19000/30000] Loss:0.000364 Loss_1:0.000356 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000345 Time:19.607300s (6.11min in total, 3.54min remains)
2022-11-28 03:06:14 NUM_SUB: 38;----------------------------
2022-11-28 03:06:14 Epoch [20000/30000] Loss:0.000361 Loss_1:0.000355 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:18.946707s (6.43min in total, 3.22min remains)
2022-11-28 03:06:33 NUM_SUB: 38;----------------------------
2022-11-28 03:06:33 Epoch [21000/30000] Loss:0.000362 Loss_1:0.000355 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000323 Time:18.832629s (6.74min in total, 2.89min remains)
2022-11-28 03:06:51 NUM_SUB: 38;----------------------------
2022-11-28 03:06:51 Epoch [22000/30000] Loss:0.000358 Loss_1:0.000353 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:18.940976s (7.06min in total, 2.57min remains)
2022-11-28 03:07:10 NUM_SUB: 38;----------------------------
2022-11-28 03:07:10 Epoch [23000/30000] Loss:0.000359 Loss_1:0.000353 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:18.724177s (7.37min in total, 2.24min remains)
2022-11-28 03:07:29 NUM_SUB: 38;----------------------------
2022-11-28 03:07:29 Epoch [24000/30000] Loss:0.000356 Loss_1:0.000352 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:18.965890s (7.69min in total, 1.92min remains)
2022-11-28 03:07:48 NUM_SUB: 38;----------------------------
2022-11-28 03:07:48 Epoch [25000/30000] Loss:0.000386 Loss_1:0.000358 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:18.970595s (8.00min in total, 1.60min remains)
2022-11-28 03:08:08 NUM_SUB: 38;----------------------------
2022-11-28 03:08:08 Epoch [26000/30000] Loss:0.000356 Loss_1:0.000353 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.506207s (8.33min in total, 1.28min remains)
2022-11-28 03:08:27 NUM_SUB: 38;----------------------------
2022-11-28 03:08:27 Epoch [27000/30000] Loss:0.000357 Loss_1:0.000354 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.092092s (8.65min in total, 0.96min remains)
2022-11-28 03:08:46 NUM_SUB: 38;----------------------------
2022-11-28 03:08:46 Epoch [28000/30000] Loss:0.000357 Loss_1:0.000353 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.015018s (8.96min in total, 0.64min remains)
2022-11-28 03:09:05 NUM_SUB: 38;----------------------------
2022-11-28 03:09:05 Epoch [29000/30000] Loss:0.000390 Loss_1:0.000388 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.134808s (9.28min in total, 0.32min remains)
2022-11-28 03:09:24 NUM_SUB: 38;----------------------------
2022-11-28 03:09:24 Epoch [30000/30000] Loss:0.000353 Loss_1:0.000350 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.871023s (9.60min in total, 0.00min remains)
2022-11-28 03:09:24 Testing & drawing...
2022-11-28 03:09:24 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:09:25 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=38/
2022-11-28 03:09:25 [Loss]
2022-11-28 03:09:25 NUM_SUB: 38; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:09:25 NUM_SUB: 38; Personalized parameter estimation: Parameter containing:
tensor([0.0167, 0.0405, 0.0118, 0.7926, 0.3074, 0.0146, 3.2557, 0.8964, 0.4556,
        0.0137, 0.0325, 0.0120, 0.8098, 0.1689, 0.0172, 3.1518, 0.6977, 0.8000,
        0.0118, 4.2180, 0.6816, 0.0220, 3.7189, 0.8742, 0.0085, 4.1488, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:09:25 NUM_SUB: 38------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:09:25 Testing & drawing...
2022-11-28 03:09:25 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:09:27 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=38/
2022-11-28 03:09:27 [Loss]
2022-11-28 03:09:27 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:09:27 General parameter estimation: Parameter containing:
tensor([0.0167, 0.0405, 0.0118, 0.7926, 0.3074, 0.0146, 3.2557, 0.8964, 0.4556,
        0.0137, 0.0325, 0.0120, 0.8098, 0.1689, 0.0172, 3.1518, 0.6977, 0.8000,
        0.0118, 4.2180, 0.6816, 0.0220, 3.7189, 0.8742, 0.0085, 4.1488, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:09:27 A: prod, degr, TonA, NonA
2022-11-28 03:09:27 [0.41869396 0.48536333 0.08289171 0.013051  ]
2022-11-28 03:09:27 T: prod, degr, AonT, NonT
2022-11-28 03:09:27 [0.41362348 0.46782225 0.09890115 0.01965311]
2022-11-28 03:09:27 N: AonN, TonN, ATonN
2022-11-28 03:09:27 [0.00774538 0.98041993 0.01183467]
2022-11-28 03:09:27 using cpu
2022-11-28 03:09:27 epoch = 30000
2022-11-28 03:09:27 epoch_step = 1000
2022-11-28 03:09:27 model_name = SimpleNetworkAD
2022-11-28 03:09:27 now_string = 2022-11-27-19-40-13
2022-11-28 03:09:27 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:09:27 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:09:27 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:09:27 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:09:27 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:09:27 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:09:46 NUM_SUB: 39;----------------------------
2022-11-28 03:09:46 Epoch [01000/30000] Loss:0.037007 Loss_1:0.031159 Loss_2:0.001947 Loss_3:0.000000 Lr:0.000909 Time:19.082256s (0.32min in total, 9.22min remains)
2022-11-28 03:10:05 NUM_SUB: 39;----------------------------
2022-11-28 03:10:05 Epoch [02000/30000] Loss:0.031077 Loss_1:0.029847 Loss_2:0.000767 Loss_3:0.000000 Lr:0.000833 Time:19.190142s (0.64min in total, 8.93min remains)
2022-11-28 03:10:25 NUM_SUB: 39;----------------------------
2022-11-28 03:10:25 Epoch [03000/30000] Loss:0.028055 Loss_1:0.027536 Loss_2:0.000421 Loss_3:0.000000 Lr:0.000769 Time:19.345210s (0.96min in total, 8.64min remains)
2022-11-28 03:10:44 NUM_SUB: 39;----------------------------
2022-11-28 03:10:44 Epoch [04000/30000] Loss:0.024957 Loss_1:0.024545 Loss_2:0.000270 Loss_3:0.000000 Lr:0.000714 Time:19.170440s (1.28min in total, 8.32min remains)
2022-11-28 03:11:03 NUM_SUB: 39;----------------------------
2022-11-28 03:11:03 Epoch [05000/30000] Loss:0.021207 Loss_1:0.020850 Loss_2:0.000212 Loss_3:0.000000 Lr:0.000667 Time:19.441720s (1.60min in total, 8.02min remains)
2022-11-28 03:11:22 NUM_SUB: 39;----------------------------
2022-11-28 03:11:22 Epoch [06000/30000] Loss:0.016291 Loss_1:0.015976 Loss_2:0.000194 Loss_3:0.000000 Lr:0.000625 Time:18.737591s (1.92min in total, 7.66min remains)
2022-11-28 03:11:41 NUM_SUB: 39;----------------------------
2022-11-28 03:11:41 Epoch [07000/30000] Loss:0.010000 Loss_1:0.009814 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000588 Time:19.283988s (2.24min in total, 7.35min remains)
2022-11-28 03:12:00 NUM_SUB: 39;----------------------------
2022-11-28 03:12:00 Epoch [08000/30000] Loss:0.004761 Loss_1:0.004648 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000556 Time:18.904000s (2.55min in total, 7.02min remains)
2022-11-28 03:12:19 NUM_SUB: 39;----------------------------
2022-11-28 03:12:19 Epoch [09000/30000] Loss:0.001808 Loss_1:0.001720 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000526 Time:19.056482s (2.87min in total, 6.70min remains)
2022-11-28 03:12:38 NUM_SUB: 39;----------------------------
2022-11-28 03:12:38 Epoch [10000/30000] Loss:0.000758 Loss_1:0.000684 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000500 Time:19.006020s (3.19min in total, 6.37min remains)
2022-11-28 03:12:57 NUM_SUB: 39;----------------------------
2022-11-28 03:12:57 Epoch [11000/30000] Loss:0.000512 Loss_1:0.000449 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000476 Time:18.826951s (3.50min in total, 6.05min remains)
2022-11-28 03:13:16 NUM_SUB: 39;----------------------------
2022-11-28 03:13:16 Epoch [12000/30000] Loss:0.000423 Loss_1:0.000370 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000455 Time:19.127957s (3.82min in total, 5.73min remains)
2022-11-28 03:13:35 NUM_SUB: 39;----------------------------
2022-11-28 03:13:35 Epoch [13000/30000] Loss:0.000285 Loss_1:0.000253 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000435 Time:19.076099s (4.14min in total, 5.41min remains)
2022-11-28 03:13:55 NUM_SUB: 39;----------------------------
2022-11-28 03:13:55 Epoch [14000/30000] Loss:0.000137 Loss_1:0.000113 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:19.112947s (4.46min in total, 5.09min remains)
2022-11-28 03:14:14 NUM_SUB: 39;----------------------------
2022-11-28 03:14:14 Epoch [15000/30000] Loss:0.000044 Loss_1:0.000024 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000400 Time:19.285174s (4.78min in total, 4.78min remains)
2022-11-28 03:14:33 NUM_SUB: 39;----------------------------
2022-11-28 03:14:33 Epoch [16000/30000] Loss:0.000021 Loss_1:0.000003 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:19.108502s (5.10min in total, 4.46min remains)
2022-11-28 03:14:52 NUM_SUB: 39;----------------------------
2022-11-28 03:14:52 Epoch [17000/30000] Loss:0.000015 Loss_1:0.000001 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000370 Time:19.018812s (5.41min in total, 4.14min remains)
2022-11-28 03:15:11 NUM_SUB: 39;----------------------------
2022-11-28 03:15:11 Epoch [18000/30000] Loss:0.000012 Loss_1:0.000000 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:18.874274s (5.73min in total, 3.82min remains)
2022-11-28 03:15:30 NUM_SUB: 39;----------------------------
2022-11-28 03:15:30 Epoch [19000/30000] Loss:0.000011 Loss_1:0.000000 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000345 Time:19.518788s (6.05min in total, 3.50min remains)
2022-11-28 03:15:49 NUM_SUB: 39;----------------------------
2022-11-28 03:15:49 Epoch [20000/30000] Loss:0.000009 Loss_1:0.000000 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:18.931392s (6.37min in total, 3.18min remains)
2022-11-28 03:16:08 NUM_SUB: 39;----------------------------
2022-11-28 03:16:08 Epoch [21000/30000] Loss:0.000008 Loss_1:0.000000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000323 Time:18.958487s (6.68min in total, 2.86min remains)
2022-11-28 03:16:27 NUM_SUB: 39;----------------------------
2022-11-28 03:16:27 Epoch [22000/30000] Loss:0.000008 Loss_1:0.000000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:18.971911s (7.00min in total, 2.55min remains)
2022-11-28 03:16:46 NUM_SUB: 39;----------------------------
2022-11-28 03:16:46 Epoch [23000/30000] Loss:0.000007 Loss_1:0.000000 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000303 Time:18.894382s (7.32min in total, 2.23min remains)
2022-11-28 03:17:05 NUM_SUB: 39;----------------------------
2022-11-28 03:17:05 Epoch [24000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:18.909849s (7.63min in total, 1.91min remains)
2022-11-28 03:17:24 NUM_SUB: 39;----------------------------
2022-11-28 03:17:24 Epoch [25000/30000] Loss:0.000005 Loss_1:0.000000 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:18.988988s (7.95min in total, 1.59min remains)
2022-11-28 03:17:43 NUM_SUB: 39;----------------------------
2022-11-28 03:17:43 Epoch [26000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:18.811650s (8.26min in total, 1.27min remains)
2022-11-28 03:18:02 NUM_SUB: 39;----------------------------
2022-11-28 03:18:02 Epoch [27000/30000] Loss:0.000004 Loss_1:0.000001 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.153493s (8.58min in total, 0.95min remains)
2022-11-28 03:18:21 NUM_SUB: 39;----------------------------
2022-11-28 03:18:21 Epoch [28000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.954575s (8.90min in total, 0.64min remains)
2022-11-28 03:18:40 NUM_SUB: 39;----------------------------
2022-11-28 03:18:40 Epoch [29000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.895362s (9.21min in total, 0.32min remains)
2022-11-28 03:18:59 NUM_SUB: 39;----------------------------
2022-11-28 03:18:59 Epoch [30000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.118045s (9.53min in total, 0.00min remains)
2022-11-28 03:18:59 Testing & drawing...
2022-11-28 03:18:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:19:01 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=39/
2022-11-28 03:19:01 [Loss]
2022-11-28 03:19:01 NUM_SUB: 39; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:19:01 NUM_SUB: 39; Personalized parameter estimation: Parameter containing:
tensor([0.0066, 0.0172, 0.0095, 2.6353, 0.3074, 0.0178, 3.3062, 0.8964, 0.4556,
        0.0135, 0.0335, 0.0128, 0.8788, 0.1689, 0.0177, 1.4672, 0.6977, 0.8000,
        0.0121, 3.5167, 0.6816, 0.0184, 3.3544, 0.8742, 0.0213, 4.1841, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:19:01 NUM_SUB: 39------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:19:01 Testing & drawing...
2022-11-28 03:19:01 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:19:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=39/
2022-11-28 03:19:02 [Loss]
2022-11-28 03:19:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:19:02 General parameter estimation: Parameter containing:
tensor([0.0066, 0.0172, 0.0095, 2.6353, 0.3074, 0.0178, 3.3062, 0.8964, 0.4556,
        0.0135, 0.0335, 0.0128, 0.8788, 0.1689, 0.0177, 1.4672, 0.6977, 0.8000,
        0.0121, 3.5167, 0.6816, 0.0184, 3.3544, 0.8742, 0.0213, 4.1841, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:19:02 A: prod, degr, TonA, NonA
2022-11-28 03:19:02 [0.49426025 0.43054104 0.02965206 0.04554663]
2022-11-28 03:19:02 T: prod, degr, AonT, NonT
2022-11-28 03:19:02 [0.43611163 0.3620025  0.11561858 0.08626729]
2022-11-28 03:19:02 N: AonN, TonN, ATonN
2022-11-28 03:19:02 [0.00713157 0.9629971  0.02987136]
2022-11-28 03:19:03 using cpu
2022-11-28 03:19:03 epoch = 30000
2022-11-28 03:19:03 epoch_step = 1000
2022-11-28 03:19:03 model_name = SimpleNetworkAD
2022-11-28 03:19:03 now_string = 2022-11-27-19-40-13
2022-11-28 03:19:03 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:19:03 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:19:03 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:19:03 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:19:03 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:19:03 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:19:21 NUM_SUB: 40;----------------------------
2022-11-28 03:19:21 Epoch [01000/30000] Loss:0.031814 Loss_1:0.026370 Loss_2:0.001576 Loss_3:0.000000 Lr:0.000909 Time:18.943350s (0.32min in total, 9.16min remains)
2022-11-28 03:19:40 NUM_SUB: 40;----------------------------
2022-11-28 03:19:40 Epoch [02000/30000] Loss:0.026175 Loss_1:0.025287 Loss_2:0.000438 Loss_3:0.000000 Lr:0.000833 Time:19.041159s (0.63min in total, 8.86min remains)
2022-11-28 03:20:00 NUM_SUB: 40;----------------------------
2022-11-28 03:20:00 Epoch [03000/30000] Loss:0.023626 Loss_1:0.023425 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000769 Time:19.070126s (0.95min in total, 8.56min remains)
2022-11-28 03:20:18 NUM_SUB: 40;----------------------------
2022-11-28 03:20:18 Epoch [04000/30000] Loss:0.021219 Loss_1:0.021047 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000714 Time:18.808233s (1.26min in total, 8.22min remains)
2022-11-28 03:20:37 NUM_SUB: 40;----------------------------
2022-11-28 03:20:37 Epoch [05000/30000] Loss:0.018364 Loss_1:0.018192 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000667 Time:19.076792s (1.58min in total, 7.91min remains)
2022-11-28 03:20:56 NUM_SUB: 40;----------------------------
2022-11-28 03:20:56 Epoch [06000/30000] Loss:0.014581 Loss_1:0.014430 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000625 Time:18.841847s (1.90min in total, 7.59min remains)
2022-11-28 03:21:15 NUM_SUB: 40;----------------------------
2022-11-28 03:21:15 Epoch [07000/30000] Loss:0.010101 Loss_1:0.009978 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000588 Time:19.139680s (2.22min in total, 7.28min remains)
2022-11-28 03:21:35 NUM_SUB: 40;----------------------------
2022-11-28 03:21:35 Epoch [08000/30000] Loss:0.006006 Loss_1:0.005904 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000556 Time:19.161523s (2.53min in total, 6.97min remains)
2022-11-28 03:21:54 NUM_SUB: 40;----------------------------
2022-11-28 03:21:54 Epoch [09000/30000] Loss:0.003699 Loss_1:0.003605 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000526 Time:19.118786s (2.85min in total, 6.66min remains)
2022-11-28 03:22:13 NUM_SUB: 40;----------------------------
2022-11-28 03:22:13 Epoch [10000/30000] Loss:0.002853 Loss_1:0.002778 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000500 Time:19.021933s (3.17min in total, 6.34min remains)
2022-11-28 03:22:32 NUM_SUB: 40;----------------------------
2022-11-28 03:22:32 Epoch [11000/30000] Loss:0.002603 Loss_1:0.002534 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000476 Time:18.968768s (3.49min in total, 6.02min remains)
2022-11-28 03:22:51 NUM_SUB: 40;----------------------------
2022-11-28 03:22:51 Epoch [12000/30000] Loss:0.002428 Loss_1:0.002370 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000455 Time:18.950944s (3.80min in total, 5.70min remains)
2022-11-28 03:23:10 NUM_SUB: 40;----------------------------
2022-11-28 03:23:10 Epoch [13000/30000] Loss:0.002122 Loss_1:0.002089 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000435 Time:19.209537s (4.12min in total, 5.39min remains)
2022-11-28 03:23:29 NUM_SUB: 40;----------------------------
2022-11-28 03:23:29 Epoch [14000/30000] Loss:0.001783 Loss_1:0.001752 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000417 Time:19.131169s (4.44min in total, 5.08min remains)
2022-11-28 03:23:48 NUM_SUB: 40;----------------------------
2022-11-28 03:23:48 Epoch [15000/30000] Loss:0.001572 Loss_1:0.001544 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000400 Time:19.133879s (4.76min in total, 4.76min remains)
2022-11-28 03:24:07 NUM_SUB: 40;----------------------------
2022-11-28 03:24:07 Epoch [16000/30000] Loss:0.001537 Loss_1:0.001513 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000385 Time:19.036000s (5.08min in total, 4.44min remains)
2022-11-28 03:24:26 NUM_SUB: 40;----------------------------
2022-11-28 03:24:26 Epoch [17000/30000] Loss:0.001583 Loss_1:0.001502 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000370 Time:18.941461s (5.39min in total, 4.12min remains)
2022-11-28 03:24:45 NUM_SUB: 40;----------------------------
2022-11-28 03:24:45 Epoch [18000/30000] Loss:0.001519 Loss_1:0.001502 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000357 Time:19.183578s (5.71min in total, 3.81min remains)
2022-11-28 03:25:04 NUM_SUB: 40;----------------------------
2022-11-28 03:25:04 Epoch [19000/30000] Loss:0.001512 Loss_1:0.001498 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000345 Time:19.042539s (6.03min in total, 3.49min remains)
2022-11-28 03:25:24 NUM_SUB: 40;----------------------------
2022-11-28 03:25:24 Epoch [20000/30000] Loss:0.001508 Loss_1:0.001496 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:19.179762s (6.35min in total, 3.18min remains)
2022-11-28 03:25:44 NUM_SUB: 40;----------------------------
2022-11-28 03:25:44 Epoch [21000/30000] Loss:0.001505 Loss_1:0.001495 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000323 Time:20.699831s (6.70min in total, 2.87min remains)
2022-11-28 03:26:04 NUM_SUB: 40;----------------------------
2022-11-28 03:26:04 Epoch [22000/30000] Loss:0.001510 Loss_1:0.001501 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:19.886642s (7.03min in total, 2.56min remains)
2022-11-28 03:26:23 NUM_SUB: 40;----------------------------
2022-11-28 03:26:23 Epoch [23000/30000] Loss:0.001502 Loss_1:0.001494 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000303 Time:19.062793s (7.34min in total, 2.24min remains)
2022-11-28 03:26:42 NUM_SUB: 40;----------------------------
2022-11-28 03:26:42 Epoch [24000/30000] Loss:0.001500 Loss_1:0.001494 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:19.107695s (7.66min in total, 1.92min remains)
2022-11-28 03:27:01 NUM_SUB: 40;----------------------------
2022-11-28 03:27:01 Epoch [25000/30000] Loss:0.001499 Loss_1:0.001494 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:18.916384s (7.98min in total, 1.60min remains)
2022-11-28 03:27:21 NUM_SUB: 40;----------------------------
2022-11-28 03:27:21 Epoch [26000/30000] Loss:0.001500 Loss_1:0.001496 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:20.087948s (8.31min in total, 1.28min remains)
2022-11-28 03:27:41 NUM_SUB: 40;----------------------------
2022-11-28 03:27:41 Epoch [27000/30000] Loss:0.001497 Loss_1:0.001494 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.250841s (8.63min in total, 0.96min remains)
2022-11-28 03:28:00 NUM_SUB: 40;----------------------------
2022-11-28 03:28:00 Epoch [28000/30000] Loss:0.001497 Loss_1:0.001494 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.344380s (8.96min in total, 0.64min remains)
2022-11-28 03:28:19 NUM_SUB: 40;----------------------------
2022-11-28 03:28:19 Epoch [29000/30000] Loss:0.001497 Loss_1:0.001494 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.641096s (9.27min in total, 0.32min remains)
2022-11-28 03:28:38 NUM_SUB: 40;----------------------------
2022-11-28 03:28:38 Epoch [30000/30000] Loss:0.001496 Loss_1:0.001494 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.238264s (9.59min in total, 0.00min remains)
2022-11-28 03:28:38 Testing & drawing...
2022-11-28 03:28:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:28:39 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=40/
2022-11-28 03:28:39 [Loss]
2022-11-28 03:28:39 NUM_SUB: 40; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:28:39 NUM_SUB: 40; Personalized parameter estimation: Parameter containing:
tensor([0.0381, 0.2400, 0.0096, 0.0059, 0.3074, 0.1712, 0.8146, 0.8964, 0.4556,
        0.0137, 0.0298, 0.0128, 0.8820, 0.1689, 0.0175, 2.6045, 0.6977, 0.8000,
        0.0121, 3.6932, 0.6816, 0.0220, 3.7094, 0.8742, 0.0081, 3.9638, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:28:39 NUM_SUB: 40------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:28:39 Testing & drawing...
2022-11-28 03:28:39 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:28:41 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=40/
2022-11-28 03:28:41 [Loss]
2022-11-28 03:28:41 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:28:41 General parameter estimation: Parameter containing:
tensor([0.0381, 0.2400, 0.0096, 0.0059, 0.3074, 0.1712, 0.8146, 0.8964, 0.4556,
        0.0137, 0.0298, 0.0128, 0.8820, 0.1689, 0.0175, 2.6045, 0.6977, 0.8000,
        0.0121, 3.6932, 0.6816, 0.0220, 3.7094, 0.8742, 0.0081, 3.9638, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:28:41 A: prod, degr, TonA, NonA
2022-11-28 03:28:41 [0.18916388 0.4991433  0.04765583 0.26403698]
2022-11-28 03:28:41 T: prod, degr, AonT, NonT
2022-11-28 03:28:41 [0.44949052 0.40964937 0.11651419 0.02434592]
2022-11-28 03:28:41 N: AonN, TonN, ATonN
2022-11-28 03:28:41 [0.00761014 0.9804053  0.01198455]
2022-11-28 03:28:41 using cpu
2022-11-28 03:28:41 epoch = 30000
2022-11-28 03:28:41 epoch_step = 1000
2022-11-28 03:28:41 model_name = SimpleNetworkAD
2022-11-28 03:28:41 now_string = 2022-11-27-19-40-13
2022-11-28 03:28:41 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:28:41 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:28:41 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:28:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:28:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:28:41 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:29:00 NUM_SUB: 41;----------------------------
2022-11-28 03:29:00 Epoch [01000/30000] Loss:0.081656 Loss_1:0.075916 Loss_2:0.001910 Loss_3:0.000000 Lr:0.000909 Time:19.078863s (0.32min in total, 9.22min remains)
2022-11-28 03:29:19 NUM_SUB: 41;----------------------------
2022-11-28 03:29:19 Epoch [02000/30000] Loss:0.073201 Loss_1:0.072177 Loss_2:0.000603 Loss_3:0.000000 Lr:0.000833 Time:18.689658s (0.63min in total, 8.81min remains)
2022-11-28 03:29:38 NUM_SUB: 41;----------------------------
2022-11-28 03:29:38 Epoch [03000/30000] Loss:0.067084 Loss_1:0.066635 Loss_2:0.000184 Loss_3:0.000000 Lr:0.000769 Time:19.212004s (0.95min in total, 8.55min remains)
2022-11-28 03:29:58 NUM_SUB: 41;----------------------------
2022-11-28 03:29:58 Epoch [04000/30000] Loss:0.060038 Loss_1:0.059654 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000714 Time:19.725529s (1.28min in total, 8.31min remains)
2022-11-28 03:30:17 NUM_SUB: 41;----------------------------
2022-11-28 03:30:17 Epoch [05000/30000] Loss:0.049791 Loss_1:0.049446 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000667 Time:19.143717s (1.60min in total, 7.99min remains)
2022-11-28 03:30:36 NUM_SUB: 41;----------------------------
2022-11-28 03:30:36 Epoch [06000/30000] Loss:0.035482 Loss_1:0.035200 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000625 Time:18.988455s (1.91min in total, 7.66min remains)
2022-11-28 03:30:55 NUM_SUB: 41;----------------------------
2022-11-28 03:30:55 Epoch [07000/30000] Loss:0.019316 Loss_1:0.019111 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000588 Time:18.679489s (2.23min in total, 7.31min remains)
2022-11-28 03:31:14 NUM_SUB: 41;----------------------------
2022-11-28 03:31:14 Epoch [08000/30000] Loss:0.008758 Loss_1:0.008619 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000556 Time:18.996151s (2.54min in total, 6.99min remains)
2022-11-28 03:31:33 NUM_SUB: 41;----------------------------
2022-11-28 03:31:33 Epoch [09000/30000] Loss:0.005363 Loss_1:0.005251 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000526 Time:19.041085s (2.86min in total, 6.67min remains)
2022-11-28 03:31:52 NUM_SUB: 41;----------------------------
2022-11-28 03:31:52 Epoch [10000/30000] Loss:0.004290 Loss_1:0.004187 Loss_2:0.000100 Loss_3:0.000000 Lr:0.000500 Time:18.947743s (3.18min in total, 6.35min remains)
2022-11-28 03:32:11 NUM_SUB: 41;----------------------------
2022-11-28 03:32:11 Epoch [11000/30000] Loss:0.003809 Loss_1:0.003716 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000476 Time:19.041236s (3.49min in total, 6.03min remains)
2022-11-28 03:32:30 NUM_SUB: 41;----------------------------
2022-11-28 03:32:30 Epoch [12000/30000] Loss:0.003217 Loss_1:0.003172 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000455 Time:18.849857s (3.81min in total, 5.71min remains)
2022-11-28 03:32:49 NUM_SUB: 41;----------------------------
2022-11-28 03:32:49 Epoch [13000/30000] Loss:0.002703 Loss_1:0.002667 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:18.928581s (4.12min in total, 5.39min remains)
2022-11-28 03:33:08 NUM_SUB: 41;----------------------------
2022-11-28 03:33:08 Epoch [14000/30000] Loss:0.002483 Loss_1:0.002450 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000417 Time:19.400783s (4.45min in total, 5.08min remains)
2022-11-28 03:33:27 NUM_SUB: 41;----------------------------
2022-11-28 03:33:27 Epoch [15000/30000] Loss:0.002367 Loss_1:0.002340 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000400 Time:19.167571s (4.77min in total, 4.77min remains)
2022-11-28 03:33:46 NUM_SUB: 41;----------------------------
2022-11-28 03:33:46 Epoch [16000/30000] Loss:0.002289 Loss_1:0.002269 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:18.603587s (5.08min in total, 4.44min remains)
2022-11-28 03:34:05 NUM_SUB: 41;----------------------------
2022-11-28 03:34:05 Epoch [17000/30000] Loss:0.002269 Loss_1:0.002253 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:19.482844s (5.40min in total, 4.13min remains)
2022-11-28 03:34:25 NUM_SUB: 41;----------------------------
2022-11-28 03:34:25 Epoch [18000/30000] Loss:0.002263 Loss_1:0.002249 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:19.873991s (5.73min in total, 3.82min remains)
2022-11-28 03:34:44 NUM_SUB: 41;----------------------------
2022-11-28 03:34:44 Epoch [19000/30000] Loss:0.002259 Loss_1:0.002246 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.120569s (6.05min in total, 3.50min remains)
2022-11-28 03:35:03 NUM_SUB: 41;----------------------------
2022-11-28 03:35:03 Epoch [20000/30000] Loss:0.002253 Loss_1:0.002239 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:19.274677s (6.37min in total, 3.19min remains)
2022-11-28 03:35:23 NUM_SUB: 41;----------------------------
2022-11-28 03:35:23 Epoch [21000/30000] Loss:0.002244 Loss_1:0.002230 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000323 Time:19.324017s (6.69min in total, 2.87min remains)
2022-11-28 03:35:42 NUM_SUB: 41;----------------------------
2022-11-28 03:35:42 Epoch [22000/30000] Loss:0.002232 Loss_1:0.002220 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000313 Time:19.268582s (7.01min in total, 2.55min remains)
2022-11-28 03:36:01 NUM_SUB: 41;----------------------------
2022-11-28 03:36:01 Epoch [23000/30000] Loss:0.002220 Loss_1:0.002208 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000303 Time:18.910381s (7.33min in total, 2.23min remains)
2022-11-28 03:36:21 NUM_SUB: 41;----------------------------
2022-11-28 03:36:21 Epoch [24000/30000] Loss:0.002203 Loss_1:0.002189 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000294 Time:19.598415s (7.66min in total, 1.91min remains)
2022-11-28 03:36:40 NUM_SUB: 41;----------------------------
2022-11-28 03:36:40 Epoch [25000/30000] Loss:0.002182 Loss_1:0.002169 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000286 Time:19.770040s (7.99min in total, 1.60min remains)
2022-11-28 03:37:00 NUM_SUB: 41;----------------------------
2022-11-28 03:37:00 Epoch [26000/30000] Loss:0.002155 Loss_1:0.002146 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:19.225301s (8.31min in total, 1.28min remains)
2022-11-28 03:37:19 NUM_SUB: 41;----------------------------
2022-11-28 03:37:19 Epoch [27000/30000] Loss:0.002133 Loss_1:0.002123 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.083360s (8.62min in total, 0.96min remains)
2022-11-28 03:37:39 NUM_SUB: 41;----------------------------
2022-11-28 03:37:39 Epoch [28000/30000] Loss:0.002113 Loss_1:0.002104 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:20.134685s (8.96min in total, 0.64min remains)
2022-11-28 03:37:59 NUM_SUB: 41;----------------------------
2022-11-28 03:37:59 Epoch [29000/30000] Loss:0.002097 Loss_1:0.002090 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:20.205217s (9.30min in total, 0.32min remains)
2022-11-28 03:38:18 NUM_SUB: 41;----------------------------
2022-11-28 03:38:18 Epoch [30000/30000] Loss:0.002086 Loss_1:0.002083 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.459043s (9.62min in total, 0.00min remains)
2022-11-28 03:38:18 Testing & drawing...
2022-11-28 03:38:18 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:38:20 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=41/
2022-11-28 03:38:20 [Loss]
2022-11-28 03:38:20 NUM_SUB: 41; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:38:20 NUM_SUB: 41; Personalized parameter estimation: Parameter containing:
tensor([0.0088, 0.0247, 0.0621, 1.5050, 0.3074, 0.0085, 1.2231, 0.8964, 0.4556,
        0.0142, 0.0287, 0.0137, 0.9444, 0.1689, 0.0173, 3.1572, 0.6977, 0.8000,
        0.0086, 4.6587, 0.6816, 0.0205, 3.8525, 0.8742, 0.0194, 4.8198, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:38:20 NUM_SUB: 41------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:38:20 Testing & drawing...
2022-11-28 03:38:20 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:38:22 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=41/
2022-11-28 03:38:22 [Loss]
2022-11-28 03:38:22 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:38:22 General parameter estimation: Parameter containing:
tensor([0.0088, 0.0247, 0.0621, 1.5050, 0.3074, 0.0085, 1.2231, 0.8964, 0.4556,
        0.0142, 0.0287, 0.0137, 0.9444, 0.1689, 0.0173, 3.1572, 0.6977, 0.8000,
        0.0086, 4.6587, 0.6816, 0.0205, 3.8525, 0.8742, 0.0194, 4.8198, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:38:22 A: prod, degr, TonA, NonA
2022-11-28 03:38:22 [0.23572141 0.48159033 0.21915863 0.06352965]
2022-11-28 03:38:22 T: prod, degr, AonT, NonT
2022-11-28 03:38:22 [0.35460553 0.5261829  0.09514387 0.02406774]
2022-11-28 03:38:22 N: AonN, TonN, ATonN
2022-11-28 03:38:22 [0.01093977 0.95162904 0.03743124]
2022-11-28 03:38:22 using cpu
2022-11-28 03:38:22 epoch = 30000
2022-11-28 03:38:22 epoch_step = 1000
2022-11-28 03:38:22 model_name = SimpleNetworkAD
2022-11-28 03:38:22 now_string = 2022-11-27-19-40-13
2022-11-28 03:38:22 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:38:22 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:38:22 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:38:22 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:38:22 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:38:22 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:38:42 NUM_SUB: 42;----------------------------
2022-11-28 03:38:42 Epoch [01000/30000] Loss:0.158143 Loss_1:0.151761 Loss_2:0.002136 Loss_3:0.000000 Lr:0.000909 Time:19.857380s (0.33min in total, 9.60min remains)
2022-11-28 03:39:03 NUM_SUB: 42;----------------------------
2022-11-28 03:39:03 Epoch [02000/30000] Loss:0.148176 Loss_1:0.146701 Loss_2:0.000714 Loss_3:0.000000 Lr:0.000833 Time:20.902367s (0.68min in total, 9.51min remains)
2022-11-28 03:39:22 NUM_SUB: 42;----------------------------
2022-11-28 03:39:22 Epoch [03000/30000] Loss:0.138783 Loss_1:0.137899 Loss_2:0.000188 Loss_3:0.000000 Lr:0.000769 Time:19.322797s (1.00min in total, 9.01min remains)
2022-11-28 03:39:41 NUM_SUB: 42;----------------------------
2022-11-28 03:39:41 Epoch [04000/30000] Loss:0.125879 Loss_1:0.124943 Loss_2:0.000170 Loss_3:0.000000 Lr:0.000714 Time:19.128623s (1.32min in total, 8.58min remains)
2022-11-28 03:40:00 NUM_SUB: 42;----------------------------
2022-11-28 03:40:00 Epoch [05000/30000] Loss:0.106673 Loss_1:0.105810 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000667 Time:19.049574s (1.64min in total, 8.19min remains)
2022-11-28 03:40:19 NUM_SUB: 42;----------------------------
2022-11-28 03:40:19 Epoch [06000/30000] Loss:0.077902 Loss_1:0.077162 Loss_2:0.000193 Loss_3:0.000000 Lr:0.000625 Time:19.021591s (1.95min in total, 7.82min remains)
2022-11-28 03:40:38 NUM_SUB: 42;----------------------------
2022-11-28 03:40:38 Epoch [07000/30000] Loss:0.039359 Loss_1:0.038784 Loss_2:0.000243 Loss_3:0.000000 Lr:0.000588 Time:18.954291s (2.27min in total, 7.46min remains)
2022-11-28 03:40:58 NUM_SUB: 42;----------------------------
2022-11-28 03:40:58 Epoch [08000/30000] Loss:0.009646 Loss_1:0.009265 Loss_2:0.000288 Loss_3:0.000000 Lr:0.000556 Time:19.349858s (2.59min in total, 7.13min remains)
2022-11-28 03:41:17 NUM_SUB: 42;----------------------------
2022-11-28 03:41:17 Epoch [09000/30000] Loss:0.003543 Loss_1:0.003283 Loss_2:0.000254 Loss_3:0.000000 Lr:0.000526 Time:19.289388s (2.91min in total, 6.80min remains)
2022-11-28 03:41:36 NUM_SUB: 42;----------------------------
2022-11-28 03:41:36 Epoch [10000/30000] Loss:0.002375 Loss_1:0.002188 Loss_2:0.000187 Loss_3:0.000000 Lr:0.000500 Time:19.557091s (3.24min in total, 6.48min remains)
2022-11-28 03:41:55 NUM_SUB: 42;----------------------------
2022-11-28 03:41:55 Epoch [11000/30000] Loss:0.001137 Loss_1:0.001012 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000476 Time:18.994551s (3.56min in total, 6.14min remains)
2022-11-28 03:42:15 NUM_SUB: 42;----------------------------
2022-11-28 03:42:15 Epoch [12000/30000] Loss:0.000471 Loss_1:0.000390 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000455 Time:19.691248s (3.89min in total, 5.83min remains)
2022-11-28 03:42:34 NUM_SUB: 42;----------------------------
2022-11-28 03:42:34 Epoch [13000/30000] Loss:0.000367 Loss_1:0.000312 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000435 Time:19.226503s (4.21min in total, 5.50min remains)
2022-11-28 03:42:53 NUM_SUB: 42;----------------------------
2022-11-28 03:42:53 Epoch [14000/30000] Loss:0.000276 Loss_1:0.000220 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000417 Time:19.118272s (4.52min in total, 5.17min remains)
2022-11-28 03:43:13 NUM_SUB: 42;----------------------------
2022-11-28 03:43:13 Epoch [15000/30000] Loss:0.000127 Loss_1:0.000071 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000400 Time:19.488909s (4.85min in total, 4.85min remains)
2022-11-28 03:43:32 NUM_SUB: 42;----------------------------
2022-11-28 03:43:32 Epoch [16000/30000] Loss:0.000109 Loss_1:0.000064 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000385 Time:19.430385s (5.17min in total, 4.53min remains)
2022-11-28 03:43:51 NUM_SUB: 42;----------------------------
2022-11-28 03:43:51 Epoch [17000/30000] Loss:0.000104 Loss_1:0.000061 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000370 Time:18.944777s (5.49min in total, 4.20min remains)
2022-11-28 03:44:10 NUM_SUB: 42;----------------------------
2022-11-28 03:44:10 Epoch [18000/30000] Loss:0.000080 Loss_1:0.000051 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000357 Time:19.161830s (5.81min in total, 3.87min remains)
2022-11-28 03:44:29 NUM_SUB: 42;----------------------------
2022-11-28 03:44:29 Epoch [19000/30000] Loss:0.000074 Loss_1:0.000050 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000345 Time:18.507321s (6.12min in total, 3.54min remains)
2022-11-28 03:44:48 NUM_SUB: 42;----------------------------
2022-11-28 03:44:48 Epoch [20000/30000] Loss:0.000067 Loss_1:0.000047 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000333 Time:19.094527s (6.44min in total, 3.22min remains)
2022-11-28 03:45:07 NUM_SUB: 42;----------------------------
2022-11-28 03:45:07 Epoch [21000/30000] Loss:0.000063 Loss_1:0.000045 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000323 Time:19.399414s (6.76min in total, 2.90min remains)
2022-11-28 03:45:27 NUM_SUB: 42;----------------------------
2022-11-28 03:45:27 Epoch [22000/30000] Loss:0.000059 Loss_1:0.000043 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000313 Time:19.550974s (7.08min in total, 2.58min remains)
2022-11-28 03:45:46 NUM_SUB: 42;----------------------------
2022-11-28 03:45:46 Epoch [23000/30000] Loss:0.000056 Loss_1:0.000042 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000303 Time:18.834059s (7.40min in total, 2.25min remains)
2022-11-28 03:46:05 NUM_SUB: 42;----------------------------
2022-11-28 03:46:05 Epoch [24000/30000] Loss:0.000060 Loss_1:0.000046 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000294 Time:18.812567s (7.71min in total, 1.93min remains)
2022-11-28 03:46:24 NUM_SUB: 42;----------------------------
2022-11-28 03:46:24 Epoch [25000/30000] Loss:0.000048 Loss_1:0.000037 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000286 Time:19.060466s (8.03min in total, 1.61min remains)
2022-11-28 03:46:42 NUM_SUB: 42;----------------------------
2022-11-28 03:46:42 Epoch [26000/30000] Loss:0.000045 Loss_1:0.000035 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000278 Time:18.712689s (8.34min in total, 1.28min remains)
2022-11-28 03:47:02 NUM_SUB: 42;----------------------------
2022-11-28 03:47:02 Epoch [27000/30000] Loss:0.000042 Loss_1:0.000033 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000270 Time:19.116104s (8.66min in total, 0.96min remains)
2022-11-28 03:47:21 NUM_SUB: 42;----------------------------
2022-11-28 03:47:21 Epoch [28000/30000] Loss:0.000051 Loss_1:0.000043 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000263 Time:19.036086s (8.98min in total, 0.64min remains)
2022-11-28 03:47:40 NUM_SUB: 42;----------------------------
2022-11-28 03:47:40 Epoch [29000/30000] Loss:0.000034 Loss_1:0.000026 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000256 Time:19.060812s (9.29min in total, 0.32min remains)
2022-11-28 03:47:59 NUM_SUB: 42;----------------------------
2022-11-28 03:47:59 Epoch [30000/30000] Loss:0.000032 Loss_1:0.000023 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000250 Time:19.272949s (9.62min in total, 0.00min remains)
2022-11-28 03:47:59 Testing & drawing...
2022-11-28 03:47:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:48:01 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=42/
2022-11-28 03:48:01 [Loss]
2022-11-28 03:48:01 NUM_SUB: 42; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:48:01 NUM_SUB: 42; Personalized parameter estimation: Parameter containing:
tensor([0.2348, 0.3666, 0.0198, 0.0768, 0.3074, 0.3740, 1.5676, 0.8964, 0.4556,
        0.0177, 0.0461, 0.0151, 0.2394, 0.1689, 0.0179, 0.2951, 0.6977, 0.8000,
        0.0089, 4.3836, 0.6816, 0.0099, 2.5594, 0.8742, 0.0197, 4.1699, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:48:01 NUM_SUB: 42------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:48:01 Testing & drawing...
2022-11-28 03:48:01 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:48:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=42/
2022-11-28 03:48:02 [Loss]
2022-11-28 03:48:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:48:02 General parameter estimation: Parameter containing:
tensor([0.2348, 0.3666, 0.0198, 0.0768, 0.3074, 0.3740, 1.5676, 0.8964, 0.4556,
        0.0177, 0.0461, 0.0151, 0.2394, 0.1689, 0.0179, 0.2951, 0.6977, 0.8000,
        0.0089, 4.3836, 0.6816, 0.0099, 2.5594, 0.8742, 0.0197, 4.1699, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:48:02 A: prod, degr, TonA, NonA
2022-11-28 03:48:02 [0.34502122 0.4990984  0.02885081 0.12702961]
2022-11-28 03:48:02 T: prod, degr, AonT, NonT
2022-11-28 03:48:02 [0.19575383 0.47472963 0.1575301  0.17198643]
2022-11-28 03:48:02 N: AonN, TonN, ATonN
2022-11-28 03:48:02 [0.03276604 0.80430055 0.16293344]
2022-11-28 03:48:02 using cpu
2022-11-28 03:48:02 epoch = 30000
2022-11-28 03:48:02 epoch_step = 1000
2022-11-28 03:48:02 model_name = SimpleNetworkAD
2022-11-28 03:48:02 now_string = 2022-11-27-19-40-13
2022-11-28 03:48:02 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:48:02 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:48:02 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:48:02 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:48:02 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:48:02 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:48:21 NUM_SUB: 43;----------------------------
2022-11-28 03:48:21 Epoch [01000/30000] Loss:0.114890 Loss_1:0.109466 Loss_2:0.001675 Loss_3:0.000000 Lr:0.000909 Time:18.958398s (0.32min in total, 9.16min remains)
2022-11-28 03:48:40 NUM_SUB: 43;----------------------------
2022-11-28 03:48:40 Epoch [02000/30000] Loss:0.102562 Loss_1:0.101690 Loss_2:0.000484 Loss_3:0.000000 Lr:0.000833 Time:18.727243s (0.63min in total, 8.79min remains)
2022-11-28 03:48:59 NUM_SUB: 43;----------------------------
2022-11-28 03:48:59 Epoch [03000/30000] Loss:0.090597 Loss_1:0.090158 Loss_2:0.000140 Loss_3:0.000000 Lr:0.000769 Time:18.674063s (0.94min in total, 8.45min remains)
2022-11-28 03:49:18 NUM_SUB: 43;----------------------------
2022-11-28 03:49:18 Epoch [04000/30000] Loss:0.074430 Loss_1:0.074086 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000714 Time:19.062121s (1.26min in total, 8.17min remains)
2022-11-28 03:49:37 NUM_SUB: 43;----------------------------
2022-11-28 03:49:37 Epoch [05000/30000] Loss:0.051460 Loss_1:0.051166 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000667 Time:19.022099s (1.57min in total, 7.87min remains)
2022-11-28 03:49:56 NUM_SUB: 43;----------------------------
2022-11-28 03:49:56 Epoch [06000/30000] Loss:0.025408 Loss_1:0.025198 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000625 Time:18.705940s (1.89min in total, 7.54min remains)
2022-11-28 03:50:14 NUM_SUB: 43;----------------------------
2022-11-28 03:50:14 Epoch [07000/30000] Loss:0.009397 Loss_1:0.009282 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000588 Time:18.875294s (2.20min in total, 7.23min remains)
2022-11-28 03:50:33 NUM_SUB: 43;----------------------------
2022-11-28 03:50:33 Epoch [08000/30000] Loss:0.005568 Loss_1:0.005493 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000556 Time:18.722820s (2.51min in total, 6.91min remains)
2022-11-28 03:50:53 NUM_SUB: 43;----------------------------
2022-11-28 03:50:53 Epoch [09000/30000] Loss:0.004626 Loss_1:0.004549 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000526 Time:20.026967s (2.85min in total, 6.64min remains)
2022-11-28 03:51:13 NUM_SUB: 43;----------------------------
2022-11-28 03:51:13 Epoch [10000/30000] Loss:0.003896 Loss_1:0.003806 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000500 Time:19.781413s (3.18min in total, 6.35min remains)
2022-11-28 03:51:33 NUM_SUB: 43;----------------------------
2022-11-28 03:51:33 Epoch [11000/30000] Loss:0.003015 Loss_1:0.002943 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000476 Time:19.664915s (3.50min in total, 6.05min remains)
2022-11-28 03:51:52 NUM_SUB: 43;----------------------------
2022-11-28 03:51:52 Epoch [12000/30000] Loss:0.001757 Loss_1:0.001717 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:19.228758s (3.82min in total, 5.74min remains)
2022-11-28 03:52:11 NUM_SUB: 43;----------------------------
2022-11-28 03:52:11 Epoch [13000/30000] Loss:0.000648 Loss_1:0.000611 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000435 Time:18.964628s (4.14min in total, 5.41min remains)
2022-11-28 03:52:30 NUM_SUB: 43;----------------------------
2022-11-28 03:52:30 Epoch [14000/30000] Loss:0.000394 Loss_1:0.000365 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:19.280976s (4.46min in total, 5.10min remains)
2022-11-28 03:52:50 NUM_SUB: 43;----------------------------
2022-11-28 03:52:50 Epoch [15000/30000] Loss:0.000379 Loss_1:0.000358 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000400 Time:19.480605s (4.79min in total, 4.79min remains)
2022-11-28 03:53:09 NUM_SUB: 43;----------------------------
2022-11-28 03:53:09 Epoch [16000/30000] Loss:0.000370 Loss_1:0.000355 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:19.137712s (5.11min in total, 4.47min remains)
2022-11-28 03:53:29 NUM_SUB: 43;----------------------------
2022-11-28 03:53:29 Epoch [17000/30000] Loss:0.000361 Loss_1:0.000350 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000370 Time:20.023731s (5.44min in total, 4.16min remains)
2022-11-28 03:53:49 NUM_SUB: 43;----------------------------
2022-11-28 03:53:49 Epoch [18000/30000] Loss:0.000352 Loss_1:0.000343 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:20.058908s (5.77min in total, 3.85min remains)
2022-11-28 03:54:08 NUM_SUB: 43;----------------------------
2022-11-28 03:54:08 Epoch [19000/30000] Loss:0.000341 Loss_1:0.000335 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.260808s (6.09min in total, 3.53min remains)
2022-11-28 03:54:28 NUM_SUB: 43;----------------------------
2022-11-28 03:54:28 Epoch [20000/30000] Loss:0.000329 Loss_1:0.000324 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.392170s (6.42min in total, 3.21min remains)
2022-11-28 03:54:47 NUM_SUB: 43;----------------------------
2022-11-28 03:54:47 Epoch [21000/30000] Loss:0.000314 Loss_1:0.000310 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.207186s (6.74min in total, 2.89min remains)
2022-11-28 03:55:06 NUM_SUB: 43;----------------------------
2022-11-28 03:55:06 Epoch [22000/30000] Loss:0.000297 Loss_1:0.000294 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:19.246016s (7.06min in total, 2.57min remains)
2022-11-28 03:55:25 NUM_SUB: 43;----------------------------
2022-11-28 03:55:25 Epoch [23000/30000] Loss:0.000288 Loss_1:0.000287 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.079927s (7.38min in total, 2.25min remains)
2022-11-28 03:55:44 NUM_SUB: 43;----------------------------
2022-11-28 03:55:44 Epoch [24000/30000] Loss:0.000288 Loss_1:0.000286 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.288246s (7.70min in total, 1.92min remains)
2022-11-28 03:56:03 NUM_SUB: 43;----------------------------
2022-11-28 03:56:03 Epoch [25000/30000] Loss:0.000287 Loss_1:0.000286 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.132520s (8.02min in total, 1.60min remains)
2022-11-28 03:56:23 NUM_SUB: 43;----------------------------
2022-11-28 03:56:23 Epoch [26000/30000] Loss:0.000287 Loss_1:0.000286 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.462400s (8.34min in total, 1.28min remains)
2022-11-28 03:56:42 NUM_SUB: 43;----------------------------
2022-11-28 03:56:42 Epoch [27000/30000] Loss:0.000287 Loss_1:0.000286 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.253742s (8.66min in total, 0.96min remains)
2022-11-28 03:57:01 NUM_SUB: 43;----------------------------
2022-11-28 03:57:01 Epoch [28000/30000] Loss:0.000287 Loss_1:0.000285 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.285693s (8.98min in total, 0.64min remains)
2022-11-28 03:57:21 NUM_SUB: 43;----------------------------
2022-11-28 03:57:21 Epoch [29000/30000] Loss:0.000287 Loss_1:0.000285 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.530414s (9.31min in total, 0.32min remains)
2022-11-28 03:57:40 NUM_SUB: 43;----------------------------
2022-11-28 03:57:40 Epoch [30000/30000] Loss:0.000287 Loss_1:0.000285 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.429929s (9.63min in total, 0.00min remains)
2022-11-28 03:57:40 Testing & drawing...
2022-11-28 03:57:40 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:57:42 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=43/
2022-11-28 03:57:42 [Loss]
2022-11-28 03:57:42 NUM_SUB: 43; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:57:42 NUM_SUB: 43; Personalized parameter estimation: Parameter containing:
tensor([0.2728, 0.8671, 0.0099, 0.8934, 0.3074, 0.2968, 0.8170, 0.8964, 0.4556,
        0.0146, 0.0819, 0.0837, 0.7288, 0.1689, 0.0177, 1.7844, 0.6977, 0.8000,
        0.0122, 2.5059, 0.6816, 0.0226, 3.0501, 0.8742, 0.0176, 3.3812, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:57:42 NUM_SUB: 43------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 03:57:42 Testing & drawing...
2022-11-28 03:57:42 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 03:57:44 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=43/
2022-11-28 03:57:44 [Loss]
2022-11-28 03:57:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 03:57:44 General parameter estimation: Parameter containing:
tensor([0.2728, 0.8671, 0.0099, 0.8934, 0.3074, 0.2968, 0.8170, 0.8964, 0.4556,
        0.0146, 0.0819, 0.0837, 0.7288, 0.1689, 0.0177, 1.7844, 0.6977, 0.8000,
        0.0122, 2.5059, 0.6816, 0.0226, 3.0501, 0.8742, 0.0176, 3.3812, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 03:57:44 A: prod, degr, TonA, NonA
2022-11-28 03:57:44 [0.30976942 0.49987993 0.0032619  0.18708877]
2022-11-28 03:57:44 T: prod, degr, AonT, NonT
2022-11-28 03:57:44 [0.1636208  0.46144733 0.33386055 0.04107132]
2022-11-28 03:57:44 N: AonN, TonN, ATonN
2022-11-28 03:57:44 [0.02237347 0.93659985 0.04102672]
2022-11-28 03:57:44 using cpu
2022-11-28 03:57:44 epoch = 30000
2022-11-28 03:57:44 epoch_step = 1000
2022-11-28 03:57:44 model_name = SimpleNetworkAD
2022-11-28 03:57:44 now_string = 2022-11-27-19-40-13
2022-11-28 03:57:44 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 03:57:44 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 03:57:44 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 03:57:44 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 03:57:44 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 03:57:44 --------------------------------------------------training start--------------------------------------------------
2022-11-28 03:58:03 NUM_SUB: 44;----------------------------
2022-11-28 03:58:03 Epoch [01000/30000] Loss:0.024857 Loss_1:0.019702 Loss_2:0.001503 Loss_3:0.000000 Lr:0.000909 Time:19.424228s (0.32min in total, 9.39min remains)
2022-11-28 03:58:23 NUM_SUB: 44;----------------------------
2022-11-28 03:58:23 Epoch [02000/30000] Loss:0.019407 Loss_1:0.018604 Loss_2:0.000406 Loss_3:0.000000 Lr:0.000833 Time:19.257394s (0.64min in total, 9.03min remains)
2022-11-28 03:58:42 NUM_SUB: 44;----------------------------
2022-11-28 03:58:42 Epoch [03000/30000] Loss:0.017440 Loss_1:0.017256 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000769 Time:19.166433s (0.96min in total, 8.68min remains)
2022-11-28 03:59:01 NUM_SUB: 44;----------------------------
2022-11-28 03:59:01 Epoch [04000/30000] Loss:0.015556 Loss_1:0.015453 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000714 Time:19.591560s (1.29min in total, 8.39min remains)
2022-11-28 03:59:21 NUM_SUB: 44;----------------------------
2022-11-28 03:59:21 Epoch [05000/30000] Loss:0.013563 Loss_1:0.013452 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000667 Time:19.153756s (1.61min in total, 8.05min remains)
2022-11-28 03:59:40 NUM_SUB: 44;----------------------------
2022-11-28 03:59:40 Epoch [06000/30000] Loss:0.011005 Loss_1:0.010893 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000625 Time:19.077296s (1.93min in total, 7.71min remains)
2022-11-28 03:59:58 NUM_SUB: 44;----------------------------
2022-11-28 03:59:58 Epoch [07000/30000] Loss:0.008075 Loss_1:0.007960 Loss_2:0.000095 Loss_3:0.000000 Lr:0.000588 Time:18.830366s (2.24min in total, 7.37min remains)
2022-11-28 04:00:17 NUM_SUB: 44;----------------------------
2022-11-28 04:00:17 Epoch [08000/30000] Loss:0.005415 Loss_1:0.005309 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000556 Time:19.058672s (2.56min in total, 7.04min remains)
2022-11-28 04:00:36 NUM_SUB: 44;----------------------------
2022-11-28 04:00:36 Epoch [09000/30000] Loss:0.003772 Loss_1:0.003715 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000526 Time:18.888382s (2.87min in total, 6.71min remains)
2022-11-28 04:00:55 NUM_SUB: 44;----------------------------
2022-11-28 04:00:55 Epoch [10000/30000] Loss:0.003078 Loss_1:0.003063 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000500 Time:18.693617s (3.19min in total, 6.37min remains)
2022-11-28 04:01:14 NUM_SUB: 44;----------------------------
2022-11-28 04:01:14 Epoch [11000/30000] Loss:0.002701 Loss_1:0.002689 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000476 Time:18.924358s (3.50min in total, 6.05min remains)
2022-11-28 04:01:33 NUM_SUB: 44;----------------------------
2022-11-28 04:01:33 Epoch [12000/30000] Loss:0.002254 Loss_1:0.002242 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000455 Time:18.586404s (3.81min in total, 5.72min remains)
2022-11-28 04:01:52 NUM_SUB: 44;----------------------------
2022-11-28 04:01:52 Epoch [13000/30000] Loss:0.001632 Loss_1:0.001619 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000435 Time:19.188496s (4.13min in total, 5.40min remains)
2022-11-28 04:02:10 NUM_SUB: 44;----------------------------
2022-11-28 04:02:10 Epoch [14000/30000] Loss:0.000889 Loss_1:0.000874 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:18.567688s (4.44min in total, 5.07min remains)
2022-11-28 04:02:29 NUM_SUB: 44;----------------------------
2022-11-28 04:02:29 Epoch [15000/30000] Loss:0.000388 Loss_1:0.000372 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:18.981952s (4.76min in total, 4.76min remains)
2022-11-28 04:02:48 NUM_SUB: 44;----------------------------
2022-11-28 04:02:48 Epoch [16000/30000] Loss:0.000288 Loss_1:0.000276 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:18.913127s (5.07min in total, 4.44min remains)
2022-11-28 04:03:08 NUM_SUB: 44;----------------------------
2022-11-28 04:03:08 Epoch [17000/30000] Loss:0.000274 Loss_1:0.000267 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:19.338668s (5.39min in total, 4.13min remains)
2022-11-28 04:03:27 NUM_SUB: 44;----------------------------
2022-11-28 04:03:27 Epoch [18000/30000] Loss:0.000264 Loss_1:0.000259 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:19.562868s (5.72min in total, 3.81min remains)
2022-11-28 04:03:46 NUM_SUB: 44;----------------------------
2022-11-28 04:03:46 Epoch [19000/30000] Loss:0.000258 Loss_1:0.000254 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000345 Time:18.645568s (6.03min in total, 3.49min remains)
2022-11-28 04:04:05 NUM_SUB: 44;----------------------------
2022-11-28 04:04:05 Epoch [20000/30000] Loss:0.000254 Loss_1:0.000251 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:18.864691s (6.35min in total, 3.17min remains)
2022-11-28 04:04:24 NUM_SUB: 44;----------------------------
2022-11-28 04:04:24 Epoch [21000/30000] Loss:0.000253 Loss_1:0.000250 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:19.160322s (6.66min in total, 2.86min remains)
2022-11-28 04:04:43 NUM_SUB: 44;----------------------------
2022-11-28 04:04:43 Epoch [22000/30000] Loss:0.000252 Loss_1:0.000250 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:19.141445s (6.98min in total, 2.54min remains)
2022-11-28 04:05:02 NUM_SUB: 44;----------------------------
2022-11-28 04:05:02 Epoch [23000/30000] Loss:0.000251 Loss_1:0.000250 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:18.954204s (7.30min in total, 2.22min remains)
2022-11-28 04:05:21 NUM_SUB: 44;----------------------------
2022-11-28 04:05:21 Epoch [24000/30000] Loss:0.000251 Loss_1:0.000250 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:18.617732s (7.61min in total, 1.90min remains)
2022-11-28 04:05:40 NUM_SUB: 44;----------------------------
2022-11-28 04:05:40 Epoch [25000/30000] Loss:0.000251 Loss_1:0.000250 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.076426s (7.93min in total, 1.59min remains)
2022-11-28 04:05:59 NUM_SUB: 44;----------------------------
2022-11-28 04:05:59 Epoch [26000/30000] Loss:0.000251 Loss_1:0.000250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.156347s (8.25min in total, 1.27min remains)
2022-11-28 04:06:18 NUM_SUB: 44;----------------------------
2022-11-28 04:06:18 Epoch [27000/30000] Loss:0.000251 Loss_1:0.000250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.015005s (8.56min in total, 0.95min remains)
2022-11-28 04:06:37 NUM_SUB: 44;----------------------------
2022-11-28 04:06:37 Epoch [28000/30000] Loss:0.000250 Loss_1:0.000250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.041549s (8.88min in total, 0.63min remains)
2022-11-28 04:06:56 NUM_SUB: 44;----------------------------
2022-11-28 04:06:56 Epoch [29000/30000] Loss:0.000250 Loss_1:0.000250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.784248s (9.19min in total, 0.32min remains)
2022-11-28 04:07:15 NUM_SUB: 44;----------------------------
2022-11-28 04:07:15 Epoch [30000/30000] Loss:0.000250 Loss_1:0.000250 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.913120s (9.51min in total, 0.00min remains)
2022-11-28 04:07:15 Testing & drawing...
2022-11-28 04:07:15 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:07:16 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=44/
2022-11-28 04:07:16 [Loss]
2022-11-28 04:07:16 NUM_SUB: 44; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:07:16 NUM_SUB: 44; Personalized parameter estimation: Parameter containing:
tensor([3.3644e-01, 9.4652e-01, 9.2900e-03, 2.4162e+00, 3.0742e-01, 1.4504e-02,
        1.0269e+00, 8.9644e-01, 4.5563e-01, 9.3458e-04, 1.7359e-02, 6.5753e-03,
        2.1431e-01, 1.6886e-01, 1.7649e-02, 7.2110e-01, 6.9767e-01, 8.0001e-01,
        8.2077e-03, 3.1893e+00, 6.8161e-01, 2.1887e-02, 3.4549e+00, 8.7416e-01,
        1.8855e-02, 4.1398e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 04:07:16 NUM_SUB: 44------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:07:16 Testing & drawing...
2022-11-28 04:07:16 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:07:18 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=44/
2022-11-28 04:07:18 [Loss]
2022-11-28 04:07:18 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:07:18 General parameter estimation: Parameter containing:
tensor([3.3644e-01, 9.4652e-01, 9.2900e-03, 2.4162e+00, 3.0742e-01, 1.4504e-02,
        1.0269e+00, 8.9644e-01, 4.5563e-01, 9.3458e-04, 1.7359e-02, 6.5753e-03,
        2.1431e-01, 1.6886e-01, 1.7649e-02, 7.2110e-01, 6.9767e-01, 8.0001e-01,
        8.2077e-03, 3.1893e+00, 6.8161e-01, 2.1887e-02, 3.4549e+00, 8.7416e-01,
        1.8855e-02, 4.1398e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 04:07:18 A: prod, degr, TonA, NonA
2022-11-28 04:07:18 [4.9577242e-01 5.0004756e-01 4.8730031e-04 3.6927105e-03]
2022-11-28 04:07:18 T: prod, degr, AonT, NonT
2022-11-28 04:07:18 [0.05630559 0.37491548 0.25790593 0.31087297]
2022-11-28 04:07:18 N: AonN, TonN, ATonN
2022-11-28 04:07:18 [0.01405437 0.95498776 0.03095787]
2022-11-28 04:07:18 using cpu
2022-11-28 04:07:18 epoch = 30000
2022-11-28 04:07:18 epoch_step = 1000
2022-11-28 04:07:18 model_name = SimpleNetworkAD
2022-11-28 04:07:18 now_string = 2022-11-27-19-40-13
2022-11-28 04:07:18 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:07:18 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:07:18 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:07:18 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:07:18 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:07:18 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:07:37 NUM_SUB: 45;----------------------------
2022-11-28 04:07:37 Epoch [01000/30000] Loss:0.068124 Loss_1:0.062104 Loss_2:0.002313 Loss_3:0.000000 Lr:0.000909 Time:18.974421s (0.32min in total, 9.17min remains)
2022-11-28 04:07:56 NUM_SUB: 45;----------------------------
2022-11-28 04:07:56 Epoch [02000/30000] Loss:0.057739 Loss_1:0.056454 Loss_2:0.000931 Loss_3:0.000000 Lr:0.000833 Time:18.951552s (0.63min in total, 8.85min remains)
2022-11-28 04:08:15 NUM_SUB: 45;----------------------------
2022-11-28 04:08:15 Epoch [03000/30000] Loss:0.049564 Loss_1:0.048819 Loss_2:0.000539 Loss_3:0.000000 Lr:0.000769 Time:19.259539s (0.95min in total, 8.58min remains)
2022-11-28 04:08:35 NUM_SUB: 45;----------------------------
2022-11-28 04:08:35 Epoch [04000/30000] Loss:0.040509 Loss_1:0.039874 Loss_2:0.000437 Loss_3:0.000000 Lr:0.000714 Time:19.440685s (1.28min in total, 8.30min remains)
2022-11-28 04:08:54 NUM_SUB: 45;----------------------------
2022-11-28 04:08:54 Epoch [05000/30000] Loss:0.030002 Loss_1:0.029635 Loss_2:0.000217 Loss_3:0.000000 Lr:0.000667 Time:19.344593s (1.60min in total, 8.00min remains)
2022-11-28 04:09:13 NUM_SUB: 45;----------------------------
2022-11-28 04:09:13 Epoch [06000/30000] Loss:0.020559 Loss_1:0.020285 Loss_2:0.000188 Loss_3:0.000000 Lr:0.000625 Time:19.205225s (1.92min in total, 7.68min remains)
2022-11-28 04:09:33 NUM_SUB: 45;----------------------------
2022-11-28 04:09:33 Epoch [07000/30000] Loss:0.013913 Loss_1:0.013702 Loss_2:0.000168 Loss_3:0.000000 Lr:0.000588 Time:19.338184s (2.24min in total, 7.37min remains)
2022-11-28 04:09:52 NUM_SUB: 45;----------------------------
2022-11-28 04:09:52 Epoch [08000/30000] Loss:0.008646 Loss_1:0.008453 Loss_2:0.000167 Loss_3:0.000000 Lr:0.000556 Time:19.126900s (2.56min in total, 7.04min remains)
2022-11-28 04:10:11 NUM_SUB: 45;----------------------------
2022-11-28 04:10:11 Epoch [09000/30000] Loss:0.003791 Loss_1:0.003601 Loss_2:0.000178 Loss_3:0.000000 Lr:0.000526 Time:18.895931s (2.88min in total, 6.71min remains)
2022-11-28 04:10:30 NUM_SUB: 45;----------------------------
2022-11-28 04:10:30 Epoch [10000/30000] Loss:0.001274 Loss_1:0.001113 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000500 Time:19.021202s (3.19min in total, 6.39min remains)
2022-11-28 04:10:49 NUM_SUB: 45;----------------------------
2022-11-28 04:10:49 Epoch [11000/30000] Loss:0.000812 Loss_1:0.000708 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000476 Time:19.149828s (3.51min in total, 6.07min remains)
2022-11-28 04:11:08 NUM_SUB: 45;----------------------------
2022-11-28 04:11:08 Epoch [12000/30000] Loss:0.000690 Loss_1:0.000626 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000455 Time:18.885321s (3.83min in total, 5.74min remains)
2022-11-28 04:11:27 NUM_SUB: 45;----------------------------
2022-11-28 04:11:27 Epoch [13000/30000] Loss:0.000632 Loss_1:0.000586 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000435 Time:19.179022s (4.15min in total, 5.42min remains)
2022-11-28 04:11:46 NUM_SUB: 45;----------------------------
2022-11-28 04:11:46 Epoch [14000/30000] Loss:0.000588 Loss_1:0.000552 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:18.818063s (4.46min in total, 5.10min remains)
2022-11-28 04:12:05 NUM_SUB: 45;----------------------------
2022-11-28 04:12:05 Epoch [15000/30000] Loss:0.000546 Loss_1:0.000519 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000400 Time:19.227188s (4.78min in total, 4.78min remains)
2022-11-28 04:12:24 NUM_SUB: 45;----------------------------
2022-11-28 04:12:24 Epoch [16000/30000] Loss:0.000514 Loss_1:0.000492 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000385 Time:19.019336s (5.10min in total, 4.46min remains)
2022-11-28 04:12:43 NUM_SUB: 45;----------------------------
2022-11-28 04:12:43 Epoch [17000/30000] Loss:0.000493 Loss_1:0.000476 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000370 Time:19.289866s (5.42min in total, 4.14min remains)
2022-11-28 04:13:03 NUM_SUB: 45;----------------------------
2022-11-28 04:13:03 Epoch [18000/30000] Loss:0.000477 Loss_1:0.000463 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:19.575498s (5.75min in total, 3.83min remains)
2022-11-28 04:13:22 NUM_SUB: 45;----------------------------
2022-11-28 04:13:22 Epoch [19000/30000] Loss:0.000450 Loss_1:0.000440 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.231322s (6.07min in total, 3.51min remains)
2022-11-28 04:13:41 NUM_SUB: 45;----------------------------
2022-11-28 04:13:41 Epoch [20000/30000] Loss:0.000405 Loss_1:0.000398 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:19.041156s (6.38min in total, 3.19min remains)
2022-11-28 04:14:00 NUM_SUB: 45;----------------------------
2022-11-28 04:14:00 Epoch [21000/30000] Loss:0.000385 Loss_1:0.000380 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:18.896153s (6.70min in total, 2.87min remains)
2022-11-28 04:14:19 NUM_SUB: 45;----------------------------
2022-11-28 04:14:19 Epoch [22000/30000] Loss:0.000360 Loss_1:0.000356 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.973508s (7.01min in total, 2.55min remains)
2022-11-28 04:14:38 NUM_SUB: 45;----------------------------
2022-11-28 04:14:38 Epoch [23000/30000] Loss:0.000350 Loss_1:0.000347 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.085855s (7.33min in total, 2.23min remains)
2022-11-28 04:14:57 NUM_SUB: 45;----------------------------
2022-11-28 04:14:57 Epoch [24000/30000] Loss:0.000347 Loss_1:0.000345 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.095896s (7.65min in total, 1.91min remains)
2022-11-28 04:15:16 NUM_SUB: 45;----------------------------
2022-11-28 04:15:16 Epoch [25000/30000] Loss:0.000346 Loss_1:0.000344 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.844900s (7.96min in total, 1.59min remains)
2022-11-28 04:15:35 NUM_SUB: 45;----------------------------
2022-11-28 04:15:35 Epoch [26000/30000] Loss:0.000344 Loss_1:0.000342 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.274584s (8.29min in total, 1.27min remains)
2022-11-28 04:15:54 NUM_SUB: 45;----------------------------
2022-11-28 04:15:54 Epoch [27000/30000] Loss:0.000343 Loss_1:0.000341 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.219185s (8.61min in total, 0.96min remains)
2022-11-28 04:16:13 NUM_SUB: 45;----------------------------
2022-11-28 04:16:13 Epoch [28000/30000] Loss:0.000342 Loss_1:0.000339 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:18.958314s (8.92min in total, 0.64min remains)
2022-11-28 04:16:33 NUM_SUB: 45;----------------------------
2022-11-28 04:16:33 Epoch [29000/30000] Loss:0.000341 Loss_1:0.000339 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.610724s (9.25min in total, 0.32min remains)
2022-11-28 04:16:52 NUM_SUB: 45;----------------------------
2022-11-28 04:16:52 Epoch [30000/30000] Loss:0.000340 Loss_1:0.000338 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.492412s (9.57min in total, 0.00min remains)
2022-11-28 04:16:52 Testing & drawing...
2022-11-28 04:16:52 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:16:54 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=45/
2022-11-28 04:16:54 [Loss]
2022-11-28 04:16:54 NUM_SUB: 45; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:16:54 NUM_SUB: 45; Personalized parameter estimation: Parameter containing:
tensor([0.0184, 0.0329, 0.0252, 1.5891, 0.3074, 0.0172, 0.7275, 0.8964, 0.4556,
        0.0137, 0.0345, 0.0144, 0.5067, 0.1689, 0.0172, 2.6912, 0.6977, 0.8000,
        0.0113, 3.6529, 0.6816, 0.0232, 2.4166, 0.8742, 0.0198, 3.5148, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:16:54 NUM_SUB: 45------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:16:54 Testing & drawing...
2022-11-28 04:16:54 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:16:56 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=45/
2022-11-28 04:16:56 [Loss]
2022-11-28 04:16:56 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:16:56 General parameter estimation: Parameter containing:
tensor([0.0184, 0.0329, 0.0252, 1.5891, 0.3074, 0.0172, 0.7275, 0.8964, 0.4556,
        0.0137, 0.0345, 0.0144, 0.5067, 0.1689, 0.0172, 2.6912, 0.6977, 0.8000,
        0.0113, 3.6529, 0.6816, 0.0232, 2.4166, 0.8742, 0.0198, 3.5148, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:16:56 A: prod, degr, TonA, NonA
2022-11-28 04:16:56 [0.31051475 0.485002   0.06379162 0.14069165]
2022-11-28 04:16:56 T: prod, degr, AonT, NonT
2022-11-28 04:16:56 [0.25210556 0.55562335 0.16666421 0.02560689]
2022-11-28 04:16:56 N: AonN, TonN, ATonN
2022-11-28 04:16:56 [0.02629096 0.8989954  0.07471365]
2022-11-28 04:16:56 using cpu
2022-11-28 04:16:56 epoch = 30000
2022-11-28 04:16:56 epoch_step = 1000
2022-11-28 04:16:56 model_name = SimpleNetworkAD
2022-11-28 04:16:56 now_string = 2022-11-27-19-40-13
2022-11-28 04:16:56 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:16:56 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:16:56 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:16:56 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:16:56 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:16:56 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:17:15 NUM_SUB: 46;----------------------------
2022-11-28 04:17:15 Epoch [01000/30000] Loss:0.018620 Loss_1:0.013323 Loss_2:0.001472 Loss_3:0.000000 Lr:0.000909 Time:18.901253s (0.32min in total, 9.14min remains)
2022-11-28 04:17:34 NUM_SUB: 46;----------------------------
2022-11-28 04:17:34 Epoch [02000/30000] Loss:0.013573 Loss_1:0.012736 Loss_2:0.000393 Loss_3:0.000000 Lr:0.000833 Time:18.973180s (0.63min in total, 8.84min remains)
2022-11-28 04:17:53 NUM_SUB: 46;----------------------------
2022-11-28 04:17:53 Epoch [03000/30000] Loss:0.011946 Loss_1:0.011759 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000769 Time:18.878097s (0.95min in total, 8.51min remains)
2022-11-28 04:18:12 NUM_SUB: 46;----------------------------
2022-11-28 04:18:12 Epoch [04000/30000] Loss:0.010461 Loss_1:0.010383 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000714 Time:19.176043s (1.27min in total, 8.23min remains)
2022-11-28 04:18:31 NUM_SUB: 46;----------------------------
2022-11-28 04:18:31 Epoch [05000/30000] Loss:0.009050 Loss_1:0.008962 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000667 Time:19.317295s (1.59min in total, 7.94min remains)
2022-11-28 04:18:50 NUM_SUB: 46;----------------------------
2022-11-28 04:18:50 Epoch [06000/30000] Loss:0.007355 Loss_1:0.007273 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000625 Time:19.178554s (1.91min in total, 7.63min remains)
2022-11-28 04:19:09 NUM_SUB: 46;----------------------------
2022-11-28 04:19:09 Epoch [07000/30000] Loss:0.005706 Loss_1:0.005640 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000588 Time:18.949886s (2.22min in total, 7.30min remains)
2022-11-28 04:19:29 NUM_SUB: 46;----------------------------
2022-11-28 04:19:29 Epoch [08000/30000] Loss:0.004450 Loss_1:0.004396 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000556 Time:19.112187s (2.54min in total, 6.99min remains)
2022-11-28 04:19:47 NUM_SUB: 46;----------------------------
2022-11-28 04:19:47 Epoch [09000/30000] Loss:0.003861 Loss_1:0.003818 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000526 Time:18.939978s (2.86min in total, 6.67min remains)
2022-11-28 04:20:06 NUM_SUB: 46;----------------------------
2022-11-28 04:20:06 Epoch [10000/30000] Loss:0.003596 Loss_1:0.003560 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000500 Time:18.894426s (3.17min in total, 6.34min remains)
2022-11-28 04:20:25 NUM_SUB: 46;----------------------------
2022-11-28 04:20:25 Epoch [11000/30000] Loss:0.003391 Loss_1:0.003361 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000476 Time:19.002761s (3.49min in total, 6.03min remains)
2022-11-28 04:20:44 NUM_SUB: 46;----------------------------
2022-11-28 04:20:44 Epoch [12000/30000] Loss:0.003194 Loss_1:0.003169 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000455 Time:18.937368s (3.80min in total, 5.71min remains)
2022-11-28 04:21:03 NUM_SUB: 46;----------------------------
2022-11-28 04:21:03 Epoch [13000/30000] Loss:0.003000 Loss_1:0.002982 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000435 Time:19.098752s (4.12min in total, 5.39min remains)
2022-11-28 04:21:23 NUM_SUB: 46;----------------------------
2022-11-28 04:21:23 Epoch [14000/30000] Loss:0.002853 Loss_1:0.002840 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000417 Time:19.332263s (4.45min in total, 5.08min remains)
2022-11-28 04:21:42 NUM_SUB: 46;----------------------------
2022-11-28 04:21:42 Epoch [15000/30000] Loss:0.002822 Loss_1:0.002809 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000400 Time:19.016748s (4.76min in total, 4.76min remains)
2022-11-28 04:22:01 NUM_SUB: 46;----------------------------
2022-11-28 04:22:01 Epoch [16000/30000] Loss:0.002795 Loss_1:0.002787 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000385 Time:18.927015s (5.08min in total, 4.44min remains)
2022-11-28 04:22:20 NUM_SUB: 46;----------------------------
2022-11-28 04:22:20 Epoch [17000/30000] Loss:0.002794 Loss_1:0.002785 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:19.155042s (5.40min in total, 4.13min remains)
2022-11-28 04:22:39 NUM_SUB: 46;----------------------------
2022-11-28 04:22:39 Epoch [18000/30000] Loss:0.002790 Loss_1:0.002786 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:19.037129s (5.71min in total, 3.81min remains)
2022-11-28 04:22:58 NUM_SUB: 46;----------------------------
2022-11-28 04:22:58 Epoch [19000/30000] Loss:0.002787 Loss_1:0.002783 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:18.993420s (6.03min in total, 3.49min remains)
2022-11-28 04:23:17 NUM_SUB: 46;----------------------------
2022-11-28 04:23:17 Epoch [20000/30000] Loss:0.002783 Loss_1:0.002780 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.094765s (6.35min in total, 3.17min remains)
2022-11-28 04:23:36 NUM_SUB: 46;----------------------------
2022-11-28 04:23:36 Epoch [21000/30000] Loss:0.002782 Loss_1:0.002780 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.230641s (6.67min in total, 2.86min remains)
2022-11-28 04:23:55 NUM_SUB: 46;----------------------------
2022-11-28 04:23:55 Epoch [22000/30000] Loss:0.002781 Loss_1:0.002779 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:18.965093s (6.99min in total, 2.54min remains)
2022-11-28 04:24:14 NUM_SUB: 46;----------------------------
2022-11-28 04:24:14 Epoch [23000/30000] Loss:0.002781 Loss_1:0.002778 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.218110s (7.31min in total, 2.22min remains)
2022-11-28 04:24:33 NUM_SUB: 46;----------------------------
2022-11-28 04:24:33 Epoch [24000/30000] Loss:0.002781 Loss_1:0.002779 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:18.923563s (7.62min in total, 1.91min remains)
2022-11-28 04:24:52 NUM_SUB: 46;----------------------------
2022-11-28 04:24:52 Epoch [25000/30000] Loss:0.002781 Loss_1:0.002777 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:18.931401s (7.94min in total, 1.59min remains)
2022-11-28 04:25:11 NUM_SUB: 46;----------------------------
2022-11-28 04:25:11 Epoch [26000/30000] Loss:0.002853 Loss_1:0.002852 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.028155s (8.25min in total, 1.27min remains)
2022-11-28 04:25:30 NUM_SUB: 46;----------------------------
2022-11-28 04:25:30 Epoch [27000/30000] Loss:0.002781 Loss_1:0.002779 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:18.778339s (8.57min in total, 0.95min remains)
2022-11-28 04:25:49 NUM_SUB: 46;----------------------------
2022-11-28 04:25:49 Epoch [28000/30000] Loss:0.002781 Loss_1:0.002779 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.083629s (8.89min in total, 0.63min remains)
2022-11-28 04:26:08 NUM_SUB: 46;----------------------------
2022-11-28 04:26:08 Epoch [29000/30000] Loss:0.002781 Loss_1:0.002780 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.054278s (9.20min in total, 0.32min remains)
2022-11-28 04:26:28 NUM_SUB: 46;----------------------------
2022-11-28 04:26:28 Epoch [30000/30000] Loss:0.002781 Loss_1:0.002780 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.571879s (9.53min in total, 0.00min remains)
2022-11-28 04:26:28 Testing & drawing...
2022-11-28 04:26:28 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:26:29 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=46/
2022-11-28 04:26:29 [Loss]
2022-11-28 04:26:29 NUM_SUB: 46; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:26:29 NUM_SUB: 46; Personalized parameter estimation: Parameter containing:
tensor([0.3120, 0.9605, 0.0098, 0.1586, 0.3074, 0.0350, 0.7920, 0.8964, 0.4556,
        0.0112, 0.3026, 0.1922, 0.3707, 0.1689, 0.0177, 0.7234, 0.6977, 0.8000,
        0.0122, 3.5851, 0.6816, 0.0223, 3.1053, 0.8742, 0.0215, 3.9972, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:26:29 NUM_SUB: 46------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:26:29 Testing & drawing...
2022-11-28 04:26:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:26:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=46/
2022-11-28 04:26:31 [Loss]
2022-11-28 04:26:31 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:26:31 General parameter estimation: Parameter containing:
tensor([0.3120, 0.9605, 0.0098, 0.1586, 0.3074, 0.0350, 0.7920, 0.8964, 0.4556,
        0.0112, 0.3026, 0.1922, 0.3707, 0.1689, 0.0177, 0.7234, 0.6977, 0.8000,
        0.0122, 3.5851, 0.6816, 0.0223, 3.1053, 0.8742, 0.0215, 3.9972, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:26:31 A: prod, degr, TonA, NonA
2022-11-28 04:26:31 [0.47818205 0.49988475 0.01207208 0.00986113]
2022-11-28 04:26:31 T: prod, degr, AonT, NonT
2022-11-28 04:26:31 [0.05550969 0.51106447 0.41472098 0.01870491]
2022-11-28 04:26:31 N: AonN, TonN, ATonN
2022-11-28 04:26:31 [0.00606794 0.9775599  0.01637211]
2022-11-28 04:26:31 using cpu
2022-11-28 04:26:31 epoch = 30000
2022-11-28 04:26:31 epoch_step = 1000
2022-11-28 04:26:31 model_name = SimpleNetworkAD
2022-11-28 04:26:31 now_string = 2022-11-27-19-40-13
2022-11-28 04:26:31 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:26:31 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:26:31 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:26:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:26:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:26:31 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:26:50 NUM_SUB: 47;----------------------------
2022-11-28 04:26:50 Epoch [01000/30000] Loss:0.017036 Loss_1:0.011316 Loss_2:0.001869 Loss_3:0.000000 Lr:0.000909 Time:19.214598s (0.32min in total, 9.29min remains)
2022-11-28 04:27:10 NUM_SUB: 47;----------------------------
2022-11-28 04:27:10 Epoch [02000/30000] Loss:0.012129 Loss_1:0.011111 Loss_2:0.000581 Loss_3:0.000000 Lr:0.000833 Time:19.255327s (0.64min in total, 8.98min remains)
2022-11-28 04:27:29 NUM_SUB: 47;----------------------------
2022-11-28 04:27:29 Epoch [03000/30000] Loss:0.010876 Loss_1:0.010622 Loss_2:0.000177 Loss_3:0.000000 Lr:0.000769 Time:18.935368s (0.96min in total, 8.61min remains)
2022-11-28 04:27:48 NUM_SUB: 47;----------------------------
2022-11-28 04:27:48 Epoch [04000/30000] Loss:0.010055 Loss_1:0.009905 Loss_2:0.000103 Loss_3:0.000000 Lr:0.000714 Time:19.232021s (1.28min in total, 8.30min remains)
2022-11-28 04:28:07 NUM_SUB: 47;----------------------------
2022-11-28 04:28:07 Epoch [05000/30000] Loss:0.009116 Loss_1:0.008966 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000667 Time:18.843115s (1.59min in total, 7.96min remains)
2022-11-28 04:28:26 NUM_SUB: 47;----------------------------
2022-11-28 04:28:26 Epoch [06000/30000] Loss:0.007899 Loss_1:0.007762 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000625 Time:19.157144s (1.91min in total, 7.64min remains)
2022-11-28 04:28:45 NUM_SUB: 47;----------------------------
2022-11-28 04:28:45 Epoch [07000/30000] Loss:0.006468 Loss_1:0.006343 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000588 Time:19.071432s (2.23min in total, 7.32min remains)
2022-11-28 04:29:04 NUM_SUB: 47;----------------------------
2022-11-28 04:29:04 Epoch [08000/30000] Loss:0.004868 Loss_1:0.004759 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000556 Time:18.901798s (2.54min in total, 6.99min remains)
2022-11-28 04:29:23 NUM_SUB: 47;----------------------------
2022-11-28 04:29:23 Epoch [09000/30000] Loss:0.003424 Loss_1:0.003326 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000526 Time:19.043385s (2.86min in total, 6.68min remains)
2022-11-28 04:29:42 NUM_SUB: 47;----------------------------
2022-11-28 04:29:42 Epoch [10000/30000] Loss:0.002509 Loss_1:0.002427 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000500 Time:18.915997s (3.18min in total, 6.35min remains)
2022-11-28 04:30:01 NUM_SUB: 47;----------------------------
2022-11-28 04:30:01 Epoch [11000/30000] Loss:0.002227 Loss_1:0.002161 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:19.004348s (3.49min in total, 6.03min remains)
2022-11-28 04:30:20 NUM_SUB: 47;----------------------------
2022-11-28 04:30:20 Epoch [12000/30000] Loss:0.002157 Loss_1:0.002109 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000455 Time:18.968315s (3.81min in total, 5.71min remains)
2022-11-28 04:30:39 NUM_SUB: 47;----------------------------
2022-11-28 04:30:39 Epoch [13000/30000] Loss:0.002093 Loss_1:0.002064 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000435 Time:19.106638s (4.13min in total, 5.40min remains)
2022-11-28 04:30:58 NUM_SUB: 47;----------------------------
2022-11-28 04:30:58 Epoch [14000/30000] Loss:0.002041 Loss_1:0.002022 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:18.991935s (4.44min in total, 5.08min remains)
2022-11-28 04:31:17 NUM_SUB: 47;----------------------------
2022-11-28 04:31:17 Epoch [15000/30000] Loss:0.002009 Loss_1:0.001993 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000400 Time:18.971783s (4.76min in total, 4.76min remains)
2022-11-28 04:31:36 NUM_SUB: 47;----------------------------
2022-11-28 04:31:36 Epoch [16000/30000] Loss:0.001988 Loss_1:0.001976 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:19.330647s (5.08min in total, 4.45min remains)
2022-11-28 04:31:55 NUM_SUB: 47;----------------------------
2022-11-28 04:31:55 Epoch [17000/30000] Loss:0.001975 Loss_1:0.001965 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000370 Time:19.205410s (5.40min in total, 4.13min remains)
2022-11-28 04:32:15 NUM_SUB: 47;----------------------------
2022-11-28 04:32:15 Epoch [18000/30000] Loss:0.001965 Loss_1:0.001957 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:19.349085s (5.73min in total, 3.82min remains)
2022-11-28 04:32:34 NUM_SUB: 47;----------------------------
2022-11-28 04:32:34 Epoch [19000/30000] Loss:0.001956 Loss_1:0.001948 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:19.109481s (6.04min in total, 3.50min remains)
2022-11-28 04:32:53 NUM_SUB: 47;----------------------------
2022-11-28 04:32:53 Epoch [20000/30000] Loss:0.001948 Loss_1:0.001940 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.059784s (6.36min in total, 3.18min remains)
2022-11-28 04:33:12 NUM_SUB: 47;----------------------------
2022-11-28 04:33:12 Epoch [21000/30000] Loss:0.001943 Loss_1:0.001937 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.217670s (6.68min in total, 2.86min remains)
2022-11-28 04:33:32 NUM_SUB: 47;----------------------------
2022-11-28 04:33:32 Epoch [22000/30000] Loss:0.001938 Loss_1:0.001935 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.490486s (7.01min in total, 2.55min remains)
2022-11-28 04:33:51 NUM_SUB: 47;----------------------------
2022-11-28 04:33:51 Epoch [23000/30000] Loss:0.001935 Loss_1:0.001932 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.334141s (7.33min in total, 2.23min remains)
2022-11-28 04:34:10 NUM_SUB: 47;----------------------------
2022-11-28 04:34:10 Epoch [24000/30000] Loss:0.001933 Loss_1:0.001931 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.170434s (7.65min in total, 1.91min remains)
2022-11-28 04:34:29 NUM_SUB: 47;----------------------------
2022-11-28 04:34:29 Epoch [25000/30000] Loss:0.001932 Loss_1:0.001930 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.941249s (7.96min in total, 1.59min remains)
2022-11-28 04:34:48 NUM_SUB: 47;----------------------------
2022-11-28 04:34:48 Epoch [26000/30000] Loss:0.001930 Loss_1:0.001929 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.100885s (8.28min in total, 1.27min remains)
2022-11-28 04:35:07 NUM_SUB: 47;----------------------------
2022-11-28 04:35:07 Epoch [27000/30000] Loss:0.001929 Loss_1:0.001928 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.924626s (8.60min in total, 0.96min remains)
2022-11-28 04:35:26 NUM_SUB: 47;----------------------------
2022-11-28 04:35:26 Epoch [28000/30000] Loss:0.001928 Loss_1:0.001927 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.141416s (8.92min in total, 0.64min remains)
2022-11-28 04:35:45 NUM_SUB: 47;----------------------------
2022-11-28 04:35:45 Epoch [29000/30000] Loss:0.001928 Loss_1:0.001927 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.895295s (9.23min in total, 0.32min remains)
2022-11-28 04:36:04 NUM_SUB: 47;----------------------------
2022-11-28 04:36:04 Epoch [30000/30000] Loss:0.001927 Loss_1:0.001926 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.717056s (9.54min in total, 0.00min remains)
2022-11-28 04:36:04 Testing & drawing...
2022-11-28 04:36:04 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:36:05 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=47/
2022-11-28 04:36:05 [Loss]
2022-11-28 04:36:05 NUM_SUB: 47; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:36:05 NUM_SUB: 47; Personalized parameter estimation: Parameter containing:
tensor([0.4361, 0.7467, 0.0277, 0.3214, 0.3074, 0.0050, 0.7266, 0.8964, 0.4556,
        0.0133, 0.0349, 0.0120, 0.7472, 0.1689, 0.0177, 1.4142, 0.6977, 0.8000,
        0.0112, 4.5235, 0.6816, 0.0222, 3.6587, 0.8742, 0.0194, 4.6358, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:36:05 NUM_SUB: 47------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:36:05 Testing & drawing...
2022-11-28 04:36:05 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:36:07 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=47/
2022-11-28 04:36:07 [Loss]
2022-11-28 04:36:07 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:36:07 General parameter estimation: Parameter containing:
tensor([0.4361, 0.7467, 0.0277, 0.3214, 0.3074, 0.0050, 0.7266, 0.8964, 0.4556,
        0.0133, 0.0349, 0.0120, 0.7472, 0.1689, 0.0177, 1.4142, 0.6977, 0.8000,
        0.0112, 4.5235, 0.6816, 0.0222, 3.6587, 0.8742, 0.0194, 4.6358, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:36:07 A: prod, degr, TonA, NonA
2022-11-28 04:36:07 [0.4782011  0.4998545  0.02115291 0.00079152]
2022-11-28 04:36:07 T: prod, degr, AonT, NonT
2022-11-28 04:36:07 [0.34111407 0.54711455 0.09220371 0.01956766]
2022-11-28 04:36:07 N: AonN, TonN, ATonN
2022-11-28 04:36:07 [0.00973301 0.96409255 0.02617449]
2022-11-28 04:36:07 using cpu
2022-11-28 04:36:07 epoch = 30000
2022-11-28 04:36:07 epoch_step = 1000
2022-11-28 04:36:07 model_name = SimpleNetworkAD
2022-11-28 04:36:07 now_string = 2022-11-27-19-40-13
2022-11-28 04:36:07 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:36:07 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:36:07 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:36:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:36:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:36:07 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:36:26 NUM_SUB: 48;----------------------------
2022-11-28 04:36:26 Epoch [01000/30000] Loss:0.070223 Loss_1:0.064740 Loss_2:0.001696 Loss_3:0.000000 Lr:0.000909 Time:19.150538s (0.32min in total, 9.26min remains)
2022-11-28 04:36:45 NUM_SUB: 48;----------------------------
2022-11-28 04:36:45 Epoch [02000/30000] Loss:0.060297 Loss_1:0.059386 Loss_2:0.000507 Loss_3:0.000000 Lr:0.000833 Time:18.657913s (0.63min in total, 8.82min remains)
2022-11-28 04:37:04 NUM_SUB: 48;----------------------------
2022-11-28 04:37:04 Epoch [03000/30000] Loss:0.052570 Loss_1:0.052096 Loss_2:0.000156 Loss_3:0.000000 Lr:0.000769 Time:19.151772s (0.95min in total, 8.54min remains)
2022-11-28 04:37:23 NUM_SUB: 48;----------------------------
2022-11-28 04:37:23 Epoch [04000/30000] Loss:0.043368 Loss_1:0.042997 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000714 Time:19.078548s (1.27min in total, 8.24min remains)
2022-11-28 04:37:42 NUM_SUB: 48;----------------------------
2022-11-28 04:37:42 Epoch [05000/30000] Loss:0.031194 Loss_1:0.030883 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000667 Time:18.951495s (1.58min in total, 7.92min remains)
2022-11-28 04:38:01 NUM_SUB: 48;----------------------------
2022-11-28 04:38:01 Epoch [06000/30000] Loss:0.017567 Loss_1:0.017337 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000625 Time:18.609405s (1.89min in total, 7.57min remains)
2022-11-28 04:38:20 NUM_SUB: 48;----------------------------
2022-11-28 04:38:20 Epoch [07000/30000] Loss:0.007829 Loss_1:0.007656 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000588 Time:18.950523s (2.21min in total, 7.26min remains)
2022-11-28 04:38:39 NUM_SUB: 48;----------------------------
2022-11-28 04:38:39 Epoch [08000/30000] Loss:0.004294 Loss_1:0.004180 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000556 Time:18.921058s (2.52min in total, 6.94min remains)
2022-11-28 04:38:57 NUM_SUB: 48;----------------------------
2022-11-28 04:38:57 Epoch [09000/30000] Loss:0.003045 Loss_1:0.002946 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000526 Time:18.779831s (2.84min in total, 6.62min remains)
2022-11-28 04:39:17 NUM_SUB: 48;----------------------------
2022-11-28 04:39:17 Epoch [10000/30000] Loss:0.002360 Loss_1:0.002260 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000500 Time:19.052991s (3.16min in total, 6.31min remains)
2022-11-28 04:39:36 NUM_SUB: 48;----------------------------
2022-11-28 04:39:36 Epoch [11000/30000] Loss:0.001872 Loss_1:0.001786 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000476 Time:19.196716s (3.48min in total, 6.00min remains)
2022-11-28 04:39:55 NUM_SUB: 48;----------------------------
2022-11-28 04:39:55 Epoch [12000/30000] Loss:0.001332 Loss_1:0.001281 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:19.245226s (3.80min in total, 5.69min remains)
2022-11-28 04:40:14 NUM_SUB: 48;----------------------------
2022-11-28 04:40:14 Epoch [13000/30000] Loss:0.000897 Loss_1:0.000853 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000435 Time:18.926294s (4.11min in total, 5.38min remains)
2022-11-28 04:40:33 NUM_SUB: 48;----------------------------
2022-11-28 04:40:33 Epoch [14000/30000] Loss:0.000687 Loss_1:0.000656 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:18.965269s (4.43min in total, 5.06min remains)
2022-11-28 04:40:52 NUM_SUB: 48;----------------------------
2022-11-28 04:40:52 Epoch [15000/30000] Loss:0.000653 Loss_1:0.000628 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000400 Time:18.658875s (4.74min in total, 4.74min remains)
2022-11-28 04:41:11 NUM_SUB: 48;----------------------------
2022-11-28 04:41:11 Epoch [16000/30000] Loss:0.000642 Loss_1:0.000622 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:19.029666s (5.06min in total, 4.42min remains)
2022-11-28 04:41:29 NUM_SUB: 48;----------------------------
2022-11-28 04:41:29 Epoch [17000/30000] Loss:0.000635 Loss_1:0.000621 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000370 Time:18.768165s (5.37min in total, 4.11min remains)
2022-11-28 04:41:48 NUM_SUB: 48;----------------------------
2022-11-28 04:41:48 Epoch [18000/30000] Loss:0.000629 Loss_1:0.000617 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:18.906148s (5.68min in total, 3.79min remains)
2022-11-28 04:42:07 NUM_SUB: 48;----------------------------
2022-11-28 04:42:07 Epoch [19000/30000] Loss:0.000624 Loss_1:0.000614 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000345 Time:18.850221s (6.00min in total, 3.47min remains)
2022-11-28 04:42:26 NUM_SUB: 48;----------------------------
2022-11-28 04:42:26 Epoch [20000/30000] Loss:0.000624 Loss_1:0.000616 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:19.215689s (6.32min in total, 3.16min remains)
2022-11-28 04:42:45 NUM_SUB: 48;----------------------------
2022-11-28 04:42:45 Epoch [21000/30000] Loss:0.000620 Loss_1:0.000614 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:18.838899s (6.63min in total, 2.84min remains)
2022-11-28 04:43:04 NUM_SUB: 48;----------------------------
2022-11-28 04:43:04 Epoch [22000/30000] Loss:0.000614 Loss_1:0.000610 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:18.648659s (6.94min in total, 2.52min remains)
2022-11-28 04:43:23 NUM_SUB: 48;----------------------------
2022-11-28 04:43:23 Epoch [23000/30000] Loss:0.000614 Loss_1:0.000610 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.096542s (7.26min in total, 2.21min remains)
2022-11-28 04:43:42 NUM_SUB: 48;----------------------------
2022-11-28 04:43:42 Epoch [24000/30000] Loss:0.000614 Loss_1:0.000611 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.728452s (7.57min in total, 1.89min remains)
2022-11-28 04:44:01 NUM_SUB: 48;----------------------------
2022-11-28 04:44:01 Epoch [25000/30000] Loss:0.000618 Loss_1:0.000616 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.272311s (7.89min in total, 1.58min remains)
2022-11-28 04:44:20 NUM_SUB: 48;----------------------------
2022-11-28 04:44:20 Epoch [26000/30000] Loss:0.000615 Loss_1:0.000608 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.007024s (8.21min in total, 1.26min remains)
2022-11-28 04:44:39 NUM_SUB: 48;----------------------------
2022-11-28 04:44:39 Epoch [27000/30000] Loss:0.000628 Loss_1:0.000610 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.683444s (8.52min in total, 0.95min remains)
2022-11-28 04:44:58 NUM_SUB: 48;----------------------------
2022-11-28 04:44:58 Epoch [28000/30000] Loss:0.000611 Loss_1:0.000610 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.241205s (8.84min in total, 0.63min remains)
2022-11-28 04:45:17 NUM_SUB: 48;----------------------------
2022-11-28 04:45:17 Epoch [29000/30000] Loss:0.000611 Loss_1:0.000610 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.858982s (9.16min in total, 0.32min remains)
2022-11-28 04:45:35 NUM_SUB: 48;----------------------------
2022-11-28 04:45:35 Epoch [30000/30000] Loss:0.000613 Loss_1:0.000612 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.828223s (9.47min in total, 0.00min remains)
2022-11-28 04:45:36 Testing & drawing...
2022-11-28 04:45:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:45:37 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=48/
2022-11-28 04:45:37 [Loss]
2022-11-28 04:45:37 NUM_SUB: 48; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:45:37 NUM_SUB: 48; Personalized parameter estimation: Parameter containing:
tensor([0.0128, 0.1718, 0.0082, 0.4384, 0.3074, 0.3118, 1.0940, 0.8964, 0.4556,
        0.0139, 0.0357, 0.0122, 0.7624, 0.1689, 0.0174, 2.9505, 0.6977, 0.8000,
        0.0115, 4.2924, 0.6816, 0.0222, 3.7370, 0.8742, 0.0203, 4.6124, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:45:37 NUM_SUB: 48------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:45:37 Testing & drawing...
2022-11-28 04:45:37 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:45:39 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=48/
2022-11-28 04:45:39 [Loss]
2022-11-28 04:45:39 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:45:39 General parameter estimation: Parameter containing:
tensor([0.0128, 0.1718, 0.0082, 0.4384, 0.3074, 0.3118, 1.0940, 0.8964, 0.4556,
        0.0139, 0.0357, 0.0122, 0.7624, 0.1689, 0.0174, 2.9505, 0.6977, 0.8000,
        0.0115, 4.2924, 0.6816, 0.0222, 3.7370, 0.8742, 0.0203, 4.6124, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:45:39 A: prod, degr, TonA, NonA
2022-11-28 04:45:39 [0.07484524 0.49830544 0.02557375 0.40127555]
2022-11-28 04:45:39 T: prod, degr, AonT, NonT
2022-11-28 04:45:39 [0.38984212 0.49651143 0.09544734 0.01819907]
2022-11-28 04:45:39 N: AonN, TonN, ATonN
2022-11-28 04:45:39 [0.00752675 0.9705806  0.02189271]
2022-11-28 04:45:39 using cpu
2022-11-28 04:45:39 epoch = 30000
2022-11-28 04:45:39 epoch_step = 1000
2022-11-28 04:45:39 model_name = SimpleNetworkAD
2022-11-28 04:45:39 now_string = 2022-11-27-19-40-13
2022-11-28 04:45:39 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:45:39 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:45:39 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:45:39 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:45:39 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:45:39 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:45:58 NUM_SUB: 49;----------------------------
2022-11-28 04:45:58 Epoch [01000/30000] Loss:0.048153 Loss_1:0.042723 Loss_2:0.001698 Loss_3:0.000000 Lr:0.000909 Time:19.340882s (0.32min in total, 9.35min remains)
2022-11-28 04:46:17 NUM_SUB: 49;----------------------------
2022-11-28 04:46:17 Epoch [02000/30000] Loss:0.041473 Loss_1:0.040509 Loss_2:0.000590 Loss_3:0.000000 Lr:0.000833 Time:19.164931s (0.64min in total, 8.98min remains)
2022-11-28 04:46:36 NUM_SUB: 49;----------------------------
2022-11-28 04:46:36 Epoch [03000/30000] Loss:0.037323 Loss_1:0.036908 Loss_2:0.000367 Loss_3:0.000000 Lr:0.000769 Time:18.970705s (0.96min in total, 8.62min remains)
2022-11-28 04:46:56 NUM_SUB: 49;----------------------------
2022-11-28 04:46:56 Epoch [04000/30000] Loss:0.032071 Loss_1:0.031428 Loss_2:0.000591 Loss_3:0.000000 Lr:0.000714 Time:19.252758s (1.28min in total, 8.31min remains)
2022-11-28 04:47:16 NUM_SUB: 49;----------------------------
2022-11-28 04:47:16 Epoch [05000/30000] Loss:0.024745 Loss_1:0.024273 Loss_2:0.000401 Loss_3:0.000000 Lr:0.000667 Time:20.037571s (1.61min in total, 8.06min remains)
2022-11-28 04:47:35 NUM_SUB: 49;----------------------------
2022-11-28 04:47:35 Epoch [06000/30000] Loss:0.017632 Loss_1:0.017398 Loss_2:0.000177 Loss_3:0.000000 Lr:0.000625 Time:19.463634s (1.94min in total, 7.75min remains)
2022-11-28 04:47:54 NUM_SUB: 49;----------------------------
2022-11-28 04:47:54 Epoch [07000/30000] Loss:0.011300 Loss_1:0.011120 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000588 Time:19.244712s (2.26min in total, 7.42min remains)
2022-11-28 04:48:13 NUM_SUB: 49;----------------------------
2022-11-28 04:48:13 Epoch [08000/30000] Loss:0.007132 Loss_1:0.006978 Loss_2:0.000135 Loss_3:0.000000 Lr:0.000556 Time:19.031090s (2.58min in total, 7.08min remains)
2022-11-28 04:48:32 NUM_SUB: 49;----------------------------
2022-11-28 04:48:32 Epoch [09000/30000] Loss:0.004955 Loss_1:0.004809 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000526 Time:19.019206s (2.89min in total, 6.75min remains)
2022-11-28 04:48:52 NUM_SUB: 49;----------------------------
2022-11-28 04:48:52 Epoch [10000/30000] Loss:0.004117 Loss_1:0.003801 Loss_2:0.000130 Loss_3:0.000000 Lr:0.000500 Time:19.624643s (3.22min in total, 6.44min remains)
2022-11-28 04:49:12 NUM_SUB: 49;----------------------------
2022-11-28 04:49:12 Epoch [11000/30000] Loss:0.003533 Loss_1:0.003424 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000476 Time:19.506754s (3.54min in total, 6.12min remains)
2022-11-28 04:49:31 NUM_SUB: 49;----------------------------
2022-11-28 04:49:31 Epoch [12000/30000] Loss:0.003254 Loss_1:0.003192 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000455 Time:19.285131s (3.87min in total, 5.80min remains)
2022-11-28 04:49:50 NUM_SUB: 49;----------------------------
2022-11-28 04:49:50 Epoch [13000/30000] Loss:0.003211 Loss_1:0.003156 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000435 Time:19.016784s (4.18min in total, 5.47min remains)
2022-11-28 04:50:10 NUM_SUB: 49;----------------------------
2022-11-28 04:50:10 Epoch [14000/30000] Loss:0.003148 Loss_1:0.003107 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000417 Time:19.864355s (4.51min in total, 5.16min remains)
2022-11-28 04:50:29 NUM_SUB: 49;----------------------------
2022-11-28 04:50:29 Epoch [15000/30000] Loss:0.003142 Loss_1:0.003110 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000400 Time:19.567288s (4.84min in total, 4.84min remains)
2022-11-28 04:50:49 NUM_SUB: 49;----------------------------
2022-11-28 04:50:49 Epoch [16000/30000] Loss:0.003133 Loss_1:0.003099 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000385 Time:19.684713s (5.17min in total, 4.52min remains)
2022-11-28 04:51:09 NUM_SUB: 49;----------------------------
2022-11-28 04:51:09 Epoch [17000/30000] Loss:0.003125 Loss_1:0.003091 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000370 Time:19.746092s (5.50min in total, 4.20min remains)
2022-11-28 04:51:28 NUM_SUB: 49;----------------------------
2022-11-28 04:51:28 Epoch [18000/30000] Loss:0.003121 Loss_1:0.003099 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000357 Time:19.265311s (5.82min in total, 3.88min remains)
2022-11-28 04:51:47 NUM_SUB: 49;----------------------------
2022-11-28 04:51:47 Epoch [19000/30000] Loss:0.003107 Loss_1:0.003085 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000345 Time:19.153647s (6.14min in total, 3.55min remains)
2022-11-28 04:52:06 NUM_SUB: 49;----------------------------
2022-11-28 04:52:06 Epoch [20000/30000] Loss:0.003098 Loss_1:0.003078 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000333 Time:19.143643s (6.46min in total, 3.23min remains)
2022-11-28 04:52:25 NUM_SUB: 49;----------------------------
2022-11-28 04:52:25 Epoch [21000/30000] Loss:0.003087 Loss_1:0.003069 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000323 Time:19.163035s (6.78min in total, 2.90min remains)
2022-11-28 04:52:44 NUM_SUB: 49;----------------------------
2022-11-28 04:52:44 Epoch [22000/30000] Loss:0.003078 Loss_1:0.003061 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000313 Time:18.982333s (7.09min in total, 2.58min remains)
2022-11-28 04:53:04 NUM_SUB: 49;----------------------------
2022-11-28 04:53:04 Epoch [23000/30000] Loss:0.003074 Loss_1:0.003058 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000303 Time:19.156332s (7.41min in total, 2.26min remains)
2022-11-28 04:53:23 NUM_SUB: 49;----------------------------
2022-11-28 04:53:23 Epoch [24000/30000] Loss:0.003072 Loss_1:0.003057 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000294 Time:19.090436s (7.73min in total, 1.93min remains)
2022-11-28 04:53:42 NUM_SUB: 49;----------------------------
2022-11-28 04:53:42 Epoch [25000/30000] Loss:0.003072 Loss_1:0.003057 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000286 Time:18.983052s (8.05min in total, 1.61min remains)
2022-11-28 04:54:01 NUM_SUB: 49;----------------------------
2022-11-28 04:54:01 Epoch [26000/30000] Loss:0.003071 Loss_1:0.003057 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000278 Time:19.656685s (8.37min in total, 1.29min remains)
2022-11-28 04:54:21 NUM_SUB: 49;----------------------------
2022-11-28 04:54:21 Epoch [27000/30000] Loss:0.003070 Loss_1:0.003056 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000270 Time:19.198216s (8.69min in total, 0.97min remains)
2022-11-28 04:54:40 NUM_SUB: 49;----------------------------
2022-11-28 04:54:40 Epoch [28000/30000] Loss:0.003068 Loss_1:0.003055 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000263 Time:19.490797s (9.02min in total, 0.64min remains)
2022-11-28 04:54:59 NUM_SUB: 49;----------------------------
2022-11-28 04:54:59 Epoch [29000/30000] Loss:0.003067 Loss_1:0.003055 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000256 Time:19.150588s (9.34min in total, 0.32min remains)
2022-11-28 04:55:19 NUM_SUB: 49;----------------------------
2022-11-28 04:55:19 Epoch [30000/30000] Loss:0.003066 Loss_1:0.003055 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000250 Time:19.451650s (9.66min in total, 0.00min remains)
2022-11-28 04:55:19 Testing & drawing...
2022-11-28 04:55:19 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:55:20 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=49/
2022-11-28 04:55:20 [Loss]
2022-11-28 04:55:20 NUM_SUB: 49; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:55:20 NUM_SUB: 49; Personalized parameter estimation: Parameter containing:
tensor([0.0150, 0.0266, 0.0099, 3.1603, 0.3074, 0.0188, 2.0350, 0.8964, 0.4556,
        0.0143, 0.0434, 0.0134, 0.7617, 0.1689, 0.0185, 0.9071, 0.6977, 0.8000,
        0.0120, 3.8967, 0.6816, 0.0228, 2.9416, 0.8742, 0.0211, 4.0289, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:55:20 NUM_SUB: 49------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 04:55:20 Testing & drawing...
2022-11-28 04:55:20 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 04:55:22 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=49/
2022-11-28 04:55:22 [Loss]
2022-11-28 04:55:22 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 04:55:22 General parameter estimation: Parameter containing:
tensor([0.0150, 0.0266, 0.0099, 3.1603, 0.3074, 0.0188, 2.0350, 0.8964, 0.4556,
        0.0143, 0.0434, 0.0134, 0.7617, 0.1689, 0.0185, 0.9071, 0.6977, 0.8000,
        0.0120, 3.8967, 0.6816, 0.0228, 2.9416, 0.8742, 0.0211, 4.0289, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 04:55:22 A: prod, degr, TonA, NonA
2022-11-28 04:55:22 [0.49012858 0.45355594 0.0087126  0.04760285]
2022-11-28 04:55:22 T: prod, degr, AonT, NonT
2022-11-28 04:55:22 [0.30818188 0.4855516  0.0909646  0.11530191]
2022-11-28 04:55:22 N: AonN, TonN, ATonN
2022-11-28 04:55:22 [0.0110819  0.95476955 0.03414856]
2022-11-28 04:55:22 using cpu
2022-11-28 04:55:22 epoch = 30000
2022-11-28 04:55:22 epoch_step = 1000
2022-11-28 04:55:22 model_name = SimpleNetworkAD
2022-11-28 04:55:22 now_string = 2022-11-27-19-40-13
2022-11-28 04:55:22 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 04:55:22 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 04:55:22 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 04:55:22 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 04:55:22 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 04:55:22 --------------------------------------------------training start--------------------------------------------------
2022-11-28 04:55:41 NUM_SUB: 50;----------------------------
2022-11-28 04:55:41 Epoch [01000/30000] Loss:0.053548 Loss_1:0.048280 Loss_2:0.001527 Loss_3:0.000000 Lr:0.000909 Time:18.982508s (0.32min in total, 9.17min remains)
2022-11-28 04:56:01 NUM_SUB: 50;----------------------------
2022-11-28 04:56:01 Epoch [02000/30000] Loss:0.046816 Loss_1:0.046018 Loss_2:0.000417 Loss_3:0.000000 Lr:0.000833 Time:19.289270s (0.64min in total, 8.93min remains)
2022-11-28 04:56:20 NUM_SUB: 50;----------------------------
2022-11-28 04:56:20 Epoch [03000/30000] Loss:0.042759 Loss_1:0.042560 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000769 Time:19.074143s (0.96min in total, 8.60min remains)
2022-11-28 04:56:39 NUM_SUB: 50;----------------------------
2022-11-28 04:56:39 Epoch [04000/30000] Loss:0.038679 Loss_1:0.038477 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000714 Time:19.504022s (1.28min in total, 8.33min remains)
2022-11-28 04:56:58 NUM_SUB: 50;----------------------------
2022-11-28 04:56:58 Epoch [05000/30000] Loss:0.032999 Loss_1:0.032816 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000667 Time:19.331972s (1.60min in total, 8.02min remains)
2022-11-28 04:57:18 NUM_SUB: 50;----------------------------
2022-11-28 04:57:18 Epoch [06000/30000] Loss:0.025272 Loss_1:0.025121 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000625 Time:19.522630s (1.93min in total, 7.71min remains)
2022-11-28 04:57:38 NUM_SUB: 50;----------------------------
2022-11-28 04:57:38 Epoch [07000/30000] Loss:0.016293 Loss_1:0.016172 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000588 Time:19.546356s (2.25min in total, 7.41min remains)
2022-11-28 04:57:57 NUM_SUB: 50;----------------------------
2022-11-28 04:57:57 Epoch [08000/30000] Loss:0.009286 Loss_1:0.009200 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000556 Time:19.154715s (2.57min in total, 7.08min remains)
2022-11-28 04:58:16 NUM_SUB: 50;----------------------------
2022-11-28 04:58:16 Epoch [09000/30000] Loss:0.006426 Loss_1:0.006347 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000526 Time:19.131527s (2.89min in total, 6.75min remains)
2022-11-28 04:58:35 NUM_SUB: 50;----------------------------
2022-11-28 04:58:35 Epoch [10000/30000] Loss:0.005363 Loss_1:0.005268 Loss_2:0.000095 Loss_3:0.000000 Lr:0.000500 Time:19.109354s (3.21min in total, 6.42min remains)
2022-11-28 04:58:54 NUM_SUB: 50;----------------------------
2022-11-28 04:58:54 Epoch [11000/30000] Loss:0.004253 Loss_1:0.004189 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:19.043982s (3.53min in total, 6.09min remains)
2022-11-28 04:59:13 NUM_SUB: 50;----------------------------
2022-11-28 04:59:13 Epoch [12000/30000] Loss:0.002817 Loss_1:0.002778 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000455 Time:19.119313s (3.85min in total, 5.77min remains)
2022-11-28 04:59:32 NUM_SUB: 50;----------------------------
2022-11-28 04:59:32 Epoch [13000/30000] Loss:0.001916 Loss_1:0.001883 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000435 Time:18.813458s (4.16min in total, 5.44min remains)
2022-11-28 04:59:51 NUM_SUB: 50;----------------------------
2022-11-28 04:59:51 Epoch [14000/30000] Loss:0.001810 Loss_1:0.001784 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:19.041171s (4.48min in total, 5.12min remains)
2022-11-28 05:00:11 NUM_SUB: 50;----------------------------
2022-11-28 05:00:11 Epoch [15000/30000] Loss:0.001798 Loss_1:0.001779 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:19.614937s (4.80min in total, 4.80min remains)
2022-11-28 05:00:30 NUM_SUB: 50;----------------------------
2022-11-28 05:00:30 Epoch [16000/30000] Loss:0.001790 Loss_1:0.001778 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:19.389708s (5.13min in total, 4.49min remains)
2022-11-28 05:00:49 NUM_SUB: 50;----------------------------
2022-11-28 05:00:49 Epoch [17000/30000] Loss:0.001785 Loss_1:0.001775 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.058936s (5.45min in total, 4.16min remains)
2022-11-28 05:01:08 NUM_SUB: 50;----------------------------
2022-11-28 05:01:08 Epoch [18000/30000] Loss:0.001783 Loss_1:0.001775 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:19.111712s (5.76min in total, 3.84min remains)
2022-11-28 05:01:27 NUM_SUB: 50;----------------------------
2022-11-28 05:01:27 Epoch [19000/30000] Loss:0.001781 Loss_1:0.001776 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.085539s (6.08min in total, 3.52min remains)
2022-11-28 05:01:46 NUM_SUB: 50;----------------------------
2022-11-28 05:01:46 Epoch [20000/30000] Loss:0.001780 Loss_1:0.001775 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:18.959447s (6.40min in total, 3.20min remains)
2022-11-28 05:02:05 NUM_SUB: 50;----------------------------
2022-11-28 05:02:05 Epoch [21000/30000] Loss:0.001779 Loss_1:0.001775 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.135205s (6.72min in total, 2.88min remains)
2022-11-28 05:02:24 NUM_SUB: 50;----------------------------
2022-11-28 05:02:24 Epoch [22000/30000] Loss:0.001779 Loss_1:0.001774 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.950965s (7.03min in total, 2.56min remains)
2022-11-28 05:02:43 NUM_SUB: 50;----------------------------
2022-11-28 05:02:43 Epoch [23000/30000] Loss:0.001778 Loss_1:0.001774 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.025065s (7.35min in total, 2.24min remains)
2022-11-28 05:03:02 NUM_SUB: 50;----------------------------
2022-11-28 05:03:02 Epoch [24000/30000] Loss:0.001778 Loss_1:0.001774 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.879703s (7.66min in total, 1.92min remains)
2022-11-28 05:03:22 NUM_SUB: 50;----------------------------
2022-11-28 05:03:22 Epoch [25000/30000] Loss:0.001777 Loss_1:0.001774 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.420105s (7.99min in total, 1.60min remains)
2022-11-28 05:03:41 NUM_SUB: 50;----------------------------
2022-11-28 05:03:41 Epoch [26000/30000] Loss:0.001777 Loss_1:0.001775 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.550705s (8.31min in total, 1.28min remains)
2022-11-28 05:04:01 NUM_SUB: 50;----------------------------
2022-11-28 05:04:01 Epoch [27000/30000] Loss:0.001777 Loss_1:0.001775 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.412683s (8.64min in total, 0.96min remains)
2022-11-28 05:04:20 NUM_SUB: 50;----------------------------
2022-11-28 05:04:20 Epoch [28000/30000] Loss:0.001777 Loss_1:0.001774 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.478543s (8.96min in total, 0.64min remains)
2022-11-28 05:04:40 NUM_SUB: 50;----------------------------
2022-11-28 05:04:40 Epoch [29000/30000] Loss:0.001776 Loss_1:0.001775 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.468170s (9.29min in total, 0.32min remains)
2022-11-28 05:04:59 NUM_SUB: 50;----------------------------
2022-11-28 05:04:59 Epoch [30000/30000] Loss:0.001776 Loss_1:0.001775 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.403527s (9.61min in total, 0.00min remains)
2022-11-28 05:04:59 Testing & drawing...
2022-11-28 05:04:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:05:01 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=50/
2022-11-28 05:05:01 [Loss]
2022-11-28 05:05:01 NUM_SUB: 50; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:05:01 NUM_SUB: 50; Personalized parameter estimation: Parameter containing:
tensor([3.3783e-01, 9.3770e-01, 9.6233e-03, 1.5331e-36, 3.0742e-01, 1.0943e-03,
        7.9350e-01, 8.9644e-01, 4.5563e-01, 1.4501e-02, 3.0702e-02, 1.3541e-02,
        8.4010e-01, 1.6886e-01, 1.7350e-02, 3.1391e+00, 6.9767e-01, 8.0001e-01,
        1.2478e-02, 3.1564e+00, 6.8161e-01, 2.1502e-02, 3.6244e+00, 8.7416e-01,
        2.1000e-02, 4.2347e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:05:01 NUM_SUB: 50------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:05:01 Testing & drawing...
2022-11-28 05:05:01 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:05:02 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=50/
2022-11-28 05:05:02 [Loss]
2022-11-28 05:05:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:05:02 General parameter estimation: Parameter containing:
tensor([3.3783e-01, 9.3770e-01, 9.6233e-03, 1.5331e-36, 3.0742e-01, 1.0943e-03,
        7.9350e-01, 8.9644e-01, 4.5563e-01, 1.4501e-02, 3.0702e-02, 1.3541e-02,
        8.4010e-01, 1.6886e-01, 1.7350e-02, 3.1391e+00, 6.9767e-01, 8.0001e-01,
        1.2478e-02, 3.1564e+00, 6.8161e-01, 2.1502e-02, 3.6244e+00, 8.7416e-01,
        2.1000e-02, 4.2347e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:05:02 A: prod, degr, TonA, NonA
2022-11-28 05:05:02 [0.48550463 0.499945   0.01382993 0.00072041]
2022-11-28 05:05:02 T: prod, degr, AonT, NonT
2022-11-28 05:05:02 [0.4693084  0.36862117 0.13303076 0.02903966]
2022-11-28 05:05:02 N: AonN, TonN, ATonN
2022-11-28 05:05:02 [0.00849899 0.9653446  0.02615639]
2022-11-28 05:05:03 using cpu
2022-11-28 05:05:03 epoch = 30000
2022-11-28 05:05:03 epoch_step = 1000
2022-11-28 05:05:03 model_name = SimpleNetworkAD
2022-11-28 05:05:03 now_string = 2022-11-27-19-40-13
2022-11-28 05:05:03 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:05:03 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:05:03 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:05:03 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:05:03 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:05:03 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:05:22 NUM_SUB: 51;----------------------------
2022-11-28 05:05:22 Epoch [01000/30000] Loss:0.026894 Loss_1:0.020468 Loss_2:0.002714 Loss_3:0.000000 Lr:0.000909 Time:19.137426s (0.32min in total, 9.25min remains)
2022-11-28 05:05:41 NUM_SUB: 51;----------------------------
2022-11-28 05:05:41 Epoch [02000/30000] Loss:0.020558 Loss_1:0.019009 Loss_2:0.001172 Loss_3:0.000000 Lr:0.000833 Time:19.573389s (0.65min in total, 9.03min remains)
2022-11-28 05:06:00 NUM_SUB: 51;----------------------------
2022-11-28 05:06:00 Epoch [03000/30000] Loss:0.015181 Loss_1:0.014603 Loss_2:0.000536 Loss_3:0.000000 Lr:0.000769 Time:19.176463s (0.96min in total, 8.68min remains)
2022-11-28 05:06:20 NUM_SUB: 51;----------------------------
2022-11-28 05:06:20 Epoch [04000/30000] Loss:0.013178 Loss_1:0.012941 Loss_2:0.000234 Loss_3:0.000000 Lr:0.000714 Time:19.327483s (1.29min in total, 8.37min remains)
2022-11-28 05:06:39 NUM_SUB: 51;----------------------------
2022-11-28 05:06:39 Epoch [05000/30000] Loss:0.011616 Loss_1:0.011399 Loss_2:0.000202 Loss_3:0.000000 Lr:0.000667 Time:19.151580s (1.61min in total, 8.03min remains)
2022-11-28 05:06:58 NUM_SUB: 51;----------------------------
2022-11-28 05:06:58 Epoch [06000/30000] Loss:0.010040 Loss_1:0.009846 Loss_2:0.000176 Loss_3:0.000000 Lr:0.000625 Time:19.555328s (1.93min in total, 7.73min remains)
2022-11-28 05:07:19 NUM_SUB: 51;----------------------------
2022-11-28 05:07:19 Epoch [07000/30000] Loss:0.008231 Loss_1:0.008060 Loss_2:0.000158 Loss_3:0.000000 Lr:0.000588 Time:20.371418s (2.27min in total, 7.46min remains)
2022-11-28 05:07:38 NUM_SUB: 51;----------------------------
2022-11-28 05:07:38 Epoch [08000/30000] Loss:0.006511 Loss_1:0.006360 Loss_2:0.000143 Loss_3:0.000000 Lr:0.000556 Time:19.517307s (2.60min in total, 7.14min remains)
2022-11-28 05:07:57 NUM_SUB: 51;----------------------------
2022-11-28 05:07:57 Epoch [09000/30000] Loss:0.005235 Loss_1:0.005092 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000526 Time:18.788306s (2.91min in total, 6.79min remains)
2022-11-28 05:08:17 NUM_SUB: 51;----------------------------
2022-11-28 05:08:17 Epoch [10000/30000] Loss:0.004353 Loss_1:0.004213 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000500 Time:19.544461s (3.24min in total, 6.47min remains)
2022-11-28 05:08:36 NUM_SUB: 51;----------------------------
2022-11-28 05:08:36 Epoch [11000/30000] Loss:0.003283 Loss_1:0.003197 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000476 Time:19.078237s (3.55min in total, 6.14min remains)
2022-11-28 05:08:55 NUM_SUB: 51;----------------------------
2022-11-28 05:08:55 Epoch [12000/30000] Loss:0.001896 Loss_1:0.001829 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000455 Time:19.499755s (3.88min in total, 5.82min remains)
2022-11-28 05:09:15 NUM_SUB: 51;----------------------------
2022-11-28 05:09:15 Epoch [13000/30000] Loss:0.000725 Loss_1:0.000666 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000435 Time:19.692088s (4.21min in total, 5.50min remains)
2022-11-28 05:09:34 NUM_SUB: 51;----------------------------
2022-11-28 05:09:34 Epoch [14000/30000] Loss:0.000416 Loss_1:0.000367 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000417 Time:19.037532s (4.52min in total, 5.17min remains)
2022-11-28 05:09:53 NUM_SUB: 51;----------------------------
2022-11-28 05:09:53 Epoch [15000/30000] Loss:0.000293 Loss_1:0.000254 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000400 Time:19.476192s (4.85min in total, 4.85min remains)
2022-11-28 05:10:13 NUM_SUB: 51;----------------------------
2022-11-28 05:10:13 Epoch [16000/30000] Loss:0.000241 Loss_1:0.000208 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000385 Time:19.221953s (5.17min in total, 4.52min remains)
2022-11-28 05:10:32 NUM_SUB: 51;----------------------------
2022-11-28 05:10:32 Epoch [17000/30000] Loss:0.000271 Loss_1:0.000243 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000370 Time:19.270246s (5.49min in total, 4.20min remains)
2022-11-28 05:10:51 NUM_SUB: 51;----------------------------
2022-11-28 05:10:51 Epoch [18000/30000] Loss:0.000223 Loss_1:0.000197 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000357 Time:19.239714s (5.81min in total, 3.87min remains)
2022-11-28 05:11:10 NUM_SUB: 51;----------------------------
2022-11-28 05:11:10 Epoch [19000/30000] Loss:0.000219 Loss_1:0.000195 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000345 Time:19.021239s (6.13min in total, 3.55min remains)
2022-11-28 05:11:30 NUM_SUB: 51;----------------------------
2022-11-28 05:11:30 Epoch [20000/30000] Loss:0.000215 Loss_1:0.000193 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000333 Time:19.347022s (6.45min in total, 3.23min remains)
2022-11-28 05:11:49 NUM_SUB: 51;----------------------------
2022-11-28 05:11:49 Epoch [21000/30000] Loss:0.000211 Loss_1:0.000191 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000323 Time:19.426835s (6.77min in total, 2.90min remains)
2022-11-28 05:12:08 NUM_SUB: 51;----------------------------
2022-11-28 05:12:08 Epoch [22000/30000] Loss:0.000208 Loss_1:0.000189 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000313 Time:19.090741s (7.09min in total, 2.58min remains)
2022-11-28 05:12:27 NUM_SUB: 51;----------------------------
2022-11-28 05:12:27 Epoch [23000/30000] Loss:0.000217 Loss_1:0.000200 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000303 Time:19.065346s (7.41min in total, 2.26min remains)
2022-11-28 05:12:46 NUM_SUB: 51;----------------------------
2022-11-28 05:12:46 Epoch [24000/30000] Loss:0.000205 Loss_1:0.000189 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000294 Time:18.863086s (7.72min in total, 1.93min remains)
2022-11-28 05:13:05 NUM_SUB: 51;----------------------------
2022-11-28 05:13:05 Epoch [25000/30000] Loss:0.000204 Loss_1:0.000189 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000286 Time:19.086083s (8.04min in total, 1.61min remains)
2022-11-28 05:13:24 NUM_SUB: 51;----------------------------
2022-11-28 05:13:24 Epoch [26000/30000] Loss:0.000212 Loss_1:0.000197 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000278 Time:19.035823s (8.36min in total, 1.29min remains)
2022-11-28 05:13:43 NUM_SUB: 51;----------------------------
2022-11-28 05:13:43 Epoch [27000/30000] Loss:0.000203 Loss_1:0.000189 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000270 Time:19.101563s (8.68min in total, 0.96min remains)
2022-11-28 05:14:02 NUM_SUB: 51;----------------------------
2022-11-28 05:14:02 Epoch [28000/30000] Loss:0.000212 Loss_1:0.000199 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000263 Time:18.918153s (8.99min in total, 0.64min remains)
2022-11-28 05:14:22 NUM_SUB: 51;----------------------------
2022-11-28 05:14:22 Epoch [29000/30000] Loss:0.000221 Loss_1:0.000193 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000256 Time:20.125715s (9.33min in total, 0.32min remains)
2022-11-28 05:14:41 NUM_SUB: 51;----------------------------
2022-11-28 05:14:41 Epoch [30000/30000] Loss:0.000200 Loss_1:0.000188 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000250 Time:18.675087s (9.64min in total, 0.00min remains)
2022-11-28 05:14:41 Testing & drawing...
2022-11-28 05:14:41 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:14:43 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=51/
2022-11-28 05:14:43 [Loss]
2022-11-28 05:14:43 NUM_SUB: 51; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:14:43 NUM_SUB: 51; Personalized parameter estimation: Parameter containing:
tensor([3.1927e-03, 1.9994e-02, 2.2499e-02, 2.5452e-01, 3.0742e-01, 1.6273e-02,
        3.0384e+00, 8.9644e-01, 4.5563e-01, 1.4790e-02, 8.8313e-02, 9.1369e-02,
        6.8870e-01, 1.6886e-01, 1.7592e-02, 1.5434e+00, 6.9767e-01, 8.0001e-01,
        1.0439e-02, 5.3072e+00, 6.8161e-01, 2.1815e-02, 4.0057e+00, 8.7416e-01,
        1.6342e-02, 5.1954e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:14:43 NUM_SUB: 51------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:14:43 Testing & drawing...
2022-11-28 05:14:43 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:14:44 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=51/
2022-11-28 05:14:44 [Loss]
2022-11-28 05:14:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:14:44 General parameter estimation: Parameter containing:
tensor([3.1927e-03, 1.9994e-02, 2.2499e-02, 2.5452e-01, 3.0742e-01, 1.6273e-02,
        3.0384e+00, 8.9644e-01, 4.5563e-01, 1.4790e-02, 8.8313e-02, 9.1369e-02,
        6.8870e-01, 1.6886e-01, 1.7592e-02, 1.5434e+00, 6.9767e-01, 8.0001e-01,
        1.0439e-02, 5.3072e+00, 6.8161e-01, 2.1815e-02, 4.0057e+00, 8.7416e-01,
        1.6342e-02, 5.1954e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:14:44 A: prod, degr, TonA, NonA
2022-11-28 05:14:44 [0.08516681 0.46883285 0.43896016 0.00704016]
2022-11-28 05:14:44 T: prod, degr, AonT, NonT
2022-11-28 05:14:44 [0.12194386 0.63163704 0.23771112 0.00870804]
2022-11-28 05:14:44 N: AonN, TonN, ATonN
2022-11-28 05:14:44 [0.01526379 0.95223826 0.03249791]
2022-11-28 05:14:45 using cpu
2022-11-28 05:14:45 epoch = 30000
2022-11-28 05:14:45 epoch_step = 1000
2022-11-28 05:14:45 model_name = SimpleNetworkAD
2022-11-28 05:14:45 now_string = 2022-11-27-19-40-13
2022-11-28 05:14:45 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:14:45 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:14:45 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:14:45 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:14:45 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:14:45 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:15:04 NUM_SUB: 52;----------------------------
2022-11-28 05:15:04 Epoch [01000/30000] Loss:0.069157 Loss_1:0.063779 Loss_2:0.001733 Loss_3:0.000000 Lr:0.000909 Time:19.775644s (0.33min in total, 9.56min remains)
2022-11-28 05:15:23 NUM_SUB: 52;----------------------------
2022-11-28 05:15:23 Epoch [02000/30000] Loss:0.057704 Loss_1:0.056839 Loss_2:0.000504 Loss_3:0.000000 Lr:0.000833 Time:19.078751s (0.65min in total, 9.07min remains)
2022-11-28 05:15:43 NUM_SUB: 52;----------------------------
2022-11-28 05:15:43 Epoch [03000/30000] Loss:0.047591 Loss_1:0.047225 Loss_2:0.000151 Loss_3:0.000000 Lr:0.000769 Time:19.186976s (0.97min in total, 8.71min remains)
2022-11-28 05:16:01 NUM_SUB: 52;----------------------------
2022-11-28 05:16:01 Epoch [04000/30000] Loss:0.035714 Loss_1:0.035447 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000714 Time:18.607117s (1.28min in total, 8.30min remains)
2022-11-28 05:16:21 NUM_SUB: 52;----------------------------
2022-11-28 05:16:21 Epoch [05000/30000] Loss:0.021939 Loss_1:0.021733 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000667 Time:19.320306s (1.60min in total, 8.00min remains)
2022-11-28 05:16:39 NUM_SUB: 52;----------------------------
2022-11-28 05:16:39 Epoch [06000/30000] Loss:0.010663 Loss_1:0.010520 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000625 Time:18.773634s (1.91min in total, 7.65min remains)
2022-11-28 05:16:58 NUM_SUB: 52;----------------------------
2022-11-28 05:16:58 Epoch [07000/30000] Loss:0.006154 Loss_1:0.006046 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000588 Time:18.905630s (2.23min in total, 7.32min remains)
2022-11-28 05:17:17 NUM_SUB: 52;----------------------------
2022-11-28 05:17:17 Epoch [08000/30000] Loss:0.005290 Loss_1:0.005175 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000556 Time:18.963260s (2.54min in total, 7.00min remains)
2022-11-28 05:17:36 NUM_SUB: 52;----------------------------
2022-11-28 05:17:36 Epoch [09000/30000] Loss:0.004728 Loss_1:0.004618 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000526 Time:18.520984s (2.85min in total, 6.66min remains)
2022-11-28 05:17:55 NUM_SUB: 52;----------------------------
2022-11-28 05:17:55 Epoch [10000/30000] Loss:0.003888 Loss_1:0.003836 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000500 Time:18.843726s (3.17min in total, 6.33min remains)
2022-11-28 05:18:13 NUM_SUB: 52;----------------------------
2022-11-28 05:18:13 Epoch [11000/30000] Loss:0.002896 Loss_1:0.002863 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000476 Time:18.856361s (3.48min in total, 6.01min remains)
2022-11-28 05:18:32 NUM_SUB: 52;----------------------------
2022-11-28 05:18:32 Epoch [12000/30000] Loss:0.002032 Loss_1:0.002003 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000455 Time:18.708336s (3.79min in total, 5.69min remains)
2022-11-28 05:18:51 NUM_SUB: 52;----------------------------
2022-11-28 05:18:51 Epoch [13000/30000] Loss:0.001627 Loss_1:0.001598 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000435 Time:18.842628s (4.11min in total, 5.37min remains)
2022-11-28 05:19:10 NUM_SUB: 52;----------------------------
2022-11-28 05:19:10 Epoch [14000/30000] Loss:0.001546 Loss_1:0.001518 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000417 Time:18.734750s (4.42min in total, 5.05min remains)
2022-11-28 05:19:28 NUM_SUB: 52;----------------------------
2022-11-28 05:19:28 Epoch [15000/30000] Loss:0.001514 Loss_1:0.001487 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000400 Time:18.766527s (4.73min in total, 4.73min remains)
2022-11-28 05:19:48 NUM_SUB: 52;----------------------------
2022-11-28 05:19:48 Epoch [16000/30000] Loss:0.001483 Loss_1:0.001458 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000385 Time:19.324196s (5.05min in total, 4.42min remains)
2022-11-28 05:20:07 NUM_SUB: 52;----------------------------
2022-11-28 05:20:07 Epoch [17000/30000] Loss:0.001453 Loss_1:0.001432 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000370 Time:19.188644s (5.37min in total, 4.11min remains)
2022-11-28 05:20:26 NUM_SUB: 52;----------------------------
2022-11-28 05:20:26 Epoch [18000/30000] Loss:0.001413 Loss_1:0.001395 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000357 Time:19.295308s (5.70min in total, 3.80min remains)
2022-11-28 05:20:45 NUM_SUB: 52;----------------------------
2022-11-28 05:20:45 Epoch [19000/30000] Loss:0.001346 Loss_1:0.001332 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000345 Time:19.029893s (6.01min in total, 3.48min remains)
2022-11-28 05:21:05 NUM_SUB: 52;----------------------------
2022-11-28 05:21:05 Epoch [20000/30000] Loss:0.001241 Loss_1:0.001232 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:19.415691s (6.34min in total, 3.17min remains)
2022-11-28 05:21:24 NUM_SUB: 52;----------------------------
2022-11-28 05:21:24 Epoch [21000/30000] Loss:0.001198 Loss_1:0.001193 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.028830s (6.65min in total, 2.85min remains)
2022-11-28 05:21:43 NUM_SUB: 52;----------------------------
2022-11-28 05:21:43 Epoch [22000/30000] Loss:0.001174 Loss_1:0.001172 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:18.897891s (6.97min in total, 2.53min remains)
2022-11-28 05:22:02 NUM_SUB: 52;----------------------------
2022-11-28 05:22:02 Epoch [23000/30000] Loss:0.001149 Loss_1:0.001146 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:18.905115s (7.28min in total, 2.22min remains)
2022-11-28 05:22:20 NUM_SUB: 52;----------------------------
2022-11-28 05:22:20 Epoch [24000/30000] Loss:0.001108 Loss_1:0.001104 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.825398s (7.60min in total, 1.90min remains)
2022-11-28 05:22:40 NUM_SUB: 52;----------------------------
2022-11-28 05:22:40 Epoch [25000/30000] Loss:0.001077 Loss_1:0.001073 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.770427s (7.93min in total, 1.59min remains)
2022-11-28 05:22:59 NUM_SUB: 52;----------------------------
2022-11-28 05:22:59 Epoch [26000/30000] Loss:0.001064 Loss_1:0.001059 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.002792s (8.24min in total, 1.27min remains)
2022-11-28 05:23:18 NUM_SUB: 52;----------------------------
2022-11-28 05:23:18 Epoch [27000/30000] Loss:0.001063 Loss_1:0.001058 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:19.011610s (8.56min in total, 0.95min remains)
2022-11-28 05:23:37 NUM_SUB: 52;----------------------------
2022-11-28 05:23:37 Epoch [28000/30000] Loss:0.001063 Loss_1:0.001058 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:18.912708s (8.88min in total, 0.63min remains)
2022-11-28 05:23:56 NUM_SUB: 52;----------------------------
2022-11-28 05:23:56 Epoch [29000/30000] Loss:0.001062 Loss_1:0.001058 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:18.812139s (9.19min in total, 0.32min remains)
2022-11-28 05:24:15 NUM_SUB: 52;----------------------------
2022-11-28 05:24:15 Epoch [30000/30000] Loss:0.001062 Loss_1:0.001058 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.195061s (9.51min in total, 0.00min remains)
2022-11-28 05:24:15 Testing & drawing...
2022-11-28 05:24:15 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:24:17 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=52/
2022-11-28 05:24:17 [Loss]
2022-11-28 05:24:17 NUM_SUB: 52; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:24:17 NUM_SUB: 52; Personalized parameter estimation: Parameter containing:
tensor([0.0171, 0.0551, 0.0108, 0.0374, 0.3074, 0.0098, 1.4899, 0.8964, 0.4556,
        0.0152, 0.1733, 0.1174, 0.4283, 0.1689, 0.0183, 2.1451, 0.6977, 0.8000,
        0.0103, 2.6176, 0.6816, 0.0230, 0.7638, 0.8742, 0.0207, 2.5969, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:24:17 NUM_SUB: 52------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:24:17 Testing & drawing...
2022-11-28 05:24:17 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:24:18 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=52/
2022-11-28 05:24:18 [Loss]
2022-11-28 05:24:18 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:24:18 General parameter estimation: Parameter containing:
tensor([0.0171, 0.0551, 0.0108, 0.0374, 0.3074, 0.0098, 1.4899, 0.8964, 0.4556,
        0.0152, 0.1733, 0.1174, 0.4283, 0.1689, 0.0183, 2.1451, 0.6977, 0.8000,
        0.0103, 2.6176, 0.6816, 0.0230, 0.7638, 0.8742, 0.0207, 2.5969, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:24:18 A: prod, degr, TonA, NonA
2022-11-28 05:24:18 [0.28354862 0.49750856 0.17542163 0.04352121]
2022-11-28 05:24:18 T: prod, degr, AonT, NonT
2022-11-28 05:24:18 [0.09764841 0.6003235  0.2844915  0.0175366 ]
2022-11-28 05:24:18 N: AonN, TonN, ATonN
2022-11-28 05:24:18 [0.02320472 0.90918225 0.06761307]
2022-11-28 05:24:19 using cpu
2022-11-28 05:24:19 epoch = 30000
2022-11-28 05:24:19 epoch_step = 1000
2022-11-28 05:24:19 model_name = SimpleNetworkAD
2022-11-28 05:24:19 now_string = 2022-11-27-19-40-13
2022-11-28 05:24:19 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:24:19 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:24:19 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:24:19 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:24:19 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:24:19 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:24:38 NUM_SUB: 53;----------------------------
2022-11-28 05:24:38 Epoch [01000/30000] Loss:0.082938 Loss_1:0.077742 Loss_2:0.001424 Loss_3:0.000000 Lr:0.000909 Time:19.291068s (0.32min in total, 9.32min remains)
2022-11-28 05:24:57 NUM_SUB: 53;----------------------------
2022-11-28 05:24:57 Epoch [02000/30000] Loss:0.073163 Loss_1:0.072386 Loss_2:0.000372 Loss_3:0.000000 Lr:0.000833 Time:19.017040s (0.64min in total, 8.94min remains)
2022-11-28 05:25:17 NUM_SUB: 53;----------------------------
2022-11-28 05:25:17 Epoch [03000/30000] Loss:0.065519 Loss_1:0.065070 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000769 Time:19.712328s (0.97min in total, 8.70min remains)
2022-11-28 05:25:36 NUM_SUB: 53;----------------------------
2022-11-28 05:25:36 Epoch [04000/30000] Loss:0.055836 Loss_1:0.055502 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000714 Time:19.161173s (1.29min in total, 8.36min remains)
2022-11-28 05:25:55 NUM_SUB: 53;----------------------------
2022-11-28 05:25:55 Epoch [05000/30000] Loss:0.042003 Loss_1:0.041724 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000667 Time:19.078882s (1.60min in total, 8.02min remains)
2022-11-28 05:26:14 NUM_SUB: 53;----------------------------
2022-11-28 05:26:14 Epoch [06000/30000] Loss:0.024307 Loss_1:0.024108 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000625 Time:19.323900s (1.93min in total, 7.71min remains)
2022-11-28 05:26:33 NUM_SUB: 53;----------------------------
2022-11-28 05:26:33 Epoch [07000/30000] Loss:0.009012 Loss_1:0.008903 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000588 Time:19.159009s (2.25min in total, 7.38min remains)
2022-11-28 05:26:53 NUM_SUB: 53;----------------------------
2022-11-28 05:26:53 Epoch [08000/30000] Loss:0.003322 Loss_1:0.003265 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000556 Time:19.386712s (2.57min in total, 7.06min remains)
2022-11-28 05:27:12 NUM_SUB: 53;----------------------------
2022-11-28 05:27:12 Epoch [09000/30000] Loss:0.002488 Loss_1:0.002439 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000526 Time:19.085731s (2.89min in total, 6.74min remains)
2022-11-28 05:27:32 NUM_SUB: 53;----------------------------
2022-11-28 05:27:32 Epoch [10000/30000] Loss:0.002198 Loss_1:0.002140 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000500 Time:19.714784s (3.22min in total, 6.43min remains)
2022-11-28 05:27:50 NUM_SUB: 53;----------------------------
2022-11-28 05:27:50 Epoch [11000/30000] Loss:0.001862 Loss_1:0.001803 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000476 Time:18.836265s (3.53min in total, 6.10min remains)
2022-11-28 05:28:10 NUM_SUB: 53;----------------------------
2022-11-28 05:28:10 Epoch [12000/30000] Loss:0.001336 Loss_1:0.001315 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000455 Time:19.448872s (3.85min in total, 5.78min remains)
2022-11-28 05:28:29 NUM_SUB: 53;----------------------------
2022-11-28 05:28:29 Epoch [13000/30000] Loss:0.000784 Loss_1:0.000765 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000435 Time:19.432110s (4.18min in total, 5.46min remains)
2022-11-28 05:28:49 NUM_SUB: 53;----------------------------
2022-11-28 05:28:49 Epoch [14000/30000] Loss:0.000481 Loss_1:0.000462 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000417 Time:19.528404s (4.50min in total, 5.15min remains)
2022-11-28 05:29:09 NUM_SUB: 53;----------------------------
2022-11-28 05:29:09 Epoch [15000/30000] Loss:0.000433 Loss_1:0.000421 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000400 Time:19.803953s (4.83min in total, 4.83min remains)
2022-11-28 05:29:29 NUM_SUB: 53;----------------------------
2022-11-28 05:29:29 Epoch [16000/30000] Loss:0.000426 Loss_1:0.000419 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:20.119399s (5.17min in total, 4.52min remains)
2022-11-28 05:29:48 NUM_SUB: 53;----------------------------
2022-11-28 05:29:48 Epoch [17000/30000] Loss:0.000424 Loss_1:0.000418 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000370 Time:18.939826s (5.48min in total, 4.19min remains)
2022-11-28 05:30:07 NUM_SUB: 53;----------------------------
2022-11-28 05:30:07 Epoch [18000/30000] Loss:0.000433 Loss_1:0.000429 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:19.500134s (5.81min in total, 3.87min remains)
2022-11-28 05:30:26 NUM_SUB: 53;----------------------------
2022-11-28 05:30:26 Epoch [19000/30000] Loss:0.000421 Loss_1:0.000418 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000345 Time:19.137243s (6.13min in total, 3.55min remains)
2022-11-28 05:30:45 NUM_SUB: 53;----------------------------
2022-11-28 05:30:45 Epoch [20000/30000] Loss:0.000420 Loss_1:0.000418 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:19.060426s (6.45min in total, 3.22min remains)
2022-11-28 05:31:04 NUM_SUB: 53;----------------------------
2022-11-28 05:31:04 Epoch [21000/30000] Loss:0.000421 Loss_1:0.000419 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:18.909537s (6.76min in total, 2.90min remains)
2022-11-28 05:31:23 NUM_SUB: 53;----------------------------
2022-11-28 05:31:23 Epoch [22000/30000] Loss:0.000420 Loss_1:0.000418 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.195427s (7.08min in total, 2.57min remains)
2022-11-28 05:31:42 NUM_SUB: 53;----------------------------
2022-11-28 05:31:42 Epoch [23000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.067941s (7.40min in total, 2.25min remains)
2022-11-28 05:32:01 NUM_SUB: 53;----------------------------
2022-11-28 05:32:01 Epoch [24000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:18.750705s (7.71min in total, 1.93min remains)
2022-11-28 05:32:20 NUM_SUB: 53;----------------------------
2022-11-28 05:32:20 Epoch [25000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.912527s (8.03min in total, 1.61min remains)
2022-11-28 05:32:39 NUM_SUB: 53;----------------------------
2022-11-28 05:32:39 Epoch [26000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:18.988697s (8.34min in total, 1.28min remains)
2022-11-28 05:32:58 NUM_SUB: 53;----------------------------
2022-11-28 05:32:58 Epoch [27000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.086938s (8.66min in total, 0.96min remains)
2022-11-28 05:33:17 NUM_SUB: 53;----------------------------
2022-11-28 05:33:17 Epoch [28000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.244342s (8.98min in total, 0.64min remains)
2022-11-28 05:33:36 NUM_SUB: 53;----------------------------
2022-11-28 05:33:36 Epoch [29000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.787378s (9.30min in total, 0.32min remains)
2022-11-28 05:33:55 NUM_SUB: 53;----------------------------
2022-11-28 05:33:55 Epoch [30000/30000] Loss:0.000419 Loss_1:0.000418 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.973235s (9.61min in total, 0.00min remains)
2022-11-28 05:33:55 Testing & drawing...
2022-11-28 05:33:55 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:33:57 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=53/
2022-11-28 05:33:57 [Loss]
2022-11-28 05:33:57 NUM_SUB: 53; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:33:57 NUM_SUB: 53; Personalized parameter estimation: Parameter containing:
tensor([2.7455e-01, 9.8379e-01, 9.6100e-03, 7.6725e-37, 3.0742e-01, 5.1235e-03,
        7.5781e-01, 8.9644e-01, 4.5563e-01, 1.4339e-02, 1.0742e-01, 1.0768e-01,
        7.0955e-01, 1.6886e-01, 1.7677e-02, 1.1720e+00, 6.9767e-01, 8.0001e-01,
        1.2428e-02, 2.7720e+00, 6.8161e-01, 2.1992e-02, 3.3844e+00, 8.7416e-01,
        2.1748e-02, 3.9821e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:33:57 NUM_SUB: 53------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:33:57 Testing & drawing...
2022-11-28 05:33:57 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:33:59 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=53/
2022-11-28 05:33:59 [Loss]
2022-11-28 05:33:59 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:33:59 General parameter estimation: Parameter containing:
tensor([2.7455e-01, 9.8379e-01, 9.6100e-03, 7.6725e-37, 3.0742e-01, 5.1235e-03,
        7.5781e-01, 8.9644e-01, 4.5563e-01, 1.4339e-02, 1.0742e-01, 1.0768e-01,
        7.0955e-01, 1.6886e-01, 1.7677e-02, 1.1720e+00, 6.9767e-01, 8.0001e-01,
        1.2428e-02, 2.7720e+00, 6.8161e-01, 2.1992e-02, 3.3844e+00, 8.7416e-01,
        2.1748e-02, 3.9821e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 05:33:59 A: prod, degr, TonA, NonA
2022-11-28 05:33:59 [0.478472   0.49999654 0.01674753 0.00478392]
2022-11-28 05:33:59 T: prod, degr, AonT, NonT
2022-11-28 05:33:59 [0.17040262 0.37224662 0.38983825 0.06751253]
2022-11-28 05:33:59 N: AonN, TonN, ATonN
2022-11-28 05:33:59 [0.00690673 0.9706742  0.02241908]
2022-11-28 05:33:59 using cpu
2022-11-28 05:33:59 epoch = 30000
2022-11-28 05:33:59 epoch_step = 1000
2022-11-28 05:33:59 model_name = SimpleNetworkAD
2022-11-28 05:33:59 now_string = 2022-11-27-19-40-13
2022-11-28 05:33:59 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:33:59 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:33:59 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:33:59 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:33:59 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:33:59 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:34:18 NUM_SUB: 54;----------------------------
2022-11-28 05:34:18 Epoch [01000/30000] Loss:0.053184 Loss_1:0.047206 Loss_2:0.002096 Loss_3:0.000000 Lr:0.000909 Time:19.184178s (0.32min in total, 9.27min remains)
2022-11-28 05:34:37 NUM_SUB: 54;----------------------------
2022-11-28 05:34:37 Epoch [02000/30000] Loss:0.046744 Loss_1:0.045557 Loss_2:0.000740 Loss_3:0.000000 Lr:0.000833 Time:18.868748s (0.63min in total, 8.88min remains)
2022-11-28 05:34:56 NUM_SUB: 54;----------------------------
2022-11-28 05:34:56 Epoch [03000/30000] Loss:0.043171 Loss_1:0.042745 Loss_2:0.000269 Loss_3:0.000000 Lr:0.000769 Time:19.141021s (0.95min in total, 8.58min remains)
2022-11-28 05:35:15 NUM_SUB: 54;----------------------------
2022-11-28 05:35:15 Epoch [04000/30000] Loss:0.039130 Loss_1:0.038764 Loss_2:0.000181 Loss_3:0.000000 Lr:0.000714 Time:19.109547s (1.27min in total, 8.27min remains)
2022-11-28 05:35:34 NUM_SUB: 54;----------------------------
2022-11-28 05:35:34 Epoch [05000/30000] Loss:0.033777 Loss_1:0.033436 Loss_2:0.000146 Loss_3:0.000000 Lr:0.000667 Time:19.202793s (1.59min in total, 7.96min remains)
2022-11-28 05:35:54 NUM_SUB: 54;----------------------------
2022-11-28 05:35:54 Epoch [06000/30000] Loss:0.026085 Loss_1:0.025763 Loss_2:0.000157 Loss_3:0.000000 Lr:0.000625 Time:19.248603s (1.91min in total, 7.65min remains)
2022-11-28 05:36:12 NUM_SUB: 54;----------------------------
2022-11-28 05:36:12 Epoch [07000/30000] Loss:0.017329 Loss_1:0.017054 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000588 Time:18.809247s (2.23min in total, 7.31min remains)
2022-11-28 05:36:31 NUM_SUB: 54;----------------------------
2022-11-28 05:36:31 Epoch [08000/30000] Loss:0.008221 Loss_1:0.007988 Loss_2:0.000169 Loss_3:0.000000 Lr:0.000556 Time:19.045286s (2.54min in total, 6.99min remains)
2022-11-28 05:36:50 NUM_SUB: 54;----------------------------
2022-11-28 05:36:50 Epoch [09000/30000] Loss:0.002328 Loss_1:0.002130 Loss_2:0.000183 Loss_3:0.000000 Lr:0.000526 Time:18.788065s (2.86min in total, 6.67min remains)
2022-11-28 05:37:09 NUM_SUB: 54;----------------------------
2022-11-28 05:37:09 Epoch [10000/30000] Loss:0.000939 Loss_1:0.000785 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000500 Time:19.204886s (3.18min in total, 6.35min remains)
2022-11-28 05:37:28 NUM_SUB: 54;----------------------------
2022-11-28 05:37:28 Epoch [11000/30000] Loss:0.000567 Loss_1:0.000465 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000476 Time:18.723021s (3.49min in total, 6.03min remains)
2022-11-28 05:37:47 NUM_SUB: 54;----------------------------
2022-11-28 05:37:47 Epoch [12000/30000] Loss:0.000288 Loss_1:0.000227 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000455 Time:19.192181s (3.81min in total, 5.71min remains)
2022-11-28 05:38:06 NUM_SUB: 54;----------------------------
2022-11-28 05:38:06 Epoch [13000/30000] Loss:0.000194 Loss_1:0.000147 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000435 Time:18.754238s (4.12min in total, 5.39min remains)
2022-11-28 05:38:25 NUM_SUB: 54;----------------------------
2022-11-28 05:38:25 Epoch [14000/30000] Loss:0.000167 Loss_1:0.000132 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:19.350417s (4.44min in total, 5.08min remains)
2022-11-28 05:38:44 NUM_SUB: 54;----------------------------
2022-11-28 05:38:44 Epoch [15000/30000] Loss:0.000152 Loss_1:0.000124 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000400 Time:18.809012s (4.76min in total, 4.76min remains)
2022-11-28 05:39:04 NUM_SUB: 54;----------------------------
2022-11-28 05:39:04 Epoch [16000/30000] Loss:0.000141 Loss_1:0.000120 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000385 Time:19.420591s (5.08min in total, 4.45min remains)
2022-11-28 05:39:23 NUM_SUB: 54;----------------------------
2022-11-28 05:39:23 Epoch [17000/30000] Loss:0.000137 Loss_1:0.000120 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000370 Time:18.972501s (5.40min in total, 4.13min remains)
2022-11-28 05:39:42 NUM_SUB: 54;----------------------------
2022-11-28 05:39:42 Epoch [18000/30000] Loss:0.000129 Loss_1:0.000116 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:19.181770s (5.72min in total, 3.81min remains)
2022-11-28 05:40:01 NUM_SUB: 54;----------------------------
2022-11-28 05:40:01 Epoch [19000/30000] Loss:0.000125 Loss_1:0.000114 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:18.997694s (6.03min in total, 3.49min remains)
2022-11-28 05:40:20 NUM_SUB: 54;----------------------------
2022-11-28 05:40:20 Epoch [20000/30000] Loss:0.000120 Loss_1:0.000111 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:19.134172s (6.35min in total, 3.18min remains)
2022-11-28 05:40:39 NUM_SUB: 54;----------------------------
2022-11-28 05:40:39 Epoch [21000/30000] Loss:0.000115 Loss_1:0.000107 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000323 Time:19.235706s (6.67min in total, 2.86min remains)
2022-11-28 05:40:59 NUM_SUB: 54;----------------------------
2022-11-28 05:40:59 Epoch [22000/30000] Loss:0.000105 Loss_1:0.000099 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:19.959206s (7.01min in total, 2.55min remains)
2022-11-28 05:41:19 NUM_SUB: 54;----------------------------
2022-11-28 05:41:19 Epoch [23000/30000] Loss:0.000094 Loss_1:0.000088 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:19.457921s (7.33min in total, 2.23min remains)
2022-11-28 05:41:37 NUM_SUB: 54;----------------------------
2022-11-28 05:41:37 Epoch [24000/30000] Loss:0.000081 Loss_1:0.000077 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.885434s (7.65min in total, 1.91min remains)
2022-11-28 05:41:57 NUM_SUB: 54;----------------------------
2022-11-28 05:41:57 Epoch [25000/30000] Loss:0.000066 Loss_1:0.000062 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.285765s (7.97min in total, 1.59min remains)
2022-11-28 05:42:16 NUM_SUB: 54;----------------------------
2022-11-28 05:42:16 Epoch [26000/30000] Loss:0.000063 Loss_1:0.000059 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:18.995824s (8.28min in total, 1.27min remains)
2022-11-28 05:42:35 NUM_SUB: 54;----------------------------
2022-11-28 05:42:35 Epoch [27000/30000] Loss:0.000060 Loss_1:0.000057 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:19.224782s (8.60min in total, 0.96min remains)
2022-11-28 05:42:54 NUM_SUB: 54;----------------------------
2022-11-28 05:42:54 Epoch [28000/30000] Loss:0.000059 Loss_1:0.000055 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:19.077624s (8.92min in total, 0.64min remains)
2022-11-28 05:43:13 NUM_SUB: 54;----------------------------
2022-11-28 05:43:13 Epoch [29000/30000] Loss:0.000063 Loss_1:0.000059 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.054550s (9.24min in total, 0.32min remains)
2022-11-28 05:43:32 NUM_SUB: 54;----------------------------
2022-11-28 05:43:32 Epoch [30000/30000] Loss:0.000056 Loss_1:0.000052 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.191835s (9.56min in total, 0.00min remains)
2022-11-28 05:43:32 Testing & drawing...
2022-11-28 05:43:32 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:43:34 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=54/
2022-11-28 05:43:34 [Loss]
2022-11-28 05:43:34 NUM_SUB: 54; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:43:34 NUM_SUB: 54; Personalized parameter estimation: Parameter containing:
tensor([0.0161, 0.0259, 0.0117, 1.8444, 0.3074, 0.0111, 2.2404, 0.8964, 0.4556,
        0.0138, 0.0248, 0.0150, 1.0150, 0.1689, 0.0176, 1.7201, 0.6977, 0.8000,
        0.0108, 4.7327, 0.6816, 0.0210, 4.2510, 0.8742, 0.0187, 5.0539, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:43:34 NUM_SUB: 54------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:43:34 Testing & drawing...
2022-11-28 05:43:34 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:43:36 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=54/
2022-11-28 05:43:36 [Loss]
2022-11-28 05:43:36 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:43:36 General parameter estimation: Parameter containing:
tensor([0.0161, 0.0259, 0.0117, 1.8444, 0.3074, 0.0111, 2.2404, 0.8964, 0.4556,
        0.0138, 0.0248, 0.0150, 1.0150, 0.1689, 0.0176, 1.7201, 0.6977, 0.8000,
        0.0108, 4.7327, 0.6816, 0.0210, 4.2510, 0.8742, 0.0187, 5.0539, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:43:36 A: prod, degr, TonA, NonA
2022-11-28 05:43:36 [0.46411693 0.477427   0.04781849 0.01063751]
2022-11-28 05:43:36 T: prod, degr, AonT, NonT
2022-11-28 05:43:36 [0.38657257 0.44101593 0.1455095  0.02690204]
2022-11-28 05:43:36 N: AonN, TonN, ATonN
2022-11-28 05:43:36 [0.00943358 0.95727795 0.03328849]
2022-11-28 05:43:36 using cpu
2022-11-28 05:43:36 epoch = 30000
2022-11-28 05:43:36 epoch_step = 1000
2022-11-28 05:43:36 model_name = SimpleNetworkAD
2022-11-28 05:43:36 now_string = 2022-11-27-19-40-13
2022-11-28 05:43:36 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:43:36 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:43:36 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:43:36 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:43:36 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:43:36 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:43:55 NUM_SUB: 55;----------------------------
2022-11-28 05:43:55 Epoch [01000/30000] Loss:0.023655 Loss_1:0.018157 Loss_2:0.001665 Loss_3:0.000000 Lr:0.000909 Time:19.045851s (0.32min in total, 9.21min remains)
2022-11-28 05:44:14 NUM_SUB: 55;----------------------------
2022-11-28 05:44:14 Epoch [02000/30000] Loss:0.018557 Loss_1:0.017625 Loss_2:0.000508 Loss_3:0.000000 Lr:0.000833 Time:19.280638s (0.64min in total, 8.94min remains)
2022-11-28 05:44:33 NUM_SUB: 55;----------------------------
2022-11-28 05:44:33 Epoch [03000/30000] Loss:0.016896 Loss_1:0.016649 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000769 Time:19.073652s (0.96min in total, 8.61min remains)
2022-11-28 05:44:53 NUM_SUB: 55;----------------------------
2022-11-28 05:44:53 Epoch [04000/30000] Loss:0.015235 Loss_1:0.015019 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000714 Time:19.367342s (1.28min in total, 8.32min remains)
2022-11-28 05:45:12 NUM_SUB: 55;----------------------------
2022-11-28 05:45:12 Epoch [05000/30000] Loss:0.013567 Loss_1:0.013355 Loss_2:0.000135 Loss_3:0.000000 Lr:0.000667 Time:19.092271s (1.60min in total, 7.99min remains)
2022-11-28 05:45:31 NUM_SUB: 55;----------------------------
2022-11-28 05:45:31 Epoch [06000/30000] Loss:0.011583 Loss_1:0.011399 Loss_2:0.000113 Loss_3:0.000000 Lr:0.000625 Time:19.353592s (1.92min in total, 7.68min remains)
2022-11-28 05:45:50 NUM_SUB: 55;----------------------------
2022-11-28 05:45:50 Epoch [07000/30000] Loss:0.009183 Loss_1:0.009025 Loss_2:0.000103 Loss_3:0.000000 Lr:0.000588 Time:19.047275s (2.24min in total, 7.35min remains)
2022-11-28 05:46:10 NUM_SUB: 55;----------------------------
2022-11-28 05:46:10 Epoch [08000/30000] Loss:0.006625 Loss_1:0.006490 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000556 Time:19.502577s (2.56min in total, 7.05min remains)
2022-11-28 05:46:29 NUM_SUB: 55;----------------------------
2022-11-28 05:46:29 Epoch [09000/30000] Loss:0.004404 Loss_1:0.004272 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000526 Time:19.287270s (2.88min in total, 6.73min remains)
2022-11-28 05:46:48 NUM_SUB: 55;----------------------------
2022-11-28 05:46:48 Epoch [10000/30000] Loss:0.003096 Loss_1:0.002987 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000500 Time:19.164124s (3.20min in total, 6.41min remains)
2022-11-28 05:47:07 NUM_SUB: 55;----------------------------
2022-11-28 05:47:07 Epoch [11000/30000] Loss:0.002626 Loss_1:0.002536 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000476 Time:19.129296s (3.52min in total, 6.08min remains)
2022-11-28 05:47:27 NUM_SUB: 55;----------------------------
2022-11-28 05:47:27 Epoch [12000/30000] Loss:0.002323 Loss_1:0.002260 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000455 Time:19.814135s (3.85min in total, 5.78min remains)
2022-11-28 05:47:46 NUM_SUB: 55;----------------------------
2022-11-28 05:47:46 Epoch [13000/30000] Loss:0.001943 Loss_1:0.001908 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:19.176938s (4.17min in total, 5.46min remains)
2022-11-28 05:48:06 NUM_SUB: 55;----------------------------
2022-11-28 05:48:06 Epoch [14000/30000] Loss:0.001687 Loss_1:0.001663 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:19.380989s (4.50min in total, 5.14min remains)
2022-11-28 05:48:25 NUM_SUB: 55;----------------------------
2022-11-28 05:48:25 Epoch [15000/30000] Loss:0.001593 Loss_1:0.001576 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:19.447003s (4.82min in total, 4.82min remains)
2022-11-28 05:48:44 NUM_SUB: 55;----------------------------
2022-11-28 05:48:44 Epoch [16000/30000] Loss:0.001580 Loss_1:0.001567 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:18.983515s (5.14min in total, 4.49min remains)
2022-11-28 05:49:03 NUM_SUB: 55;----------------------------
2022-11-28 05:49:03 Epoch [17000/30000] Loss:0.001574 Loss_1:0.001564 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000370 Time:19.404479s (5.46min in total, 4.17min remains)
2022-11-28 05:49:22 NUM_SUB: 55;----------------------------
2022-11-28 05:49:22 Epoch [18000/30000] Loss:0.001567 Loss_1:0.001559 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:18.798711s (5.77min in total, 3.85min remains)
2022-11-28 05:49:42 NUM_SUB: 55;----------------------------
2022-11-28 05:49:42 Epoch [19000/30000] Loss:0.001558 Loss_1:0.001551 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:19.967331s (6.11min in total, 3.53min remains)
2022-11-28 05:50:01 NUM_SUB: 55;----------------------------
2022-11-28 05:50:01 Epoch [20000/30000] Loss:0.001555 Loss_1:0.001550 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:18.979694s (6.42min in total, 3.21min remains)
2022-11-28 05:50:20 NUM_SUB: 55;----------------------------
2022-11-28 05:50:20 Epoch [21000/30000] Loss:0.001554 Loss_1:0.001550 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.312973s (6.74min in total, 2.89min remains)
2022-11-28 05:50:39 NUM_SUB: 55;----------------------------
2022-11-28 05:50:40 Epoch [22000/30000] Loss:0.001553 Loss_1:0.001550 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.082455s (7.06min in total, 2.57min remains)
2022-11-28 05:50:58 NUM_SUB: 55;----------------------------
2022-11-28 05:50:58 Epoch [23000/30000] Loss:0.001553 Loss_1:0.001549 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.873602s (7.38min in total, 2.24min remains)
2022-11-28 05:51:17 NUM_SUB: 55;----------------------------
2022-11-28 05:51:17 Epoch [24000/30000] Loss:0.001560 Loss_1:0.001556 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.994212s (7.69min in total, 1.92min remains)
2022-11-28 05:51:37 NUM_SUB: 55;----------------------------
2022-11-28 05:51:37 Epoch [25000/30000] Loss:0.001554 Loss_1:0.001550 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.253733s (8.01min in total, 1.60min remains)
2022-11-28 05:51:56 NUM_SUB: 55;----------------------------
2022-11-28 05:51:56 Epoch [26000/30000] Loss:0.001552 Loss_1:0.001549 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.394964s (8.34min in total, 1.28min remains)
2022-11-28 05:52:15 NUM_SUB: 55;----------------------------
2022-11-28 05:52:15 Epoch [27000/30000] Loss:0.001552 Loss_1:0.001550 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:18.603506s (8.65min in total, 0.96min remains)
2022-11-28 05:52:34 NUM_SUB: 55;----------------------------
2022-11-28 05:52:34 Epoch [28000/30000] Loss:0.001567 Loss_1:0.001558 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.277392s (8.97min in total, 0.64min remains)
2022-11-28 05:52:52 NUM_SUB: 55;----------------------------
2022-11-28 05:52:52 Epoch [29000/30000] Loss:0.001552 Loss_1:0.001550 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:18.584826s (9.28min in total, 0.32min remains)
2022-11-28 05:53:12 NUM_SUB: 55;----------------------------
2022-11-28 05:53:12 Epoch [30000/30000] Loss:0.001552 Loss_1:0.001549 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.348608s (9.60min in total, 0.00min remains)
2022-11-28 05:53:12 Testing & drawing...
2022-11-28 05:53:12 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:53:13 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=55/
2022-11-28 05:53:13 [Loss]
2022-11-28 05:53:14 NUM_SUB: 55; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:53:14 NUM_SUB: 55; Personalized parameter estimation: Parameter containing:
tensor([0.0167, 0.0409, 0.0108, 1.0422, 0.3074, 0.0122, 1.9283, 0.8964, 0.4556,
        0.0138, 0.0303, 0.0132, 0.8925, 0.1689, 0.0176, 2.1839, 0.6977, 0.8000,
        0.0118, 4.1589, 0.6816, 0.0211, 3.8327, 0.8742, 0.0098, 4.1766, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:53:14 NUM_SUB: 55------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 05:53:14 Testing & drawing...
2022-11-28 05:53:14 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 05:53:15 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=55/
2022-11-28 05:53:15 [Loss]
2022-11-28 05:53:15 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 05:53:15 General parameter estimation: Parameter containing:
tensor([0.0167, 0.0409, 0.0108, 1.0422, 0.3074, 0.0122, 1.9283, 0.8964, 0.4556,
        0.0138, 0.0303, 0.0132, 0.8925, 0.1689, 0.0176, 2.1839, 0.6977, 0.8000,
        0.0118, 4.1589, 0.6816, 0.0211, 3.8327, 0.8742, 0.0098, 4.1766, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 05:53:15 A: prod, degr, TonA, NonA
2022-11-28 05:53:15 [0.4399602  0.48916906 0.06219541 0.00867534]
2022-11-28 05:53:15 T: prod, degr, AonT, NonT
2022-11-28 05:53:15 [0.43719256 0.4353315  0.1157009  0.01177503]
2022-11-28 05:53:15 N: AonN, TonN, ATonN
2022-11-28 05:53:15 [0.00722903 0.97830653 0.01446449]
2022-11-28 05:53:15 using cpu
2022-11-28 05:53:15 epoch = 30000
2022-11-28 05:53:15 epoch_step = 1000
2022-11-28 05:53:15 model_name = SimpleNetworkAD
2022-11-28 05:53:15 now_string = 2022-11-27-19-40-13
2022-11-28 05:53:15 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 05:53:15 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 05:53:15 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 05:53:15 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 05:53:15 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 05:53:15 --------------------------------------------------training start--------------------------------------------------
2022-11-28 05:53:34 NUM_SUB: 56;----------------------------
2022-11-28 05:53:34 Epoch [01000/30000] Loss:0.175431 Loss_1:0.169467 Loss_2:0.001894 Loss_3:0.000000 Lr:0.000909 Time:18.903758s (0.32min in total, 9.14min remains)
2022-11-28 05:53:54 NUM_SUB: 56;----------------------------
2022-11-28 05:53:54 Epoch [02000/30000] Loss:0.161709 Loss_1:0.160489 Loss_2:0.000602 Loss_3:0.000000 Lr:0.000833 Time:19.324425s (0.64min in total, 8.92min remains)
2022-11-28 05:54:13 NUM_SUB: 56;----------------------------
2022-11-28 05:54:13 Epoch [03000/30000] Loss:0.148191 Loss_1:0.147203 Loss_2:0.000162 Loss_3:0.000000 Lr:0.000769 Time:19.360773s (0.96min in total, 8.64min remains)
2022-11-28 05:54:32 NUM_SUB: 56;----------------------------
2022-11-28 05:54:32 Epoch [04000/30000] Loss:0.130012 Loss_1:0.129056 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000714 Time:19.304245s (1.28min in total, 8.33min remains)
2022-11-28 05:54:51 NUM_SUB: 56;----------------------------
2022-11-28 05:54:51 Epoch [05000/30000] Loss:0.103073 Loss_1:0.102235 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000667 Time:18.855089s (1.60min in total, 7.98min remains)
2022-11-28 05:55:10 NUM_SUB: 56;----------------------------
2022-11-28 05:55:10 Epoch [06000/30000] Loss:0.066420 Loss_1:0.065749 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000625 Time:19.045514s (1.91min in total, 7.65min remains)
2022-11-28 05:55:29 NUM_SUB: 56;----------------------------
2022-11-28 05:55:29 Epoch [07000/30000] Loss:0.028576 Loss_1:0.028104 Loss_2:0.000208 Loss_3:0.000000 Lr:0.000588 Time:19.076349s (2.23min in total, 7.33min remains)
2022-11-28 05:55:49 NUM_SUB: 56;----------------------------
2022-11-28 05:55:49 Epoch [08000/30000] Loss:0.006855 Loss_1:0.006545 Loss_2:0.000256 Loss_3:0.000000 Lr:0.000556 Time:19.407658s (2.55min in total, 7.03min remains)
2022-11-28 05:56:08 NUM_SUB: 56;----------------------------
2022-11-28 05:56:08 Epoch [09000/30000] Loss:0.002706 Loss_1:0.002463 Loss_2:0.000243 Loss_3:0.000000 Lr:0.000526 Time:19.358637s (2.88min in total, 6.71min remains)
2022-11-28 05:56:27 NUM_SUB: 56;----------------------------
2022-11-28 05:56:27 Epoch [10000/30000] Loss:0.001659 Loss_1:0.001479 Loss_2:0.000180 Loss_3:0.000000 Lr:0.000500 Time:19.286176s (3.20min in total, 6.40min remains)
2022-11-28 05:56:46 NUM_SUB: 56;----------------------------
2022-11-28 05:56:46 Epoch [11000/30000] Loss:0.000700 Loss_1:0.000592 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000476 Time:19.119663s (3.52min in total, 6.08min remains)
2022-11-28 05:57:06 NUM_SUB: 56;----------------------------
2022-11-28 05:57:06 Epoch [12000/30000] Loss:0.000354 Loss_1:0.000269 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000455 Time:19.488852s (3.84min in total, 5.76min remains)
2022-11-28 05:57:26 NUM_SUB: 56;----------------------------
2022-11-28 05:57:26 Epoch [13000/30000] Loss:0.000306 Loss_1:0.000240 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000435 Time:19.636455s (4.17min in total, 5.45min remains)
2022-11-28 05:57:45 NUM_SUB: 56;----------------------------
2022-11-28 05:57:45 Epoch [14000/30000] Loss:0.000304 Loss_1:0.000256 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000417 Time:19.024870s (4.49min in total, 5.13min remains)
2022-11-28 05:58:04 NUM_SUB: 56;----------------------------
2022-11-28 05:58:04 Epoch [15000/30000] Loss:0.000265 Loss_1:0.000227 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000400 Time:19.259400s (4.81min in total, 4.81min remains)
2022-11-28 05:58:23 NUM_SUB: 56;----------------------------
2022-11-28 05:58:23 Epoch [16000/30000] Loss:0.000267 Loss_1:0.000237 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000385 Time:18.831073s (5.12min in total, 4.48min remains)
2022-11-28 05:58:42 NUM_SUB: 56;----------------------------
2022-11-28 05:58:42 Epoch [17000/30000] Loss:0.000246 Loss_1:0.000222 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000370 Time:19.332862s (5.44min in total, 4.16min remains)
2022-11-28 05:59:01 NUM_SUB: 56;----------------------------
2022-11-28 05:59:01 Epoch [18000/30000] Loss:0.000241 Loss_1:0.000222 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000357 Time:18.899123s (5.76min in total, 3.84min remains)
2022-11-28 05:59:20 NUM_SUB: 56;----------------------------
2022-11-28 05:59:20 Epoch [19000/30000] Loss:0.000241 Loss_1:0.000225 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000345 Time:19.310576s (6.08min in total, 3.52min remains)
2022-11-28 05:59:39 NUM_SUB: 56;----------------------------
2022-11-28 05:59:39 Epoch [20000/30000] Loss:0.000233 Loss_1:0.000221 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000333 Time:18.757743s (6.39min in total, 3.20min remains)
2022-11-28 05:59:58 NUM_SUB: 56;----------------------------
2022-11-28 05:59:58 Epoch [21000/30000] Loss:0.000231 Loss_1:0.000221 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000323 Time:19.247991s (6.71min in total, 2.88min remains)
2022-11-28 06:00:17 NUM_SUB: 56;----------------------------
2022-11-28 06:00:17 Epoch [22000/30000] Loss:0.000229 Loss_1:0.000221 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:18.868002s (7.03min in total, 2.56min remains)
2022-11-28 06:00:36 NUM_SUB: 56;----------------------------
2022-11-28 06:00:36 Epoch [23000/30000] Loss:0.000228 Loss_1:0.000221 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000303 Time:19.209566s (7.35min in total, 2.24min remains)
2022-11-28 06:00:55 NUM_SUB: 56;----------------------------
2022-11-28 06:00:55 Epoch [24000/30000] Loss:0.000226 Loss_1:0.000221 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.010643s (7.67min in total, 1.92min remains)
2022-11-28 06:01:15 NUM_SUB: 56;----------------------------
2022-11-28 06:01:15 Epoch [25000/30000] Loss:0.000225 Loss_1:0.000221 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.399582s (7.99min in total, 1.60min remains)
2022-11-28 06:01:34 NUM_SUB: 56;----------------------------
2022-11-28 06:01:34 Epoch [26000/30000] Loss:0.000225 Loss_1:0.000221 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.076411s (8.31min in total, 1.28min remains)
2022-11-28 06:01:53 NUM_SUB: 56;----------------------------
2022-11-28 06:01:53 Epoch [27000/30000] Loss:0.000224 Loss_1:0.000222 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.056461s (8.62min in total, 0.96min remains)
2022-11-28 06:02:12 NUM_SUB: 56;----------------------------
2022-11-28 06:02:12 Epoch [28000/30000] Loss:0.000223 Loss_1:0.000221 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.236384s (8.95min in total, 0.64min remains)
2022-11-28 06:02:32 NUM_SUB: 56;----------------------------
2022-11-28 06:02:32 Epoch [29000/30000] Loss:0.000223 Loss_1:0.000221 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.539861s (9.27min in total, 0.32min remains)
2022-11-28 06:02:51 NUM_SUB: 56;----------------------------
2022-11-28 06:02:51 Epoch [30000/30000] Loss:0.000223 Loss_1:0.000221 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.124934s (9.59min in total, 0.00min remains)
2022-11-28 06:02:51 Testing & drawing...
2022-11-28 06:02:51 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:02:52 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=56/
2022-11-28 06:02:52 [Loss]
2022-11-28 06:02:52 NUM_SUB: 56; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:02:52 NUM_SUB: 56; Personalized parameter estimation: Parameter containing:
tensor([0.2109, 0.4180, 0.0204, 0.0079, 0.3074, 0.0623, 0.6970, 0.8964, 0.4556,
        0.0147, 0.0262, 0.0157, 0.7694, 0.1689, 0.0176, 1.8953, 0.6977, 0.8000,
        0.0112, 4.6889, 0.6816, 0.0202, 4.4957, 0.8742, 0.0166, 5.1720, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:02:52 NUM_SUB: 56------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:02:52 Testing & drawing...
2022-11-28 06:02:52 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:02:54 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=56/
2022-11-28 06:02:54 [Loss]
2022-11-28 06:02:54 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:02:54 General parameter estimation: Parameter containing:
tensor([0.2109, 0.4180, 0.0204, 0.0079, 0.3074, 0.0623, 0.6970, 0.8964, 0.4556,
        0.0147, 0.0262, 0.0157, 0.7694, 0.1689, 0.0176, 1.8953, 0.6977, 0.8000,
        0.0112, 4.6889, 0.6816, 0.0202, 4.4957, 0.8742, 0.0166, 5.1720, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:02:54 A: prod, degr, TonA, NonA
2022-11-28 06:02:54 [0.39195302 0.4993964  0.03789511 0.07075543]
2022-11-28 06:02:54 T: prod, degr, AonT, NonT
2022-11-28 06:02:54 [0.33439568 0.38141435 0.21360485 0.07058512]
2022-11-28 06:02:54 N: AonN, TonN, ATonN
2022-11-28 06:02:54 [0.01008043 0.95122313 0.0386964 ]
2022-11-28 06:02:54 using cpu
2022-11-28 06:02:54 epoch = 30000
2022-11-28 06:02:54 epoch_step = 1000
2022-11-28 06:02:54 model_name = SimpleNetworkAD
2022-11-28 06:02:54 now_string = 2022-11-27-19-40-13
2022-11-28 06:02:54 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:02:54 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:02:54 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:02:54 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:02:54 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:02:54 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:03:14 NUM_SUB: 57;----------------------------
2022-11-28 06:03:14 Epoch [01000/30000] Loss:0.050262 Loss_1:0.044703 Loss_2:0.001644 Loss_3:0.000000 Lr:0.000909 Time:19.167183s (0.32min in total, 9.26min remains)
2022-11-28 06:03:33 NUM_SUB: 57;----------------------------
2022-11-28 06:03:33 Epoch [02000/30000] Loss:0.043726 Loss_1:0.042783 Loss_2:0.000471 Loss_3:0.000000 Lr:0.000833 Time:19.082236s (0.64min in total, 8.93min remains)
2022-11-28 06:03:52 NUM_SUB: 57;----------------------------
2022-11-28 06:03:52 Epoch [03000/30000] Loss:0.039675 Loss_1:0.039435 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000769 Time:19.155633s (0.96min in total, 8.61min remains)
2022-11-28 06:04:11 NUM_SUB: 57;----------------------------
2022-11-28 06:04:11 Epoch [04000/30000] Loss:0.036657 Loss_1:0.036309 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000714 Time:18.938203s (1.27min in total, 8.27min remains)
2022-11-28 06:04:30 NUM_SUB: 57;----------------------------
2022-11-28 06:04:30 Epoch [05000/30000] Loss:0.029810 Loss_1:0.029571 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000667 Time:19.193820s (1.59min in total, 7.96min remains)
2022-11-28 06:04:49 NUM_SUB: 57;----------------------------
2022-11-28 06:04:49 Epoch [06000/30000] Loss:0.022418 Loss_1:0.022215 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000625 Time:19.535348s (1.92min in total, 7.67min remains)
2022-11-28 06:05:09 NUM_SUB: 57;----------------------------
2022-11-28 06:05:09 Epoch [07000/30000] Loss:0.014332 Loss_1:0.014171 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000588 Time:19.128993s (2.24min in total, 7.35min remains)
2022-11-28 06:05:28 NUM_SUB: 57;----------------------------
2022-11-28 06:05:28 Epoch [08000/30000] Loss:0.008442 Loss_1:0.008331 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000556 Time:19.212004s (2.56min in total, 7.03min remains)
2022-11-28 06:05:47 NUM_SUB: 57;----------------------------
2022-11-28 06:05:47 Epoch [09000/30000] Loss:0.005979 Loss_1:0.005894 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000526 Time:19.096407s (2.88min in total, 6.71min remains)
2022-11-28 06:06:06 NUM_SUB: 57;----------------------------
2022-11-28 06:06:06 Epoch [10000/30000] Loss:0.005078 Loss_1:0.005010 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000500 Time:19.325601s (3.20min in total, 6.39min remains)
2022-11-28 06:06:25 NUM_SUB: 57;----------------------------
2022-11-28 06:06:25 Epoch [11000/30000] Loss:0.004667 Loss_1:0.004608 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000476 Time:19.023298s (3.51min in total, 6.07min remains)
2022-11-28 06:06:44 NUM_SUB: 57;----------------------------
2022-11-28 06:06:44 Epoch [12000/30000] Loss:0.004290 Loss_1:0.004239 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000455 Time:19.125466s (3.83min in total, 5.75min remains)
2022-11-28 06:07:03 NUM_SUB: 57;----------------------------
2022-11-28 06:07:03 Epoch [13000/30000] Loss:0.003846 Loss_1:0.003817 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000435 Time:19.010200s (4.15min in total, 5.43min remains)
2022-11-28 06:07:23 NUM_SUB: 57;----------------------------
2022-11-28 06:07:23 Epoch [14000/30000] Loss:0.003523 Loss_1:0.003501 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:19.288485s (4.47min in total, 5.11min remains)
2022-11-28 06:07:42 NUM_SUB: 57;----------------------------
2022-11-28 06:07:42 Epoch [15000/30000] Loss:0.003388 Loss_1:0.003369 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:19.113927s (4.79min in total, 4.79min remains)
2022-11-28 06:08:01 NUM_SUB: 57;----------------------------
2022-11-28 06:08:01 Epoch [16000/30000] Loss:0.003354 Loss_1:0.003337 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:19.122728s (5.11min in total, 4.47min remains)
2022-11-28 06:08:20 NUM_SUB: 57;----------------------------
2022-11-28 06:08:20 Epoch [17000/30000] Loss:0.003346 Loss_1:0.003334 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.167103s (5.43min in total, 4.15min remains)
2022-11-28 06:08:39 NUM_SUB: 57;----------------------------
2022-11-28 06:08:39 Epoch [18000/30000] Loss:0.003339 Loss_1:0.003325 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:19.348758s (5.75min in total, 3.83min remains)
2022-11-28 06:08:59 NUM_SUB: 57;----------------------------
2022-11-28 06:08:59 Epoch [19000/30000] Loss:0.003331 Loss_1:0.003322 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.347171s (6.07min in total, 3.52min remains)
2022-11-28 06:09:18 NUM_SUB: 57;----------------------------
2022-11-28 06:09:18 Epoch [20000/30000] Loss:0.003329 Loss_1:0.003321 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:18.913220s (6.39min in total, 3.19min remains)
2022-11-28 06:09:37 NUM_SUB: 57;----------------------------
2022-11-28 06:09:37 Epoch [21000/30000] Loss:0.003328 Loss_1:0.003321 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.375546s (6.71min in total, 2.88min remains)
2022-11-28 06:09:56 NUM_SUB: 57;----------------------------
2022-11-28 06:09:56 Epoch [22000/30000] Loss:0.003327 Loss_1:0.003322 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.221085s (7.03min in total, 2.56min remains)
2022-11-28 06:10:16 NUM_SUB: 57;----------------------------
2022-11-28 06:10:16 Epoch [23000/30000] Loss:0.003326 Loss_1:0.003322 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.320550s (7.35min in total, 2.24min remains)
2022-11-28 06:10:34 NUM_SUB: 57;----------------------------
2022-11-28 06:10:34 Epoch [24000/30000] Loss:0.003326 Loss_1:0.003322 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.832632s (7.67min in total, 1.92min remains)
2022-11-28 06:10:54 NUM_SUB: 57;----------------------------
2022-11-28 06:10:54 Epoch [25000/30000] Loss:0.003325 Loss_1:0.003321 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.215972s (7.99min in total, 1.60min remains)
2022-11-28 06:11:13 NUM_SUB: 57;----------------------------
2022-11-28 06:11:13 Epoch [26000/30000] Loss:0.003349 Loss_1:0.003348 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.958339s (8.30min in total, 1.28min remains)
2022-11-28 06:11:32 NUM_SUB: 57;----------------------------
2022-11-28 06:11:32 Epoch [27000/30000] Loss:0.003367 Loss_1:0.003363 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.213439s (8.62min in total, 0.96min remains)
2022-11-28 06:11:51 NUM_SUB: 57;----------------------------
2022-11-28 06:11:51 Epoch [28000/30000] Loss:0.003329 Loss_1:0.003327 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.136006s (8.94min in total, 0.64min remains)
2022-11-28 06:12:10 NUM_SUB: 57;----------------------------
2022-11-28 06:12:10 Epoch [29000/30000] Loss:0.003325 Loss_1:0.003322 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.821255s (9.26min in total, 0.32min remains)
2022-11-28 06:12:29 NUM_SUB: 57;----------------------------
2022-11-28 06:12:29 Epoch [30000/30000] Loss:0.003324 Loss_1:0.003322 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.548953s (9.58min in total, 0.00min remains)
2022-11-28 06:12:29 Testing & drawing...
2022-11-28 06:12:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:12:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=57/
2022-11-28 06:12:31 [Loss]
2022-11-28 06:12:31 NUM_SUB: 57; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:12:31 NUM_SUB: 57; Personalized parameter estimation: Parameter containing:
tensor([0.3808, 0.9037, 0.0103, 0.0346, 0.3074, 0.0419, 0.7599, 0.8964, 0.4556,
        0.0135, 0.0313, 0.0129, 0.8622, 0.1689, 0.0160, 2.7362, 0.6977, 0.8000,
        0.0119, 4.1880, 0.6816, 0.0222, 3.8811, 0.8742, 0.0193, 4.6488, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:12:31 NUM_SUB: 57------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:12:31 Testing & drawing...
2022-11-28 06:12:31 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:12:33 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=57/
2022-11-28 06:12:33 [Loss]
2022-11-28 06:12:33 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:12:33 General parameter estimation: Parameter containing:
tensor([0.3808, 0.9037, 0.0103, 0.0346, 0.3074, 0.0419, 0.7599, 0.8964, 0.4556,
        0.0135, 0.0313, 0.0129, 0.8622, 0.1689, 0.0160, 2.7362, 0.6977, 0.8000,
        0.0119, 4.1880, 0.6816, 0.0222, 3.8811, 0.8742, 0.0193, 4.6488, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:12:33 A: prod, degr, TonA, NonA
2022-11-28 06:12:33 [0.4690465  0.4999627  0.01268173 0.01830909]
2022-11-28 06:12:33 T: prod, degr, AonT, NonT
2022-11-28 06:12:33 [0.42558366 0.4430911  0.11085461 0.02047061]
2022-11-28 06:12:33 N: AonN, TonN, ATonN
2022-11-28 06:12:33 [0.00656443 0.9728738  0.0205618 ]
2022-11-28 06:12:33 using cpu
2022-11-28 06:12:33 epoch = 30000
2022-11-28 06:12:33 epoch_step = 1000
2022-11-28 06:12:33 model_name = SimpleNetworkAD
2022-11-28 06:12:33 now_string = 2022-11-27-19-40-13
2022-11-28 06:12:33 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:12:33 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:12:33 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:12:33 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:12:33 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:12:33 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:12:52 NUM_SUB: 58;----------------------------
2022-11-28 06:12:52 Epoch [01000/30000] Loss:0.056438 Loss_1:0.051152 Loss_2:0.001522 Loss_3:0.000000 Lr:0.000909 Time:19.207678s (0.32min in total, 9.28min remains)
2022-11-28 06:13:11 NUM_SUB: 58;----------------------------
2022-11-28 06:13:11 Epoch [02000/30000] Loss:0.049995 Loss_1:0.049177 Loss_2:0.000414 Loss_3:0.000000 Lr:0.000833 Time:18.990102s (0.64min in total, 8.91min remains)
2022-11-28 06:13:30 NUM_SUB: 58;----------------------------
2022-11-28 06:13:30 Epoch [03000/30000] Loss:0.046276 Loss_1:0.046103 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000769 Time:19.263283s (0.96min in total, 8.62min remains)
2022-11-28 06:13:49 NUM_SUB: 58;----------------------------
2022-11-28 06:13:49 Epoch [04000/30000] Loss:0.042472 Loss_1:0.042303 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000714 Time:18.969745s (1.27min in total, 8.28min remains)
2022-11-28 06:14:08 NUM_SUB: 58;----------------------------
2022-11-28 06:14:08 Epoch [05000/30000] Loss:0.037422 Loss_1:0.037273 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000667 Time:19.041358s (1.59min in total, 7.96min remains)
2022-11-28 06:14:27 NUM_SUB: 58;----------------------------
2022-11-28 06:14:27 Epoch [06000/30000] Loss:0.030830 Loss_1:0.030706 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000625 Time:18.966238s (1.91min in total, 7.63min remains)
2022-11-28 06:14:46 NUM_SUB: 58;----------------------------
2022-11-28 06:14:46 Epoch [07000/30000] Loss:0.023753 Loss_1:0.023659 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000588 Time:18.877640s (2.22min in total, 7.30min remains)
2022-11-28 06:15:05 NUM_SUB: 58;----------------------------
2022-11-28 06:15:05 Epoch [08000/30000] Loss:0.018967 Loss_1:0.018896 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000556 Time:19.222238s (2.54min in total, 6.99min remains)
2022-11-28 06:15:24 NUM_SUB: 58;----------------------------
2022-11-28 06:15:24 Epoch [09000/30000] Loss:0.017402 Loss_1:0.017340 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000526 Time:18.714791s (2.85min in total, 6.66min remains)
2022-11-28 06:15:43 NUM_SUB: 58;----------------------------
2022-11-28 06:15:43 Epoch [10000/30000] Loss:0.016809 Loss_1:0.016738 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000500 Time:18.790110s (3.17min in total, 6.34min remains)
2022-11-28 06:16:02 NUM_SUB: 58;----------------------------
2022-11-28 06:16:02 Epoch [11000/30000] Loss:0.015989 Loss_1:0.015922 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:18.848409s (3.48min in total, 6.01min remains)
2022-11-28 06:16:21 NUM_SUB: 58;----------------------------
2022-11-28 06:16:21 Epoch [12000/30000] Loss:0.014433 Loss_1:0.014397 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000455 Time:19.194540s (3.80min in total, 5.70min remains)
2022-11-28 06:16:40 NUM_SUB: 58;----------------------------
2022-11-28 06:16:40 Epoch [13000/30000] Loss:0.011406 Loss_1:0.011363 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000435 Time:19.460760s (4.13min in total, 5.40min remains)
2022-11-28 06:16:59 NUM_SUB: 58;----------------------------
2022-11-28 06:16:59 Epoch [14000/30000] Loss:0.008474 Loss_1:0.008426 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000417 Time:18.749756s (4.44min in total, 5.07min remains)
2022-11-28 06:17:18 NUM_SUB: 58;----------------------------
2022-11-28 06:17:18 Epoch [15000/30000] Loss:0.008242 Loss_1:0.008209 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000400 Time:19.096825s (4.76min in total, 4.76min remains)
2022-11-28 06:17:37 NUM_SUB: 58;----------------------------
2022-11-28 06:17:37 Epoch [16000/30000] Loss:0.008224 Loss_1:0.008201 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000385 Time:18.611073s (5.07min in total, 4.43min remains)
2022-11-28 06:17:56 NUM_SUB: 58;----------------------------
2022-11-28 06:17:56 Epoch [17000/30000] Loss:0.008216 Loss_1:0.008197 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:18.956751s (5.38min in total, 4.12min remains)
2022-11-28 06:18:15 NUM_SUB: 58;----------------------------
2022-11-28 06:18:15 Epoch [18000/30000] Loss:0.008211 Loss_1:0.008198 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:18.810866s (5.70min in total, 3.80min remains)
2022-11-28 06:18:34 NUM_SUB: 58;----------------------------
2022-11-28 06:18:34 Epoch [19000/30000] Loss:0.008205 Loss_1:0.008193 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:19.562072s (6.02min in total, 3.49min remains)
2022-11-28 06:18:53 NUM_SUB: 58;----------------------------
2022-11-28 06:18:53 Epoch [20000/30000] Loss:0.008200 Loss_1:0.008190 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:18.837173s (6.34min in total, 3.17min remains)
2022-11-28 06:19:12 NUM_SUB: 58;----------------------------
2022-11-28 06:19:12 Epoch [21000/30000] Loss:0.008198 Loss_1:0.008188 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000323 Time:19.343354s (6.66min in total, 2.85min remains)
2022-11-28 06:19:31 NUM_SUB: 58;----------------------------
2022-11-28 06:19:31 Epoch [22000/30000] Loss:0.008196 Loss_1:0.008190 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:18.701926s (6.97min in total, 2.53min remains)
2022-11-28 06:19:50 NUM_SUB: 58;----------------------------
2022-11-28 06:19:50 Epoch [23000/30000] Loss:0.008195 Loss_1:0.008189 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:18.788795s (7.28min in total, 2.22min remains)
2022-11-28 06:20:09 NUM_SUB: 58;----------------------------
2022-11-28 06:20:09 Epoch [24000/30000] Loss:0.008195 Loss_1:0.008192 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:18.933619s (7.60min in total, 1.90min remains)
2022-11-28 06:20:27 NUM_SUB: 58;----------------------------
2022-11-28 06:20:27 Epoch [25000/30000] Loss:0.008194 Loss_1:0.008189 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.565907s (7.91min in total, 1.58min remains)
2022-11-28 06:20:46 NUM_SUB: 58;----------------------------
2022-11-28 06:20:46 Epoch [26000/30000] Loss:0.008201 Loss_1:0.008195 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:18.956317s (8.22min in total, 1.27min remains)
2022-11-28 06:21:05 NUM_SUB: 58;----------------------------
2022-11-28 06:21:05 Epoch [27000/30000] Loss:0.008193 Loss_1:0.008189 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.123184s (8.54min in total, 0.95min remains)
2022-11-28 06:21:24 NUM_SUB: 58;----------------------------
2022-11-28 06:21:24 Epoch [28000/30000] Loss:0.008192 Loss_1:0.008188 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:18.902801s (8.86min in total, 0.63min remains)
2022-11-28 06:21:44 NUM_SUB: 58;----------------------------
2022-11-28 06:21:44 Epoch [29000/30000] Loss:0.008193 Loss_1:0.008190 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.292189s (9.18min in total, 0.32min remains)
2022-11-28 06:22:02 NUM_SUB: 58;----------------------------
2022-11-28 06:22:02 Epoch [30000/30000] Loss:0.008192 Loss_1:0.008189 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.780343s (9.49min in total, 0.00min remains)
2022-11-28 06:22:02 Testing & drawing...
2022-11-28 06:22:02 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:22:04 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=58/
2022-11-28 06:22:04 [Loss]
2022-11-28 06:22:04 NUM_SUB: 58; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:22:04 NUM_SUB: 58; Personalized parameter estimation: Parameter containing:
tensor([0.3282, 0.9521, 0.0096, 0.0086, 0.3074, 0.0422, 0.7707, 0.8964, 0.4556,
        0.0144, 0.0220, 0.0125, 0.8483, 0.1689, 0.0150, 2.6593, 0.6977, 0.8000,
        0.0120, 4.0749, 0.6816, 0.0183, 4.3310, 0.8742, 0.0188, 4.9933, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:22:04 NUM_SUB: 58------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:22:04 Testing & drawing...
2022-11-28 06:22:04 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:22:06 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=58/
2022-11-28 06:22:06 [Loss]
2022-11-28 06:22:06 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:22:06 General parameter estimation: Parameter containing:
tensor([0.3282, 0.9521, 0.0096, 0.0086, 0.3074, 0.0422, 0.7707, 0.8964, 0.4556,
        0.0144, 0.0220, 0.0125, 0.8483, 0.1689, 0.0150, 2.6593, 0.6977, 0.8000,
        0.0120, 4.0749, 0.6816, 0.0183, 4.3310, 0.8742, 0.0188, 4.9933, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:22:06 A: prod, degr, TonA, NonA
2022-11-28 06:22:06 [0.46568993 0.49997687 0.01359495 0.02073823]
2022-11-28 06:22:06 T: prod, degr, AonT, NonT
2022-11-28 06:22:06 [0.5111734  0.28841656 0.17779237 0.02261765]
2022-11-28 06:22:06 N: AonN, TonN, ATonN
2022-11-28 06:22:06 [0.00578345 0.9650513  0.02916529]
2022-11-28 06:22:06 using cpu
2022-11-28 06:22:06 epoch = 30000
2022-11-28 06:22:06 epoch_step = 1000
2022-11-28 06:22:06 model_name = SimpleNetworkAD
2022-11-28 06:22:06 now_string = 2022-11-27-19-40-13
2022-11-28 06:22:06 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:22:06 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:22:06 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:22:06 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:22:06 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:22:06 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:22:25 NUM_SUB: 59;----------------------------
2022-11-28 06:22:25 Epoch [01000/30000] Loss:0.043402 Loss_1:0.037046 Loss_2:0.002223 Loss_3:0.000000 Lr:0.000909 Time:18.852284s (0.31min in total, 9.11min remains)
2022-11-28 06:22:44 NUM_SUB: 59;----------------------------
2022-11-28 06:22:44 Epoch [02000/30000] Loss:0.037365 Loss_1:0.035979 Loss_2:0.000790 Loss_3:0.000000 Lr:0.000833 Time:19.144050s (0.63min in total, 8.87min remains)
2022-11-28 06:23:03 NUM_SUB: 59;----------------------------
2022-11-28 06:23:03 Epoch [03000/30000] Loss:0.034167 Loss_1:0.033638 Loss_2:0.000281 Loss_3:0.000000 Lr:0.000769 Time:18.877729s (0.95min in total, 8.53min remains)
2022-11-28 06:23:22 NUM_SUB: 59;----------------------------
2022-11-28 06:23:22 Epoch [04000/30000] Loss:0.030821 Loss_1:0.030300 Loss_2:0.000239 Loss_3:0.000000 Lr:0.000714 Time:19.293851s (1.27min in total, 8.25min remains)
2022-11-28 06:23:41 NUM_SUB: 59;----------------------------
2022-11-28 06:23:41 Epoch [05000/30000] Loss:0.025783 Loss_1:0.025127 Loss_2:0.000371 Loss_3:0.000000 Lr:0.000667 Time:18.932319s (1.59min in total, 7.93min remains)
2022-11-28 06:24:00 NUM_SUB: 59;----------------------------
2022-11-28 06:24:00 Epoch [06000/30000] Loss:0.019110 Loss_1:0.018631 Loss_2:0.000247 Loss_3:0.000000 Lr:0.000625 Time:19.202383s (1.91min in total, 7.62min remains)
2022-11-28 06:24:19 NUM_SUB: 59;----------------------------
2022-11-28 06:24:19 Epoch [07000/30000] Loss:0.013088 Loss_1:0.012670 Loss_2:0.000262 Loss_3:0.000000 Lr:0.000588 Time:19.039156s (2.22min in total, 7.30min remains)
2022-11-28 06:24:39 NUM_SUB: 59;----------------------------
2022-11-28 06:24:39 Epoch [08000/30000] Loss:0.006621 Loss_1:0.006337 Loss_2:0.000203 Loss_3:0.000000 Lr:0.000556 Time:19.297750s (2.54min in total, 7.00min remains)
2022-11-28 06:24:58 NUM_SUB: 59;----------------------------
2022-11-28 06:24:58 Epoch [09000/30000] Loss:0.002830 Loss_1:0.002619 Loss_2:0.000189 Loss_3:0.000000 Lr:0.000526 Time:19.376443s (2.87min in total, 6.69min remains)
2022-11-28 06:25:17 NUM_SUB: 59;----------------------------
2022-11-28 06:25:17 Epoch [10000/30000] Loss:0.001836 Loss_1:0.001671 Loss_2:0.000162 Loss_3:0.000000 Lr:0.000500 Time:19.050490s (3.18min in total, 6.37min remains)
2022-11-28 06:25:36 NUM_SUB: 59;----------------------------
2022-11-28 06:25:36 Epoch [11000/30000] Loss:0.001711 Loss_1:0.001581 Loss_2:0.000128 Loss_3:0.000000 Lr:0.000476 Time:18.943160s (3.50min in total, 6.05min remains)
2022-11-28 06:25:55 NUM_SUB: 59;----------------------------
2022-11-28 06:25:55 Epoch [12000/30000] Loss:0.001612 Loss_1:0.001508 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000455 Time:19.033005s (3.82min in total, 5.73min remains)
2022-11-28 06:26:15 NUM_SUB: 59;----------------------------
2022-11-28 06:26:15 Epoch [13000/30000] Loss:0.001463 Loss_1:0.001391 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000435 Time:19.526096s (4.14min in total, 5.42min remains)
2022-11-28 06:26:34 NUM_SUB: 59;----------------------------
2022-11-28 06:26:34 Epoch [14000/30000] Loss:0.001267 Loss_1:0.001211 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000417 Time:19.170454s (4.46min in total, 5.10min remains)
2022-11-28 06:26:53 NUM_SUB: 59;----------------------------
2022-11-28 06:26:53 Epoch [15000/30000] Loss:0.001072 Loss_1:0.001023 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000400 Time:19.022845s (4.78min in total, 4.78min remains)
2022-11-28 06:27:12 NUM_SUB: 59;----------------------------
2022-11-28 06:27:12 Epoch [16000/30000] Loss:0.000978 Loss_1:0.000935 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000385 Time:19.241854s (5.10min in total, 4.46min remains)
2022-11-28 06:27:31 NUM_SUB: 59;----------------------------
2022-11-28 06:27:31 Epoch [17000/30000] Loss:0.000960 Loss_1:0.000925 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000370 Time:18.953603s (5.42min in total, 4.14min remains)
2022-11-28 06:27:50 NUM_SUB: 59;----------------------------
2022-11-28 06:27:50 Epoch [18000/30000] Loss:0.000951 Loss_1:0.000924 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000357 Time:19.141582s (5.74min in total, 3.82min remains)
2022-11-28 06:28:09 NUM_SUB: 59;----------------------------
2022-11-28 06:28:09 Epoch [19000/30000] Loss:0.000947 Loss_1:0.000923 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000345 Time:19.303965s (6.06min in total, 3.51min remains)
2022-11-28 06:28:29 NUM_SUB: 59;----------------------------
2022-11-28 06:28:29 Epoch [20000/30000] Loss:0.000938 Loss_1:0.000920 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000333 Time:19.306655s (6.38min in total, 3.19min remains)
2022-11-28 06:28:49 NUM_SUB: 59;----------------------------
2022-11-28 06:28:49 Epoch [21000/30000] Loss:0.000933 Loss_1:0.000917 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000323 Time:20.032032s (6.71min in total, 2.88min remains)
2022-11-28 06:29:08 NUM_SUB: 59;----------------------------
2022-11-28 06:29:08 Epoch [22000/30000] Loss:0.000930 Loss_1:0.000917 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000313 Time:19.194560s (7.03min in total, 2.56min remains)
2022-11-28 06:29:27 NUM_SUB: 59;----------------------------
2022-11-28 06:29:27 Epoch [23000/30000] Loss:0.000927 Loss_1:0.000915 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000303 Time:19.596163s (7.36min in total, 2.24min remains)
2022-11-28 06:29:47 NUM_SUB: 59;----------------------------
2022-11-28 06:29:47 Epoch [24000/30000] Loss:0.000925 Loss_1:0.000915 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000294 Time:19.009362s (7.68min in total, 1.92min remains)
2022-11-28 06:30:06 NUM_SUB: 59;----------------------------
2022-11-28 06:30:06 Epoch [25000/30000] Loss:0.000923 Loss_1:0.000914 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000286 Time:19.360338s (8.00min in total, 1.60min remains)
2022-11-28 06:30:25 NUM_SUB: 59;----------------------------
2022-11-28 06:30:25 Epoch [26000/30000] Loss:0.000922 Loss_1:0.000914 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:18.999487s (8.32min in total, 1.28min remains)
2022-11-28 06:30:44 NUM_SUB: 59;----------------------------
2022-11-28 06:30:44 Epoch [27000/30000] Loss:0.000925 Loss_1:0.000919 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000270 Time:19.416536s (8.64min in total, 0.96min remains)
2022-11-28 06:31:03 NUM_SUB: 59;----------------------------
2022-11-28 06:31:03 Epoch [28000/30000] Loss:0.000920 Loss_1:0.000914 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:18.845709s (8.95min in total, 0.64min remains)
2022-11-28 06:31:22 NUM_SUB: 59;----------------------------
2022-11-28 06:31:22 Epoch [29000/30000] Loss:0.000920 Loss_1:0.000914 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000256 Time:19.262663s (9.27min in total, 0.32min remains)
2022-11-28 06:31:41 NUM_SUB: 59;----------------------------
2022-11-28 06:31:41 Epoch [30000/30000] Loss:0.000919 Loss_1:0.000913 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:18.927897s (9.59min in total, 0.00min remains)
2022-11-28 06:31:41 Testing & drawing...
2022-11-28 06:31:41 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:31:43 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=59/
2022-11-28 06:31:43 [Loss]
2022-11-28 06:31:43 NUM_SUB: 59; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:31:43 NUM_SUB: 59; Personalized parameter estimation: Parameter containing:
tensor([0.0172, 0.0623, 0.0234, 1.2982, 0.3074, 0.5254, 1.4624, 0.8964, 0.4556,
        0.0130, 0.0276, 0.0136, 0.6891, 0.1689, 0.0176, 1.3702, 0.6977, 0.8000,
        0.0070, 5.4402, 0.6816, 0.0221, 4.3453, 0.8742, 0.0158, 5.4148, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:31:43 NUM_SUB: 59------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:31:43 Testing & drawing...
2022-11-28 06:31:43 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:31:45 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=59/
2022-11-28 06:31:45 [Loss]
2022-11-28 06:31:45 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:31:45 General parameter estimation: Parameter containing:
tensor([0.0172, 0.0623, 0.0234, 1.2982, 0.3074, 0.5254, 1.4624, 0.8964, 0.4556,
        0.0130, 0.0276, 0.0136, 0.6891, 0.1689, 0.0176, 1.3702, 0.6977, 0.8000,
        0.0070, 5.4402, 0.6816, 0.0221, 4.3453, 0.8742, 0.0158, 5.4148, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:31:45 A: prod, degr, TonA, NonA
2022-11-28 06:31:45 [0.1297023  0.4906552  0.04144315 0.33819932]
2022-11-28 06:31:45 T: prod, degr, AonT, NonT
2022-11-28 06:31:45 [0.25746635 0.5699454  0.13915747 0.03343086]
2022-11-28 06:31:45 N: AonN, TonN, ATonN
2022-11-28 06:31:45 [0.01186783 0.94916296 0.03896921]
2022-11-28 06:31:45 using cpu
2022-11-28 06:31:45 epoch = 30000
2022-11-28 06:31:45 epoch_step = 1000
2022-11-28 06:31:45 model_name = SimpleNetworkAD
2022-11-28 06:31:45 now_string = 2022-11-27-19-40-13
2022-11-28 06:31:45 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:31:45 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:31:45 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:31:45 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:31:45 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:31:45 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:32:04 NUM_SUB: 60;----------------------------
2022-11-28 06:32:04 Epoch [01000/30000] Loss:0.050041 Loss_1:0.044458 Loss_2:0.001801 Loss_3:0.000000 Lr:0.000909 Time:19.489653s (0.32min in total, 9.42min remains)
2022-11-28 06:32:23 NUM_SUB: 60;----------------------------
2022-11-28 06:32:23 Epoch [02000/30000] Loss:0.042902 Loss_1:0.041802 Loss_2:0.000694 Loss_3:0.000000 Lr:0.000833 Time:19.130634s (0.64min in total, 9.01min remains)
2022-11-28 06:32:42 NUM_SUB: 60;----------------------------
2022-11-28 06:32:42 Epoch [03000/30000] Loss:0.038232 Loss_1:0.037791 Loss_2:0.000384 Loss_3:0.000000 Lr:0.000769 Time:18.886006s (0.96min in total, 8.63min remains)
2022-11-28 06:33:01 NUM_SUB: 60;----------------------------
2022-11-28 06:33:01 Epoch [04000/30000] Loss:0.032823 Loss_1:0.032490 Loss_2:0.000243 Loss_3:0.000000 Lr:0.000714 Time:19.139885s (1.28min in total, 8.30min remains)
2022-11-28 06:33:21 NUM_SUB: 60;----------------------------
2022-11-28 06:33:21 Epoch [05000/30000] Loss:0.026080 Loss_1:0.025816 Loss_2:0.000180 Loss_3:0.000000 Lr:0.000667 Time:19.307458s (1.60min in total, 8.00min remains)
2022-11-28 06:33:40 NUM_SUB: 60;----------------------------
2022-11-28 06:33:40 Epoch [06000/30000] Loss:0.018193 Loss_1:0.017978 Loss_2:0.000151 Loss_3:0.000000 Lr:0.000625 Time:19.143303s (1.92min in total, 7.67min remains)
2022-11-28 06:33:59 NUM_SUB: 60;----------------------------
2022-11-28 06:33:59 Epoch [07000/30000] Loss:0.011299 Loss_1:0.011162 Loss_2:0.000100 Loss_3:0.000000 Lr:0.000588 Time:19.467926s (2.24min in total, 7.37min remains)
2022-11-28 06:34:19 NUM_SUB: 60;----------------------------
2022-11-28 06:34:19 Epoch [08000/30000] Loss:0.007836 Loss_1:0.007764 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000556 Time:19.270355s (2.56min in total, 7.05min remains)
2022-11-28 06:34:38 NUM_SUB: 60;----------------------------
2022-11-28 06:34:38 Epoch [09000/30000] Loss:0.006696 Loss_1:0.006631 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000526 Time:19.226029s (2.88min in total, 6.73min remains)
2022-11-28 06:34:57 NUM_SUB: 60;----------------------------
2022-11-28 06:34:57 Epoch [10000/30000] Loss:0.006170 Loss_1:0.006104 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000500 Time:19.176692s (3.20min in total, 6.41min remains)
2022-11-28 06:35:16 NUM_SUB: 60;----------------------------
2022-11-28 06:35:16 Epoch [11000/30000] Loss:0.005901 Loss_1:0.005837 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000476 Time:19.020733s (3.52min in total, 6.08min remains)
2022-11-28 06:35:35 NUM_SUB: 60;----------------------------
2022-11-28 06:35:35 Epoch [12000/30000] Loss:0.005615 Loss_1:0.005576 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000455 Time:19.186302s (3.84min in total, 5.76min remains)
2022-11-28 06:35:55 NUM_SUB: 60;----------------------------
2022-11-28 06:35:55 Epoch [13000/30000] Loss:0.005343 Loss_1:0.005318 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000435 Time:19.346077s (4.16min in total, 5.44min remains)
2022-11-28 06:36:14 NUM_SUB: 60;----------------------------
2022-11-28 06:36:14 Epoch [14000/30000] Loss:0.005175 Loss_1:0.005155 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:19.391144s (4.49min in total, 5.13min remains)
2022-11-28 06:36:33 NUM_SUB: 60;----------------------------
2022-11-28 06:36:33 Epoch [15000/30000] Loss:0.005032 Loss_1:0.005016 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:19.147932s (4.81min in total, 4.81min remains)
2022-11-28 06:36:53 NUM_SUB: 60;----------------------------
2022-11-28 06:36:53 Epoch [16000/30000] Loss:0.004766 Loss_1:0.004754 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:19.359861s (5.13min in total, 4.49min remains)
2022-11-28 06:37:12 NUM_SUB: 60;----------------------------
2022-11-28 06:37:12 Epoch [17000/30000] Loss:0.004022 Loss_1:0.004011 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000370 Time:19.688975s (5.46min in total, 4.17min remains)
2022-11-28 06:37:32 NUM_SUB: 60;----------------------------
2022-11-28 06:37:32 Epoch [18000/30000] Loss:0.003751 Loss_1:0.003742 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:19.281151s (5.78min in total, 3.85min remains)
2022-11-28 06:37:51 NUM_SUB: 60;----------------------------
2022-11-28 06:37:51 Epoch [19000/30000] Loss:0.003722 Loss_1:0.003712 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.068418s (6.10min in total, 3.53min remains)
2022-11-28 06:38:10 NUM_SUB: 60;----------------------------
2022-11-28 06:38:10 Epoch [20000/30000] Loss:0.003718 Loss_1:0.003709 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:19.037779s (6.41min in total, 3.21min remains)
2022-11-28 06:38:29 NUM_SUB: 60;----------------------------
2022-11-28 06:38:29 Epoch [21000/30000] Loss:0.003712 Loss_1:0.003703 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:19.730532s (6.74min in total, 2.89min remains)
2022-11-28 06:38:49 NUM_SUB: 60;----------------------------
2022-11-28 06:38:49 Epoch [22000/30000] Loss:0.003705 Loss_1:0.003696 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:19.240199s (7.06min in total, 2.57min remains)
2022-11-28 06:39:08 NUM_SUB: 60;----------------------------
2022-11-28 06:39:08 Epoch [23000/30000] Loss:0.003699 Loss_1:0.003691 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:19.291787s (7.38min in total, 2.25min remains)
2022-11-28 06:39:28 NUM_SUB: 60;----------------------------
2022-11-28 06:39:28 Epoch [24000/30000] Loss:0.003695 Loss_1:0.003689 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:19.963283s (7.72min in total, 1.93min remains)
2022-11-28 06:39:47 NUM_SUB: 60;----------------------------
2022-11-28 06:39:47 Epoch [25000/30000] Loss:0.003691 Loss_1:0.003683 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000286 Time:19.265837s (8.04min in total, 1.61min remains)
2022-11-28 06:40:07 NUM_SUB: 60;----------------------------
2022-11-28 06:40:07 Epoch [26000/30000] Loss:0.003688 Loss_1:0.003680 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:20.061929s (8.37min in total, 1.29min remains)
2022-11-28 06:40:26 NUM_SUB: 60;----------------------------
2022-11-28 06:40:26 Epoch [27000/30000] Loss:0.003685 Loss_1:0.003677 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:18.947614s (8.69min in total, 0.97min remains)
2022-11-28 06:40:45 NUM_SUB: 60;----------------------------
2022-11-28 06:40:45 Epoch [28000/30000] Loss:0.003682 Loss_1:0.003677 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.141883s (9.01min in total, 0.64min remains)
2022-11-28 06:41:04 NUM_SUB: 60;----------------------------
2022-11-28 06:41:04 Epoch [29000/30000] Loss:0.003680 Loss_1:0.003676 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.100529s (9.33min in total, 0.32min remains)
2022-11-28 06:41:23 NUM_SUB: 60;----------------------------
2022-11-28 06:41:23 Epoch [30000/30000] Loss:0.003680 Loss_1:0.003676 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.100760s (9.64min in total, 0.00min remains)
2022-11-28 06:41:23 Testing & drawing...
2022-11-28 06:41:23 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:41:25 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=60/
2022-11-28 06:41:25 [Loss]
2022-11-28 06:41:25 NUM_SUB: 60; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:41:25 NUM_SUB: 60; Personalized parameter estimation: Parameter containing:
tensor([0.0119, 0.0454, 0.0093, 2.7782, 0.3074, 0.0173, 3.5669, 0.8964, 0.4556,
        0.0141, 0.2119, 0.1641, 0.4585, 0.1689, 0.0175, 1.3500, 0.6977, 0.8000,
        0.0126, 0.5377, 0.6816, 0.0225, 2.1886, 0.8742, 0.0212, 2.4874, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:41:25 NUM_SUB: 60------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:41:25 Testing & drawing...
2022-11-28 06:41:25 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:41:27 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=60/
2022-11-28 06:41:27 [Loss]
2022-11-28 06:41:27 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:41:27 General parameter estimation: Parameter containing:
tensor([0.0119, 0.0454, 0.0093, 2.7782, 0.3074, 0.0173, 3.5669, 0.8964, 0.4556,
        0.0141, 0.2119, 0.1641, 0.4585, 0.1689, 0.0175, 1.3500, 0.6977, 0.8000,
        0.0126, 0.5377, 0.6816, 0.0225, 2.1886, 0.8742, 0.0212, 2.4874, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:41:27 A: prod, degr, TonA, NonA
2022-11-28 06:41:27 [0.4903974  0.46343252 0.01098119 0.03518888]
2022-11-28 06:41:27 T: prod, degr, AonT, NonT
2022-11-28 06:41:27 [0.09260055 0.34011707 0.53993076 0.02735161]
2022-11-28 06:41:27 N: AonN, TonN, ATonN
2022-11-28 06:41:27 [0.10056978 0.856953   0.04247721]
2022-11-28 06:41:27 using cpu
2022-11-28 06:41:27 epoch = 30000
2022-11-28 06:41:27 epoch_step = 1000
2022-11-28 06:41:27 model_name = SimpleNetworkAD
2022-11-28 06:41:27 now_string = 2022-11-27-19-40-13
2022-11-28 06:41:27 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:41:27 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:41:27 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:41:27 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:41:27 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:41:27 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:41:46 NUM_SUB: 61;----------------------------
2022-11-28 06:41:46 Epoch [01000/30000] Loss:0.134176 Loss_1:0.128868 Loss_2:0.001531 Loss_3:0.000000 Lr:0.000909 Time:19.152936s (0.32min in total, 9.26min remains)
2022-11-28 06:42:05 NUM_SUB: 61;----------------------------
2022-11-28 06:42:05 Epoch [02000/30000] Loss:0.121443 Loss_1:0.120634 Loss_2:0.000420 Loss_3:0.000000 Lr:0.000833 Time:19.066082s (0.64min in total, 8.92min remains)
2022-11-28 06:42:24 NUM_SUB: 61;----------------------------
2022-11-28 06:42:24 Epoch [03000/30000] Loss:0.108138 Loss_1:0.107781 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000769 Time:18.819724s (0.95min in total, 8.56min remains)
2022-11-28 06:42:44 NUM_SUB: 61;----------------------------
2022-11-28 06:42:44 Epoch [04000/30000] Loss:0.089852 Loss_1:0.089526 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000714 Time:19.671621s (1.28min in total, 8.31min remains)
2022-11-28 06:43:03 NUM_SUB: 61;----------------------------
2022-11-28 06:43:03 Epoch [05000/30000] Loss:0.063693 Loss_1:0.063400 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000667 Time:19.185240s (1.60min in total, 7.99min remains)
2022-11-28 06:43:22 NUM_SUB: 61;----------------------------
2022-11-28 06:43:22 Epoch [06000/30000] Loss:0.034172 Loss_1:0.033947 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000625 Time:19.444429s (1.92min in total, 7.69min remains)
2022-11-28 06:43:41 NUM_SUB: 61;----------------------------
2022-11-28 06:43:41 Epoch [07000/30000] Loss:0.015764 Loss_1:0.015622 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000588 Time:18.582387s (2.23min in total, 7.33min remains)
2022-11-28 06:44:00 NUM_SUB: 61;----------------------------
2022-11-28 06:44:00 Epoch [08000/30000] Loss:0.009793 Loss_1:0.009687 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000556 Time:19.319982s (2.55min in total, 7.02min remains)
2022-11-28 06:44:19 NUM_SUB: 61;----------------------------
2022-11-28 06:44:19 Epoch [09000/30000] Loss:0.006674 Loss_1:0.006570 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000526 Time:18.830138s (2.87min in total, 6.69min remains)
2022-11-28 06:44:38 NUM_SUB: 61;----------------------------
2022-11-28 06:44:38 Epoch [10000/30000] Loss:0.004664 Loss_1:0.004556 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000500 Time:19.045678s (3.19min in total, 6.37min remains)
2022-11-28 06:44:57 NUM_SUB: 61;----------------------------
2022-11-28 06:44:57 Epoch [11000/30000] Loss:0.003120 Loss_1:0.003049 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000476 Time:18.931027s (3.50min in total, 6.05min remains)
2022-11-28 06:45:16 NUM_SUB: 61;----------------------------
2022-11-28 06:45:16 Epoch [12000/30000] Loss:0.001912 Loss_1:0.001877 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:19.079596s (3.82min in total, 5.73min remains)
2022-11-28 06:45:35 NUM_SUB: 61;----------------------------
2022-11-28 06:45:35 Epoch [13000/30000] Loss:0.001482 Loss_1:0.001451 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:18.667647s (4.13min in total, 5.40min remains)
2022-11-28 06:45:54 NUM_SUB: 61;----------------------------
2022-11-28 06:45:54 Epoch [14000/30000] Loss:0.001380 Loss_1:0.001357 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:19.356359s (4.45min in total, 5.09min remains)
2022-11-28 06:46:14 NUM_SUB: 61;----------------------------
2022-11-28 06:46:14 Epoch [15000/30000] Loss:0.001283 Loss_1:0.001267 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000400 Time:19.421107s (4.78min in total, 4.78min remains)
2022-11-28 06:46:33 NUM_SUB: 61;----------------------------
2022-11-28 06:46:33 Epoch [16000/30000] Loss:0.001166 Loss_1:0.001155 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:19.179988s (5.10min in total, 4.46min remains)
2022-11-28 06:46:52 NUM_SUB: 61;----------------------------
2022-11-28 06:46:52 Epoch [17000/30000] Loss:0.001005 Loss_1:0.000998 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:19.409488s (5.42min in total, 4.14min remains)
2022-11-28 06:47:11 NUM_SUB: 61;----------------------------
2022-11-28 06:47:11 Epoch [18000/30000] Loss:0.000698 Loss_1:0.000694 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:18.909233s (5.73min in total, 3.82min remains)
2022-11-28 06:47:31 NUM_SUB: 61;----------------------------
2022-11-28 06:47:31 Epoch [19000/30000] Loss:0.000177 Loss_1:0.000174 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:19.376018s (6.06min in total, 3.51min remains)
2022-11-28 06:47:50 NUM_SUB: 61;----------------------------
2022-11-28 06:47:50 Epoch [20000/30000] Loss:0.000097 Loss_1:0.000094 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:19.106450s (6.38min in total, 3.19min remains)
2022-11-28 06:48:09 NUM_SUB: 61;----------------------------
2022-11-28 06:48:09 Epoch [21000/30000] Loss:0.000081 Loss_1:0.000077 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.320915s (6.70min in total, 2.87min remains)
2022-11-28 06:48:28 NUM_SUB: 61;----------------------------
2022-11-28 06:48:28 Epoch [22000/30000] Loss:0.000080 Loss_1:0.000076 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.180184s (7.02min in total, 2.55min remains)
2022-11-28 06:48:48 NUM_SUB: 61;----------------------------
2022-11-28 06:48:48 Epoch [23000/30000] Loss:0.000079 Loss_1:0.000076 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:19.378672s (7.34min in total, 2.23min remains)
2022-11-28 06:49:07 NUM_SUB: 61;----------------------------
2022-11-28 06:49:07 Epoch [24000/30000] Loss:0.000079 Loss_1:0.000075 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:19.341355s (7.66min in total, 1.92min remains)
2022-11-28 06:49:26 NUM_SUB: 61;----------------------------
2022-11-28 06:49:26 Epoch [25000/30000] Loss:0.000079 Loss_1:0.000075 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.381925s (7.99min in total, 1.60min remains)
2022-11-28 06:49:45 NUM_SUB: 61;----------------------------
2022-11-28 06:49:45 Epoch [26000/30000] Loss:0.000078 Loss_1:0.000074 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.156704s (8.31min in total, 1.28min remains)
2022-11-28 06:50:05 NUM_SUB: 61;----------------------------
2022-11-28 06:50:05 Epoch [27000/30000] Loss:0.000078 Loss_1:0.000074 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:19.558478s (8.63min in total, 0.96min remains)
2022-11-28 06:50:24 NUM_SUB: 61;----------------------------
2022-11-28 06:50:24 Epoch [28000/30000] Loss:0.000078 Loss_1:0.000074 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.295236s (8.95min in total, 0.64min remains)
2022-11-28 06:50:44 NUM_SUB: 61;----------------------------
2022-11-28 06:50:44 Epoch [29000/30000] Loss:0.000089 Loss_1:0.000073 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.523931s (9.28min in total, 0.32min remains)
2022-11-28 06:51:03 NUM_SUB: 61;----------------------------
2022-11-28 06:51:03 Epoch [30000/30000] Loss:0.000077 Loss_1:0.000073 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:19.232650s (9.60min in total, 0.00min remains)
2022-11-28 06:51:03 Testing & drawing...
2022-11-28 06:51:03 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:51:05 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=61/
2022-11-28 06:51:05 [Loss]
2022-11-28 06:51:05 NUM_SUB: 61; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:51:05 NUM_SUB: 61; Personalized parameter estimation: Parameter containing:
tensor([0.1445, 0.6837, 0.0139, 0.4255, 0.3074, 0.2301, 0.9197, 0.8964, 0.4556,
        0.0145, 0.0351, 0.0142, 0.5815, 0.1689, 0.0151, 2.8179, 0.6977, 0.8000,
        0.0118, 2.7316, 0.6816, 0.0227, 1.3102, 0.8742, 0.0217, 2.8197, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:51:05 NUM_SUB: 61------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 06:51:05 Testing & drawing...
2022-11-28 06:51:05 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 06:51:06 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=61/
2022-11-28 06:51:06 [Loss]
2022-11-28 06:51:06 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 06:51:06 General parameter estimation: Parameter containing:
tensor([0.1445, 0.6837, 0.0139, 0.4255, 0.3074, 0.2301, 0.9197, 0.8964, 0.4556,
        0.0145, 0.0351, 0.0142, 0.5815, 0.1689, 0.0151, 2.8179, 0.6977, 0.8000,
        0.0118, 2.7316, 0.6816, 0.0227, 1.3102, 0.8742, 0.0217, 2.8197, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 06:51:06 A: prod, degr, TonA, NonA
2022-11-28 06:51:06 [0.25471175 0.49925587 0.01629301 0.22973935]
2022-11-28 06:51:06 T: prod, degr, AonT, NonT
2022-11-28 06:51:06 [0.37374833 0.37521216 0.1920663  0.05897323]
2022-11-28 06:51:06 N: AonN, TonN, ATonN
2022-11-28 06:51:06 [0.01215913 0.92212445 0.06571639]
2022-11-28 06:51:07 using cpu
2022-11-28 06:51:07 epoch = 30000
2022-11-28 06:51:07 epoch_step = 1000
2022-11-28 06:51:07 model_name = SimpleNetworkAD
2022-11-28 06:51:07 now_string = 2022-11-27-19-40-13
2022-11-28 06:51:07 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 06:51:07 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 06:51:07 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 06:51:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 06:51:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 06:51:07 --------------------------------------------------training start--------------------------------------------------
2022-11-28 06:51:26 NUM_SUB: 62;----------------------------
2022-11-28 06:51:26 Epoch [01000/30000] Loss:0.030585 Loss_1:0.025476 Loss_2:0.001410 Loss_3:0.000000 Lr:0.000909 Time:19.593414s (0.33min in total, 9.47min remains)
2022-11-28 06:51:45 NUM_SUB: 62;----------------------------
2022-11-28 06:51:45 Epoch [02000/30000] Loss:0.024822 Loss_1:0.024040 Loss_2:0.000365 Loss_3:0.000000 Lr:0.000833 Time:18.895581s (0.64min in total, 8.98min remains)
2022-11-28 06:52:05 NUM_SUB: 62;----------------------------
2022-11-28 06:52:05 Epoch [03000/30000] Loss:0.022220 Loss_1:0.022039 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000769 Time:19.625035s (0.97min in total, 8.72min remains)
2022-11-28 06:52:24 NUM_SUB: 62;----------------------------
2022-11-28 06:52:24 Epoch [04000/30000] Loss:0.019772 Loss_1:0.019630 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000714 Time:19.674450s (1.30min in total, 8.43min remains)
2022-11-28 06:52:44 NUM_SUB: 62;----------------------------
2022-11-28 06:52:44 Epoch [05000/30000] Loss:0.016790 Loss_1:0.016666 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000667 Time:19.490551s (1.62min in total, 8.11min remains)
2022-11-28 06:53:03 NUM_SUB: 62;----------------------------
2022-11-28 06:53:03 Epoch [06000/30000] Loss:0.012876 Loss_1:0.012761 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000625 Time:19.334586s (1.94min in total, 7.77min remains)
2022-11-28 06:53:22 NUM_SUB: 62;----------------------------
2022-11-28 06:53:22 Epoch [07000/30000] Loss:0.008380 Loss_1:0.008276 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000588 Time:19.193880s (2.26min in total, 7.44min remains)
2022-11-28 06:53:41 NUM_SUB: 62;----------------------------
2022-11-28 06:53:41 Epoch [08000/30000] Loss:0.004535 Loss_1:0.004443 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000556 Time:18.862034s (2.58min in total, 7.09min remains)
2022-11-28 06:54:01 NUM_SUB: 62;----------------------------
2022-11-28 06:54:01 Epoch [09000/30000] Loss:0.002657 Loss_1:0.002595 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000526 Time:19.388185s (2.90min in total, 6.77min remains)
2022-11-28 06:54:20 NUM_SUB: 62;----------------------------
2022-11-28 06:54:20 Epoch [10000/30000] Loss:0.002089 Loss_1:0.002070 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000500 Time:18.839184s (3.22min in total, 6.43min remains)
2022-11-28 06:54:39 NUM_SUB: 62;----------------------------
2022-11-28 06:54:39 Epoch [11000/30000] Loss:0.001831 Loss_1:0.001823 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000476 Time:19.612540s (3.54min in total, 6.12min remains)
2022-11-28 06:54:59 NUM_SUB: 62;----------------------------
2022-11-28 06:54:59 Epoch [12000/30000] Loss:0.001617 Loss_1:0.001609 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000455 Time:19.600445s (3.87min in total, 5.80min remains)
2022-11-28 06:55:18 NUM_SUB: 62;----------------------------
2022-11-28 06:55:18 Epoch [13000/30000] Loss:0.001421 Loss_1:0.001408 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000435 Time:19.269057s (4.19min in total, 5.48min remains)
2022-11-28 06:55:37 NUM_SUB: 62;----------------------------
2022-11-28 06:55:37 Epoch [14000/30000] Loss:0.001237 Loss_1:0.001230 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000417 Time:19.384475s (4.51min in total, 5.16min remains)
2022-11-28 06:55:56 NUM_SUB: 62;----------------------------
2022-11-28 06:55:56 Epoch [15000/30000] Loss:0.001103 Loss_1:0.001098 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000400 Time:18.870834s (4.83min in total, 4.83min remains)
2022-11-28 06:56:16 NUM_SUB: 62;----------------------------
2022-11-28 06:56:16 Epoch [16000/30000] Loss:0.001015 Loss_1:0.001011 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000385 Time:19.383799s (5.15min in total, 4.51min remains)
2022-11-28 06:56:34 NUM_SUB: 62;----------------------------
2022-11-28 06:56:34 Epoch [17000/30000] Loss:0.001011 Loss_1:0.001008 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:18.707710s (5.46min in total, 4.18min remains)
2022-11-28 06:56:54 NUM_SUB: 62;----------------------------
2022-11-28 06:56:54 Epoch [18000/30000] Loss:0.000997 Loss_1:0.000995 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:19.529130s (5.79min in total, 3.86min remains)
2022-11-28 06:57:13 NUM_SUB: 62;----------------------------
2022-11-28 06:57:13 Epoch [19000/30000] Loss:0.000996 Loss_1:0.000995 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000345 Time:18.666740s (6.10min in total, 3.53min remains)
2022-11-28 06:57:32 NUM_SUB: 62;----------------------------
2022-11-28 06:57:32 Epoch [20000/30000] Loss:0.000996 Loss_1:0.000995 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.227571s (6.42min in total, 3.21min remains)
2022-11-28 06:57:51 NUM_SUB: 62;----------------------------
2022-11-28 06:57:51 Epoch [21000/30000] Loss:0.000996 Loss_1:0.000994 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.216406s (6.74min in total, 2.89min remains)
2022-11-28 06:58:10 NUM_SUB: 62;----------------------------
2022-11-28 06:58:10 Epoch [22000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.084381s (7.06min in total, 2.57min remains)
2022-11-28 06:58:29 NUM_SUB: 62;----------------------------
2022-11-28 06:58:29 Epoch [23000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000303 Time:19.123665s (7.38min in total, 2.25min remains)
2022-11-28 06:58:48 NUM_SUB: 62;----------------------------
2022-11-28 06:58:48 Epoch [24000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:19.098098s (7.69min in total, 1.92min remains)
2022-11-28 06:59:07 NUM_SUB: 62;----------------------------
2022-11-28 06:59:07 Epoch [25000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:18.897091s (8.01min in total, 1.60min remains)
2022-11-28 06:59:26 NUM_SUB: 62;----------------------------
2022-11-28 06:59:26 Epoch [26000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.234277s (8.33min in total, 1.28min remains)
2022-11-28 06:59:46 NUM_SUB: 62;----------------------------
2022-11-28 06:59:46 Epoch [27000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.048635s (8.65min in total, 0.96min remains)
2022-11-28 07:00:04 NUM_SUB: 62;----------------------------
2022-11-28 07:00:04 Epoch [28000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:18.777666s (8.96min in total, 0.64min remains)
2022-11-28 07:00:24 NUM_SUB: 62;----------------------------
2022-11-28 07:00:24 Epoch [29000/30000] Loss:0.000995 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.534019s (9.29min in total, 0.32min remains)
2022-11-28 07:00:42 NUM_SUB: 62;----------------------------
2022-11-28 07:00:42 Epoch [30000/30000] Loss:0.000994 Loss_1:0.000994 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.618579s (9.60min in total, 0.00min remains)
2022-11-28 07:00:42 Testing & drawing...
2022-11-28 07:00:42 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:00:44 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=62/
2022-11-28 07:00:44 [Loss]
2022-11-28 07:00:44 NUM_SUB: 62; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:00:44 NUM_SUB: 62; Personalized parameter estimation: Parameter containing:
tensor([0.2828, 0.9862, 0.0096, 1.3101, 0.3074, 0.0111, 0.8214, 0.8964, 0.4556,
        0.0094, 0.1685, 0.0972, 0.3563, 0.1689, 0.0175, 1.1900, 0.6977, 0.8000,
        0.0123, 3.2269, 0.6816, 0.0222, 2.8137, 0.8742, 0.0214, 3.6591, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:00:44 NUM_SUB: 62------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:00:44 Testing & drawing...
2022-11-28 07:00:44 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:00:46 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=62/
2022-11-28 07:00:46 [Loss]
2022-11-28 07:00:46 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:00:46 General parameter estimation: Parameter containing:
tensor([0.2828, 0.9862, 0.0096, 1.3101, 0.3074, 0.0111, 0.8214, 0.8964, 0.4556,
        0.0094, 0.1685, 0.0972, 0.3563, 0.1689, 0.0175, 1.1900, 0.6977, 0.8000,
        0.0123, 3.2269, 0.6816, 0.0222, 2.8137, 0.8742, 0.0214, 3.6591, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:00:46 A: prod, degr, TonA, NonA
2022-11-28 07:00:46 [0.49421075 0.5000531  0.00063032 0.00510581]
2022-11-28 07:00:46 T: prod, degr, AonT, NonT
2022-11-28 07:00:46 [0.10584068 0.54849267 0.31709963 0.02856701]
2022-11-28 07:00:46 N: AonN, TonN, ATonN
2022-11-28 07:00:46 [0.0080358  0.97443205 0.01753211]
2022-11-28 07:00:46 using cpu
2022-11-28 07:00:46 epoch = 30000
2022-11-28 07:00:46 epoch_step = 1000
2022-11-28 07:00:46 model_name = SimpleNetworkAD
2022-11-28 07:00:46 now_string = 2022-11-27-19-40-13
2022-11-28 07:00:46 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:00:46 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:00:46 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:00:46 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:00:46 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:00:46 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:01:06 NUM_SUB: 63;----------------------------
2022-11-28 07:01:06 Epoch [01000/30000] Loss:0.113011 Loss_1:0.107392 Loss_2:0.001873 Loss_3:0.000000 Lr:0.000909 Time:19.533332s (0.33min in total, 9.44min remains)
2022-11-28 07:01:25 NUM_SUB: 63;----------------------------
2022-11-28 07:01:25 Epoch [02000/30000] Loss:0.097940 Loss_1:0.096892 Loss_2:0.000667 Loss_3:0.000000 Lr:0.000833 Time:19.288800s (0.65min in total, 9.06min remains)
2022-11-28 07:01:44 NUM_SUB: 63;----------------------------
2022-11-28 07:01:44 Epoch [03000/30000] Loss:0.083340 Loss_1:0.082617 Loss_2:0.000308 Loss_3:0.000000 Lr:0.000769 Time:19.223696s (0.97min in total, 8.71min remains)
2022-11-28 07:02:03 NUM_SUB: 63;----------------------------
2022-11-28 07:02:03 Epoch [04000/30000] Loss:0.064184 Loss_1:0.063609 Loss_2:0.000235 Loss_3:0.000000 Lr:0.000714 Time:18.707283s (1.28min in total, 8.32min remains)
2022-11-28 07:02:22 NUM_SUB: 63;----------------------------
2022-11-28 07:02:22 Epoch [05000/30000] Loss:0.040678 Loss_1:0.040225 Loss_2:0.000209 Loss_3:0.000000 Lr:0.000667 Time:19.422717s (1.60min in total, 8.01min remains)
2022-11-28 07:02:41 NUM_SUB: 63;----------------------------
2022-11-28 07:02:41 Epoch [06000/30000] Loss:0.020868 Loss_1:0.020580 Loss_2:0.000163 Loss_3:0.000000 Lr:0.000625 Time:19.033701s (1.92min in total, 7.68min remains)
2022-11-28 07:03:01 NUM_SUB: 63;----------------------------
2022-11-28 07:03:01 Epoch [07000/30000] Loss:0.012229 Loss_1:0.012033 Loss_2:0.000146 Loss_3:0.000000 Lr:0.000588 Time:19.302145s (2.24min in total, 7.37min remains)
2022-11-28 07:03:20 NUM_SUB: 63;----------------------------
2022-11-28 07:03:20 Epoch [08000/30000] Loss:0.008317 Loss_1:0.008169 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000556 Time:19.231703s (2.56min in total, 7.05min remains)
2022-11-28 07:03:39 NUM_SUB: 63;----------------------------
2022-11-28 07:03:39 Epoch [09000/30000] Loss:0.004631 Loss_1:0.004499 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000526 Time:19.623215s (2.89min in total, 6.74min remains)
2022-11-28 07:03:59 NUM_SUB: 63;----------------------------
2022-11-28 07:03:59 Epoch [10000/30000] Loss:0.001975 Loss_1:0.001850 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000500 Time:19.133328s (3.21min in total, 6.42min remains)
2022-11-28 07:04:18 NUM_SUB: 63;----------------------------
2022-11-28 07:04:18 Epoch [11000/30000] Loss:0.001418 Loss_1:0.001149 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000476 Time:19.159803s (3.53min in total, 6.09min remains)
2022-11-28 07:04:37 NUM_SUB: 63;----------------------------
2022-11-28 07:04:37 Epoch [12000/30000] Loss:0.001020 Loss_1:0.000965 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:18.957691s (3.84min in total, 5.77min remains)
2022-11-28 07:04:56 NUM_SUB: 63;----------------------------
2022-11-28 07:04:56 Epoch [13000/30000] Loss:0.000929 Loss_1:0.000893 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:19.361159s (4.17min in total, 5.45min remains)
2022-11-28 07:05:15 NUM_SUB: 63;----------------------------
2022-11-28 07:05:15 Epoch [14000/30000] Loss:0.000862 Loss_1:0.000837 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:19.392591s (4.49min in total, 5.13min remains)
2022-11-28 07:05:34 NUM_SUB: 63;----------------------------
2022-11-28 07:05:34 Epoch [15000/30000] Loss:0.000826 Loss_1:0.000807 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000400 Time:19.042713s (4.81min in total, 4.81min remains)
2022-11-28 07:05:54 NUM_SUB: 63;----------------------------
2022-11-28 07:05:54 Epoch [16000/30000] Loss:0.000810 Loss_1:0.000796 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:19.118737s (5.13min in total, 4.49min remains)
2022-11-28 07:06:12 NUM_SUB: 63;----------------------------
2022-11-28 07:06:12 Epoch [17000/30000] Loss:0.000805 Loss_1:0.000793 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:18.771948s (5.44min in total, 4.16min remains)
2022-11-28 07:06:32 NUM_SUB: 63;----------------------------
2022-11-28 07:06:32 Epoch [18000/30000] Loss:0.000801 Loss_1:0.000791 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:19.230440s (5.76min in total, 3.84min remains)
2022-11-28 07:06:51 NUM_SUB: 63;----------------------------
2022-11-28 07:06:51 Epoch [19000/30000] Loss:0.000798 Loss_1:0.000790 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000345 Time:19.294252s (6.08min in total, 3.52min remains)
2022-11-28 07:07:10 NUM_SUB: 63;----------------------------
2022-11-28 07:07:10 Epoch [20000/30000] Loss:0.000796 Loss_1:0.000789 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:19.522862s (6.41min in total, 3.20min remains)
2022-11-28 07:07:30 NUM_SUB: 63;----------------------------
2022-11-28 07:07:30 Epoch [21000/30000] Loss:0.000793 Loss_1:0.000788 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:19.298624s (6.73min in total, 2.88min remains)
2022-11-28 07:07:49 NUM_SUB: 63;----------------------------
2022-11-28 07:07:49 Epoch [22000/30000] Loss:0.000791 Loss_1:0.000786 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:19.224618s (7.05min in total, 2.56min remains)
2022-11-28 07:08:08 NUM_SUB: 63;----------------------------
2022-11-28 07:08:08 Epoch [23000/30000] Loss:0.000790 Loss_1:0.000785 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:19.131880s (7.37min in total, 2.24min remains)
2022-11-28 07:08:27 NUM_SUB: 63;----------------------------
2022-11-28 07:08:27 Epoch [24000/30000] Loss:0.000789 Loss_1:0.000786 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:19.085825s (7.69min in total, 1.92min remains)
2022-11-28 07:08:46 NUM_SUB: 63;----------------------------
2022-11-28 07:08:46 Epoch [25000/30000] Loss:0.000787 Loss_1:0.000784 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.246750s (8.01min in total, 1.60min remains)
2022-11-28 07:09:06 NUM_SUB: 63;----------------------------
2022-11-28 07:09:06 Epoch [26000/30000] Loss:0.000785 Loss_1:0.000782 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.169317s (8.33min in total, 1.28min remains)
2022-11-28 07:09:24 NUM_SUB: 63;----------------------------
2022-11-28 07:09:24 Epoch [27000/30000] Loss:0.000781 Loss_1:0.000778 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:18.834807s (8.64min in total, 0.96min remains)
2022-11-28 07:09:44 NUM_SUB: 63;----------------------------
2022-11-28 07:09:44 Epoch [28000/30000] Loss:0.000774 Loss_1:0.000771 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.455757s (8.96min in total, 0.64min remains)
2022-11-28 07:10:03 NUM_SUB: 63;----------------------------
2022-11-28 07:10:03 Epoch [29000/30000] Loss:0.000772 Loss_1:0.000770 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000256 Time:19.055217s (9.28min in total, 0.32min remains)
2022-11-28 07:10:22 NUM_SUB: 63;----------------------------
2022-11-28 07:10:22 Epoch [30000/30000] Loss:0.000771 Loss_1:0.000769 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.419416s (9.61min in total, 0.00min remains)
2022-11-28 07:10:22 Testing & drawing...
2022-11-28 07:10:22 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:10:24 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=63/
2022-11-28 07:10:24 [Loss]
2022-11-28 07:10:24 NUM_SUB: 63; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:10:24 NUM_SUB: 63; Personalized parameter estimation: Parameter containing:
tensor([1.6756e-02, 3.0911e-02, 1.0170e-02, 3.2794e+00, 3.0742e-01, 1.6486e-02,
        3.5342e+00, 8.9644e-01, 4.5563e-01, 2.2003e-02, 5.1490e-02, 2.7902e-03,
        2.5301e-01, 1.6886e-01, 1.7652e-02, 7.4893e-01, 6.9767e-01, 8.0001e-01,
        1.1550e-02, 4.3951e+00, 6.8161e-01, 2.1954e-02, 3.9593e+00, 8.7416e-01,
        1.9792e-02, 4.7761e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:10:24 NUM_SUB: 63------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:10:24 Testing & drawing...
2022-11-28 07:10:24 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:10:26 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=63/
2022-11-28 07:10:26 [Loss]
2022-11-28 07:10:26 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:10:26 General parameter estimation: Parameter containing:
tensor([1.6756e-02, 3.0911e-02, 1.0170e-02, 3.2794e+00, 3.0742e-01, 1.6486e-02,
        3.5342e+00, 8.9644e-01, 4.5563e-01, 2.2003e-02, 5.1490e-02, 2.7902e-03,
        2.5301e-01, 1.6886e-01, 1.7652e-02, 7.4893e-01, 6.9767e-01, 8.0001e-01,
        1.1550e-02, 4.3951e+00, 6.8161e-01, 2.1954e-02, 3.9593e+00, 8.7416e-01,
        1.9792e-02, 4.7761e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:10:26 A: prod, degr, TonA, NonA
2022-11-28 07:10:26 [0.49405584 0.47902587 0.01036199 0.01655629]
2022-11-28 07:10:26 T: prod, degr, AonT, NonT
2022-11-28 07:10:26 [0.37166148 0.4570482  0.04040457 0.13088568]
2022-11-28 07:10:26 N: AonN, TonN, ATonN
2022-11-28 07:10:26 [0.00796353 0.96529615 0.02674031]
2022-11-28 07:10:26 using cpu
2022-11-28 07:10:26 epoch = 30000
2022-11-28 07:10:26 epoch_step = 1000
2022-11-28 07:10:26 model_name = SimpleNetworkAD
2022-11-28 07:10:26 now_string = 2022-11-27-19-40-13
2022-11-28 07:10:26 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:10:26 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:10:26 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:10:26 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:10:26 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:10:26 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:10:45 NUM_SUB: 64;----------------------------
2022-11-28 07:10:45 Epoch [01000/30000] Loss:0.074012 Loss_1:0.068441 Loss_2:0.001708 Loss_3:0.000000 Lr:0.000909 Time:19.395222s (0.32min in total, 9.37min remains)
2022-11-28 07:11:04 NUM_SUB: 64;----------------------------
2022-11-28 07:11:04 Epoch [02000/30000] Loss:0.066759 Loss_1:0.065812 Loss_2:0.000501 Loss_3:0.000000 Lr:0.000833 Time:19.263315s (0.64min in total, 9.02min remains)
2022-11-28 07:11:23 NUM_SUB: 64;----------------------------
2022-11-28 07:11:23 Epoch [03000/30000] Loss:0.061800 Loss_1:0.061459 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000769 Time:18.992863s (0.96min in total, 8.65min remains)
2022-11-28 07:11:43 NUM_SUB: 64;----------------------------
2022-11-28 07:11:43 Epoch [04000/30000] Loss:0.055882 Loss_1:0.055491 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000714 Time:19.264145s (1.28min in total, 8.33min remains)
2022-11-28 07:12:02 NUM_SUB: 64;----------------------------
2022-11-28 07:12:02 Epoch [05000/30000] Loss:0.047614 Loss_1:0.047240 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000667 Time:19.229460s (1.60min in total, 8.01min remains)
2022-11-28 07:12:21 NUM_SUB: 64;----------------------------
2022-11-28 07:12:21 Epoch [06000/30000] Loss:0.036092 Loss_1:0.035744 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000625 Time:19.562269s (1.93min in total, 7.71min remains)
2022-11-28 07:12:41 NUM_SUB: 64;----------------------------
2022-11-28 07:12:41 Epoch [07000/30000] Loss:0.021585 Loss_1:0.021259 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000588 Time:19.167825s (2.25min in total, 7.39min remains)
2022-11-28 07:13:00 NUM_SUB: 64;----------------------------
2022-11-28 07:13:00 Epoch [08000/30000] Loss:0.007458 Loss_1:0.007206 Loss_2:0.000163 Loss_3:0.000000 Lr:0.000556 Time:19.533053s (2.57min in total, 7.08min remains)
2022-11-28 07:13:19 NUM_SUB: 64;----------------------------
2022-11-28 07:13:19 Epoch [09000/30000] Loss:0.001319 Loss_1:0.001127 Loss_2:0.000168 Loss_3:0.000000 Lr:0.000526 Time:19.144911s (2.89min in total, 6.75min remains)
2022-11-28 07:13:38 NUM_SUB: 64;----------------------------
2022-11-28 07:13:38 Epoch [10000/30000] Loss:0.000577 Loss_1:0.000451 Loss_2:0.000120 Loss_3:0.000000 Lr:0.000500 Time:19.014608s (3.21min in total, 6.42min remains)
2022-11-28 07:13:57 NUM_SUB: 64;----------------------------
2022-11-28 07:13:57 Epoch [11000/30000] Loss:0.000485 Loss_1:0.000408 Loss_2:0.000075 Loss_3:0.000000 Lr:0.000476 Time:19.022420s (3.53min in total, 6.09min remains)
2022-11-28 07:14:16 NUM_SUB: 64;----------------------------
2022-11-28 07:14:16 Epoch [12000/30000] Loss:0.000422 Loss_1:0.000373 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000455 Time:18.951888s (3.84min in total, 5.76min remains)
2022-11-28 07:14:35 NUM_SUB: 64;----------------------------
2022-11-28 07:14:35 Epoch [13000/30000] Loss:0.000387 Loss_1:0.000336 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000435 Time:19.017813s (4.16min in total, 5.44min remains)
2022-11-28 07:14:54 NUM_SUB: 64;----------------------------
2022-11-28 07:14:54 Epoch [14000/30000] Loss:0.000325 Loss_1:0.000302 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:18.993816s (4.48min in total, 5.12min remains)
2022-11-28 07:15:14 NUM_SUB: 64;----------------------------
2022-11-28 07:15:14 Epoch [15000/30000] Loss:0.000284 Loss_1:0.000265 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:19.223000s (4.80min in total, 4.80min remains)
2022-11-28 07:15:33 NUM_SUB: 64;----------------------------
2022-11-28 07:15:33 Epoch [16000/30000] Loss:0.000238 Loss_1:0.000225 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:19.306621s (5.12min in total, 4.48min remains)
2022-11-28 07:15:52 NUM_SUB: 64;----------------------------
2022-11-28 07:15:52 Epoch [17000/30000] Loss:0.000193 Loss_1:0.000183 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:19.160202s (5.44min in total, 4.16min remains)
2022-11-28 07:16:11 NUM_SUB: 64;----------------------------
2022-11-28 07:16:11 Epoch [18000/30000] Loss:0.000169 Loss_1:0.000161 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:19.114719s (5.76min in total, 3.84min remains)
2022-11-28 07:16:30 NUM_SUB: 64;----------------------------
2022-11-28 07:16:30 Epoch [19000/30000] Loss:0.000164 Loss_1:0.000158 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.235950s (6.08min in total, 3.52min remains)
2022-11-28 07:16:50 NUM_SUB: 64;----------------------------
2022-11-28 07:16:50 Epoch [20000/30000] Loss:0.000172 Loss_1:0.000167 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:19.165649s (6.40min in total, 3.20min remains)
2022-11-28 07:17:09 NUM_SUB: 64;----------------------------
2022-11-28 07:17:09 Epoch [21000/30000] Loss:0.000161 Loss_1:0.000158 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.326989s (6.72min in total, 2.88min remains)
2022-11-28 07:17:28 NUM_SUB: 64;----------------------------
2022-11-28 07:17:28 Epoch [22000/30000] Loss:0.000160 Loss_1:0.000158 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.246377s (7.04min in total, 2.56min remains)
2022-11-28 07:17:47 NUM_SUB: 64;----------------------------
2022-11-28 07:17:47 Epoch [23000/30000] Loss:0.000160 Loss_1:0.000158 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.291121s (7.36min in total, 2.24min remains)
2022-11-28 07:18:07 NUM_SUB: 64;----------------------------
2022-11-28 07:18:07 Epoch [24000/30000] Loss:0.000159 Loss_1:0.000158 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.388774s (7.68min in total, 1.92min remains)
2022-11-28 07:18:26 NUM_SUB: 64;----------------------------
2022-11-28 07:18:26 Epoch [25000/30000] Loss:0.000160 Loss_1:0.000158 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.134758s (8.00min in total, 1.60min remains)
2022-11-28 07:18:45 NUM_SUB: 64;----------------------------
2022-11-28 07:18:45 Epoch [26000/30000] Loss:0.000159 Loss_1:0.000158 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.489824s (8.33min in total, 1.28min remains)
2022-11-28 07:19:05 NUM_SUB: 64;----------------------------
2022-11-28 07:19:05 Epoch [27000/30000] Loss:0.000159 Loss_1:0.000158 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.336863s (8.65min in total, 0.96min remains)
2022-11-28 07:19:24 NUM_SUB: 64;----------------------------
2022-11-28 07:19:24 Epoch [28000/30000] Loss:0.000158 Loss_1:0.000158 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.209558s (8.97min in total, 0.64min remains)
2022-11-28 07:19:43 NUM_SUB: 64;----------------------------
2022-11-28 07:19:43 Epoch [29000/30000] Loss:0.000158 Loss_1:0.000158 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.071735s (9.29min in total, 0.32min remains)
2022-11-28 07:20:02 NUM_SUB: 64;----------------------------
2022-11-28 07:20:02 Epoch [30000/30000] Loss:0.000160 Loss_1:0.000159 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.856915s (9.60min in total, 0.00min remains)
2022-11-28 07:20:02 Testing & drawing...
2022-11-28 07:20:02 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:20:03 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=64/
2022-11-28 07:20:03 [Loss]
2022-11-28 07:20:04 NUM_SUB: 64; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:20:04 NUM_SUB: 64; Personalized parameter estimation: Parameter containing:
tensor([4.1058e-01, 8.6895e-01, 1.0349e-02, 1.2875e-01, 3.0742e-01, 3.7860e-03,
        7.9416e-01, 8.9644e-01, 4.5563e-01, 4.4172e-03, 2.6697e-02, 1.4593e-02,
        2.4286e-01, 1.6886e-01, 1.7592e-02, 1.1203e+00, 6.9767e-01, 8.0001e-01,
        1.1674e-02, 4.4041e+00, 6.8161e-01, 2.0759e-02, 4.2638e+00, 8.7416e-01,
        1.8800e-02, 4.9831e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:20:04 NUM_SUB: 64------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:20:04 Testing & drawing...
2022-11-28 07:20:04 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:20:05 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=64/
2022-11-28 07:20:05 [Loss]
2022-11-28 07:20:05 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:20:05 General parameter estimation: Parameter containing:
tensor([4.1058e-01, 8.6895e-01, 1.0349e-02, 1.2875e-01, 3.0742e-01, 3.7860e-03,
        7.9416e-01, 8.9644e-01, 4.5563e-01, 4.4172e-03, 2.6697e-02, 1.4593e-02,
        2.4286e-01, 1.6886e-01, 1.7592e-02, 1.1203e+00, 6.9767e-01, 8.0001e-01,
        1.1674e-02, 4.4041e+00, 6.8161e-01, 2.0759e-02, 4.2638e+00, 8.7416e-01,
        1.8800e-02, 4.9831e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:20:05 A: prod, degr, TonA, NonA
2022-11-28 07:20:05 [0.48711184 0.49983692 0.01191358 0.00113771]
2022-11-28 07:20:05 T: prod, degr, AonT, NonT
2022-11-28 07:20:05 [0.1335159  0.3912395  0.39779902 0.07744556]
2022-11-28 07:20:05 N: AonN, TonN, ATonN
2022-11-28 07:20:05 [0.00684153 0.9651765  0.02798195]
2022-11-28 07:20:05 using cpu
2022-11-28 07:20:05 epoch = 30000
2022-11-28 07:20:05 epoch_step = 1000
2022-11-28 07:20:05 model_name = SimpleNetworkAD
2022-11-28 07:20:05 now_string = 2022-11-27-19-40-13
2022-11-28 07:20:05 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:20:05 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:20:05 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:20:05 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:20:05 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:20:05 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:20:25 NUM_SUB: 65;----------------------------
2022-11-28 07:20:25 Epoch [01000/30000] Loss:0.028249 Loss_1:0.021556 Loss_2:0.002933 Loss_3:0.000000 Lr:0.000909 Time:19.926975s (0.33min in total, 9.63min remains)
2022-11-28 07:20:45 NUM_SUB: 65;----------------------------
2022-11-28 07:20:45 Epoch [02000/30000] Loss:0.020868 Loss_1:0.019062 Loss_2:0.001411 Loss_3:0.000000 Lr:0.000833 Time:19.294948s (0.65min in total, 9.15min remains)
2022-11-28 07:21:04 NUM_SUB: 65;----------------------------
2022-11-28 07:21:04 Epoch [03000/30000] Loss:0.017149 Loss_1:0.016654 Loss_2:0.000445 Loss_3:0.000000 Lr:0.000769 Time:19.086972s (0.97min in total, 8.75min remains)
2022-11-28 07:21:23 NUM_SUB: 65;----------------------------
2022-11-28 07:21:23 Epoch [04000/30000] Loss:0.014315 Loss_1:0.014062 Loss_2:0.000204 Loss_3:0.000000 Lr:0.000714 Time:19.150427s (1.29min in total, 8.39min remains)
2022-11-28 07:21:42 NUM_SUB: 65;----------------------------
2022-11-28 07:21:42 Epoch [05000/30000] Loss:0.011429 Loss_1:0.011212 Loss_2:0.000157 Loss_3:0.000000 Lr:0.000667 Time:19.055964s (1.61min in total, 8.04min remains)
2022-11-28 07:22:01 NUM_SUB: 65;----------------------------
2022-11-28 07:22:01 Epoch [06000/30000] Loss:0.008037 Loss_1:0.007864 Loss_2:0.000129 Loss_3:0.000000 Lr:0.000625 Time:18.852338s (1.92min in total, 7.69min remains)
2022-11-28 07:22:20 NUM_SUB: 65;----------------------------
2022-11-28 07:22:20 Epoch [07000/30000] Loss:0.004780 Loss_1:0.004648 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000588 Time:19.278896s (2.24min in total, 7.37min remains)
2022-11-28 07:22:39 NUM_SUB: 65;----------------------------
2022-11-28 07:22:39 Epoch [08000/30000] Loss:0.002548 Loss_1:0.002447 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000556 Time:19.271442s (2.57min in total, 7.05min remains)
2022-11-28 07:22:58 NUM_SUB: 65;----------------------------
2022-11-28 07:22:58 Epoch [09000/30000] Loss:0.001529 Loss_1:0.001436 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000526 Time:19.207829s (2.89min in total, 6.73min remains)
2022-11-28 07:23:18 NUM_SUB: 65;----------------------------
2022-11-28 07:23:18 Epoch [10000/30000] Loss:0.001082 Loss_1:0.000994 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000500 Time:19.141956s (3.20min in total, 6.41min remains)
2022-11-28 07:23:37 NUM_SUB: 65;----------------------------
2022-11-28 07:23:37 Epoch [11000/30000] Loss:0.000918 Loss_1:0.000804 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000476 Time:18.971405s (3.52min in total, 6.08min remains)
2022-11-28 07:23:55 NUM_SUB: 65;----------------------------
2022-11-28 07:23:55 Epoch [12000/30000] Loss:0.000696 Loss_1:0.000646 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000455 Time:18.909639s (3.84min in total, 5.75min remains)
2022-11-28 07:24:15 NUM_SUB: 65;----------------------------
2022-11-28 07:24:15 Epoch [13000/30000] Loss:0.000581 Loss_1:0.000547 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000435 Time:19.331470s (4.16min in total, 5.44min remains)
2022-11-28 07:24:34 NUM_SUB: 65;----------------------------
2022-11-28 07:24:34 Epoch [14000/30000] Loss:0.000545 Loss_1:0.000518 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:19.304653s (4.48min in total, 5.12min remains)
2022-11-28 07:24:53 NUM_SUB: 65;----------------------------
2022-11-28 07:24:53 Epoch [15000/30000] Loss:0.000535 Loss_1:0.000513 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000400 Time:19.167023s (4.80min in total, 4.80min remains)
2022-11-28 07:25:13 NUM_SUB: 65;----------------------------
2022-11-28 07:25:13 Epoch [16000/30000] Loss:0.000529 Loss_1:0.000511 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:19.381654s (5.12min in total, 4.48min remains)
2022-11-28 07:25:32 NUM_SUB: 65;----------------------------
2022-11-28 07:25:32 Epoch [17000/30000] Loss:0.000525 Loss_1:0.000509 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000370 Time:19.239503s (5.44min in total, 4.16min remains)
2022-11-28 07:25:51 NUM_SUB: 65;----------------------------
2022-11-28 07:25:51 Epoch [18000/30000] Loss:0.000522 Loss_1:0.000508 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:19.228779s (5.76min in total, 3.84min remains)
2022-11-28 07:26:10 NUM_SUB: 65;----------------------------
2022-11-28 07:26:10 Epoch [19000/30000] Loss:0.000528 Loss_1:0.000515 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000345 Time:19.189300s (6.08min in total, 3.52min remains)
2022-11-28 07:26:29 NUM_SUB: 65;----------------------------
2022-11-28 07:26:29 Epoch [20000/30000] Loss:0.000518 Loss_1:0.000507 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:19.063146s (6.40min in total, 3.20min remains)
2022-11-28 07:26:48 NUM_SUB: 65;----------------------------
2022-11-28 07:26:48 Epoch [21000/30000] Loss:0.000520 Loss_1:0.000509 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000323 Time:18.990463s (6.72min in total, 2.88min remains)
2022-11-28 07:27:08 NUM_SUB: 65;----------------------------
2022-11-28 07:27:08 Epoch [22000/30000] Loss:0.000517 Loss_1:0.000505 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000313 Time:19.365643s (7.04min in total, 2.56min remains)
2022-11-28 07:27:27 NUM_SUB: 65;----------------------------
2022-11-28 07:27:27 Epoch [23000/30000] Loss:0.000515 Loss_1:0.000504 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000303 Time:19.006189s (7.36min in total, 2.24min remains)
2022-11-28 07:27:46 NUM_SUB: 65;----------------------------
2022-11-28 07:27:46 Epoch [24000/30000] Loss:0.000514 Loss_1:0.000503 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000294 Time:19.052589s (7.67min in total, 1.92min remains)
2022-11-28 07:28:05 NUM_SUB: 65;----------------------------
2022-11-28 07:28:05 Epoch [25000/30000] Loss:0.000512 Loss_1:0.000502 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000286 Time:19.150150s (7.99min in total, 1.60min remains)
2022-11-28 07:28:24 NUM_SUB: 65;----------------------------
2022-11-28 07:28:24 Epoch [26000/30000] Loss:0.000510 Loss_1:0.000501 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:19.190740s (8.31min in total, 1.28min remains)
2022-11-28 07:28:43 NUM_SUB: 65;----------------------------
2022-11-28 07:28:43 Epoch [27000/30000] Loss:0.000507 Loss_1:0.000499 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000270 Time:19.336005s (8.64min in total, 0.96min remains)
2022-11-28 07:29:03 NUM_SUB: 65;----------------------------
2022-11-28 07:29:03 Epoch [28000/30000] Loss:0.000503 Loss_1:0.000497 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:19.382121s (8.96min in total, 0.64min remains)
2022-11-28 07:29:22 NUM_SUB: 65;----------------------------
2022-11-28 07:29:22 Epoch [29000/30000] Loss:0.000500 Loss_1:0.000494 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.120776s (9.28min in total, 0.32min remains)
2022-11-28 07:29:41 NUM_SUB: 65;----------------------------
2022-11-28 07:29:41 Epoch [30000/30000] Loss:0.000498 Loss_1:0.000494 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.351293s (9.60min in total, 0.00min remains)
2022-11-28 07:29:41 Testing & drawing...
2022-11-28 07:29:41 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:29:43 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=65/
2022-11-28 07:29:43 [Loss]
2022-11-28 07:29:43 NUM_SUB: 65; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:29:43 NUM_SUB: 65; Personalized parameter estimation: Parameter containing:
tensor([0.0059, 0.0072, 0.0102, 2.4714, 0.3074, 0.0177, 3.5520, 0.8964, 0.4556,
        0.0140, 0.1308, 0.1043, 0.5328, 0.1689, 0.0175, 1.1937, 0.6977, 0.8000,
        0.0111, 4.4502, 0.6816, 0.0217, 3.4224, 0.8742, 0.0199, 4.5351, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:29:43 NUM_SUB: 65------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:29:43 Testing & drawing...
2022-11-28 07:29:43 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:29:45 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=65/
2022-11-28 07:29:45 [Loss]
2022-11-28 07:29:45 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:29:45 General parameter estimation: Parameter containing:
tensor([0.0059, 0.0072, 0.0102, 2.4714, 0.3074, 0.0177, 3.5520, 0.8964, 0.4556,
        0.0140, 0.1308, 0.1043, 0.5328, 0.1689, 0.0175, 1.1937, 0.6977, 0.8000,
        0.0111, 4.4502, 0.6816, 0.0217, 3.4224, 0.8742, 0.0199, 4.5351, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:29:45 A: prod, degr, TonA, NonA
2022-11-28 07:29:45 [0.54649866 0.39753255 0.02832633 0.02764247]
2022-11-28 07:29:45 T: prod, degr, AonT, NonT
2022-11-28 07:29:45 [0.10576522 0.57414603 0.30309016 0.01699856]
2022-11-28 07:29:45 N: AonN, TonN, ATonN
2022-11-28 07:29:45 [0.01100526 0.9609912  0.02800355]
2022-11-28 07:29:45 using cpu
2022-11-28 07:29:45 epoch = 30000
2022-11-28 07:29:45 epoch_step = 1000
2022-11-28 07:29:45 model_name = SimpleNetworkAD
2022-11-28 07:29:45 now_string = 2022-11-27-19-40-13
2022-11-28 07:29:45 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:29:45 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:29:45 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:29:45 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:29:45 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:29:45 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:30:04 NUM_SUB: 66;----------------------------
2022-11-28 07:30:04 Epoch [01000/30000] Loss:0.022743 Loss_1:0.017500 Loss_2:0.001530 Loss_3:0.000000 Lr:0.000909 Time:19.455087s (0.32min in total, 9.40min remains)
2022-11-28 07:30:23 NUM_SUB: 66;----------------------------
2022-11-28 07:30:23 Epoch [02000/30000] Loss:0.017038 Loss_1:0.016216 Loss_2:0.000419 Loss_3:0.000000 Lr:0.000833 Time:19.070449s (0.64min in total, 8.99min remains)
2022-11-28 07:30:43 NUM_SUB: 66;----------------------------
2022-11-28 07:30:43 Epoch [03000/30000] Loss:0.014628 Loss_1:0.014442 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000769 Time:19.413092s (0.97min in total, 8.69min remains)
2022-11-28 07:31:02 NUM_SUB: 66;----------------------------
2022-11-28 07:31:02 Epoch [04000/30000] Loss:0.012495 Loss_1:0.012357 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000714 Time:19.162487s (1.29min in total, 8.35min remains)
2022-11-28 07:31:21 NUM_SUB: 66;----------------------------
2022-11-28 07:31:21 Epoch [05000/30000] Loss:0.010233 Loss_1:0.010110 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000667 Time:19.449239s (1.61min in total, 8.05min remains)
2022-11-28 07:31:41 NUM_SUB: 66;----------------------------
2022-11-28 07:31:41 Epoch [06000/30000] Loss:0.007152 Loss_1:0.007051 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000625 Time:19.409016s (1.93min in total, 7.73min remains)
2022-11-28 07:32:00 NUM_SUB: 66;----------------------------
2022-11-28 07:32:00 Epoch [07000/30000] Loss:0.004182 Loss_1:0.004099 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000588 Time:19.171266s (2.25min in total, 7.40min remains)
2022-11-28 07:32:20 NUM_SUB: 66;----------------------------
2022-11-28 07:32:20 Epoch [08000/30000] Loss:0.002141 Loss_1:0.002067 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000556 Time:20.031631s (2.59min in total, 7.11min remains)
2022-11-28 07:32:39 NUM_SUB: 66;----------------------------
2022-11-28 07:32:39 Epoch [09000/30000] Loss:0.001388 Loss_1:0.001320 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000526 Time:19.306962s (2.91min in total, 6.79min remains)
2022-11-28 07:32:58 NUM_SUB: 66;----------------------------
2022-11-28 07:32:58 Epoch [10000/30000] Loss:0.001161 Loss_1:0.001109 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000500 Time:18.990531s (3.22min in total, 6.45min remains)
2022-11-28 07:33:18 NUM_SUB: 66;----------------------------
2022-11-28 07:33:18 Epoch [11000/30000] Loss:0.000942 Loss_1:0.000920 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000476 Time:19.125354s (3.54min in total, 6.12min remains)
2022-11-28 07:33:37 NUM_SUB: 66;----------------------------
2022-11-28 07:33:37 Epoch [12000/30000] Loss:0.000732 Loss_1:0.000720 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000455 Time:18.993067s (3.86min in total, 5.79min remains)
2022-11-28 07:33:56 NUM_SUB: 66;----------------------------
2022-11-28 07:33:56 Epoch [13000/30000] Loss:0.000585 Loss_1:0.000574 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000435 Time:19.141799s (4.18min in total, 5.46min remains)
2022-11-28 07:34:15 NUM_SUB: 66;----------------------------
2022-11-28 07:34:15 Epoch [14000/30000] Loss:0.000500 Loss_1:0.000492 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000417 Time:19.401491s (4.50min in total, 5.15min remains)
2022-11-28 07:34:34 NUM_SUB: 66;----------------------------
2022-11-28 07:34:34 Epoch [15000/30000] Loss:0.000442 Loss_1:0.000435 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000400 Time:19.148828s (4.82min in total, 4.82min remains)
2022-11-28 07:34:53 NUM_SUB: 66;----------------------------
2022-11-28 07:34:53 Epoch [16000/30000] Loss:0.000381 Loss_1:0.000376 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:19.074161s (5.14min in total, 4.50min remains)
2022-11-28 07:35:12 NUM_SUB: 66;----------------------------
2022-11-28 07:35:12 Epoch [17000/30000] Loss:0.000336 Loss_1:0.000332 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000370 Time:18.970168s (5.46min in total, 4.17min remains)
2022-11-28 07:35:32 NUM_SUB: 66;----------------------------
2022-11-28 07:35:32 Epoch [18000/30000] Loss:0.000325 Loss_1:0.000322 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:20.037253s (5.79min in total, 3.86min remains)
2022-11-28 07:35:52 NUM_SUB: 66;----------------------------
2022-11-28 07:35:52 Epoch [19000/30000] Loss:0.000324 Loss_1:0.000321 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:19.760208s (6.12min in total, 3.54min remains)
2022-11-28 07:36:11 NUM_SUB: 66;----------------------------
2022-11-28 07:36:11 Epoch [20000/30000] Loss:0.000323 Loss_1:0.000322 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.060503s (6.44min in total, 3.22min remains)
2022-11-28 07:36:30 NUM_SUB: 66;----------------------------
2022-11-28 07:36:30 Epoch [21000/30000] Loss:0.000323 Loss_1:0.000322 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.158277s (6.76min in total, 2.90min remains)
2022-11-28 07:36:49 NUM_SUB: 66;----------------------------
2022-11-28 07:36:49 Epoch [22000/30000] Loss:0.000326 Loss_1:0.000324 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.160828s (7.08min in total, 2.57min remains)
2022-11-28 07:37:09 NUM_SUB: 66;----------------------------
2022-11-28 07:37:09 Epoch [23000/30000] Loss:0.000322 Loss_1:0.000322 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000303 Time:19.311731s (7.40min in total, 2.25min remains)
2022-11-28 07:37:28 NUM_SUB: 66;----------------------------
2022-11-28 07:37:28 Epoch [24000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:19.007248s (7.71min in total, 1.93min remains)
2022-11-28 07:37:48 NUM_SUB: 66;----------------------------
2022-11-28 07:37:48 Epoch [25000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000286 Time:20.146434s (8.05min in total, 1.61min remains)
2022-11-28 07:38:08 NUM_SUB: 66;----------------------------
2022-11-28 07:38:08 Epoch [26000/30000] Loss:0.000325 Loss_1:0.000324 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.896465s (8.38min in total, 1.29min remains)
2022-11-28 07:38:26 NUM_SUB: 66;----------------------------
2022-11-28 07:38:26 Epoch [27000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:18.677708s (8.69min in total, 0.97min remains)
2022-11-28 07:38:46 NUM_SUB: 66;----------------------------
2022-11-28 07:38:46 Epoch [28000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.697816s (9.02min in total, 0.64min remains)
2022-11-28 07:39:05 NUM_SUB: 66;----------------------------
2022-11-28 07:39:05 Epoch [29000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.114399s (9.34min in total, 0.32min remains)
2022-11-28 07:39:24 NUM_SUB: 66;----------------------------
2022-11-28 07:39:24 Epoch [30000/30000] Loss:0.000325 Loss_1:0.000324 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.085536s (9.66min in total, 0.00min remains)
2022-11-28 07:39:24 Testing & drawing...
2022-11-28 07:39:24 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:39:26 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=66/
2022-11-28 07:39:26 [Loss]
2022-11-28 07:39:26 NUM_SUB: 66; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:39:26 NUM_SUB: 66; Personalized parameter estimation: Parameter containing:
tensor([3.3835e-01, 9.3953e-01, 9.6494e-03, 6.6675e-06, 3.0742e-01, 1.2817e-02,
        7.9770e-01, 8.9644e-01, 4.5563e-01, 1.4304e-02, 2.0782e-01, 1.4422e-01,
        4.4824e-01, 1.6886e-01, 1.7598e-02, 6.9555e-01, 6.9767e-01, 8.0001e-01,
        7.0736e-03, 3.4767e+00, 6.8161e-01, 1.1454e-02, 2.8251e+00, 8.7416e-01,
        2.0621e-02, 3.8941e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:39:26 NUM_SUB: 66------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:39:26 Testing & drawing...
2022-11-28 07:39:26 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:39:28 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=66/
2022-11-28 07:39:28 [Loss]
2022-11-28 07:39:28 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:39:28 General parameter estimation: Parameter containing:
tensor([3.3835e-01, 9.3953e-01, 9.6494e-03, 6.6675e-06, 3.0742e-01, 1.2817e-02,
        7.9770e-01, 8.9644e-01, 4.5563e-01, 1.4304e-02, 2.0782e-01, 1.4422e-01,
        4.4824e-01, 1.6886e-01, 1.7598e-02, 6.9555e-01, 6.9767e-01, 8.0001e-01,
        7.0736e-03, 3.4767e+00, 6.8161e-01, 1.1454e-02, 2.8251e+00, 8.7416e-01,
        2.0621e-02, 3.8941e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 07:39:28 A: prod, degr, TonA, NonA
2022-11-28 07:39:28 [0.48223972 0.49994126 0.01375283 0.00406619]
2022-11-28 07:39:28 T: prod, degr, AonT, NonT
2022-11-28 07:39:28 [0.10180531 0.5522012  0.3118087  0.03418471]
2022-11-28 07:39:28 N: AonN, TonN, ATonN
2022-11-28 07:39:28 [0.00920257 0.9554647  0.03533269]
2022-11-28 07:39:28 using cpu
2022-11-28 07:39:28 epoch = 30000
2022-11-28 07:39:28 epoch_step = 1000
2022-11-28 07:39:28 model_name = SimpleNetworkAD
2022-11-28 07:39:28 now_string = 2022-11-27-19-40-13
2022-11-28 07:39:28 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:39:28 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:39:28 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:39:28 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:39:28 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:39:28 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:39:47 NUM_SUB: 67;----------------------------
2022-11-28 07:39:47 Epoch [01000/30000] Loss:0.095202 Loss_1:0.089514 Loss_2:0.001815 Loss_3:0.000000 Lr:0.000909 Time:19.066024s (0.32min in total, 9.22min remains)
2022-11-28 07:40:06 NUM_SUB: 67;----------------------------
2022-11-28 07:40:06 Epoch [02000/30000] Loss:0.083830 Loss_1:0.082822 Loss_2:0.000566 Loss_3:0.000000 Lr:0.000833 Time:19.333998s (0.64min in total, 8.96min remains)
2022-11-28 07:40:26 NUM_SUB: 67;----------------------------
2022-11-28 07:40:26 Epoch [03000/30000] Loss:0.073270 Loss_1:0.072785 Loss_2:0.000164 Loss_3:0.000000 Lr:0.000769 Time:19.370848s (0.96min in total, 8.67min remains)
2022-11-28 07:40:45 NUM_SUB: 67;----------------------------
2022-11-28 07:40:45 Epoch [04000/30000] Loss:0.060291 Loss_1:0.059807 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000714 Time:19.452836s (1.29min in total, 8.37min remains)
2022-11-28 07:41:04 NUM_SUB: 67;----------------------------
2022-11-28 07:41:04 Epoch [05000/30000] Loss:0.043346 Loss_1:0.042922 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000667 Time:19.370171s (1.61min in total, 8.05min remains)
2022-11-28 07:41:24 NUM_SUB: 67;----------------------------
2022-11-28 07:41:24 Epoch [06000/30000] Loss:0.025319 Loss_1:0.024979 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000625 Time:19.532544s (1.94min in total, 7.74min remains)
2022-11-28 07:41:43 NUM_SUB: 67;----------------------------
2022-11-28 07:41:43 Epoch [07000/30000] Loss:0.012367 Loss_1:0.012114 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000588 Time:19.335075s (2.26min in total, 7.42min remains)
2022-11-28 07:42:03 NUM_SUB: 67;----------------------------
2022-11-28 07:42:03 Epoch [08000/30000] Loss:0.005320 Loss_1:0.005121 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000556 Time:19.535148s (2.58min in total, 7.10min remains)
2022-11-28 07:42:22 NUM_SUB: 67;----------------------------
2022-11-28 07:42:22 Epoch [09000/30000] Loss:0.002072 Loss_1:0.001909 Loss_2:0.000145 Loss_3:0.000000 Lr:0.000526 Time:18.850130s (2.90min in total, 6.76min remains)
2022-11-28 07:42:41 NUM_SUB: 67;----------------------------
2022-11-28 07:42:41 Epoch [10000/30000] Loss:0.001315 Loss_1:0.001192 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000500 Time:19.430757s (3.22min in total, 6.44min remains)
2022-11-28 07:43:00 NUM_SUB: 67;----------------------------
2022-11-28 07:43:00 Epoch [11000/30000] Loss:0.001020 Loss_1:0.000936 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000476 Time:18.803363s (3.53min in total, 6.11min remains)
2022-11-28 07:43:20 NUM_SUB: 67;----------------------------
2022-11-28 07:43:20 Epoch [12000/30000] Loss:0.000755 Loss_1:0.000696 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000455 Time:19.939999s (3.87min in total, 5.80min remains)
2022-11-28 07:43:40 NUM_SUB: 67;----------------------------
2022-11-28 07:43:40 Epoch [13000/30000] Loss:0.000533 Loss_1:0.000491 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000435 Time:19.807744s (4.20min in total, 5.49min remains)
2022-11-28 07:43:59 NUM_SUB: 67;----------------------------
2022-11-28 07:43:59 Epoch [14000/30000] Loss:0.000410 Loss_1:0.000378 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:19.775278s (4.53min in total, 5.17min remains)
2022-11-28 07:44:19 NUM_SUB: 67;----------------------------
2022-11-28 07:44:19 Epoch [15000/30000] Loss:0.000384 Loss_1:0.000356 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000400 Time:19.244644s (4.85min in total, 4.85min remains)
2022-11-28 07:44:38 NUM_SUB: 67;----------------------------
2022-11-28 07:44:38 Epoch [16000/30000] Loss:0.000364 Loss_1:0.000344 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:19.626343s (5.17min in total, 4.53min remains)
2022-11-28 07:44:57 NUM_SUB: 67;----------------------------
2022-11-28 07:44:57 Epoch [17000/30000] Loss:0.000351 Loss_1:0.000334 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000370 Time:19.176836s (5.49min in total, 4.20min remains)
2022-11-28 07:45:17 NUM_SUB: 67;----------------------------
2022-11-28 07:45:17 Epoch [18000/30000] Loss:0.000336 Loss_1:0.000322 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:19.289267s (5.82min in total, 3.88min remains)
2022-11-28 07:45:36 NUM_SUB: 67;----------------------------
2022-11-28 07:45:36 Epoch [19000/30000] Loss:0.000333 Loss_1:0.000322 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000345 Time:19.654800s (6.14min in total, 3.56min remains)
2022-11-28 07:45:56 NUM_SUB: 67;----------------------------
2022-11-28 07:45:56 Epoch [20000/30000] Loss:0.000329 Loss_1:0.000320 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:19.593204s (6.47min in total, 3.24min remains)
2022-11-28 07:46:16 NUM_SUB: 67;----------------------------
2022-11-28 07:46:16 Epoch [21000/30000] Loss:0.000326 Loss_1:0.000320 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:19.545154s (6.80min in total, 2.91min remains)
2022-11-28 07:46:35 NUM_SUB: 67;----------------------------
2022-11-28 07:46:35 Epoch [22000/30000] Loss:0.000325 Loss_1:0.000319 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:19.268571s (7.12min in total, 2.59min remains)
2022-11-28 07:46:54 NUM_SUB: 67;----------------------------
2022-11-28 07:46:54 Epoch [23000/30000] Loss:0.000324 Loss_1:0.000320 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:19.058923s (7.43min in total, 2.26min remains)
2022-11-28 07:47:13 NUM_SUB: 67;----------------------------
2022-11-28 07:47:13 Epoch [24000/30000] Loss:0.000323 Loss_1:0.000320 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.184194s (7.75min in total, 1.94min remains)
2022-11-28 07:47:33 NUM_SUB: 67;----------------------------
2022-11-28 07:47:33 Epoch [25000/30000] Loss:0.000323 Loss_1:0.000320 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.568918s (8.08min in total, 1.62min remains)
2022-11-28 07:47:52 NUM_SUB: 67;----------------------------
2022-11-28 07:47:52 Epoch [26000/30000] Loss:0.000322 Loss_1:0.000320 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.575060s (8.41min in total, 1.29min remains)
2022-11-28 07:48:12 NUM_SUB: 67;----------------------------
2022-11-28 07:48:12 Epoch [27000/30000] Loss:0.000322 Loss_1:0.000320 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.562374s (8.73min in total, 0.97min remains)
2022-11-28 07:48:31 NUM_SUB: 67;----------------------------
2022-11-28 07:48:31 Epoch [28000/30000] Loss:0.000321 Loss_1:0.000320 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.438002s (9.06min in total, 0.65min remains)
2022-11-28 07:48:50 NUM_SUB: 67;----------------------------
2022-11-28 07:48:50 Epoch [29000/30000] Loss:0.000321 Loss_1:0.000319 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:19.124328s (9.38min in total, 0.32min remains)
2022-11-28 07:49:10 NUM_SUB: 67;----------------------------
2022-11-28 07:49:10 Epoch [30000/30000] Loss:0.000321 Loss_1:0.000319 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.528598s (9.70min in total, 0.00min remains)
2022-11-28 07:49:10 Testing & drawing...
2022-11-28 07:49:10 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:49:12 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=67/
2022-11-28 07:49:12 [Loss]
2022-11-28 07:49:12 NUM_SUB: 67; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:49:12 NUM_SUB: 67; Personalized parameter estimation: Parameter containing:
tensor([0.1150, 0.4848, 0.0162, 0.5840, 0.3074, 0.4967, 0.8097, 0.8964, 0.4556,
        0.0130, 0.0317, 0.0138, 0.7735, 0.1689, 0.0175, 1.8722, 0.6977, 0.8000,
        0.0111, 4.6636, 0.6816, 0.0182, 4.0119, 0.8742, 0.0176, 4.9088, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:49:12 NUM_SUB: 67------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:49:12 Testing & drawing...
2022-11-28 07:49:12 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:49:13 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=67/
2022-11-28 07:49:13 [Loss]
2022-11-28 07:49:13 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:49:13 General parameter estimation: Parameter containing:
tensor([0.1150, 0.4848, 0.0162, 0.5840, 0.3074, 0.4967, 0.8097, 0.8964, 0.4556,
        0.0130, 0.0317, 0.0138, 0.7735, 0.1689, 0.0175, 1.8722, 0.6977, 0.8000,
        0.0111, 4.6636, 0.6816, 0.0182, 4.0119, 0.8742, 0.0176, 4.9088, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:49:13 A: prod, degr, TonA, NonA
2022-11-28 07:49:13 [0.19547686 0.49962738 0.01429658 0.29059917]
2022-11-28 07:49:13 T: prod, degr, AonT, NonT
2022-11-28 07:49:13 [0.33278003 0.49256027 0.13456514 0.04009457]
2022-11-28 07:49:13 N: AonN, TonN, ATonN
2022-11-28 07:49:13 [0.01049457 0.959833   0.02967243]
2022-11-28 07:49:14 using cpu
2022-11-28 07:49:14 epoch = 30000
2022-11-28 07:49:14 epoch_step = 1000
2022-11-28 07:49:14 model_name = SimpleNetworkAD
2022-11-28 07:49:14 now_string = 2022-11-27-19-40-13
2022-11-28 07:49:14 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:49:14 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:49:14 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:49:14 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:49:14 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:49:14 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:49:33 NUM_SUB: 68;----------------------------
2022-11-28 07:49:33 Epoch [01000/30000] Loss:0.132243 Loss_1:0.126605 Loss_2:0.001712 Loss_3:0.000000 Lr:0.000909 Time:19.454468s (0.32min in total, 9.40min remains)
2022-11-28 07:49:53 NUM_SUB: 68;----------------------------
2022-11-28 07:49:53 Epoch [02000/30000] Loss:0.119827 Loss_1:0.118829 Loss_2:0.000513 Loss_3:0.000000 Lr:0.000833 Time:19.499967s (0.65min in total, 9.09min remains)
2022-11-28 07:50:12 NUM_SUB: 68;----------------------------
2022-11-28 07:50:12 Epoch [03000/30000] Loss:0.106902 Loss_1:0.106379 Loss_2:0.000145 Loss_3:0.000000 Lr:0.000769 Time:19.230438s (0.97min in total, 8.73min remains)
2022-11-28 07:50:31 NUM_SUB: 68;----------------------------
2022-11-28 07:50:31 Epoch [04000/30000] Loss:0.089645 Loss_1:0.089090 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000714 Time:19.622980s (1.30min in total, 8.43min remains)
2022-11-28 07:50:51 NUM_SUB: 68;----------------------------
2022-11-28 07:50:51 Epoch [05000/30000] Loss:0.065198 Loss_1:0.064697 Loss_2:0.000100 Loss_3:0.000000 Lr:0.000667 Time:20.033396s (1.63min in total, 8.15min remains)
2022-11-28 07:51:11 NUM_SUB: 68;----------------------------
2022-11-28 07:51:11 Epoch [06000/30000] Loss:0.036091 Loss_1:0.035678 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000625 Time:19.114802s (1.95min in total, 7.80min remains)
2022-11-28 07:51:30 NUM_SUB: 68;----------------------------
2022-11-28 07:51:30 Epoch [07000/30000] Loss:0.013466 Loss_1:0.013171 Loss_2:0.000134 Loss_3:0.000000 Lr:0.000588 Time:19.786824s (2.28min in total, 7.49min remains)
2022-11-28 07:51:49 NUM_SUB: 68;----------------------------
2022-11-28 07:51:49 Epoch [08000/30000] Loss:0.003240 Loss_1:0.003036 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000556 Time:19.030266s (2.60min in total, 7.14min remains)
2022-11-28 07:52:09 NUM_SUB: 68;----------------------------
2022-11-28 07:52:09 Epoch [09000/30000] Loss:0.000611 Loss_1:0.000456 Loss_2:0.000149 Loss_3:0.000000 Lr:0.000526 Time:19.662346s (2.92min in total, 6.82min remains)
2022-11-28 07:52:28 NUM_SUB: 68;----------------------------
2022-11-28 07:52:28 Epoch [10000/30000] Loss:0.000323 Loss_1:0.000206 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000500 Time:18.990537s (3.24min in total, 6.48min remains)
2022-11-28 07:52:47 NUM_SUB: 68;----------------------------
2022-11-28 07:52:47 Epoch [11000/30000] Loss:0.000180 Loss_1:0.000106 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000476 Time:19.072864s (3.56min in total, 6.15min remains)
2022-11-28 07:53:06 NUM_SUB: 68;----------------------------
2022-11-28 07:53:06 Epoch [12000/30000] Loss:0.000080 Loss_1:0.000038 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000455 Time:19.356145s (3.88min in total, 5.82min remains)
2022-11-28 07:53:27 NUM_SUB: 68;----------------------------
2022-11-28 07:53:27 Epoch [13000/30000] Loss:0.000042 Loss_1:0.000012 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:20.733858s (4.23min in total, 5.53min remains)
2022-11-28 07:53:47 NUM_SUB: 68;----------------------------
2022-11-28 07:53:47 Epoch [14000/30000] Loss:0.000026 Loss_1:0.000003 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:20.323673s (4.57min in total, 5.22min remains)
2022-11-28 07:54:07 NUM_SUB: 68;----------------------------
2022-11-28 07:54:07 Epoch [15000/30000] Loss:0.000018 Loss_1:0.000001 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000400 Time:19.646820s (4.89min in total, 4.89min remains)
2022-11-28 07:54:27 NUM_SUB: 68;----------------------------
2022-11-28 07:54:27 Epoch [16000/30000] Loss:0.000013 Loss_1:0.000000 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:19.618726s (5.22min in total, 4.57min remains)
2022-11-28 07:54:46 NUM_SUB: 68;----------------------------
2022-11-28 07:54:46 Epoch [17000/30000] Loss:0.000010 Loss_1:0.000000 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000370 Time:19.244697s (5.54min in total, 4.24min remains)
2022-11-28 07:55:05 NUM_SUB: 68;----------------------------
2022-11-28 07:55:05 Epoch [18000/30000] Loss:0.000008 Loss_1:0.000000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:19.263440s (5.86min in total, 3.91min remains)
2022-11-28 07:55:25 NUM_SUB: 68;----------------------------
2022-11-28 07:55:25 Epoch [19000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000345 Time:19.334917s (6.18min in total, 3.58min remains)
2022-11-28 07:55:44 NUM_SUB: 68;----------------------------
2022-11-28 07:55:44 Epoch [20000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.264578s (6.51min in total, 3.25min remains)
2022-11-28 07:56:03 NUM_SUB: 68;----------------------------
2022-11-28 07:56:03 Epoch [21000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000323 Time:19.479823s (6.83min in total, 2.93min remains)
2022-11-28 07:56:23 NUM_SUB: 68;----------------------------
2022-11-28 07:56:23 Epoch [22000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.199792s (7.15min in total, 2.60min remains)
2022-11-28 07:56:42 NUM_SUB: 68;----------------------------
2022-11-28 07:56:42 Epoch [23000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000303 Time:19.072378s (7.47min in total, 2.27min remains)
2022-11-28 07:57:00 NUM_SUB: 68;----------------------------
2022-11-28 07:57:00 Epoch [24000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.805621s (7.78min in total, 1.95min remains)
2022-11-28 07:57:20 NUM_SUB: 68;----------------------------
2022-11-28 07:57:20 Epoch [25000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.608570s (8.11min in total, 1.62min remains)
2022-11-28 07:57:39 NUM_SUB: 68;----------------------------
2022-11-28 07:57:39 Epoch [26000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:18.604347s (8.42min in total, 1.30min remains)
2022-11-28 07:57:58 NUM_SUB: 68;----------------------------
2022-11-28 07:57:58 Epoch [27000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.364016s (8.74min in total, 0.97min remains)
2022-11-28 07:58:17 NUM_SUB: 68;----------------------------
2022-11-28 07:58:17 Epoch [28000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:19.208436s (9.06min in total, 0.65min remains)
2022-11-28 07:58:36 NUM_SUB: 68;----------------------------
2022-11-28 07:58:36 Epoch [29000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:18.957120s (9.38min in total, 0.32min remains)
2022-11-28 07:58:55 NUM_SUB: 68;----------------------------
2022-11-28 07:58:55 Epoch [30000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:18.738064s (9.69min in total, 0.00min remains)
2022-11-28 07:58:55 Testing & drawing...
2022-11-28 07:58:55 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:58:57 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=68/
2022-11-28 07:58:57 [Loss]
2022-11-28 07:58:57 NUM_SUB: 68; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:58:57 NUM_SUB: 68; Personalized parameter estimation: Parameter containing:
tensor([0.0148, 0.5117, 0.0102, 0.6000, 0.3074, 0.7523, 1.1226, 0.8964, 0.4556,
        0.0138, 0.0307, 0.0147, 0.8976, 0.1689, 0.0175, 2.0259, 0.6977, 0.8000,
        0.0112, 4.2504, 0.6816, 0.0218, 4.0170, 0.8742, 0.0133, 4.6892, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:58:57 NUM_SUB: 68------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 07:58:57 Testing & drawing...
2022-11-28 07:58:57 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 07:58:58 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=68/
2022-11-28 07:58:58 [Loss]
2022-11-28 07:58:58 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 07:58:58 General parameter estimation: Parameter containing:
tensor([0.0148, 0.5117, 0.0102, 0.6000, 0.3074, 0.7523, 1.1226, 0.8964, 0.4556,
        0.0138, 0.0307, 0.0147, 0.8976, 0.1689, 0.0175, 2.0259, 0.6977, 0.8000,
        0.0112, 4.2504, 0.6816, 0.0218, 4.0170, 0.8742, 0.0133, 4.6892, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 07:58:58 A: prod, degr, TonA, NonA
2022-11-28 07:58:58 [0.02884704 0.49955544 0.01080558 0.46079195]
2022-11-28 07:58:58 T: prod, degr, AonT, NonT
2022-11-28 07:58:58 [0.37765205 0.42224953 0.14069326 0.05940519]
2022-11-28 07:58:58 N: AonN, TonN, ATonN
2022-11-28 07:58:58 [0.00743022 0.9732766  0.01929317]
2022-11-28 07:58:58 using cpu
2022-11-28 07:58:58 epoch = 30000
2022-11-28 07:58:58 epoch_step = 1000
2022-11-28 07:58:58 model_name = SimpleNetworkAD
2022-11-28 07:58:58 now_string = 2022-11-27-19-40-13
2022-11-28 07:58:58 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 07:58:58 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 07:58:58 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 07:58:58 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 07:58:58 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 07:58:58 --------------------------------------------------training start--------------------------------------------------
2022-11-28 07:59:18 NUM_SUB: 69;----------------------------
2022-11-28 07:59:18 Epoch [01000/30000] Loss:0.125081 Loss_1:0.118700 Loss_2:0.002381 Loss_3:0.000000 Lr:0.000909 Time:19.489824s (0.32min in total, 9.42min remains)
2022-11-28 07:59:37 NUM_SUB: 69;----------------------------
2022-11-28 07:59:37 Epoch [02000/30000] Loss:0.116182 Loss_1:0.114268 Loss_2:0.001329 Loss_3:0.000000 Lr:0.000833 Time:18.914076s (0.64min in total, 8.96min remains)
2022-11-28 07:59:56 NUM_SUB: 69;----------------------------
2022-11-28 07:59:56 Epoch [03000/30000] Loss:0.103715 Loss_1:0.102180 Loss_2:0.001053 Loss_3:0.000000 Lr:0.000769 Time:19.525787s (0.97min in total, 8.69min remains)
2022-11-28 08:00:15 NUM_SUB: 69;----------------------------
2022-11-28 08:00:15 Epoch [04000/30000] Loss:0.093184 Loss_1:0.092397 Loss_2:0.000278 Loss_3:0.000000 Lr:0.000714 Time:18.959596s (1.28min in total, 8.33min remains)
2022-11-28 08:00:35 NUM_SUB: 69;----------------------------
2022-11-28 08:00:35 Epoch [05000/30000] Loss:0.079270 Loss_1:0.078601 Loss_2:0.000199 Loss_3:0.000000 Lr:0.000667 Time:19.435983s (1.61min in total, 8.03min remains)
2022-11-28 08:00:54 NUM_SUB: 69;----------------------------
2022-11-28 08:00:54 Epoch [06000/30000] Loss:0.058332 Loss_1:0.057729 Loss_2:0.000191 Loss_3:0.000000 Lr:0.000625 Time:19.007309s (1.92min in total, 7.69min remains)
2022-11-28 08:01:13 NUM_SUB: 69;----------------------------
2022-11-28 08:01:13 Epoch [07000/30000] Loss:0.029435 Loss_1:0.028908 Loss_2:0.000237 Loss_3:0.000000 Lr:0.000588 Time:19.410082s (2.25min in total, 7.38min remains)
2022-11-28 08:01:32 NUM_SUB: 69;----------------------------
2022-11-28 08:01:32 Epoch [08000/30000] Loss:0.006291 Loss_1:0.005875 Loss_2:0.000294 Loss_3:0.000000 Lr:0.000556 Time:19.057610s (2.56min in total, 7.05min remains)
2022-11-28 08:01:52 NUM_SUB: 69;----------------------------
2022-11-28 08:01:52 Epoch [09000/30000] Loss:0.001398 Loss_1:0.001119 Loss_2:0.000249 Loss_3:0.000000 Lr:0.000526 Time:19.320667s (2.89min in total, 6.73min remains)
2022-11-28 08:02:11 NUM_SUB: 69;----------------------------
2022-11-28 08:02:11 Epoch [10000/30000] Loss:0.000923 Loss_1:0.000732 Loss_2:0.000178 Loss_3:0.000000 Lr:0.000500 Time:19.101813s (3.20min in total, 6.41min remains)
2022-11-28 08:02:30 NUM_SUB: 69;----------------------------
2022-11-28 08:02:30 Epoch [11000/30000] Loss:0.000629 Loss_1:0.000496 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000476 Time:19.327498s (3.53min in total, 6.09min remains)
2022-11-28 08:02:49 NUM_SUB: 69;----------------------------
2022-11-28 08:02:49 Epoch [12000/30000] Loss:0.000395 Loss_1:0.000298 Loss_2:0.000095 Loss_3:0.000000 Lr:0.000455 Time:19.135883s (3.84min in total, 5.77min remains)
2022-11-28 08:03:08 NUM_SUB: 69;----------------------------
2022-11-28 08:03:08 Epoch [13000/30000] Loss:0.000262 Loss_1:0.000180 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000435 Time:19.283063s (4.17min in total, 5.45min remains)
2022-11-28 08:03:28 NUM_SUB: 69;----------------------------
2022-11-28 08:03:28 Epoch [14000/30000] Loss:0.000165 Loss_1:0.000102 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000417 Time:19.181572s (4.49min in total, 5.13min remains)
2022-11-28 08:03:47 NUM_SUB: 69;----------------------------
2022-11-28 08:03:47 Epoch [15000/30000] Loss:0.000103 Loss_1:0.000052 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000400 Time:19.288709s (4.81min in total, 4.81min remains)
2022-11-28 08:04:06 NUM_SUB: 69;----------------------------
2022-11-28 08:04:06 Epoch [16000/30000] Loss:0.000066 Loss_1:0.000023 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000385 Time:19.174004s (5.13min in total, 4.49min remains)
2022-11-28 08:04:25 NUM_SUB: 69;----------------------------
2022-11-28 08:04:25 Epoch [17000/30000] Loss:0.000051 Loss_1:0.000008 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000370 Time:19.250780s (5.45min in total, 4.17min remains)
2022-11-28 08:04:45 NUM_SUB: 69;----------------------------
2022-11-28 08:04:45 Epoch [18000/30000] Loss:0.000038 Loss_1:0.000002 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000357 Time:19.810132s (5.78min in total, 3.85min remains)
2022-11-28 08:05:04 NUM_SUB: 69;----------------------------
2022-11-28 08:05:04 Epoch [19000/30000] Loss:0.000032 Loss_1:0.000001 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000345 Time:19.257518s (6.10min in total, 3.53min remains)
2022-11-28 08:05:24 NUM_SUB: 69;----------------------------
2022-11-28 08:05:24 Epoch [20000/30000] Loss:0.000029 Loss_1:0.000000 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000333 Time:19.253570s (6.42min in total, 3.21min remains)
2022-11-28 08:05:43 NUM_SUB: 69;----------------------------
2022-11-28 08:05:43 Epoch [21000/30000] Loss:0.000026 Loss_1:0.000000 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000323 Time:19.343332s (6.74min in total, 2.89min remains)
2022-11-28 08:06:02 NUM_SUB: 69;----------------------------
2022-11-28 08:06:02 Epoch [22000/30000] Loss:0.000024 Loss_1:0.000000 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000313 Time:19.246989s (7.06min in total, 2.57min remains)
2022-11-28 08:06:21 NUM_SUB: 69;----------------------------
2022-11-28 08:06:21 Epoch [23000/30000] Loss:0.000021 Loss_1:0.000000 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000303 Time:19.174266s (7.38min in total, 2.25min remains)
2022-11-28 08:06:41 NUM_SUB: 69;----------------------------
2022-11-28 08:06:41 Epoch [24000/30000] Loss:0.000019 Loss_1:0.000000 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000294 Time:19.350991s (7.71min in total, 1.93min remains)
2022-11-28 08:07:00 NUM_SUB: 69;----------------------------
2022-11-28 08:07:00 Epoch [25000/30000] Loss:0.000015 Loss_1:0.000000 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000286 Time:19.502994s (8.03min in total, 1.61min remains)
2022-11-28 08:07:19 NUM_SUB: 69;----------------------------
2022-11-28 08:07:19 Epoch [26000/30000] Loss:0.000013 Loss_1:0.000000 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000278 Time:19.096318s (8.35min in total, 1.28min remains)
2022-11-28 08:07:39 NUM_SUB: 69;----------------------------
2022-11-28 08:07:39 Epoch [27000/30000] Loss:0.000011 Loss_1:0.000000 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000270 Time:19.498778s (8.67min in total, 0.96min remains)
2022-11-28 08:07:58 NUM_SUB: 69;----------------------------
2022-11-28 08:07:58 Epoch [28000/30000] Loss:0.000009 Loss_1:0.000000 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000263 Time:19.235065s (8.99min in total, 0.64min remains)
2022-11-28 08:08:17 NUM_SUB: 69;----------------------------
2022-11-28 08:08:17 Epoch [29000/30000] Loss:0.000009 Loss_1:0.000000 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000256 Time:19.225551s (9.31min in total, 0.32min remains)
2022-11-28 08:08:37 NUM_SUB: 69;----------------------------
2022-11-28 08:08:37 Epoch [30000/30000] Loss:0.000008 Loss_1:0.000000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000250 Time:19.548563s (9.64min in total, 0.00min remains)
2022-11-28 08:08:37 Testing & drawing...
2022-11-28 08:08:37 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:08:39 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=69/
2022-11-28 08:08:39 [Loss]
2022-11-28 08:08:39 NUM_SUB: 69; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:08:39 NUM_SUB: 69; Personalized parameter estimation: Parameter containing:
tensor([2.4346e-03, 1.0787e-03, 9.3941e-03, 4.0416e+00, 3.0742e-01, 1.8309e-02,
        3.0970e+00, 8.9644e-01, 4.5563e-01, 9.7447e-02, 1.2164e-01, 1.4225e-02,
        2.0956e-01, 1.6886e-01, 1.7640e-02, 1.7021e+00, 6.9767e-01, 8.0001e-01,
        1.1296e-02, 4.6933e+00, 6.8161e-01, 2.1791e-02, 4.3998e+00, 8.7416e-01,
        1.9105e-02, 5.1822e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:08:39 NUM_SUB: 69------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 08:08:39 Testing & drawing...
2022-11-28 08:08:39 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:08:40 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=69/
2022-11-28 08:08:40 [Loss]
2022-11-28 08:08:40 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:08:40 General parameter estimation: Parameter containing:
tensor([2.4346e-03, 1.0787e-03, 9.3941e-03, 4.0416e+00, 3.0742e-01, 1.8309e-02,
        3.0970e+00, 8.9644e-01, 4.5563e-01, 9.7447e-02, 1.2164e-01, 1.4225e-02,
        2.0956e-01, 1.6886e-01, 1.7640e-02, 1.7021e+00, 6.9767e-01, 8.0001e-01,
        1.1296e-02, 4.6933e+00, 6.8161e-01, 2.1791e-02, 4.3998e+00, 8.7416e-01,
        1.9105e-02, 5.1822e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:08:40 A: prod, degr, TonA, NonA
2022-11-28 08:08:40 [0.6196548  0.16033542 0.11816908 0.1018407 ]
2022-11-28 08:08:40 T: prod, degr, AonT, NonT
2022-11-28 08:08:40 [0.5363284  0.38270387 0.07444261 0.00652515]
2022-11-28 08:08:40 N: AonN, TonN, ATonN
2022-11-28 08:08:40 [0.0093903  0.9518495  0.03876019]
2022-11-28 08:08:40 using cpu
2022-11-28 08:08:40 epoch = 30000
2022-11-28 08:08:40 epoch_step = 1000
2022-11-28 08:08:40 model_name = SimpleNetworkAD
2022-11-28 08:08:40 now_string = 2022-11-27-19-40-13
2022-11-28 08:08:40 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 08:08:40 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 08:08:40 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 08:08:40 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 08:08:40 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 08:08:40 --------------------------------------------------training start--------------------------------------------------
2022-11-28 08:08:59 NUM_SUB: 70;----------------------------
2022-11-28 08:08:59 Epoch [01000/30000] Loss:0.095806 Loss_1:0.090710 Loss_2:0.001302 Loss_3:0.000000 Lr:0.000909 Time:19.060756s (0.32min in total, 9.21min remains)
2022-11-28 08:09:19 NUM_SUB: 70;----------------------------
2022-11-28 08:09:19 Epoch [02000/30000] Loss:0.086278 Loss_1:0.085559 Loss_2:0.000317 Loss_3:0.000000 Lr:0.000833 Time:19.602276s (0.64min in total, 9.02min remains)
2022-11-28 08:09:38 NUM_SUB: 70;----------------------------
2022-11-28 08:09:38 Epoch [03000/30000] Loss:0.077710 Loss_1:0.077456 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000769 Time:19.041805s (0.96min in total, 8.66min remains)
2022-11-28 08:09:57 NUM_SUB: 70;----------------------------
2022-11-28 08:09:57 Epoch [04000/30000] Loss:0.066794 Loss_1:0.066531 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000714 Time:19.346994s (1.28min in total, 8.35min remains)
2022-11-28 08:10:17 NUM_SUB: 70;----------------------------
2022-11-28 08:10:17 Epoch [05000/30000] Loss:0.051245 Loss_1:0.051001 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000667 Time:19.504056s (1.61min in total, 8.05min remains)
2022-11-28 08:10:36 NUM_SUB: 70;----------------------------
2022-11-28 08:10:36 Epoch [06000/30000] Loss:0.031913 Loss_1:0.031711 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000625 Time:18.854795s (1.92min in total, 7.69min remains)
2022-11-28 08:10:55 NUM_SUB: 70;----------------------------
2022-11-28 08:10:55 Epoch [07000/30000] Loss:0.015700 Loss_1:0.015556 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000588 Time:19.610742s (2.25min in total, 7.39min remains)
2022-11-28 08:11:15 NUM_SUB: 70;----------------------------
2022-11-28 08:11:15 Epoch [08000/30000] Loss:0.008489 Loss_1:0.008386 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000556 Time:19.125344s (2.57min in total, 7.07min remains)
2022-11-28 08:11:34 NUM_SUB: 70;----------------------------
2022-11-28 08:11:34 Epoch [09000/30000] Loss:0.005445 Loss_1:0.005348 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000526 Time:19.066054s (2.89min in total, 6.74min remains)
2022-11-28 08:11:53 NUM_SUB: 70;----------------------------
2022-11-28 08:11:53 Epoch [10000/30000] Loss:0.003974 Loss_1:0.003882 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000500 Time:19.695159s (3.22min in total, 6.43min remains)
2022-11-28 08:12:13 NUM_SUB: 70;----------------------------
2022-11-28 08:12:13 Epoch [11000/30000] Loss:0.003473 Loss_1:0.003402 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000476 Time:19.699362s (3.54min in total, 6.12min remains)
2022-11-28 08:12:33 NUM_SUB: 70;----------------------------
2022-11-28 08:12:33 Epoch [12000/30000] Loss:0.003057 Loss_1:0.003026 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000455 Time:19.535760s (3.87min in total, 5.80min remains)
2022-11-28 08:12:52 NUM_SUB: 70;----------------------------
2022-11-28 08:12:52 Epoch [13000/30000] Loss:0.002820 Loss_1:0.002797 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000435 Time:19.122619s (4.19min in total, 5.48min remains)
2022-11-28 08:13:11 NUM_SUB: 70;----------------------------
2022-11-28 08:13:11 Epoch [14000/30000] Loss:0.002730 Loss_1:0.002712 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:19.532109s (4.51min in total, 5.16min remains)
2022-11-28 08:13:30 NUM_SUB: 70;----------------------------
2022-11-28 08:13:30 Epoch [15000/30000] Loss:0.002682 Loss_1:0.002668 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000400 Time:19.066347s (4.83min in total, 4.83min remains)
2022-11-28 08:13:50 NUM_SUB: 70;----------------------------
2022-11-28 08:13:50 Epoch [16000/30000] Loss:0.002652 Loss_1:0.002641 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:19.410500s (5.15min in total, 4.51min remains)
2022-11-28 08:14:10 NUM_SUB: 70;----------------------------
2022-11-28 08:14:10 Epoch [17000/30000] Loss:0.002627 Loss_1:0.002618 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000370 Time:20.480855s (5.50min in total, 4.20min remains)
2022-11-28 08:14:30 NUM_SUB: 70;----------------------------
2022-11-28 08:14:30 Epoch [18000/30000] Loss:0.002586 Loss_1:0.002580 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:19.582051s (5.82min in total, 3.88min remains)
2022-11-28 08:14:49 NUM_SUB: 70;----------------------------
2022-11-28 08:14:49 Epoch [19000/30000] Loss:0.002574 Loss_1:0.002569 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000345 Time:19.065887s (6.14min in total, 3.55min remains)
2022-11-28 08:15:08 NUM_SUB: 70;----------------------------
2022-11-28 08:15:08 Epoch [20000/30000] Loss:0.002571 Loss_1:0.002568 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:19.167544s (6.46min in total, 3.23min remains)
2022-11-28 08:15:28 NUM_SUB: 70;----------------------------
2022-11-28 08:15:28 Epoch [21000/30000] Loss:0.002570 Loss_1:0.002567 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:19.570255s (6.79min in total, 2.91min remains)
2022-11-28 08:15:46 NUM_SUB: 70;----------------------------
2022-11-28 08:15:46 Epoch [22000/30000] Loss:0.002569 Loss_1:0.002567 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:18.619679s (7.10min in total, 2.58min remains)
2022-11-28 08:16:06 NUM_SUB: 70;----------------------------
2022-11-28 08:16:06 Epoch [23000/30000] Loss:0.002569 Loss_1:0.002567 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.419699s (7.42min in total, 2.26min remains)
2022-11-28 08:16:25 NUM_SUB: 70;----------------------------
2022-11-28 08:16:25 Epoch [24000/30000] Loss:0.002569 Loss_1:0.002566 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.335525s (7.74min in total, 1.94min remains)
2022-11-28 08:16:44 NUM_SUB: 70;----------------------------
2022-11-28 08:16:44 Epoch [25000/30000] Loss:0.002568 Loss_1:0.002566 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:19.087150s (8.06min in total, 1.61min remains)
2022-11-28 08:17:03 NUM_SUB: 70;----------------------------
2022-11-28 08:17:03 Epoch [26000/30000] Loss:0.002568 Loss_1:0.002567 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:19.060708s (8.38min in total, 1.29min remains)
2022-11-28 08:17:23 NUM_SUB: 70;----------------------------
2022-11-28 08:17:23 Epoch [27000/30000] Loss:0.002568 Loss_1:0.002566 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000270 Time:19.414715s (8.70min in total, 0.97min remains)
2022-11-28 08:17:41 NUM_SUB: 70;----------------------------
2022-11-28 08:17:41 Epoch [28000/30000] Loss:0.002568 Loss_1:0.002567 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:18.762111s (9.01min in total, 0.64min remains)
2022-11-28 08:18:00 NUM_SUB: 70;----------------------------
2022-11-28 08:18:00 Epoch [29000/30000] Loss:0.002568 Loss_1:0.002566 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.098483s (9.33min in total, 0.32min remains)
2022-11-28 08:18:19 NUM_SUB: 70;----------------------------
2022-11-28 08:18:19 Epoch [30000/30000] Loss:0.002568 Loss_1:0.002566 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.017361s (9.65min in total, 0.00min remains)
2022-11-28 08:18:19 Testing & drawing...
2022-11-28 08:18:19 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:18:21 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=70/
2022-11-28 08:18:21 [Loss]
2022-11-28 08:18:21 NUM_SUB: 70; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:18:21 NUM_SUB: 70; Personalized parameter estimation: Parameter containing:
tensor([2.0306e-01, 1.0366e+00, 9.4598e-03, 3.4075e-26, 3.0742e-01, 9.1245e-03,
        7.7361e-01, 8.9644e-01, 4.5563e-01, 1.4130e-02, 2.9909e-02, 1.3932e-02,
        9.5296e-01, 1.6886e-01, 1.7518e-02, 2.6558e+00, 6.9767e-01, 8.0001e-01,
        1.2438e-02, 2.9667e+00, 6.8161e-01, 2.1122e-02, 3.6638e+00, 8.7416e-01,
        2.1605e-02, 4.3409e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:18:21 NUM_SUB: 70------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 08:18:21 Testing & drawing...
2022-11-28 08:18:21 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:18:23 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=70/
2022-11-28 08:18:23 [Loss]
2022-11-28 08:18:23 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:18:23 General parameter estimation: Parameter containing:
tensor([2.0306e-01, 1.0366e+00, 9.4598e-03, 3.4075e-26, 3.0742e-01, 9.1245e-03,
        7.7361e-01, 8.9644e-01, 4.5563e-01, 1.4130e-02, 2.9909e-02, 1.3932e-02,
        9.5296e-01, 1.6886e-01, 1.7518e-02, 2.6558e+00, 6.9767e-01, 8.0001e-01,
        1.2438e-02, 2.9667e+00, 6.8161e-01, 2.1122e-02, 3.6638e+00, 8.7416e-01,
        2.1605e-02, 4.3409e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:18:23 A: prod, degr, TonA, NonA
2022-11-28 08:18:23 [0.4679934  0.5000635  0.02180253 0.01014059]
2022-11-28 08:18:23 T: prod, degr, AonT, NonT
2022-11-28 08:18:23 [0.55120665 0.24420203 0.15438056 0.05021076]
2022-11-28 08:18:23 N: AonN, TonN, ATonN
2022-11-28 08:18:23 [0.00307622 0.9739305  0.02299331]
2022-11-28 08:18:23 using cpu
2022-11-28 08:18:23 epoch = 30000
2022-11-28 08:18:23 epoch_step = 1000
2022-11-28 08:18:23 model_name = SimpleNetworkAD
2022-11-28 08:18:23 now_string = 2022-11-27-19-40-13
2022-11-28 08:18:23 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 08:18:23 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 08:18:23 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 08:18:23 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 08:18:23 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 08:18:23 --------------------------------------------------training start--------------------------------------------------
2022-11-28 08:18:42 NUM_SUB: 71;----------------------------
2022-11-28 08:18:42 Epoch [01000/30000] Loss:0.014140 Loss_1:0.008871 Loss_2:0.001550 Loss_3:0.000000 Lr:0.000909 Time:19.007667s (0.32min in total, 9.19min remains)
2022-11-28 08:19:01 NUM_SUB: 71;----------------------------
2022-11-28 08:19:01 Epoch [02000/30000] Loss:0.009475 Loss_1:0.008644 Loss_2:0.000428 Loss_3:0.000000 Lr:0.000833 Time:18.857092s (0.63min in total, 8.84min remains)
2022-11-28 08:19:20 NUM_SUB: 71;----------------------------
2022-11-28 08:19:20 Epoch [03000/30000] Loss:0.008666 Loss_1:0.008472 Loss_2:0.000128 Loss_3:0.000000 Lr:0.000769 Time:19.150298s (0.95min in total, 8.55min remains)
2022-11-28 08:19:39 NUM_SUB: 71;----------------------------
2022-11-28 08:19:39 Epoch [04000/30000] Loss:0.008372 Loss_1:0.008292 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000714 Time:19.072676s (1.27min in total, 8.24min remains)
2022-11-28 08:19:58 NUM_SUB: 71;----------------------------
2022-11-28 08:19:58 Epoch [05000/30000] Loss:0.008159 Loss_1:0.008086 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000667 Time:19.124545s (1.59min in total, 7.93min remains)
2022-11-28 08:20:17 NUM_SUB: 71;----------------------------
2022-11-28 08:20:17 Epoch [06000/30000] Loss:0.007930 Loss_1:0.007859 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000625 Time:19.045678s (1.90min in total, 7.62min remains)
2022-11-28 08:20:36 NUM_SUB: 71;----------------------------
2022-11-28 08:20:36 Epoch [07000/30000] Loss:0.007706 Loss_1:0.007634 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000588 Time:19.224307s (2.22min in total, 7.31min remains)
2022-11-28 08:20:55 NUM_SUB: 71;----------------------------
2022-11-28 08:20:55 Epoch [08000/30000] Loss:0.007514 Loss_1:0.007439 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000556 Time:19.076102s (2.54min in total, 6.99min remains)
2022-11-28 08:21:15 NUM_SUB: 71;----------------------------
2022-11-28 08:21:15 Epoch [09000/30000] Loss:0.007340 Loss_1:0.007262 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000526 Time:19.374503s (2.87min in total, 6.69min remains)
2022-11-28 08:21:34 NUM_SUB: 71;----------------------------
2022-11-28 08:21:34 Epoch [10000/30000] Loss:0.007117 Loss_1:0.007053 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000500 Time:19.451889s (3.19min in total, 6.38min remains)
2022-11-28 08:21:53 NUM_SUB: 71;----------------------------
2022-11-28 08:21:53 Epoch [11000/30000] Loss:0.006791 Loss_1:0.006766 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000476 Time:19.082370s (3.51min in total, 6.06min remains)
2022-11-28 08:22:13 NUM_SUB: 71;----------------------------
2022-11-28 08:22:13 Epoch [12000/30000] Loss:0.006421 Loss_1:0.006408 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000455 Time:19.573042s (3.83min in total, 5.75min remains)
2022-11-28 08:22:33 NUM_SUB: 71;----------------------------
2022-11-28 08:22:33 Epoch [13000/30000] Loss:0.006079 Loss_1:0.006062 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000435 Time:19.760842s (4.16min in total, 5.44min remains)
2022-11-28 08:22:52 NUM_SUB: 71;----------------------------
2022-11-28 08:22:52 Epoch [14000/30000] Loss:0.005894 Loss_1:0.005872 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000417 Time:19.658543s (4.49min in total, 5.13min remains)
2022-11-28 08:23:11 NUM_SUB: 71;----------------------------
2022-11-28 08:23:11 Epoch [15000/30000] Loss:0.005851 Loss_1:0.005839 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000400 Time:19.089960s (4.81min in total, 4.81min remains)
2022-11-28 08:23:31 NUM_SUB: 71;----------------------------
2022-11-28 08:23:31 Epoch [16000/30000] Loss:0.005847 Loss_1:0.005838 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:19.198193s (5.13min in total, 4.49min remains)
2022-11-28 08:23:50 NUM_SUB: 71;----------------------------
2022-11-28 08:23:50 Epoch [17000/30000] Loss:0.005845 Loss_1:0.005839 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000370 Time:19.815611s (5.46min in total, 4.18min remains)
2022-11-28 08:24:10 NUM_SUB: 71;----------------------------
2022-11-28 08:24:10 Epoch [18000/30000] Loss:0.005844 Loss_1:0.005839 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000357 Time:19.275924s (5.78min in total, 3.85min remains)
2022-11-28 08:24:29 NUM_SUB: 71;----------------------------
2022-11-28 08:24:29 Epoch [19000/30000] Loss:0.005841 Loss_1:0.005837 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000345 Time:19.467947s (6.11min in total, 3.53min remains)
2022-11-28 08:24:48 NUM_SUB: 71;----------------------------
2022-11-28 08:24:48 Epoch [20000/30000] Loss:0.005840 Loss_1:0.005832 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:19.138781s (6.42min in total, 3.21min remains)
2022-11-28 08:25:08 NUM_SUB: 71;----------------------------
2022-11-28 08:25:08 Epoch [21000/30000] Loss:0.005838 Loss_1:0.005832 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000323 Time:19.363553s (6.75min in total, 2.89min remains)
2022-11-28 08:25:27 NUM_SUB: 71;----------------------------
2022-11-28 08:25:27 Epoch [22000/30000] Loss:0.005836 Loss_1:0.005832 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:19.379172s (7.07min in total, 2.57min remains)
2022-11-28 08:25:46 NUM_SUB: 71;----------------------------
2022-11-28 08:25:46 Epoch [23000/30000] Loss:0.005835 Loss_1:0.005828 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000303 Time:19.361022s (7.39min in total, 2.25min remains)
2022-11-28 08:26:06 NUM_SUB: 71;----------------------------
2022-11-28 08:26:06 Epoch [24000/30000] Loss:0.005834 Loss_1:0.005831 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:19.336749s (7.72min in total, 1.93min remains)
2022-11-28 08:26:25 NUM_SUB: 71;----------------------------
2022-11-28 08:26:25 Epoch [25000/30000] Loss:0.005834 Loss_1:0.005831 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000286 Time:18.917018s (8.03min in total, 1.61min remains)
2022-11-28 08:26:44 NUM_SUB: 71;----------------------------
2022-11-28 08:26:44 Epoch [26000/30000] Loss:0.005833 Loss_1:0.005830 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.091086s (8.35min in total, 1.28min remains)
2022-11-28 08:27:03 NUM_SUB: 71;----------------------------
2022-11-28 08:27:03 Epoch [27000/30000] Loss:0.005833 Loss_1:0.005828 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:19.104621s (8.67min in total, 0.96min remains)
2022-11-28 08:27:22 NUM_SUB: 71;----------------------------
2022-11-28 08:27:22 Epoch [28000/30000] Loss:0.005833 Loss_1:0.005828 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:18.896071s (8.98min in total, 0.64min remains)
2022-11-28 08:31:30 NUM_SUB: 71;----------------------------
2022-11-28 08:31:30 Epoch [29000/30000] Loss:0.005833 Loss_1:0.005831 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:248.512925s (13.12min in total, 0.45min remains)
2022-11-28 08:32:14 NUM_SUB: 71;----------------------------
2022-11-28 08:32:14 Epoch [30000/30000] Loss:0.005833 Loss_1:0.005827 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:43.996629s (13.86min in total, 0.00min remains)
2022-11-28 08:32:14 Testing & drawing...
2022-11-28 08:32:14 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:47:42 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=71/
2022-11-28 08:47:42 [Loss]
2022-11-28 08:47:42 NUM_SUB: 71; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:47:42 NUM_SUB: 71; Personalized parameter estimation: Parameter containing:
tensor([3.5112e-01, 9.2853e-01, 9.8407e-03, 6.5232e-38, 3.0742e-01, 1.5600e-02,
        1.2910e+00, 8.9644e-01, 4.5563e-01, 6.6281e-03, 6.3630e-02, 4.9096e-02,
        5.8901e-01, 1.6886e-01, 1.7812e-02, 5.2270e-01, 6.9767e-01, 8.0001e-01,
        8.4410e-03, 3.2753e+00, 6.8161e-01, 2.1925e-02, 3.2329e+00, 8.7416e-01,
        2.1215e-02, 3.9558e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:47:42 NUM_SUB: 71------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 08:47:42 Testing & drawing...
2022-11-28 08:47:42 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 08:47:44 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=71/
2022-11-28 08:47:44 [Loss]
2022-11-28 08:47:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 08:47:44 General parameter estimation: Parameter containing:
tensor([3.5112e-01, 9.2853e-01, 9.8407e-03, 6.5232e-38, 3.0742e-01, 1.5600e-02,
        1.2910e+00, 8.9644e-01, 4.5563e-01, 6.6281e-03, 6.3630e-02, 4.9096e-02,
        5.8901e-01, 1.6886e-01, 1.7812e-02, 5.2270e-01, 6.9767e-01, 8.0001e-01,
        8.4410e-03, 3.2753e+00, 6.8161e-01, 2.1925e-02, 3.2329e+00, 8.7416e-01,
        2.1215e-02, 3.9558e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 08:47:44 A: prod, degr, TonA, NonA
2022-11-28 08:47:44 [0.48522133 0.5000107  0.0135992  0.00116872]
2022-11-28 08:47:44 T: prod, degr, AonT, NonT
2022-11-28 08:47:44 [0.13701363 0.51250917 0.2577413  0.09273587]
2022-11-28 08:47:44 N: AonN, TonN, ATonN
2022-11-28 08:47:44 [0.00688708 0.9714956  0.02161733]
2022-11-28 08:47:44 using cpu
2022-11-28 08:47:44 epoch = 30000
2022-11-28 08:47:44 epoch_step = 1000
2022-11-28 08:47:44 model_name = SimpleNetworkAD
2022-11-28 08:47:44 now_string = 2022-11-27-19-40-13
2022-11-28 08:47:44 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 08:47:44 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 08:47:44 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 08:47:44 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 08:47:44 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 08:47:44 --------------------------------------------------training start--------------------------------------------------
2022-11-28 08:53:32 NUM_SUB: 72;----------------------------
2022-11-28 08:53:32 Epoch [01000/30000] Loss:0.042595 Loss_1:0.036790 Loss_2:0.001902 Loss_3:0.000000 Lr:0.000909 Time:347.663331s (5.79min in total, 168.04min remains)
2022-11-28 08:58:40 NUM_SUB: 72;----------------------------
2022-11-28 08:58:40 Epoch [02000/30000] Loss:0.037437 Loss_1:0.036374 Loss_2:0.000598 Loss_3:0.000000 Lr:0.000833 Time:307.963094s (10.93min in total, 152.98min remains)
2022-11-28 09:03:46 NUM_SUB: 72;----------------------------
2022-11-28 09:03:46 Epoch [03000/30000] Loss:0.035746 Loss_1:0.035455 Loss_2:0.000181 Loss_3:0.000000 Lr:0.000769 Time:306.504427s (16.04min in total, 144.32min remains)
2022-11-28 09:08:54 NUM_SUB: 72;----------------------------
2022-11-28 09:08:54 Epoch [04000/30000] Loss:0.034333 Loss_1:0.034124 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000714 Time:307.407967s (21.16min in total, 137.53min remains)
2022-11-28 09:45:14 NUM_SUB: 72;----------------------------
2022-11-28 09:45:14 Epoch [05000/30000] Loss:0.032583 Loss_1:0.032374 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000667 Time:2180.084320s (57.49min in total, 287.47min remains)
2022-11-28 09:50:46 NUM_SUB: 72;----------------------------
2022-11-28 09:50:46 Epoch [06000/30000] Loss:0.030385 Loss_1:0.030190 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000625 Time:331.964329s (63.03min in total, 252.11min remains)
2022-11-28 09:51:51 NUM_SUB: 72;----------------------------
2022-11-28 09:51:51 Epoch [07000/30000] Loss:0.027587 Loss_1:0.027418 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000588 Time:65.271782s (64.11min in total, 210.66min remains)
2022-11-28 10:10:13 NUM_SUB: 72;----------------------------
2022-11-28 10:10:13 Epoch [08000/30000] Loss:0.024456 Loss_1:0.024313 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000556 Time:1102.465149s (82.49min in total, 226.84min remains)
2022-11-28 10:42:11 NUM_SUB: 72;----------------------------
2022-11-28 10:42:11 Epoch [09000/30000] Loss:0.021768 Loss_1:0.021639 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000526 Time:1917.784056s (114.45min in total, 267.05min remains)
2022-11-28 11:31:14 NUM_SUB: 72;----------------------------
2022-11-28 11:31:14 Epoch [10000/30000] Loss:0.020286 Loss_1:0.020161 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000500 Time:2942.817070s (163.50min in total, 327.00min remains)
2022-11-28 12:04:39 NUM_SUB: 72;----------------------------
2022-11-28 12:04:39 Epoch [11000/30000] Loss:0.019598 Loss_1:0.019484 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000476 Time:2005.217819s (196.92min in total, 340.13min remains)
2022-11-28 12:37:41 NUM_SUB: 72;----------------------------
2022-11-28 12:37:41 Epoch [12000/30000] Loss:0.018905 Loss_1:0.018838 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000455 Time:1981.395583s (229.94min in total, 344.91min remains)
2022-11-28 13:12:29 NUM_SUB: 72;----------------------------
2022-11-28 13:12:29 Epoch [13000/30000] Loss:0.018196 Loss_1:0.018146 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000435 Time:2088.291991s (264.75min in total, 346.21min remains)
2022-11-28 13:59:20 NUM_SUB: 72;----------------------------
2022-11-28 13:59:20 Epoch [14000/30000] Loss:0.017871 Loss_1:0.017827 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000417 Time:2811.503936s (311.61min in total, 356.12min remains)
2022-11-28 15:05:03 NUM_SUB: 72;----------------------------
2022-11-28 15:05:03 Epoch [15000/30000] Loss:0.017825 Loss_1:0.017789 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000400 Time:3942.327774s (377.31min in total, 377.31min remains)
2022-11-28 15:37:04 NUM_SUB: 72;----------------------------
2022-11-28 15:37:04 Epoch [16000/30000] Loss:0.017805 Loss_1:0.017777 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000385 Time:1921.703570s (409.34min in total, 358.17min remains)
2022-11-28 15:37:26 NUM_SUB: 72;----------------------------
2022-11-28 15:37:26 Epoch [17000/30000] Loss:0.017788 Loss_1:0.017765 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000370 Time:21.212495s (409.69min in total, 313.29min remains)
2022-11-28 15:37:45 NUM_SUB: 72;----------------------------
2022-11-28 15:37:45 Epoch [18000/30000] Loss:0.017774 Loss_1:0.017755 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:19.345605s (410.02min in total, 273.34min remains)
2022-11-28 15:38:04 NUM_SUB: 72;----------------------------
2022-11-28 15:38:04 Epoch [19000/30000] Loss:0.017763 Loss_1:0.017747 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000345 Time:19.406751s (410.34min in total, 237.56min remains)
2022-11-28 15:38:24 NUM_SUB: 72;----------------------------
2022-11-28 15:38:24 Epoch [20000/30000] Loss:0.017756 Loss_1:0.017743 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:19.319648s (410.66min in total, 205.33min remains)
2022-11-28 15:38:43 NUM_SUB: 72;----------------------------
2022-11-28 15:38:43 Epoch [21000/30000] Loss:0.017752 Loss_1:0.017740 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:19.209564s (410.98min in total, 176.13min remains)
2022-11-28 15:39:02 NUM_SUB: 72;----------------------------
2022-11-28 15:39:02 Epoch [22000/30000] Loss:0.017749 Loss_1:0.017740 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:19.398232s (411.30min in total, 149.57min remains)
2022-11-28 15:39:21 NUM_SUB: 72;----------------------------
2022-11-28 15:39:21 Epoch [23000/30000] Loss:0.017747 Loss_1:0.017738 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000303 Time:19.007947s (411.62min in total, 125.28min remains)
2022-11-28 15:39:41 NUM_SUB: 72;----------------------------
2022-11-28 15:39:41 Epoch [24000/30000] Loss:0.017745 Loss_1:0.017737 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.332932s (411.94min in total, 102.99min remains)
2022-11-28 15:40:00 NUM_SUB: 72;----------------------------
2022-11-28 15:40:00 Epoch [25000/30000] Loss:0.017745 Loss_1:0.017718 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.395415s (412.27min in total, 82.45min remains)
2022-11-28 15:40:19 NUM_SUB: 72;----------------------------
2022-11-28 15:40:19 Epoch [26000/30000] Loss:0.017743 Loss_1:0.017735 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:19.176104s (412.59min in total, 63.47min remains)
2022-11-28 15:40:38 NUM_SUB: 72;----------------------------
2022-11-28 15:40:38 Epoch [27000/30000] Loss:0.017745 Loss_1:0.017714 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.890330s (412.90min in total, 45.88min remains)
2022-11-28 15:40:57 NUM_SUB: 72;----------------------------
2022-11-28 15:40:57 Epoch [28000/30000] Loss:0.017740 Loss_1:0.017731 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.122018s (413.22min in total, 29.52min remains)
2022-11-28 15:41:17 NUM_SUB: 72;----------------------------
2022-11-28 15:41:17 Epoch [29000/30000] Loss:0.017741 Loss_1:0.017719 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000256 Time:19.262406s (413.54min in total, 14.26min remains)
2022-11-28 15:41:36 NUM_SUB: 72;----------------------------
2022-11-28 15:41:36 Epoch [30000/30000] Loss:0.017739 Loss_1:0.017727 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:19.179261s (413.86min in total, 0.00min remains)
2022-11-28 15:41:36 Testing & drawing...
2022-11-28 15:41:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 15:41:37 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=72/
2022-11-28 15:41:37 [Loss]
2022-11-28 15:41:37 NUM_SUB: 72; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 15:41:37 NUM_SUB: 72; Personalized parameter estimation: Parameter containing:
tensor([1.5309e-01, 2.5643e-01, 1.2582e-02, 1.2667e-01, 3.0742e-01, 4.2170e-03,
        7.7621e-01, 8.9644e-01, 4.5563e-01, 1.4062e-02, 2.5206e-02, 1.3802e-02,
        1.0029e+00, 1.6886e-01, 1.7636e-02, 2.0799e+00, 6.9767e-01, 8.0001e-01,
        1.1336e-02, 4.6481e+00, 6.8161e-01, 2.1835e-02, 4.0324e+00, 8.7416e-01,
        1.9082e-02, 4.8607e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 15:41:37 NUM_SUB: 72------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 15:41:37 Testing & drawing...
2022-11-28 15:41:38 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 15:41:39 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=72/
2022-11-28 15:41:39 [Loss]
2022-11-28 15:41:39 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 15:41:39 General parameter estimation: Parameter containing:
tensor([1.5309e-01, 2.5643e-01, 1.2582e-02, 1.2667e-01, 3.0742e-01, 4.2170e-03,
        7.7621e-01, 8.9644e-01, 4.5563e-01, 1.4062e-02, 2.5206e-02, 1.3802e-02,
        1.0029e+00, 1.6886e-01, 1.7636e-02, 2.0799e+00, 6.9767e-01, 8.0001e-01,
        1.1336e-02, 4.6481e+00, 6.8161e-01, 2.1835e-02, 4.0324e+00, 8.7416e-01,
        1.9082e-02, 4.8607e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 15:41:39 A: prod, degr, TonA, NonA
2022-11-28 15:41:39 [0.46149424 0.49927527 0.03644385 0.00278662]
2022-11-28 15:41:39 T: prod, degr, AonT, NonT
2022-11-28 15:41:39 [0.39966413 0.46258828 0.11863499 0.01911262]
2022-11-28 15:41:39 N: AonN, TonN, ATonN
2022-11-28 15:41:39 [0.01010715 0.95803475 0.03185814]
2022-11-28 15:41:39 using cpu
2022-11-28 15:41:39 epoch = 30000
2022-11-28 15:41:39 epoch_step = 1000
2022-11-28 15:41:39 model_name = SimpleNetworkAD
2022-11-28 15:41:39 now_string = 2022-11-27-19-40-13
2022-11-28 15:41:39 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 15:41:39 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 15:41:39 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 15:41:39 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 15:41:39 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 15:41:39 --------------------------------------------------training start--------------------------------------------------
2022-11-28 15:41:59 NUM_SUB: 73;----------------------------
2022-11-28 15:41:59 Epoch [01000/30000] Loss:0.060867 Loss_1:0.055215 Loss_2:0.001908 Loss_3:0.000000 Lr:0.000909 Time:19.298120s (0.32min in total, 9.33min remains)
2022-11-28 15:42:18 NUM_SUB: 73;----------------------------
2022-11-28 15:42:18 Epoch [02000/30000] Loss:0.049756 Loss_1:0.048676 Loss_2:0.000664 Loss_3:0.000000 Lr:0.000833 Time:18.872973s (0.64min in total, 8.91min remains)
2022-11-28 15:42:37 NUM_SUB: 73;----------------------------
2022-11-28 15:42:37 Epoch [03000/30000] Loss:0.040299 Loss_1:0.039733 Loss_2:0.000303 Loss_3:0.000000 Lr:0.000769 Time:19.321298s (0.96min in total, 8.62min remains)
2022-11-28 15:42:56 NUM_SUB: 73;----------------------------
2022-11-28 15:42:56 Epoch [04000/30000] Loss:0.029312 Loss_1:0.028905 Loss_2:0.000212 Loss_3:0.000000 Lr:0.000714 Time:19.234206s (1.28min in total, 8.31min remains)
2022-11-28 15:43:16 NUM_SUB: 73;----------------------------
2022-11-28 15:43:16 Epoch [05000/30000] Loss:0.016350 Loss_1:0.015933 Loss_2:0.000299 Loss_3:0.000000 Lr:0.000667 Time:19.764724s (1.61min in total, 8.04min remains)
2022-11-28 15:43:35 NUM_SUB: 73;----------------------------
2022-11-28 15:43:35 Epoch [06000/30000] Loss:0.005762 Loss_1:0.005523 Loss_2:0.000187 Loss_3:0.000000 Lr:0.000625 Time:19.356789s (1.93min in total, 7.72min remains)
2022-11-28 15:43:54 NUM_SUB: 73;----------------------------
2022-11-28 15:43:54 Epoch [07000/30000] Loss:0.001513 Loss_1:0.001382 Loss_2:0.000121 Loss_3:0.000000 Lr:0.000588 Time:18.871739s (2.25min in total, 7.38min remains)
2022-11-28 15:44:13 NUM_SUB: 73;----------------------------
2022-11-28 15:44:13 Epoch [08000/30000] Loss:0.000965 Loss_1:0.000878 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000556 Time:19.414135s (2.57min in total, 7.06min remains)
2022-11-28 15:44:33 NUM_SUB: 73;----------------------------
2022-11-28 15:44:33 Epoch [09000/30000] Loss:0.000866 Loss_1:0.000787 Loss_2:0.000073 Loss_3:0.000000 Lr:0.000526 Time:19.066395s (2.89min in total, 6.74min remains)
2022-11-28 15:44:52 NUM_SUB: 73;----------------------------
2022-11-28 15:44:52 Epoch [10000/30000] Loss:0.000810 Loss_1:0.000747 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000500 Time:19.178880s (3.21min in total, 6.41min remains)
2022-11-28 15:45:11 NUM_SUB: 73;----------------------------
2022-11-28 15:45:11 Epoch [11000/30000] Loss:0.000690 Loss_1:0.000649 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000476 Time:19.721488s (3.54min in total, 6.11min remains)
2022-11-28 15:45:31 NUM_SUB: 73;----------------------------
2022-11-28 15:45:31 Epoch [12000/30000] Loss:0.000597 Loss_1:0.000576 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000455 Time:19.240765s (3.86min in total, 5.78min remains)
2022-11-28 15:45:50 NUM_SUB: 73;----------------------------
2022-11-28 15:45:50 Epoch [13000/30000] Loss:0.000515 Loss_1:0.000498 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000435 Time:19.752613s (4.19min in total, 5.47min remains)
2022-11-28 15:46:10 NUM_SUB: 73;----------------------------
2022-11-28 15:46:10 Epoch [14000/30000] Loss:0.000488 Loss_1:0.000475 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000417 Time:19.122382s (4.50min in total, 5.15min remains)
2022-11-28 15:46:28 NUM_SUB: 73;----------------------------
2022-11-28 15:46:28 Epoch [15000/30000] Loss:0.000482 Loss_1:0.000472 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000400 Time:18.812037s (4.82min in total, 4.82min remains)
2022-11-28 15:46:48 NUM_SUB: 73;----------------------------
2022-11-28 15:46:48 Epoch [16000/30000] Loss:0.000480 Loss_1:0.000472 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:19.574636s (5.14min in total, 4.50min remains)
2022-11-28 15:47:07 NUM_SUB: 73;----------------------------
2022-11-28 15:47:07 Epoch [17000/30000] Loss:0.000481 Loss_1:0.000475 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:18.807889s (5.46min in total, 4.17min remains)
2022-11-28 15:47:26 NUM_SUB: 73;----------------------------
2022-11-28 15:47:26 Epoch [18000/30000] Loss:0.000476 Loss_1:0.000471 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:19.378129s (5.78min in total, 3.85min remains)
2022-11-28 15:47:45 NUM_SUB: 73;----------------------------
2022-11-28 15:47:45 Epoch [19000/30000] Loss:0.000476 Loss_1:0.000471 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:18.826852s (6.09min in total, 3.53min remains)
2022-11-28 15:48:04 NUM_SUB: 73;----------------------------
2022-11-28 15:48:04 Epoch [20000/30000] Loss:0.000474 Loss_1:0.000470 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:18.988085s (6.41min in total, 3.21min remains)
2022-11-28 15:48:23 NUM_SUB: 73;----------------------------
2022-11-28 15:48:23 Epoch [21000/30000] Loss:0.000473 Loss_1:0.000469 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:18.771612s (6.72min in total, 2.88min remains)
2022-11-28 15:48:42 NUM_SUB: 73;----------------------------
2022-11-28 15:48:42 Epoch [22000/30000] Loss:0.000473 Loss_1:0.000470 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.556105s (7.05min in total, 2.56min remains)
2022-11-28 15:49:02 NUM_SUB: 73;----------------------------
2022-11-28 15:49:02 Epoch [23000/30000] Loss:0.000471 Loss_1:0.000467 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.403321s (7.37min in total, 2.24min remains)
2022-11-28 15:49:21 NUM_SUB: 73;----------------------------
2022-11-28 15:49:21 Epoch [24000/30000] Loss:0.000469 Loss_1:0.000466 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.397477s (7.70min in total, 1.92min remains)
2022-11-28 15:49:40 NUM_SUB: 73;----------------------------
2022-11-28 15:49:40 Epoch [25000/30000] Loss:0.000468 Loss_1:0.000465 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.289364s (8.02min in total, 1.60min remains)
2022-11-28 15:49:59 NUM_SUB: 73;----------------------------
2022-11-28 15:49:59 Epoch [26000/30000] Loss:0.000464 Loss_1:0.000462 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:18.834529s (8.33min in total, 1.28min remains)
2022-11-28 15:50:19 NUM_SUB: 73;----------------------------
2022-11-28 15:50:19 Epoch [27000/30000] Loss:0.000417 Loss_1:0.000414 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:20.165647s (8.67min in total, 0.96min remains)
2022-11-28 15:50:39 NUM_SUB: 73;----------------------------
2022-11-28 15:50:39 Epoch [28000/30000] Loss:0.000352 Loss_1:0.000349 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.354292s (8.99min in total, 0.64min remains)
2022-11-28 15:50:58 NUM_SUB: 73;----------------------------
2022-11-28 15:50:58 Epoch [29000/30000] Loss:0.000346 Loss_1:0.000344 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.497921s (9.32min in total, 0.32min remains)
2022-11-28 15:51:18 NUM_SUB: 73;----------------------------
2022-11-28 15:51:18 Epoch [30000/30000] Loss:0.000340 Loss_1:0.000338 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:19.475101s (9.64min in total, 0.00min remains)
2022-11-28 15:51:18 Testing & drawing...
2022-11-28 15:51:18 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 15:51:19 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=73/
2022-11-28 15:51:19 [Loss]
2022-11-28 15:51:19 NUM_SUB: 73; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 15:51:19 NUM_SUB: 73; Personalized parameter estimation: Parameter containing:
tensor([0.0183, 0.0452, 0.0360, 0.5033, 0.3074, 0.0160, 3.1468, 0.8964, 0.4556,
        0.0138, 0.2646, 0.1369, 0.3420, 0.1689, 0.0172, 0.7855, 0.6977, 0.8000,
        0.0122, 3.3466, 0.6816, 0.0230, 2.1150, 0.8742, 0.0210, 3.3000, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 15:51:19 NUM_SUB: 73------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 15:51:19 Testing & drawing...
2022-11-28 15:51:19 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 15:51:21 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=73/
2022-11-28 15:51:21 [Loss]
2022-11-28 15:51:21 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 15:51:21 General parameter estimation: Parameter containing:
tensor([0.0183, 0.0452, 0.0360, 0.5033, 0.3074, 0.0160, 3.1468, 0.8964, 0.4556,
        0.0138, 0.2646, 0.1369, 0.3420, 0.1689, 0.0172, 0.7855, 0.6977, 0.8000,
        0.0122, 3.3466, 0.6816, 0.0230, 2.1150, 0.8742, 0.0210, 3.3000, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 15:51:21 A: prod, degr, TonA, NonA
2022-11-28 15:51:21 [0.3429446  0.49025977 0.1553128  0.01148288]
2022-11-28 15:51:21 T: prod, degr, AonT, NonT
2022-11-28 15:51:21 [0.06114214 0.6762897  0.23359232 0.02897583]
2022-11-28 15:51:21 N: AonN, TonN, ATonN
2022-11-28 15:51:21 [0.02056993 0.9351407  0.04428932]
2022-11-28 15:51:21 using cpu
2022-11-28 15:51:21 epoch = 30000
2022-11-28 15:51:21 epoch_step = 1000
2022-11-28 15:51:21 model_name = SimpleNetworkAD
2022-11-28 15:51:21 now_string = 2022-11-27-19-40-13
2022-11-28 15:51:21 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 15:51:21 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 15:51:21 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 15:51:21 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 15:51:21 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 15:51:21 --------------------------------------------------training start--------------------------------------------------
2022-11-28 15:51:41 NUM_SUB: 74;----------------------------
2022-11-28 15:51:41 Epoch [01000/30000] Loss:0.103087 Loss_1:0.097297 Loss_2:0.002079 Loss_3:0.000000 Lr:0.000909 Time:19.166957s (0.32min in total, 9.26min remains)
2022-11-28 15:52:00 NUM_SUB: 74;----------------------------
2022-11-28 15:52:00 Epoch [02000/30000] Loss:0.093581 Loss_1:0.092362 Loss_2:0.000830 Loss_3:0.000000 Lr:0.000833 Time:19.387572s (0.64min in total, 9.00min remains)
2022-11-28 15:52:19 NUM_SUB: 74;----------------------------
2022-11-28 15:52:19 Epoch [03000/30000] Loss:0.086189 Loss_1:0.085456 Loss_2:0.000437 Loss_3:0.000000 Lr:0.000769 Time:19.417124s (0.97min in total, 8.70min remains)
2022-11-28 15:52:39 NUM_SUB: 74;----------------------------
2022-11-28 15:52:39 Epoch [04000/30000] Loss:0.076836 Loss_1:0.076294 Loss_2:0.000281 Loss_3:0.000000 Lr:0.000714 Time:19.285377s (1.29min in total, 8.37min remains)
2022-11-28 15:52:58 NUM_SUB: 74;----------------------------
2022-11-28 15:52:58 Epoch [05000/30000] Loss:0.062646 Loss_1:0.062213 Loss_2:0.000206 Loss_3:0.000000 Lr:0.000667 Time:19.179000s (1.61min in total, 8.04min remains)
2022-11-28 15:53:17 NUM_SUB: 74;----------------------------
2022-11-28 15:53:17 Epoch [06000/30000] Loss:0.041807 Loss_1:0.041450 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000625 Time:19.319543s (1.93min in total, 7.72min remains)
2022-11-28 15:53:37 NUM_SUB: 74;----------------------------
2022-11-28 15:53:37 Epoch [07000/30000] Loss:0.017960 Loss_1:0.017746 Loss_2:0.000103 Loss_3:0.000000 Lr:0.000588 Time:19.551632s (2.26min in total, 7.41min remains)
2022-11-28 15:53:56 NUM_SUB: 74;----------------------------
2022-11-28 15:53:56 Epoch [08000/30000] Loss:0.004730 Loss_1:0.004619 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000556 Time:19.487923s (2.58min in total, 7.10min remains)
2022-11-28 15:54:16 NUM_SUB: 74;----------------------------
2022-11-28 15:54:16 Epoch [09000/30000] Loss:0.002456 Loss_1:0.002368 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000526 Time:19.337640s (2.90min in total, 6.77min remains)
2022-11-28 15:54:35 NUM_SUB: 74;----------------------------
2022-11-28 15:54:35 Epoch [10000/30000] Loss:0.002074 Loss_1:0.001994 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000500 Time:19.180119s (3.22min in total, 6.44min remains)
2022-11-28 15:54:54 NUM_SUB: 74;----------------------------
2022-11-28 15:54:54 Epoch [11000/30000] Loss:0.001569 Loss_1:0.001530 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000476 Time:19.230982s (3.54min in total, 6.12min remains)
2022-11-28 15:55:13 NUM_SUB: 74;----------------------------
2022-11-28 15:55:13 Epoch [12000/30000] Loss:0.000955 Loss_1:0.000927 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000455 Time:19.326000s (3.86min in total, 5.80min remains)
2022-11-28 15:55:33 NUM_SUB: 74;----------------------------
2022-11-28 15:55:33 Epoch [13000/30000] Loss:0.000399 Loss_1:0.000376 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000435 Time:19.421421s (4.19min in total, 5.48min remains)
2022-11-28 15:55:52 NUM_SUB: 74;----------------------------
2022-11-28 15:55:52 Epoch [14000/30000] Loss:0.000150 Loss_1:0.000131 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:19.121113s (4.51min in total, 5.15min remains)
2022-11-28 15:56:11 NUM_SUB: 74;----------------------------
2022-11-28 15:56:11 Epoch [15000/30000] Loss:0.000101 Loss_1:0.000086 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000400 Time:19.360747s (4.83min in total, 4.83min remains)
2022-11-28 15:56:30 NUM_SUB: 74;----------------------------
2022-11-28 15:56:30 Epoch [16000/30000] Loss:0.000074 Loss_1:0.000063 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:19.216783s (5.15min in total, 4.51min remains)
2022-11-28 15:56:50 NUM_SUB: 74;----------------------------
2022-11-28 15:56:50 Epoch [17000/30000] Loss:0.000050 Loss_1:0.000041 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.463227s (5.47min in total, 4.19min remains)
2022-11-28 15:57:09 NUM_SUB: 74;----------------------------
2022-11-28 15:57:09 Epoch [18000/30000] Loss:0.000032 Loss_1:0.000025 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:19.626885s (5.80min in total, 3.87min remains)
2022-11-28 15:57:28 NUM_SUB: 74;----------------------------
2022-11-28 15:57:28 Epoch [19000/30000] Loss:0.000023 Loss_1:0.000018 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:19.012159s (6.12min in total, 3.54min remains)
2022-11-28 15:57:48 NUM_SUB: 74;----------------------------
2022-11-28 15:57:48 Epoch [20000/30000] Loss:0.000021 Loss_1:0.000017 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.440053s (6.44min in total, 3.22min remains)
2022-11-28 15:58:07 NUM_SUB: 74;----------------------------
2022-11-28 15:58:07 Epoch [21000/30000] Loss:0.000019 Loss_1:0.000015 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:18.844910s (6.76min in total, 2.90min remains)
2022-11-28 15:58:26 NUM_SUB: 74;----------------------------
2022-11-28 15:58:26 Epoch [22000/30000] Loss:0.000019 Loss_1:0.000015 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:19.394879s (7.08min in total, 2.57min remains)
2022-11-28 15:58:45 NUM_SUB: 74;----------------------------
2022-11-28 15:58:45 Epoch [23000/30000] Loss:0.000018 Loss_1:0.000015 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.237456s (7.40min in total, 2.25min remains)
2022-11-28 15:59:04 NUM_SUB: 74;----------------------------
2022-11-28 15:59:04 Epoch [24000/30000] Loss:0.000018 Loss_1:0.000015 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:18.816633s (7.71min in total, 1.93min remains)
2022-11-28 15:59:24 NUM_SUB: 74;----------------------------
2022-11-28 15:59:24 Epoch [25000/30000] Loss:0.000018 Loss_1:0.000016 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:19.462057s (8.04min in total, 1.61min remains)
2022-11-28 15:59:43 NUM_SUB: 74;----------------------------
2022-11-28 15:59:43 Epoch [26000/30000] Loss:0.000017 Loss_1:0.000015 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:18.832760s (8.35min in total, 1.29min remains)
2022-11-28 16:00:02 NUM_SUB: 74;----------------------------
2022-11-28 16:00:02 Epoch [27000/30000] Loss:0.000017 Loss_1:0.000015 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000270 Time:19.164479s (8.67min in total, 0.96min remains)
2022-11-28 16:00:21 NUM_SUB: 74;----------------------------
2022-11-28 16:00:21 Epoch [28000/30000] Loss:0.000017 Loss_1:0.000015 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.333353s (8.99min in total, 0.64min remains)
2022-11-28 16:00:40 NUM_SUB: 74;----------------------------
2022-11-28 16:00:40 Epoch [29000/30000] Loss:0.000017 Loss_1:0.000015 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.651705s (9.31min in total, 0.32min remains)
2022-11-28 16:00:59 NUM_SUB: 74;----------------------------
2022-11-28 16:00:59 Epoch [30000/30000] Loss:0.000019 Loss_1:0.000018 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:19.445062s (9.63min in total, 0.00min remains)
2022-11-28 16:00:59 Testing & drawing...
2022-11-28 16:00:59 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:01:01 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=74/
2022-11-28 16:01:01 [Loss]
2022-11-28 16:01:01 NUM_SUB: 74; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:01:01 NUM_SUB: 74; Personalized parameter estimation: Parameter containing:
tensor([0.0187, 0.0527, 0.0164, 0.4526, 0.3074, 0.0177, 3.8651, 0.8964, 0.4556,
        0.0147, 0.1401, 0.1304, 0.5957, 0.1689, 0.0176, 1.8165, 0.6977, 0.8000,
        0.0119, 4.1252, 0.6816, 0.0224, 3.4948, 0.8742, 0.0199, 4.4044, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:01:01 NUM_SUB: 74------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:01:01 Testing & drawing...
2022-11-28 16:01:01 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:01:03 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=74/
2022-11-28 16:01:03 [Loss]
2022-11-28 16:01:03 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:01:03 General parameter estimation: Parameter containing:
tensor([0.0187, 0.0527, 0.0164, 0.4526, 0.3074, 0.0177, 3.8651, 0.8964, 0.4556,
        0.0147, 0.1401, 0.1304, 0.5957, 0.1689, 0.0176, 1.8165, 0.6977, 0.8000,
        0.0119, 4.1252, 0.6816, 0.0224, 3.4948, 0.8742, 0.0199, 4.4044, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:01:03 A: prod, degr, TonA, NonA
2022-11-28 16:01:03 [0.36530837 0.4820591  0.13497186 0.01766068]
2022-11-28 16:01:03 T: prod, degr, AonT, NonT
2022-11-28 16:01:03 [0.12281998 0.53353995 0.31507525 0.02856477]
2022-11-28 16:01:03 N: AonN, TonN, ATonN
2022-11-28 16:01:03 [0.00834164 0.9700702  0.0215882 ]
2022-11-28 16:01:03 using cpu
2022-11-28 16:01:03 epoch = 30000
2022-11-28 16:01:03 epoch_step = 1000
2022-11-28 16:01:03 model_name = SimpleNetworkAD
2022-11-28 16:01:03 now_string = 2022-11-27-19-40-13
2022-11-28 16:01:03 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:01:03 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:01:03 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:01:03 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:01:03 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:01:03 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:01:22 NUM_SUB: 75;----------------------------
2022-11-28 16:01:22 Epoch [01000/30000] Loss:0.050529 Loss_1:0.044989 Loss_2:0.001726 Loss_3:0.000000 Lr:0.000909 Time:19.361741s (0.32min in total, 9.36min remains)
2022-11-28 16:01:41 NUM_SUB: 75;----------------------------
2022-11-28 16:01:41 Epoch [02000/30000] Loss:0.043790 Loss_1:0.042854 Loss_2:0.000504 Loss_3:0.000000 Lr:0.000833 Time:19.157288s (0.64min in total, 8.99min remains)
2022-11-28 16:02:01 NUM_SUB: 75;----------------------------
2022-11-28 16:02:01 Epoch [03000/30000] Loss:0.039741 Loss_1:0.039484 Loss_2:0.000147 Loss_3:0.000000 Lr:0.000769 Time:19.370420s (0.96min in total, 8.68min remains)
2022-11-28 16:02:19 NUM_SUB: 75;----------------------------
2022-11-28 16:02:19 Epoch [04000/30000] Loss:0.035698 Loss_1:0.035473 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000714 Time:18.616509s (1.28min in total, 8.29min remains)
2022-11-28 16:02:39 NUM_SUB: 75;----------------------------
2022-11-28 16:02:39 Epoch [05000/30000] Loss:0.030093 Loss_1:0.029895 Loss_2:0.000075 Loss_3:0.000000 Lr:0.000667 Time:19.443302s (1.60min in total, 8.00min remains)
2022-11-28 16:02:58 NUM_SUB: 75;----------------------------
2022-11-28 16:02:58 Epoch [06000/30000] Loss:0.022503 Loss_1:0.022336 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000625 Time:19.036023s (1.92min in total, 7.67min remains)
2022-11-28 16:03:17 NUM_SUB: 75;----------------------------
2022-11-28 16:03:17 Epoch [07000/30000] Loss:0.013795 Loss_1:0.013669 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000588 Time:18.986056s (2.23min in total, 7.34min remains)
2022-11-28 16:03:36 NUM_SUB: 75;----------------------------
2022-11-28 16:03:36 Epoch [08000/30000] Loss:0.007426 Loss_1:0.007338 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000556 Time:19.239801s (2.55min in total, 7.02min remains)
2022-11-28 16:03:55 NUM_SUB: 75;----------------------------
2022-11-28 16:03:55 Epoch [09000/30000] Loss:0.005416 Loss_1:0.005350 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000526 Time:18.810825s (2.87min in total, 6.69min remains)
2022-11-28 16:04:14 NUM_SUB: 75;----------------------------
2022-11-28 16:04:14 Epoch [10000/30000] Loss:0.005102 Loss_1:0.005046 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000500 Time:19.087522s (3.19min in total, 6.37min remains)
2022-11-28 16:04:33 NUM_SUB: 75;----------------------------
2022-11-28 16:04:33 Epoch [11000/30000] Loss:0.005005 Loss_1:0.004958 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000476 Time:18.797071s (3.50min in total, 6.04min remains)
2022-11-28 16:04:52 NUM_SUB: 75;----------------------------
2022-11-28 16:04:52 Epoch [12000/30000] Loss:0.004955 Loss_1:0.004918 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000455 Time:19.254453s (3.82min in total, 5.73min remains)
2022-11-28 16:05:11 NUM_SUB: 75;----------------------------
2022-11-28 16:05:11 Epoch [13000/30000] Loss:0.004902 Loss_1:0.004876 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000435 Time:18.710193s (4.13min in total, 5.40min remains)
2022-11-28 16:05:30 NUM_SUB: 75;----------------------------
2022-11-28 16:05:30 Epoch [14000/30000] Loss:0.004835 Loss_1:0.004812 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000417 Time:19.188700s (4.45min in total, 5.09min remains)
2022-11-28 16:05:49 NUM_SUB: 75;----------------------------
2022-11-28 16:05:49 Epoch [15000/30000] Loss:0.004767 Loss_1:0.004754 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000400 Time:18.777370s (4.76min in total, 4.76min remains)
2022-11-28 16:06:08 NUM_SUB: 75;----------------------------
2022-11-28 16:06:08 Epoch [16000/30000] Loss:0.004731 Loss_1:0.004722 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:19.055274s (5.08min in total, 4.45min remains)
2022-11-28 16:06:27 NUM_SUB: 75;----------------------------
2022-11-28 16:06:27 Epoch [17000/30000] Loss:0.004729 Loss_1:0.004722 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000370 Time:19.096752s (5.40min in total, 4.13min remains)
2022-11-28 16:06:45 NUM_SUB: 75;----------------------------
2022-11-28 16:06:45 Epoch [18000/30000] Loss:0.004720 Loss_1:0.004714 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:18.732817s (5.71min in total, 3.81min remains)
2022-11-28 16:07:05 NUM_SUB: 75;----------------------------
2022-11-28 16:07:05 Epoch [19000/30000] Loss:0.004719 Loss_1:0.004713 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000345 Time:19.250302s (6.03min in total, 3.49min remains)
2022-11-28 16:07:24 NUM_SUB: 75;----------------------------
2022-11-28 16:07:24 Epoch [20000/30000] Loss:0.004718 Loss_1:0.004713 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:19.280836s (6.35min in total, 3.18min remains)
2022-11-28 16:07:43 NUM_SUB: 75;----------------------------
2022-11-28 16:07:43 Epoch [21000/30000] Loss:0.004717 Loss_1:0.004712 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.215676s (6.67min in total, 2.86min remains)
2022-11-28 16:08:02 NUM_SUB: 75;----------------------------
2022-11-28 16:08:02 Epoch [22000/30000] Loss:0.004717 Loss_1:0.004712 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:18.807414s (6.99min in total, 2.54min remains)
2022-11-28 16:08:21 NUM_SUB: 75;----------------------------
2022-11-28 16:08:21 Epoch [23000/30000] Loss:0.004716 Loss_1:0.004712 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.171266s (7.31min in total, 2.22min remains)
2022-11-28 16:08:40 NUM_SUB: 75;----------------------------
2022-11-28 16:08:40 Epoch [24000/30000] Loss:0.004716 Loss_1:0.004712 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:19.175342s (7.63min in total, 1.91min remains)
2022-11-28 16:08:59 NUM_SUB: 75;----------------------------
2022-11-28 16:08:59 Epoch [25000/30000] Loss:0.004716 Loss_1:0.004712 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.049091s (7.94min in total, 1.59min remains)
2022-11-28 16:09:18 NUM_SUB: 75;----------------------------
2022-11-28 16:09:18 Epoch [26000/30000] Loss:0.004715 Loss_1:0.004712 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.100690s (8.26min in total, 1.27min remains)
2022-11-28 16:09:37 NUM_SUB: 75;----------------------------
2022-11-28 16:09:37 Epoch [27000/30000] Loss:0.004715 Loss_1:0.004712 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:18.942925s (8.58min in total, 0.95min remains)
2022-11-28 16:09:57 NUM_SUB: 75;----------------------------
2022-11-28 16:09:57 Epoch [28000/30000] Loss:0.004728 Loss_1:0.004725 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:19.067297s (8.90min in total, 0.64min remains)
2022-11-28 16:10:16 NUM_SUB: 75;----------------------------
2022-11-28 16:10:16 Epoch [29000/30000] Loss:0.004715 Loss_1:0.004712 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.269096s (9.22min in total, 0.32min remains)
2022-11-28 16:10:34 NUM_SUB: 75;----------------------------
2022-11-28 16:10:34 Epoch [30000/30000] Loss:0.004714 Loss_1:0.004711 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:18.700279s (9.53min in total, 0.00min remains)
2022-11-28 16:10:34 Testing & drawing...
2022-11-28 16:10:34 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:10:36 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=75/
2022-11-28 16:10:36 [Loss]
2022-11-28 16:10:36 NUM_SUB: 75; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:10:36 NUM_SUB: 75; Personalized parameter estimation: Parameter containing:
tensor([0.3185, 0.6632, 0.0104, 0.0096, 0.3074, 0.0256, 0.5721, 0.8964, 0.4556,
        0.0128, 0.2045, 0.1107, 0.3526, 0.1689, 0.0177, 1.2339, 0.6977, 0.8000,
        0.0124, 2.7878, 0.6816, 0.0227, 2.5374, 0.8742, 0.0212, 3.1156, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:10:36 NUM_SUB: 75------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:10:36 Testing & drawing...
2022-11-28 16:10:36 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:10:38 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=75/
2022-11-28 16:10:38 [Loss]
2022-11-28 16:10:38 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:10:38 General parameter estimation: Parameter containing:
tensor([0.3185, 0.6632, 0.0104, 0.0096, 0.3074, 0.0256, 0.5721, 0.8964, 0.4556,
        0.0128, 0.2045, 0.1107, 0.3526, 0.1689, 0.0177, 1.2339, 0.6977, 0.8000,
        0.0124, 2.7878, 0.6816, 0.0227, 2.5374, 0.8742, 0.0212, 3.1156, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:10:38 A: prod, degr, TonA, NonA
2022-11-28 16:10:38 [0.46102607 0.49977213 0.01505299 0.02414883]
2022-11-28 16:10:38 T: prod, degr, AonT, NonT
2022-11-28 16:10:38 [0.07026551 0.5860262  0.31527326 0.028435  ]
2022-11-28 16:10:38 N: AonN, TonN, ATonN
2022-11-28 16:10:38 [0.02085549 0.9366713  0.04247316]
2022-11-28 16:10:38 using cpu
2022-11-28 16:10:38 epoch = 30000
2022-11-28 16:10:38 epoch_step = 1000
2022-11-28 16:10:38 model_name = SimpleNetworkAD
2022-11-28 16:10:38 now_string = 2022-11-27-19-40-13
2022-11-28 16:10:38 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:10:38 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:10:38 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:10:38 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:10:38 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:10:38 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:10:57 NUM_SUB: 76;----------------------------
2022-11-28 16:10:57 Epoch [01000/30000] Loss:0.056414 Loss_1:0.050429 Loss_2:0.002214 Loss_3:0.000000 Lr:0.000909 Time:19.368270s (0.32min in total, 9.36min remains)
2022-11-28 16:11:17 NUM_SUB: 76;----------------------------
2022-11-28 16:11:17 Epoch [02000/30000] Loss:0.049190 Loss_1:0.048030 Loss_2:0.000768 Loss_3:0.000000 Lr:0.000833 Time:19.595699s (0.65min in total, 9.09min remains)
2022-11-28 16:11:36 NUM_SUB: 76;----------------------------
2022-11-28 16:11:36 Epoch [03000/30000] Loss:0.044708 Loss_1:0.044351 Loss_2:0.000260 Loss_3:0.000000 Lr:0.000769 Time:19.237201s (0.97min in total, 8.73min remains)
2022-11-28 16:11:56 NUM_SUB: 76;----------------------------
2022-11-28 16:11:56 Epoch [04000/30000] Loss:0.040332 Loss_1:0.039996 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000714 Time:19.400302s (1.29min in total, 8.41min remains)
2022-11-28 16:12:14 NUM_SUB: 76;----------------------------
2022-11-28 16:12:14 Epoch [05000/30000] Loss:0.034472 Loss_1:0.034171 Loss_2:0.000158 Loss_3:0.000000 Lr:0.000667 Time:18.613207s (1.60min in total, 8.02min remains)
2022-11-28 16:12:34 NUM_SUB: 76;----------------------------
2022-11-28 16:12:34 Epoch [06000/30000] Loss:0.025993 Loss_1:0.025728 Loss_2:0.000146 Loss_3:0.000000 Lr:0.000625 Time:19.384936s (1.93min in total, 7.71min remains)
2022-11-28 16:12:53 NUM_SUB: 76;----------------------------
2022-11-28 16:12:53 Epoch [07000/30000] Loss:0.016326 Loss_1:0.016118 Loss_2:0.000135 Loss_3:0.000000 Lr:0.000588 Time:19.160029s (2.25min in total, 7.38min remains)
2022-11-28 16:13:12 NUM_SUB: 76;----------------------------
2022-11-28 16:13:12 Epoch [08000/30000] Loss:0.008617 Loss_1:0.008456 Loss_2:0.000129 Loss_3:0.000000 Lr:0.000556 Time:18.913897s (2.56min in total, 7.04min remains)
2022-11-28 16:13:31 NUM_SUB: 76;----------------------------
2022-11-28 16:13:31 Epoch [09000/30000] Loss:0.005274 Loss_1:0.005139 Loss_2:0.000127 Loss_3:0.000000 Lr:0.000526 Time:19.545898s (2.89min in total, 6.74min remains)
2022-11-28 16:13:50 NUM_SUB: 76;----------------------------
2022-11-28 16:13:50 Epoch [10000/30000] Loss:0.004280 Loss_1:0.004160 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000500 Time:18.757202s (3.20min in total, 6.40min remains)
2022-11-28 16:14:09 NUM_SUB: 76;----------------------------
2022-11-28 16:14:09 Epoch [11000/30000] Loss:0.003992 Loss_1:0.003898 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000476 Time:19.293994s (3.52min in total, 6.08min remains)
2022-11-28 16:14:28 NUM_SUB: 76;----------------------------
2022-11-28 16:14:28 Epoch [12000/30000] Loss:0.003798 Loss_1:0.003745 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000455 Time:18.840066s (3.84min in total, 5.75min remains)
2022-11-28 16:14:47 NUM_SUB: 76;----------------------------
2022-11-28 16:14:47 Epoch [13000/30000] Loss:0.003704 Loss_1:0.003667 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000435 Time:19.146537s (4.15min in total, 5.43min remains)
2022-11-28 16:15:06 NUM_SUB: 76;----------------------------
2022-11-28 16:15:06 Epoch [14000/30000] Loss:0.003665 Loss_1:0.003636 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:19.038999s (4.47min in total, 5.11min remains)
2022-11-28 16:15:25 NUM_SUB: 76;----------------------------
2022-11-28 16:15:25 Epoch [15000/30000] Loss:0.003632 Loss_1:0.003611 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000400 Time:18.921694s (4.79min in total, 4.79min remains)
2022-11-28 16:15:44 NUM_SUB: 76;----------------------------
2022-11-28 16:15:44 Epoch [16000/30000] Loss:0.003597 Loss_1:0.003581 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:18.743381s (5.10min in total, 4.46min remains)
2022-11-28 16:16:03 NUM_SUB: 76;----------------------------
2022-11-28 16:16:03 Epoch [17000/30000] Loss:0.003563 Loss_1:0.003550 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000370 Time:18.952859s (5.42min in total, 4.14min remains)
2022-11-28 16:16:22 NUM_SUB: 76;----------------------------
2022-11-28 16:16:22 Epoch [18000/30000] Loss:0.003540 Loss_1:0.003530 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:18.950280s (5.73min in total, 3.82min remains)
2022-11-28 16:16:41 NUM_SUB: 76;----------------------------
2022-11-28 16:16:41 Epoch [19000/30000] Loss:0.003531 Loss_1:0.003523 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000345 Time:19.468172s (6.06min in total, 3.51min remains)
2022-11-28 16:17:00 NUM_SUB: 76;----------------------------
2022-11-28 16:17:00 Epoch [20000/30000] Loss:0.003529 Loss_1:0.003522 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:18.964950s (6.37min in total, 3.19min remains)
2022-11-28 16:17:20 NUM_SUB: 76;----------------------------
2022-11-28 16:17:20 Epoch [21000/30000] Loss:0.003528 Loss_1:0.003522 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000323 Time:19.633931s (6.70min in total, 2.87min remains)
2022-11-28 16:17:39 NUM_SUB: 76;----------------------------
2022-11-28 16:17:39 Epoch [22000/30000] Loss:0.003527 Loss_1:0.003522 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:18.837512s (7.01min in total, 2.55min remains)
2022-11-28 16:17:58 NUM_SUB: 76;----------------------------
2022-11-28 16:17:58 Epoch [23000/30000] Loss:0.003526 Loss_1:0.003522 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000303 Time:19.135621s (7.33min in total, 2.23min remains)
2022-11-28 16:18:17 NUM_SUB: 76;----------------------------
2022-11-28 16:18:17 Epoch [24000/30000] Loss:0.003526 Loss_1:0.003523 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:19.447695s (7.66min in total, 1.91min remains)
2022-11-28 16:18:36 NUM_SUB: 76;----------------------------
2022-11-28 16:18:36 Epoch [25000/30000] Loss:0.003525 Loss_1:0.003522 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000286 Time:18.570520s (7.97min in total, 1.59min remains)
2022-11-28 16:18:55 NUM_SUB: 76;----------------------------
2022-11-28 16:18:55 Epoch [26000/30000] Loss:0.003525 Loss_1:0.003522 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:19.360061s (8.29min in total, 1.28min remains)
2022-11-28 16:19:14 NUM_SUB: 76;----------------------------
2022-11-28 16:19:14 Epoch [27000/30000] Loss:0.003525 Loss_1:0.003523 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000270 Time:18.825923s (8.60min in total, 0.96min remains)
2022-11-28 16:19:34 NUM_SUB: 76;----------------------------
2022-11-28 16:19:34 Epoch [28000/30000] Loss:0.003524 Loss_1:0.003523 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:19.302703s (8.92min in total, 0.64min remains)
2022-11-28 16:19:52 NUM_SUB: 76;----------------------------
2022-11-28 16:19:52 Epoch [29000/30000] Loss:0.003524 Loss_1:0.003523 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000256 Time:18.824461s (9.24min in total, 0.32min remains)
2022-11-28 16:20:11 NUM_SUB: 76;----------------------------
2022-11-28 16:20:11 Epoch [30000/30000] Loss:0.003524 Loss_1:0.003523 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:18.941102s (9.55min in total, 0.00min remains)
2022-11-28 16:20:11 Testing & drawing...
2022-11-28 16:20:11 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:20:13 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=76/
2022-11-28 16:20:13 [Loss]
2022-11-28 16:20:13 NUM_SUB: 76; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:20:13 NUM_SUB: 76; Personalized parameter estimation: Parameter containing:
tensor([5.1237e-01, 6.9503e-01, 1.1528e-01, 2.6073e-03, 3.0742e-01, 7.1866e-03,
        7.2866e-01, 8.9644e-01, 4.5563e-01, 1.4081e-02, 3.4853e-02, 1.3098e-02,
        8.2414e-01, 1.6886e-01, 1.7405e-02, 2.5551e+00, 6.9767e-01, 8.0001e-01,
        1.0639e-02, 5.2187e+00, 6.8161e-01, 2.2426e-02, 3.8112e+00, 8.7416e-01,
        1.7502e-02, 5.0895e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 16:20:13 NUM_SUB: 76------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:20:13 Testing & drawing...
2022-11-28 16:20:13 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:20:15 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=76/
2022-11-28 16:20:15 [Loss]
2022-11-28 16:20:15 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:20:15 General parameter estimation: Parameter containing:
tensor([5.1237e-01, 6.9503e-01, 1.1528e-01, 2.6073e-03, 3.0742e-01, 7.1866e-03,
        7.2866e-01, 8.9644e-01, 4.5563e-01, 1.4081e-02, 3.4853e-02, 1.3098e-02,
        8.2414e-01, 1.6886e-01, 1.7405e-02, 2.5551e+00, 6.9767e-01, 8.0001e-01,
        1.0639e-02, 5.2187e+00, 6.8161e-01, 2.2426e-02, 3.8112e+00, 8.7416e-01,
        1.7502e-02, 5.0895e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 16:20:15 A: prod, degr, TonA, NonA
2022-11-28 16:20:15 [0.40628535 0.49993744 0.09140918 0.00236805]
2022-11-28 16:20:15 T: prod, degr, AonT, NonT
2022-11-28 16:20:15 [0.28017688 0.62906396 0.07181341 0.01894569]
2022-11-28 16:20:15 N: AonN, TonN, ATonN
2022-11-28 16:20:15 [0.01475403 0.9520303  0.03321577]
2022-11-28 16:20:15 using cpu
2022-11-28 16:20:15 epoch = 30000
2022-11-28 16:20:15 epoch_step = 1000
2022-11-28 16:20:15 model_name = SimpleNetworkAD
2022-11-28 16:20:15 now_string = 2022-11-27-19-40-13
2022-11-28 16:20:15 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:20:15 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:20:15 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:20:15 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:20:15 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:20:15 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:20:34 NUM_SUB: 77;----------------------------
2022-11-28 16:20:34 Epoch [01000/30000] Loss:0.130752 Loss_1:0.124810 Loss_2:0.002241 Loss_3:0.000000 Lr:0.000909 Time:19.208523s (0.32min in total, 9.28min remains)
2022-11-28 16:20:53 NUM_SUB: 77;----------------------------
2022-11-28 16:20:53 Epoch [02000/30000] Loss:0.114152 Loss_1:0.112847 Loss_2:0.000945 Loss_3:0.000000 Lr:0.000833 Time:18.935659s (0.64min in total, 8.90min remains)
2022-11-28 16:21:12 NUM_SUB: 77;----------------------------
2022-11-28 16:21:12 Epoch [03000/30000] Loss:0.096394 Loss_1:0.095546 Loss_2:0.000541 Loss_3:0.000000 Lr:0.000769 Time:19.178324s (0.96min in total, 8.60min remains)
2022-11-28 16:21:31 NUM_SUB: 77;----------------------------
2022-11-28 16:21:31 Epoch [04000/30000] Loss:0.072609 Loss_1:0.071874 Loss_2:0.000470 Loss_3:0.000000 Lr:0.000714 Time:19.080661s (1.27min in total, 8.28min remains)
2022-11-28 16:21:50 NUM_SUB: 77;----------------------------
2022-11-28 16:21:50 Epoch [05000/30000] Loss:0.043029 Loss_1:0.042609 Loss_2:0.000219 Loss_3:0.000000 Lr:0.000667 Time:19.156528s (1.59min in total, 7.96min remains)
2022-11-28 16:22:10 NUM_SUB: 77;----------------------------
2022-11-28 16:22:10 Epoch [06000/30000] Loss:0.018781 Loss_1:0.018553 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000625 Time:19.408373s (1.92min in total, 7.66min remains)
2022-11-28 16:22:29 NUM_SUB: 77;----------------------------
2022-11-28 16:22:29 Epoch [07000/30000] Loss:0.009722 Loss_1:0.009562 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000588 Time:19.256938s (2.24min in total, 7.35min remains)
2022-11-28 16:22:48 NUM_SUB: 77;----------------------------
2022-11-28 16:22:48 Epoch [08000/30000] Loss:0.006543 Loss_1:0.006392 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000556 Time:19.091083s (2.56min in total, 7.03min remains)
2022-11-28 16:23:08 NUM_SUB: 77;----------------------------
2022-11-28 16:23:08 Epoch [09000/30000] Loss:0.003761 Loss_1:0.003610 Loss_2:0.000141 Loss_3:0.000000 Lr:0.000526 Time:19.544319s (2.88min in total, 6.72min remains)
2022-11-28 16:23:27 NUM_SUB: 77;----------------------------
2022-11-28 16:23:27 Epoch [10000/30000] Loss:0.001975 Loss_1:0.001837 Loss_2:0.000133 Loss_3:0.000000 Lr:0.000500 Time:19.411560s (3.20min in total, 6.41min remains)
2022-11-28 16:23:47 NUM_SUB: 77;----------------------------
2022-11-28 16:23:47 Epoch [11000/30000] Loss:0.001482 Loss_1:0.001381 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000476 Time:19.573295s (3.53min in total, 6.10min remains)
2022-11-28 16:24:06 NUM_SUB: 77;----------------------------
2022-11-28 16:24:06 Epoch [12000/30000] Loss:0.001408 Loss_1:0.001341 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000455 Time:19.210510s (3.85min in total, 5.78min remains)
2022-11-28 16:24:26 NUM_SUB: 77;----------------------------
2022-11-28 16:24:26 Epoch [13000/30000] Loss:0.001397 Loss_1:0.001351 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000435 Time:20.104647s (4.19min in total, 5.47min remains)
2022-11-28 16:24:45 NUM_SUB: 77;----------------------------
2022-11-28 16:24:45 Epoch [14000/30000] Loss:0.001346 Loss_1:0.001309 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000417 Time:19.024150s (4.50min in total, 5.15min remains)
2022-11-28 16:25:04 NUM_SUB: 77;----------------------------
2022-11-28 16:25:04 Epoch [15000/30000] Loss:0.001321 Loss_1:0.001290 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000400 Time:19.424673s (4.83min in total, 4.83min remains)
2022-11-28 16:25:24 NUM_SUB: 77;----------------------------
2022-11-28 16:25:24 Epoch [16000/30000] Loss:0.001291 Loss_1:0.001265 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000385 Time:19.677373s (5.15min in total, 4.51min remains)
2022-11-28 16:25:43 NUM_SUB: 77;----------------------------
2022-11-28 16:25:43 Epoch [17000/30000] Loss:0.001258 Loss_1:0.001236 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000370 Time:18.666169s (5.47min in total, 4.18min remains)
2022-11-28 16:26:02 NUM_SUB: 77;----------------------------
2022-11-28 16:26:02 Epoch [18000/30000] Loss:0.001220 Loss_1:0.001200 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000357 Time:19.447501s (5.79min in total, 3.86min remains)
2022-11-28 16:26:21 NUM_SUB: 77;----------------------------
2022-11-28 16:26:21 Epoch [19000/30000] Loss:0.001186 Loss_1:0.001167 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000345 Time:19.205242s (6.11min in total, 3.54min remains)
2022-11-28 16:26:40 NUM_SUB: 77;----------------------------
2022-11-28 16:26:40 Epoch [20000/30000] Loss:0.001172 Loss_1:0.001154 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000333 Time:18.915156s (6.43min in total, 3.21min remains)
2022-11-28 16:27:00 NUM_SUB: 77;----------------------------
2022-11-28 16:27:00 Epoch [21000/30000] Loss:0.001169 Loss_1:0.001153 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000323 Time:19.426668s (6.75min in total, 2.89min remains)
2022-11-28 16:27:19 NUM_SUB: 77;----------------------------
2022-11-28 16:27:19 Epoch [22000/30000] Loss:0.001156 Loss_1:0.001141 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000313 Time:19.175470s (7.07min in total, 2.57min remains)
2022-11-28 16:27:38 NUM_SUB: 77;----------------------------
2022-11-28 16:27:38 Epoch [23000/30000] Loss:0.001134 Loss_1:0.001119 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000303 Time:19.559279s (7.40min in total, 2.25min remains)
2022-11-28 16:27:57 NUM_SUB: 77;----------------------------
2022-11-28 16:27:57 Epoch [24000/30000] Loss:0.001125 Loss_1:0.001111 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000294 Time:18.879211s (7.71min in total, 1.93min remains)
2022-11-28 16:28:17 NUM_SUB: 77;----------------------------
2022-11-28 16:28:17 Epoch [25000/30000] Loss:0.001077 Loss_1:0.001063 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000286 Time:19.164917s (8.03min in total, 1.61min remains)
2022-11-28 16:28:36 NUM_SUB: 77;----------------------------
2022-11-28 16:28:36 Epoch [26000/30000] Loss:0.001061 Loss_1:0.001048 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000278 Time:19.530015s (8.35min in total, 1.29min remains)
2022-11-28 16:28:55 NUM_SUB: 77;----------------------------
2022-11-28 16:28:55 Epoch [27000/30000] Loss:0.001021 Loss_1:0.001007 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000270 Time:18.697919s (8.67min in total, 0.96min remains)
2022-11-28 16:29:14 NUM_SUB: 77;----------------------------
2022-11-28 16:29:14 Epoch [28000/30000] Loss:0.001017 Loss_1:0.001003 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000263 Time:19.590925s (8.99min in total, 0.64min remains)
2022-11-28 16:29:34 NUM_SUB: 77;----------------------------
2022-11-28 16:29:34 Epoch [29000/30000] Loss:0.001016 Loss_1:0.001003 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000256 Time:19.231412s (9.31min in total, 0.32min remains)
2022-11-28 16:29:53 NUM_SUB: 77;----------------------------
2022-11-28 16:29:53 Epoch [30000/30000] Loss:0.001015 Loss_1:0.001003 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000250 Time:19.035796s (9.63min in total, 0.00min remains)
2022-11-28 16:29:53 Testing & drawing...
2022-11-28 16:29:53 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:29:54 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=77/
2022-11-28 16:29:54 [Loss]
2022-11-28 16:29:54 NUM_SUB: 77; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:29:54 NUM_SUB: 77; Personalized parameter estimation: Parameter containing:
tensor([0.0085, 0.0106, 0.0140, 3.5877, 0.3074, 0.0196, 3.1064, 0.8964, 0.4556,
        0.0130, 0.0451, 0.0096, 0.5073, 0.1689, 0.0175, 0.8317, 0.6977, 0.8000,
        0.0074, 4.6903, 0.6816, 0.0219, 3.6422, 0.8742, 0.0177, 4.7402, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:29:54 NUM_SUB: 77------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:29:54 Testing & drawing...
2022-11-28 16:29:54 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:29:56 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=77/
2022-11-28 16:29:56 [Loss]
2022-11-28 16:29:56 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:29:56 General parameter estimation: Parameter containing:
tensor([0.0085, 0.0106, 0.0140, 3.5877, 0.3074, 0.0196, 3.1064, 0.8964, 0.4556,
        0.0130, 0.0451, 0.0096, 0.5073, 0.1689, 0.0175, 0.8317, 0.6977, 0.8000,
        0.0074, 4.6903, 0.6816, 0.0219, 3.6422, 0.8742, 0.0177, 4.7402, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:29:56 A: prod, degr, TonA, NonA
2022-11-28 16:29:56 [0.47119555 0.45110115 0.0188543  0.05884896]
2022-11-28 16:29:56 T: prod, degr, AonT, NonT
2022-11-28 16:29:56 [0.21581599 0.56868774 0.08757471 0.12792148]
2022-11-28 16:29:56 N: AonN, TonN, ATonN
2022-11-28 16:29:56 [0.00949522 0.95697784 0.03352695]
2022-11-28 16:29:56 using cpu
2022-11-28 16:29:56 epoch = 30000
2022-11-28 16:29:56 epoch_step = 1000
2022-11-28 16:29:56 model_name = SimpleNetworkAD
2022-11-28 16:29:56 now_string = 2022-11-27-19-40-13
2022-11-28 16:29:56 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:29:56 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:29:56 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:29:56 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:29:56 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:29:56 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:30:15 NUM_SUB: 78;----------------------------
2022-11-28 16:30:15 Epoch [01000/30000] Loss:0.018167 Loss_1:0.012093 Loss_2:0.002223 Loss_3:0.000000 Lr:0.000909 Time:19.180596s (0.32min in total, 9.27min remains)
2022-11-28 16:30:34 NUM_SUB: 78;----------------------------
2022-11-28 16:30:34 Epoch [02000/30000] Loss:0.013045 Loss_1:0.011857 Loss_2:0.000753 Loss_3:0.000000 Lr:0.000833 Time:19.015041s (0.64min in total, 8.91min remains)
2022-11-28 16:30:54 NUM_SUB: 78;----------------------------
2022-11-28 16:30:54 Epoch [03000/30000] Loss:0.011628 Loss_1:0.011301 Loss_2:0.000250 Loss_3:0.000000 Lr:0.000769 Time:19.222897s (0.96min in total, 8.61min remains)
2022-11-28 16:31:13 NUM_SUB: 78;----------------------------
2022-11-28 16:31:13 Epoch [04000/30000] Loss:0.010580 Loss_1:0.010363 Loss_2:0.000167 Loss_3:0.000000 Lr:0.000714 Time:18.930901s (1.27min in total, 8.27min remains)
2022-11-28 16:31:32 NUM_SUB: 78;----------------------------
2022-11-28 16:31:32 Epoch [05000/30000] Loss:0.008990 Loss_1:0.008737 Loss_2:0.000190 Loss_3:0.000000 Lr:0.000667 Time:19.443972s (1.60min in total, 7.98min remains)
2022-11-28 16:31:51 NUM_SUB: 78;----------------------------
2022-11-28 16:31:51 Epoch [06000/30000] Loss:0.007555 Loss_1:0.007325 Loss_2:0.000176 Loss_3:0.000000 Lr:0.000625 Time:18.932558s (1.91min in total, 7.65min remains)
2022-11-28 16:32:10 NUM_SUB: 78;----------------------------
2022-11-28 16:32:10 Epoch [07000/30000] Loss:0.006053 Loss_1:0.005863 Loss_2:0.000147 Loss_3:0.000000 Lr:0.000588 Time:19.217594s (2.23min in total, 7.34min remains)
2022-11-28 16:32:30 NUM_SUB: 78;----------------------------
2022-11-28 16:32:30 Epoch [08000/30000] Loss:0.004351 Loss_1:0.004192 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000556 Time:19.388213s (2.56min in total, 7.03min remains)
2022-11-28 16:32:48 NUM_SUB: 78;----------------------------
2022-11-28 16:32:48 Epoch [09000/30000] Loss:0.002750 Loss_1:0.002612 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000526 Time:18.725094s (2.87min in total, 6.69min remains)
2022-11-28 16:33:08 NUM_SUB: 78;----------------------------
2022-11-28 16:33:08 Epoch [10000/30000] Loss:0.001730 Loss_1:0.001610 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000500 Time:19.211416s (3.19min in total, 6.38min remains)
2022-11-28 16:33:27 NUM_SUB: 78;----------------------------
2022-11-28 16:33:27 Epoch [11000/30000] Loss:0.001361 Loss_1:0.001260 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000476 Time:19.357982s (3.51min in total, 6.06min remains)
2022-11-28 16:33:46 NUM_SUB: 78;----------------------------
2022-11-28 16:33:46 Epoch [12000/30000] Loss:0.001112 Loss_1:0.001036 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000455 Time:18.887411s (3.83min in total, 5.74min remains)
2022-11-28 16:34:05 NUM_SUB: 78;----------------------------
2022-11-28 16:34:05 Epoch [13000/30000] Loss:0.000824 Loss_1:0.000770 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000435 Time:19.565864s (4.15min in total, 5.43min remains)
2022-11-28 16:34:24 NUM_SUB: 78;----------------------------
2022-11-28 16:34:24 Epoch [14000/30000] Loss:0.000629 Loss_1:0.000592 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:19.073879s (4.47min in total, 5.11min remains)
2022-11-28 16:34:44 NUM_SUB: 78;----------------------------
2022-11-28 16:34:44 Epoch [15000/30000] Loss:0.000576 Loss_1:0.000548 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000400 Time:19.247745s (4.79min in total, 4.79min remains)
2022-11-28 16:35:03 NUM_SUB: 78;----------------------------
2022-11-28 16:35:03 Epoch [16000/30000] Loss:0.000564 Loss_1:0.000543 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:19.118874s (5.11min in total, 4.47min remains)
2022-11-28 16:35:23 NUM_SUB: 78;----------------------------
2022-11-28 16:35:23 Epoch [17000/30000] Loss:0.000579 Loss_1:0.000539 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000370 Time:19.893750s (5.44min in total, 4.16min remains)
2022-11-28 16:35:42 NUM_SUB: 78;----------------------------
2022-11-28 16:35:42 Epoch [18000/30000] Loss:0.000548 Loss_1:0.000536 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:19.184741s (5.76min in total, 3.84min remains)
2022-11-28 16:36:01 NUM_SUB: 78;----------------------------
2022-11-28 16:36:01 Epoch [19000/30000] Loss:0.000538 Loss_1:0.000529 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:18.918992s (6.08min in total, 3.52min remains)
2022-11-28 16:36:20 NUM_SUB: 78;----------------------------
2022-11-28 16:36:20 Epoch [20000/30000] Loss:0.000541 Loss_1:0.000518 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:19.304089s (6.40min in total, 3.20min remains)
2022-11-28 16:36:40 NUM_SUB: 78;----------------------------
2022-11-28 16:36:40 Epoch [21000/30000] Loss:0.000504 Loss_1:0.000498 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000323 Time:19.465545s (6.72min in total, 2.88min remains)
2022-11-28 16:36:59 NUM_SUB: 78;----------------------------
2022-11-28 16:36:59 Epoch [22000/30000] Loss:0.000481 Loss_1:0.000476 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:19.000760s (7.04min in total, 2.56min remains)
2022-11-28 16:37:18 NUM_SUB: 78;----------------------------
2022-11-28 16:37:18 Epoch [23000/30000] Loss:0.000480 Loss_1:0.000475 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:19.329331s (7.36min in total, 2.24min remains)
2022-11-28 16:37:37 NUM_SUB: 78;----------------------------
2022-11-28 16:37:37 Epoch [24000/30000] Loss:0.000477 Loss_1:0.000472 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:18.944807s (7.68min in total, 1.92min remains)
2022-11-28 16:37:56 NUM_SUB: 78;----------------------------
2022-11-28 16:37:56 Epoch [25000/30000] Loss:0.000475 Loss_1:0.000471 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000286 Time:19.143392s (8.00min in total, 1.60min remains)
2022-11-28 16:38:15 NUM_SUB: 78;----------------------------
2022-11-28 16:38:15 Epoch [26000/30000] Loss:0.000475 Loss_1:0.000470 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:19.017029s (8.31min in total, 1.28min remains)
2022-11-28 16:38:34 NUM_SUB: 78;----------------------------
2022-11-28 16:38:34 Epoch [27000/30000] Loss:0.000475 Loss_1:0.000471 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000270 Time:19.208384s (8.63min in total, 0.96min remains)
2022-11-28 16:38:54 NUM_SUB: 78;----------------------------
2022-11-28 16:38:54 Epoch [28000/30000] Loss:0.000475 Loss_1:0.000470 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:19.504835s (8.96min in total, 0.64min remains)
2022-11-28 16:39:13 NUM_SUB: 78;----------------------------
2022-11-28 16:39:13 Epoch [29000/30000] Loss:0.000478 Loss_1:0.000474 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:19.189420s (9.28min in total, 0.32min remains)
2022-11-28 16:39:32 NUM_SUB: 78;----------------------------
2022-11-28 16:39:32 Epoch [30000/30000] Loss:0.000474 Loss_1:0.000470 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:18.877688s (9.59min in total, 0.00min remains)
2022-11-28 16:39:32 Testing & drawing...
2022-11-28 16:39:32 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:39:33 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=78/
2022-11-28 16:39:33 [Loss]
2022-11-28 16:39:34 NUM_SUB: 78; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:39:34 NUM_SUB: 78; Personalized parameter estimation: Parameter containing:
tensor([0.0117, 0.0278, 0.0183, 0.5134, 0.3074, 0.0109, 2.0623, 0.8964, 0.4556,
        0.0138, 0.0347, 0.0130, 0.6483, 0.1689, 0.0176, 1.3511, 0.6977, 0.8000,
        0.0094, 4.2678, 0.6816, 0.0219, 3.4180, 0.8742, 0.0180, 4.3458, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:39:34 NUM_SUB: 78------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:39:34 Testing & drawing...
2022-11-28 16:39:34 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:39:35 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=78/
2022-11-28 16:39:35 [Loss]
2022-11-28 16:39:35 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:39:35 General parameter estimation: Parameter containing:
tensor([0.0117, 0.0278, 0.0183, 0.5134, 0.3074, 0.0109, 2.0623, 0.8964, 0.4556,
        0.0138, 0.0347, 0.0130, 0.6483, 0.1689, 0.0176, 1.3511, 0.6977, 0.8000,
        0.0094, 4.2678, 0.6816, 0.0219, 3.4180, 0.8742, 0.0180, 4.3458, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:39:35 A: prod, degr, TonA, NonA
2022-11-28 16:39:35 [0.27768132 0.48366064 0.22988804 0.00876998]
2022-11-28 16:39:35 T: prod, degr, AonT, NonT
2022-11-28 16:39:35 [0.3001471  0.55371344 0.1176993  0.02844017]
2022-11-28 16:39:35 N: AonN, TonN, ATonN
2022-11-28 16:39:35 [0.01323981 0.9492015  0.03755865]
2022-11-28 16:39:35 using cpu
2022-11-28 16:39:35 epoch = 30000
2022-11-28 16:39:35 epoch_step = 1000
2022-11-28 16:39:35 model_name = SimpleNetworkAD
2022-11-28 16:39:35 now_string = 2022-11-27-19-40-13
2022-11-28 16:39:35 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:39:35 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:39:35 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:39:35 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:39:35 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:39:35 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:39:55 NUM_SUB: 79;----------------------------
2022-11-28 16:39:55 Epoch [01000/30000] Loss:0.181098 Loss_1:0.175013 Loss_2:0.001753 Loss_3:0.000000 Lr:0.000909 Time:19.249629s (0.32min in total, 9.30min remains)
2022-11-28 16:40:14 NUM_SUB: 79;----------------------------
2022-11-28 16:40:14 Epoch [02000/30000] Loss:0.170235 Loss_1:0.168905 Loss_2:0.000514 Loss_3:0.000000 Lr:0.000833 Time:19.192005s (0.64min in total, 8.97min remains)
2022-11-28 16:40:33 NUM_SUB: 79;----------------------------
2022-11-28 16:40:33 Epoch [03000/30000] Loss:0.159236 Loss_1:0.158377 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000769 Time:19.028910s (0.96min in total, 8.62min remains)
2022-11-28 16:40:52 NUM_SUB: 79;----------------------------
2022-11-28 16:40:52 Epoch [04000/30000] Loss:0.144583 Loss_1:0.143611 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000714 Time:19.351474s (1.28min in total, 8.32min remains)
2022-11-28 16:41:11 NUM_SUB: 79;----------------------------
2022-11-28 16:41:11 Epoch [05000/30000] Loss:0.122980 Loss_1:0.122097 Loss_2:0.000105 Loss_3:0.000000 Lr:0.000667 Time:18.863778s (1.59min in total, 7.97min remains)
2022-11-28 16:41:30 NUM_SUB: 79;----------------------------
2022-11-28 16:41:30 Epoch [06000/30000] Loss:0.091983 Loss_1:0.091230 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000625 Time:19.318023s (1.92min in total, 7.67min remains)
2022-11-28 16:41:50 NUM_SUB: 79;----------------------------
2022-11-28 16:41:50 Epoch [07000/30000] Loss:0.051553 Loss_1:0.050907 Loss_2:0.000253 Loss_3:0.000000 Lr:0.000588 Time:19.275862s (2.24min in total, 7.35min remains)
2022-11-28 16:42:08 NUM_SUB: 79;----------------------------
2022-11-28 16:42:08 Epoch [08000/30000] Loss:0.017667 Loss_1:0.017184 Loss_2:0.000343 Loss_3:0.000000 Lr:0.000556 Time:18.731465s (2.55min in total, 7.01min remains)
2022-11-28 16:42:28 NUM_SUB: 79;----------------------------
2022-11-28 16:42:28 Epoch [09000/30000] Loss:0.009162 Loss_1:0.008786 Loss_2:0.000357 Loss_3:0.000000 Lr:0.000526 Time:19.491061s (2.88min in total, 6.71min remains)
2022-11-28 16:42:47 NUM_SUB: 79;----------------------------
2022-11-28 16:42:47 Epoch [10000/30000] Loss:0.007385 Loss_1:0.007068 Loss_2:0.000299 Loss_3:0.000000 Lr:0.000500 Time:19.026233s (3.19min in total, 6.38min remains)
2022-11-28 16:43:06 NUM_SUB: 79;----------------------------
2022-11-28 16:43:06 Epoch [11000/30000] Loss:0.006224 Loss_1:0.006027 Loss_2:0.000193 Loss_3:0.000000 Lr:0.000476 Time:19.003581s (3.51min in total, 6.06min remains)
2022-11-28 16:43:25 NUM_SUB: 79;----------------------------
2022-11-28 16:43:25 Epoch [12000/30000] Loss:0.005637 Loss_1:0.005514 Loss_2:0.000121 Loss_3:0.000000 Lr:0.000455 Time:19.540055s (3.83min in total, 5.75min remains)
2022-11-28 16:43:44 NUM_SUB: 79;----------------------------
2022-11-28 16:43:44 Epoch [13000/30000] Loss:0.005426 Loss_1:0.005343 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000435 Time:18.704617s (4.15min in total, 5.42min remains)
2022-11-28 16:44:03 NUM_SUB: 79;----------------------------
2022-11-28 16:44:03 Epoch [14000/30000] Loss:0.005285 Loss_1:0.005230 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000417 Time:19.289042s (4.47min in total, 5.11min remains)
2022-11-28 16:44:23 NUM_SUB: 79;----------------------------
2022-11-28 16:44:23 Epoch [15000/30000] Loss:0.005146 Loss_1:0.005099 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000400 Time:19.234698s (4.79min in total, 4.79min remains)
2022-11-28 16:44:42 NUM_SUB: 79;----------------------------
2022-11-28 16:44:42 Epoch [16000/30000] Loss:0.004994 Loss_1:0.004958 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000385 Time:19.263386s (5.11min in total, 4.47min remains)
2022-11-28 16:45:02 NUM_SUB: 79;----------------------------
2022-11-28 16:45:02 Epoch [17000/30000] Loss:0.004815 Loss_1:0.004783 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000370 Time:19.728167s (5.44min in total, 4.16min remains)
2022-11-28 16:45:21 NUM_SUB: 79;----------------------------
2022-11-28 16:45:21 Epoch [18000/30000] Loss:0.004670 Loss_1:0.004643 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000357 Time:19.183576s (5.76min in total, 3.84min remains)
2022-11-28 16:45:40 NUM_SUB: 79;----------------------------
2022-11-28 16:45:40 Epoch [19000/30000] Loss:0.004612 Loss_1:0.004587 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000345 Time:18.914844s (6.07min in total, 3.52min remains)
2022-11-28 16:45:59 NUM_SUB: 79;----------------------------
2022-11-28 16:45:59 Epoch [20000/30000] Loss:0.004596 Loss_1:0.004574 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000333 Time:19.523349s (6.40min in total, 3.20min remains)
2022-11-28 16:46:18 NUM_SUB: 79;----------------------------
2022-11-28 16:46:18 Epoch [21000/30000] Loss:0.004590 Loss_1:0.004568 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000323 Time:18.724251s (6.71min in total, 2.88min remains)
2022-11-28 16:46:37 NUM_SUB: 79;----------------------------
2022-11-28 16:46:37 Epoch [22000/30000] Loss:0.004586 Loss_1:0.004567 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000313 Time:19.242497s (7.03min in total, 2.56min remains)
2022-11-28 16:46:57 NUM_SUB: 79;----------------------------
2022-11-28 16:46:57 Epoch [23000/30000] Loss:0.004583 Loss_1:0.004566 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000303 Time:19.261089s (7.35min in total, 2.24min remains)
2022-11-28 16:47:15 NUM_SUB: 79;----------------------------
2022-11-28 16:47:15 Epoch [24000/30000] Loss:0.004581 Loss_1:0.004564 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000294 Time:18.689437s (7.66min in total, 1.92min remains)
2022-11-28 16:47:35 NUM_SUB: 79;----------------------------
2022-11-28 16:47:35 Epoch [25000/30000] Loss:0.004578 Loss_1:0.004563 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000286 Time:19.669278s (7.99min in total, 1.60min remains)
2022-11-28 16:47:54 NUM_SUB: 79;----------------------------
2022-11-28 16:47:54 Epoch [26000/30000] Loss:0.004576 Loss_1:0.004561 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000278 Time:19.010445s (8.31min in total, 1.28min remains)
2022-11-28 16:48:13 NUM_SUB: 79;----------------------------
2022-11-28 16:48:13 Epoch [27000/30000] Loss:0.004574 Loss_1:0.004560 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000270 Time:19.374317s (8.63min in total, 0.96min remains)
2022-11-28 16:48:32 NUM_SUB: 79;----------------------------
2022-11-28 16:48:32 Epoch [28000/30000] Loss:0.004573 Loss_1:0.004560 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000263 Time:19.155544s (8.95min in total, 0.64min remains)
2022-11-28 16:48:51 NUM_SUB: 79;----------------------------
2022-11-28 16:48:51 Epoch [29000/30000] Loss:0.004572 Loss_1:0.004560 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000256 Time:18.859381s (9.27min in total, 0.32min remains)
2022-11-28 16:49:11 NUM_SUB: 79;----------------------------
2022-11-28 16:49:11 Epoch [30000/30000] Loss:0.004572 Loss_1:0.004559 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000250 Time:19.516123s (9.59min in total, 0.00min remains)
2022-11-28 16:49:11 Testing & drawing...
2022-11-28 16:49:11 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:49:12 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=79/
2022-11-28 16:49:12 [Loss]
2022-11-28 16:49:13 NUM_SUB: 79; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:49:13 NUM_SUB: 79; Personalized parameter estimation: Parameter containing:
tensor([0.0158, 0.0229, 0.0085, 3.9989, 0.3074, 0.0123, 2.3648, 0.8964, 0.4556,
        0.0740, 0.0887, 0.0137, 0.2262, 0.1689, 0.0175, 1.9189, 0.6977, 0.8000,
        0.0113, 4.9037, 0.6816, 0.0220, 4.2973, 0.8742, 0.0139, 5.0900, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:49:13 NUM_SUB: 79------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:49:13 Testing & drawing...
2022-11-28 16:49:13 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:49:14 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=79/
2022-11-28 16:49:14 [Loss]
2022-11-28 16:49:14 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:49:14 General parameter estimation: Parameter containing:
tensor([0.0158, 0.0229, 0.0085, 3.9989, 0.3074, 0.0123, 2.3648, 0.8964, 0.4556,
        0.0740, 0.0887, 0.0137, 0.2262, 0.1689, 0.0175, 1.9189, 0.6977, 0.8000,
        0.0113, 4.9037, 0.6816, 0.0220, 4.2973, 0.8742, 0.0139, 5.0900, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 16:49:14 A: prod, degr, TonA, NonA
2022-11-28 16:49:14 [0.489898   0.46386048 0.01547614 0.03076531]
2022-11-28 16:49:14 T: prod, degr, AonT, NonT
2022-11-28 16:49:14 [0.5014377  0.39632484 0.08823272 0.01400474]
2022-11-28 16:49:14 N: AonN, TonN, ATonN
2022-11-28 16:49:14 [0.00960936 0.9567882  0.03360244]
2022-11-28 16:49:14 using cpu
2022-11-28 16:49:14 epoch = 30000
2022-11-28 16:49:14 epoch_step = 1000
2022-11-28 16:49:14 model_name = SimpleNetworkAD
2022-11-28 16:49:14 now_string = 2022-11-27-19-40-13
2022-11-28 16:49:14 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:49:14 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:49:14 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:49:14 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:49:14 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:49:14 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:49:33 NUM_SUB: 80;----------------------------
2022-11-28 16:49:33 Epoch [01000/30000] Loss:0.157287 Loss_1:0.151554 Loss_2:0.001784 Loss_3:0.000000 Lr:0.000909 Time:19.080904s (0.32min in total, 9.22min remains)
2022-11-28 16:49:53 NUM_SUB: 80;----------------------------
2022-11-28 16:49:53 Epoch [02000/30000] Loss:0.146457 Loss_1:0.145357 Loss_2:0.000556 Loss_3:0.000000 Lr:0.000833 Time:19.294351s (0.64min in total, 8.95min remains)
2022-11-28 16:50:12 NUM_SUB: 80;----------------------------
2022-11-28 16:50:12 Epoch [03000/30000] Loss:0.136353 Loss_1:0.135598 Loss_2:0.000203 Loss_3:0.000000 Lr:0.000769 Time:18.994365s (0.96min in total, 8.61min remains)
2022-11-28 16:50:31 NUM_SUB: 80;----------------------------
2022-11-28 16:50:31 Epoch [04000/30000] Loss:0.123111 Loss_1:0.122349 Loss_2:0.000147 Loss_3:0.000000 Lr:0.000714 Time:18.885971s (1.27min in total, 8.26min remains)
2022-11-28 16:50:50 NUM_SUB: 80;----------------------------
2022-11-28 16:50:50 Epoch [05000/30000] Loss:0.103245 Loss_1:0.102524 Loss_2:0.000179 Loss_3:0.000000 Lr:0.000667 Time:19.524342s (1.60min in total, 7.98min remains)
2022-11-28 16:51:09 NUM_SUB: 80;----------------------------
2022-11-28 16:51:09 Epoch [06000/30000] Loss:0.074530 Loss_1:0.073749 Loss_2:0.000358 Loss_3:0.000000 Lr:0.000625 Time:19.322398s (1.92min in total, 7.67min remains)
2022-11-28 16:51:28 NUM_SUB: 80;----------------------------
2022-11-28 16:51:28 Epoch [07000/30000] Loss:0.037261 Loss_1:0.036577 Loss_2:0.000424 Loss_3:0.000000 Lr:0.000588 Time:18.837854s (2.23min in total, 7.34min remains)
2022-11-28 16:51:47 NUM_SUB: 80;----------------------------
2022-11-28 16:51:47 Epoch [08000/30000] Loss:0.010793 Loss_1:0.010190 Loss_2:0.000534 Loss_3:0.000000 Lr:0.000556 Time:19.027930s (2.55min in total, 7.01min remains)
2022-11-28 16:52:06 NUM_SUB: 80;----------------------------
2022-11-28 16:52:06 Epoch [09000/30000] Loss:0.002926 Loss_1:0.002633 Loss_2:0.000291 Loss_3:0.000000 Lr:0.000526 Time:18.943543s (2.87min in total, 6.69min remains)
2022-11-28 16:52:25 NUM_SUB: 80;----------------------------
2022-11-28 16:52:26 Epoch [10000/30000] Loss:0.002216 Loss_1:0.002002 Loss_2:0.000211 Loss_3:0.000000 Lr:0.000500 Time:19.219114s (3.19min in total, 6.37min remains)
2022-11-28 16:52:45 NUM_SUB: 80;----------------------------
2022-11-28 16:52:45 Epoch [11000/30000] Loss:0.001771 Loss_1:0.001630 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000476 Time:19.287552s (3.51min in total, 6.06min remains)
2022-11-28 16:53:04 NUM_SUB: 80;----------------------------
2022-11-28 16:53:04 Epoch [12000/30000] Loss:0.001577 Loss_1:0.001474 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000455 Time:18.936119s (3.82min in total, 5.73min remains)
2022-11-28 16:53:23 NUM_SUB: 80;----------------------------
2022-11-28 16:53:23 Epoch [13000/30000] Loss:0.001453 Loss_1:0.001374 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000435 Time:19.163583s (4.14min in total, 5.42min remains)
2022-11-28 16:53:42 NUM_SUB: 80;----------------------------
2022-11-28 16:53:42 Epoch [14000/30000] Loss:0.001326 Loss_1:0.001268 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000417 Time:19.028983s (4.46min in total, 5.10min remains)
2022-11-28 16:54:01 NUM_SUB: 80;----------------------------
2022-11-28 16:54:01 Epoch [15000/30000] Loss:0.001208 Loss_1:0.001161 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000400 Time:19.193147s (4.78min in total, 4.78min remains)
2022-11-28 16:54:20 NUM_SUB: 80;----------------------------
2022-11-28 16:54:20 Epoch [16000/30000] Loss:0.001172 Loss_1:0.001133 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000385 Time:19.194412s (5.10min in total, 4.46min remains)
2022-11-28 16:54:39 NUM_SUB: 80;----------------------------
2022-11-28 16:54:39 Epoch [17000/30000] Loss:0.001161 Loss_1:0.001128 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000370 Time:18.842058s (5.41min in total, 4.14min remains)
2022-11-28 16:54:58 NUM_SUB: 80;----------------------------
2022-11-28 16:54:58 Epoch [18000/30000] Loss:0.001153 Loss_1:0.001124 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000357 Time:19.157513s (5.73min in total, 3.82min remains)
2022-11-28 16:55:17 NUM_SUB: 80;----------------------------
2022-11-28 16:55:17 Epoch [19000/30000] Loss:0.001156 Loss_1:0.001131 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000345 Time:18.787900s (6.05min in total, 3.50min remains)
2022-11-28 16:55:36 NUM_SUB: 80;----------------------------
2022-11-28 16:55:36 Epoch [20000/30000] Loss:0.001169 Loss_1:0.001111 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000333 Time:19.286853s (6.37min in total, 3.18min remains)
2022-11-28 16:55:56 NUM_SUB: 80;----------------------------
2022-11-28 16:55:56 Epoch [21000/30000] Loss:0.001137 Loss_1:0.001117 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000323 Time:19.317035s (6.69min in total, 2.87min remains)
2022-11-28 16:56:14 NUM_SUB: 80;----------------------------
2022-11-28 16:56:14 Epoch [22000/30000] Loss:0.001134 Loss_1:0.001115 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000313 Time:18.689639s (7.00min in total, 2.55min remains)
2022-11-28 16:56:34 NUM_SUB: 80;----------------------------
2022-11-28 16:56:34 Epoch [23000/30000] Loss:0.001131 Loss_1:0.001113 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000303 Time:19.253371s (7.32min in total, 2.23min remains)
2022-11-28 16:56:53 NUM_SUB: 80;----------------------------
2022-11-28 16:56:53 Epoch [24000/30000] Loss:0.001129 Loss_1:0.001112 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000294 Time:19.297174s (7.64min in total, 1.91min remains)
2022-11-28 16:57:12 NUM_SUB: 80;----------------------------
2022-11-28 16:57:12 Epoch [25000/30000] Loss:0.001127 Loss_1:0.001111 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000286 Time:19.391223s (7.97min in total, 1.59min remains)
2022-11-28 16:57:31 NUM_SUB: 80;----------------------------
2022-11-28 16:57:31 Epoch [26000/30000] Loss:0.001125 Loss_1:0.001112 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000278 Time:18.643344s (8.28min in total, 1.27min remains)
2022-11-28 16:57:50 NUM_SUB: 80;----------------------------
2022-11-28 16:57:50 Epoch [27000/30000] Loss:0.001124 Loss_1:0.001110 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000270 Time:19.264826s (8.60min in total, 0.96min remains)
2022-11-28 16:58:09 NUM_SUB: 80;----------------------------
2022-11-28 16:58:09 Epoch [28000/30000] Loss:0.001123 Loss_1:0.001109 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000263 Time:19.232997s (8.92min in total, 0.64min remains)
2022-11-28 16:58:28 NUM_SUB: 80;----------------------------
2022-11-28 16:58:28 Epoch [29000/30000] Loss:0.001122 Loss_1:0.001108 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000256 Time:18.625368s (9.23min in total, 0.32min remains)
2022-11-28 16:58:48 NUM_SUB: 80;----------------------------
2022-11-28 16:58:48 Epoch [30000/30000] Loss:0.001121 Loss_1:0.001108 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000250 Time:19.478400s (9.55min in total, 0.00min remains)
2022-11-28 16:58:48 Testing & drawing...
2022-11-28 16:58:48 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:58:49 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=80/
2022-11-28 16:58:49 [Loss]
2022-11-28 16:58:49 NUM_SUB: 80; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:58:49 NUM_SUB: 80; Personalized parameter estimation: Parameter containing:
tensor([1.7481e-02, 2.7048e-02, 3.1172e-03, 3.5591e+00, 3.0742e-01, 1.6544e-02,
        2.2111e+00, 8.9644e-01, 4.5563e-01, 1.4358e-02, 3.5571e-02, 1.5787e-02,
        4.5071e-01, 1.6886e-01, 1.7731e-02, 8.4717e-01, 6.9767e-01, 8.0001e-01,
        1.1623e-02, 4.4627e+00, 6.8161e-01, 2.2140e-02, 3.6900e+00, 8.7416e-01,
        1.3658e-02, 4.4758e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 16:58:49 NUM_SUB: 80------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 16:58:49 Testing & drawing...
2022-11-28 16:58:49 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 16:58:51 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=80/
2022-11-28 16:58:51 [Loss]
2022-11-28 16:58:51 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 16:58:51 General parameter estimation: Parameter containing:
tensor([1.7481e-02, 2.7048e-02, 3.1172e-03, 3.5591e+00, 3.0742e-01, 1.6544e-02,
        2.2111e+00, 8.9644e-01, 4.5563e-01, 1.4358e-02, 3.5571e-02, 1.5787e-02,
        4.5071e-01, 1.6886e-01, 1.7731e-02, 8.4717e-01, 6.9767e-01, 8.0001e-01,
        1.1623e-02, 4.4627e+00, 6.8161e-01, 2.2140e-02, 3.6900e+00, 8.7416e-01,
        1.3658e-02, 4.4758e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 16:58:51 A: prod, degr, TonA, NonA
2022-11-28 16:58:51 [0.46196526 0.46558484 0.0058552  0.06659471]
2022-11-28 16:58:51 T: prod, degr, AonT, NonT
2022-11-28 16:58:51 [0.23922765 0.38646355 0.21611343 0.15819535]
2022-11-28 16:58:51 N: AonN, TonN, ATonN
2022-11-28 16:58:51 [0.01169283 0.9476371  0.0406701 ]
2022-11-28 16:58:51 using cpu
2022-11-28 16:58:51 epoch = 30000
2022-11-28 16:58:51 epoch_step = 1000
2022-11-28 16:58:51 model_name = SimpleNetworkAD
2022-11-28 16:58:51 now_string = 2022-11-27-19-40-13
2022-11-28 16:58:51 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 16:58:51 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 16:58:51 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 16:58:51 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 16:58:51 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 16:58:51 --------------------------------------------------training start--------------------------------------------------
2022-11-28 16:59:10 NUM_SUB: 81;----------------------------
2022-11-28 16:59:10 Epoch [01000/30000] Loss:0.058981 Loss_1:0.053951 Loss_2:0.001335 Loss_3:0.000000 Lr:0.000909 Time:19.015331s (0.32min in total, 9.19min remains)
2022-11-28 16:59:29 NUM_SUB: 81;----------------------------
2022-11-28 16:59:29 Epoch [02000/30000] Loss:0.051281 Loss_1:0.050548 Loss_2:0.000324 Loss_3:0.000000 Lr:0.000833 Time:18.997327s (0.63min in total, 8.87min remains)
2022-11-28 16:59:49 NUM_SUB: 81;----------------------------
2022-11-28 16:59:49 Epoch [03000/30000] Loss:0.046101 Loss_1:0.045792 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000769 Time:19.560646s (0.96min in total, 8.64min remains)
2022-11-28 17:00:08 NUM_SUB: 81;----------------------------
2022-11-28 17:00:08 Epoch [04000/30000] Loss:0.040323 Loss_1:0.040093 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000714 Time:18.821909s (1.27min in total, 8.28min remains)
2022-11-28 17:00:27 NUM_SUB: 81;----------------------------
2022-11-28 17:00:27 Epoch [05000/30000] Loss:0.032202 Loss_1:0.032002 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000667 Time:19.571542s (1.60min in total, 8.00min remains)
2022-11-28 17:00:47 NUM_SUB: 81;----------------------------
2022-11-28 17:00:47 Epoch [06000/30000] Loss:0.021417 Loss_1:0.021253 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000625 Time:19.460718s (1.92min in total, 7.70min remains)
2022-11-28 17:01:06 NUM_SUB: 81;----------------------------
2022-11-28 17:01:06 Epoch [07000/30000] Loss:0.010169 Loss_1:0.010046 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000588 Time:19.142643s (2.24min in total, 7.37min remains)
2022-11-28 17:01:25 NUM_SUB: 81;----------------------------
2022-11-28 17:01:25 Epoch [08000/30000] Loss:0.003764 Loss_1:0.003674 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000556 Time:19.624735s (2.57min in total, 7.07min remains)
2022-11-28 17:01:45 NUM_SUB: 81;----------------------------
2022-11-28 17:01:45 Epoch [09000/30000] Loss:0.002381 Loss_1:0.002313 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000526 Time:19.243231s (2.89min in total, 6.75min remains)
2022-11-28 17:02:04 NUM_SUB: 81;----------------------------
2022-11-28 17:02:04 Epoch [10000/30000] Loss:0.002064 Loss_1:0.002036 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000500 Time:19.124855s (3.21min in total, 6.42min remains)
2022-11-28 17:02:24 NUM_SUB: 81;----------------------------
2022-11-28 17:02:24 Epoch [11000/30000] Loss:0.001817 Loss_1:0.001804 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000476 Time:19.920166s (3.54min in total, 6.12min remains)
2022-11-28 17:02:43 NUM_SUB: 81;----------------------------
2022-11-28 17:02:43 Epoch [12000/30000] Loss:0.001552 Loss_1:0.001541 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000455 Time:18.997465s (3.86min in total, 5.79min remains)
2022-11-28 17:03:02 NUM_SUB: 81;----------------------------
2022-11-28 17:03:02 Epoch [13000/30000] Loss:0.001279 Loss_1:0.001255 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000435 Time:19.416178s (4.18min in total, 5.47min remains)
2022-11-28 17:03:21 NUM_SUB: 81;----------------------------
2022-11-28 17:03:21 Epoch [14000/30000] Loss:0.001025 Loss_1:0.001011 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000417 Time:19.327322s (4.50min in total, 5.15min remains)
2022-11-28 17:03:40 NUM_SUB: 81;----------------------------
2022-11-28 17:03:40 Epoch [15000/30000] Loss:0.000853 Loss_1:0.000839 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000400 Time:18.748908s (4.82min in total, 4.82min remains)
2022-11-28 17:04:00 NUM_SUB: 81;----------------------------
2022-11-28 17:04:00 Epoch [16000/30000] Loss:0.000909 Loss_1:0.000805 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000385 Time:19.367803s (5.14min in total, 4.50min remains)
2022-11-28 17:04:19 NUM_SUB: 81;----------------------------
2022-11-28 17:04:19 Epoch [17000/30000] Loss:0.000756 Loss_1:0.000747 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000370 Time:19.361685s (5.46min in total, 4.18min remains)
2022-11-28 17:04:38 NUM_SUB: 81;----------------------------
2022-11-28 17:04:38 Epoch [18000/30000] Loss:0.000746 Loss_1:0.000735 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:18.994391s (5.78min in total, 3.85min remains)
2022-11-28 17:04:57 NUM_SUB: 81;----------------------------
2022-11-28 17:04:57 Epoch [19000/30000] Loss:0.000741 Loss_1:0.000731 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000345 Time:19.289268s (6.10min in total, 3.53min remains)
2022-11-28 17:05:16 NUM_SUB: 81;----------------------------
2022-11-28 17:05:16 Epoch [20000/30000] Loss:0.000735 Loss_1:0.000727 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:19.181330s (6.42min in total, 3.21min remains)
2022-11-28 17:05:36 NUM_SUB: 81;----------------------------
2022-11-28 17:05:36 Epoch [21000/30000] Loss:0.000729 Loss_1:0.000721 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000323 Time:19.778433s (6.75min in total, 2.89min remains)
2022-11-28 17:05:56 NUM_SUB: 81;----------------------------
2022-11-28 17:05:56 Epoch [22000/30000] Loss:0.000723 Loss_1:0.000716 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:19.456151s (7.07min in total, 2.57min remains)
2022-11-28 17:06:15 NUM_SUB: 81;----------------------------
2022-11-28 17:06:15 Epoch [23000/30000] Loss:0.000718 Loss_1:0.000713 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:18.916833s (7.39min in total, 2.25min remains)
2022-11-28 17:06:34 NUM_SUB: 81;----------------------------
2022-11-28 17:06:34 Epoch [24000/30000] Loss:0.000716 Loss_1:0.000711 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:19.307776s (7.71min in total, 1.93min remains)
2022-11-28 17:06:53 NUM_SUB: 81;----------------------------
2022-11-28 17:06:53 Epoch [25000/30000] Loss:0.000714 Loss_1:0.000710 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000286 Time:19.452852s (8.04min in total, 1.61min remains)
2022-11-28 17:07:12 NUM_SUB: 81;----------------------------
2022-11-28 17:07:12 Epoch [26000/30000] Loss:0.000712 Loss_1:0.000709 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:19.077336s (8.35min in total, 1.29min remains)
2022-11-28 17:07:32 NUM_SUB: 81;----------------------------
2022-11-28 17:07:32 Epoch [27000/30000] Loss:0.000711 Loss_1:0.000708 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000270 Time:19.152339s (8.67min in total, 0.96min remains)
2022-11-28 17:07:51 NUM_SUB: 81;----------------------------
2022-11-28 17:07:51 Epoch [28000/30000] Loss:0.000709 Loss_1:0.000706 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:19.276573s (8.99min in total, 0.64min remains)
2022-11-28 17:08:10 NUM_SUB: 81;----------------------------
2022-11-28 17:08:10 Epoch [29000/30000] Loss:0.000709 Loss_1:0.000706 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000256 Time:19.348029s (9.32min in total, 0.32min remains)
2022-11-28 17:08:29 NUM_SUB: 81;----------------------------
2022-11-28 17:08:29 Epoch [30000/30000] Loss:0.000721 Loss_1:0.000708 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:19.003526s (9.63min in total, 0.00min remains)
2022-11-28 17:08:29 Testing & drawing...
2022-11-28 17:08:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:08:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=81/
2022-11-28 17:08:31 [Loss]
2022-11-28 17:08:31 NUM_SUB: 81; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:08:31 NUM_SUB: 81; Personalized parameter estimation: Parameter containing:
tensor([0.0126, 0.1983, 0.0132, 0.2442, 0.3074, 0.1665, 1.2541, 0.8964, 0.4556,
        0.0089, 0.1572, 0.1017, 0.4079, 0.1689, 0.0171, 1.0779, 0.6977, 0.8000,
        0.0123, 2.5976, 0.6816, 0.0221, 2.3782, 0.8742, 0.0221, 3.1288, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 17:08:31 NUM_SUB: 81------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 17:08:31 Testing & drawing...
2022-11-28 17:08:31 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:08:33 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=81/
2022-11-28 17:08:33 [Loss]
2022-11-28 17:08:33 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:08:33 General parameter estimation: Parameter containing:
tensor([0.0126, 0.1983, 0.0132, 0.2442, 0.3074, 0.1665, 1.2541, 0.8964, 0.4556,
        0.0089, 0.1572, 0.1017, 0.4079, 0.1689, 0.0171, 1.0779, 0.6977, 0.8000,
        0.0123, 2.5976, 0.6816, 0.0221, 2.3782, 0.8742, 0.0221, 3.1288, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 17:08:33 A: prod, degr, TonA, NonA
2022-11-28 17:08:33 [0.11185981 0.4869513  0.06255087 0.33863807]
2022-11-28 17:08:33 T: prod, degr, AonT, NonT
2022-11-28 17:08:33 [0.10279317 0.4917241  0.34969664 0.0557861 ]
2022-11-28 17:08:33 N: AonN, TonN, ATonN
2022-11-28 17:08:33 [0.00909323 0.9674007  0.02350607]
2022-11-28 17:08:33 using cpu
2022-11-28 17:08:33 epoch = 30000
2022-11-28 17:08:33 epoch_step = 1000
2022-11-28 17:08:33 model_name = SimpleNetworkAD
2022-11-28 17:08:33 now_string = 2022-11-27-19-40-13
2022-11-28 17:08:33 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 17:08:33 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 17:08:33 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 17:08:33 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 17:08:33 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 17:08:33 --------------------------------------------------training start--------------------------------------------------
2022-11-28 17:08:52 NUM_SUB: 82;----------------------------
2022-11-28 17:08:52 Epoch [01000/30000] Loss:0.185880 Loss_1:0.180149 Loss_2:0.001942 Loss_3:0.000000 Lr:0.000909 Time:19.109688s (0.32min in total, 9.24min remains)
2022-11-28 17:09:12 NUM_SUB: 82;----------------------------
2022-11-28 17:09:12 Epoch [02000/30000] Loss:0.160485 Loss_1:0.159033 Loss_2:0.000614 Loss_3:0.000000 Lr:0.000833 Time:19.875032s (0.65min in total, 9.10min remains)
2022-11-28 17:09:31 NUM_SUB: 82;----------------------------
2022-11-28 17:09:31 Epoch [03000/30000] Loss:0.131803 Loss_1:0.130733 Loss_2:0.000189 Loss_3:0.000000 Lr:0.000769 Time:19.691200s (0.98min in total, 8.80min remains)
2022-11-28 17:09:51 NUM_SUB: 82;----------------------------
2022-11-28 17:09:51 Epoch [04000/30000] Loss:0.091957 Loss_1:0.091133 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000714 Time:19.667389s (1.31min in total, 8.49min remains)
2022-11-28 17:10:10 NUM_SUB: 82;----------------------------
2022-11-28 17:10:10 Epoch [05000/30000] Loss:0.047983 Loss_1:0.047449 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000667 Time:19.360402s (1.63min in total, 8.14min remains)
2022-11-28 17:10:30 NUM_SUB: 82;----------------------------
2022-11-28 17:10:30 Epoch [06000/30000] Loss:0.022450 Loss_1:0.022179 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000625 Time:19.313956s (1.95min in total, 7.80min remains)
2022-11-28 17:10:49 NUM_SUB: 82;----------------------------
2022-11-28 17:10:49 Epoch [07000/30000] Loss:0.014815 Loss_1:0.014630 Loss_2:0.000113 Loss_3:0.000000 Lr:0.000588 Time:19.389732s (2.27min in total, 7.47min remains)
2022-11-28 17:11:08 NUM_SUB: 82;----------------------------
2022-11-28 17:11:08 Epoch [08000/30000] Loss:0.009499 Loss_1:0.009322 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000556 Time:19.139852s (2.59min in total, 7.13min remains)
2022-11-28 17:11:28 NUM_SUB: 82;----------------------------
2022-11-28 17:11:28 Epoch [09000/30000] Loss:0.004291 Loss_1:0.004120 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000526 Time:19.411997s (2.92min in total, 6.80min remains)
2022-11-28 17:11:47 NUM_SUB: 82;----------------------------
2022-11-28 17:11:47 Epoch [10000/30000] Loss:0.001607 Loss_1:0.001469 Loss_2:0.000125 Loss_3:0.000000 Lr:0.000500 Time:19.047077s (3.23min in total, 6.47min remains)
2022-11-28 17:12:06 NUM_SUB: 82;----------------------------
2022-11-28 17:12:06 Epoch [11000/30000] Loss:0.001110 Loss_1:0.001023 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000476 Time:19.382084s (3.56min in total, 6.14min remains)
2022-11-28 17:12:25 NUM_SUB: 82;----------------------------
2022-11-28 17:12:25 Epoch [12000/30000] Loss:0.000962 Loss_1:0.000911 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:18.991466s (3.87min in total, 5.81min remains)
2022-11-28 17:12:44 NUM_SUB: 82;----------------------------
2022-11-28 17:12:44 Epoch [13000/30000] Loss:0.000860 Loss_1:0.000829 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000435 Time:19.083633s (4.19min in total, 5.48min remains)
2022-11-28 17:13:04 NUM_SUB: 82;----------------------------
2022-11-28 17:13:04 Epoch [14000/30000] Loss:0.000807 Loss_1:0.000787 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:19.576437s (4.52min in total, 5.16min remains)
2022-11-28 17:13:23 NUM_SUB: 82;----------------------------
2022-11-28 17:13:23 Epoch [15000/30000] Loss:0.000775 Loss_1:0.000761 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000400 Time:18.764944s (4.83min in total, 4.83min remains)
2022-11-28 17:13:42 NUM_SUB: 82;----------------------------
2022-11-28 17:13:42 Epoch [16000/30000] Loss:0.000749 Loss_1:0.000739 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:19.474066s (5.15min in total, 4.51min remains)
2022-11-28 17:14:02 NUM_SUB: 82;----------------------------
2022-11-28 17:14:02 Epoch [17000/30000] Loss:0.000716 Loss_1:0.000709 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000370 Time:19.698670s (5.48min in total, 4.19min remains)
2022-11-28 17:14:21 NUM_SUB: 82;----------------------------
2022-11-28 17:14:21 Epoch [18000/30000] Loss:0.000671 Loss_1:0.000666 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:18.960533s (5.80min in total, 3.87min remains)
2022-11-28 17:14:40 NUM_SUB: 82;----------------------------
2022-11-28 17:14:40 Epoch [19000/30000] Loss:0.000600 Loss_1:0.000597 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000345 Time:19.672121s (6.13min in total, 3.55min remains)
2022-11-28 17:15:00 NUM_SUB: 82;----------------------------
2022-11-28 17:15:00 Epoch [20000/30000] Loss:0.000447 Loss_1:0.000445 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:19.160412s (6.45min in total, 3.22min remains)
2022-11-28 17:15:19 NUM_SUB: 82;----------------------------
2022-11-28 17:15:19 Epoch [21000/30000] Loss:0.000198 Loss_1:0.000196 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000323 Time:18.998679s (6.76min in total, 2.90min remains)
2022-11-28 17:15:38 NUM_SUB: 82;----------------------------
2022-11-28 17:15:38 Epoch [22000/30000] Loss:0.000132 Loss_1:0.000128 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:19.610995s (7.09min in total, 2.58min remains)
2022-11-28 17:15:57 NUM_SUB: 82;----------------------------
2022-11-28 17:15:57 Epoch [23000/30000] Loss:0.000123 Loss_1:0.000118 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000303 Time:19.009554s (7.41min in total, 2.25min remains)
2022-11-28 17:16:16 NUM_SUB: 82;----------------------------
2022-11-28 17:16:16 Epoch [24000/30000] Loss:0.000117 Loss_1:0.000111 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:19.226556s (7.73min in total, 1.93min remains)
2022-11-28 17:16:36 NUM_SUB: 82;----------------------------
2022-11-28 17:16:36 Epoch [25000/30000] Loss:0.000117 Loss_1:0.000110 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000286 Time:19.621683s (8.05min in total, 1.61min remains)
2022-11-28 17:16:55 NUM_SUB: 82;----------------------------
2022-11-28 17:16:55 Epoch [26000/30000] Loss:0.000117 Loss_1:0.000110 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:18.829188s (8.37min in total, 1.29min remains)
2022-11-28 17:17:14 NUM_SUB: 82;----------------------------
2022-11-28 17:17:14 Epoch [27000/30000] Loss:0.000116 Loss_1:0.000109 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000270 Time:19.475297s (8.69min in total, 0.97min remains)
2022-11-28 17:17:34 NUM_SUB: 82;----------------------------
2022-11-28 17:17:34 Epoch [28000/30000] Loss:0.000115 Loss_1:0.000109 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:19.552049s (9.02min in total, 0.64min remains)
2022-11-28 17:17:53 NUM_SUB: 82;----------------------------
2022-11-28 17:17:53 Epoch [29000/30000] Loss:0.000119 Loss_1:0.000113 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000256 Time:18.810931s (9.33min in total, 0.32min remains)
2022-11-28 17:18:12 NUM_SUB: 82;----------------------------
2022-11-28 17:18:12 Epoch [30000/30000] Loss:0.000115 Loss_1:0.000109 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:19.652014s (9.66min in total, 0.00min remains)
2022-11-28 17:18:12 Testing & drawing...
2022-11-28 17:18:12 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:18:14 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=82/
2022-11-28 17:18:14 [Loss]
2022-11-28 17:18:14 NUM_SUB: 82; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:18:14 NUM_SUB: 82; Personalized parameter estimation: Parameter containing:
tensor([0.4891, 0.7505, 0.0285, 0.0518, 0.3074, 0.0107, 0.0485, 0.8964, 0.4556,
        0.0091, 0.0550, 0.0136, 0.3713, 0.1689, 0.0176, 0.1498, 0.6977, 0.8000,
        0.0116, 2.7533, 0.6816, 0.0233, 1.5147, 0.8742, 0.0204, 2.6299, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 17:18:14 NUM_SUB: 82------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 17:18:14 Testing & drawing...
2022-11-28 17:18:14 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:18:16 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=82/
2022-11-28 17:18:16 [Loss]
2022-11-28 17:18:16 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:18:16 General parameter estimation: Parameter containing:
tensor([0.4891, 0.7505, 0.0285, 0.0518, 0.3074, 0.0107, 0.0485, 0.8964, 0.4556,
        0.0091, 0.0550, 0.0136, 0.3713, 0.1689, 0.0176, 0.1498, 0.6977, 0.8000,
        0.0116, 2.7533, 0.6816, 0.0233, 1.5147, 0.8742, 0.0204, 2.6299, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 17:18:16 A: prod, degr, TonA, NonA
2022-11-28 17:18:16 [0.46311188 0.499979   0.02679924 0.01010984]
2022-11-28 17:18:16 T: prod, degr, AonT, NonT
2022-11-28 17:18:16 [0.12075632 0.5133015  0.13694942 0.2289927 ]
2022-11-28 17:18:16 N: AonN, TonN, ATonN
2022-11-28 17:18:16 [0.0285381  0.8742284  0.09723355]
2022-11-28 17:18:16 using cpu
2022-11-28 17:18:16 epoch = 30000
2022-11-28 17:18:16 epoch_step = 1000
2022-11-28 17:18:16 model_name = SimpleNetworkAD
2022-11-28 17:18:16 now_string = 2022-11-27-19-40-13
2022-11-28 17:18:16 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 17:18:16 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 17:18:16 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 17:18:16 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 17:18:16 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 17:18:16 --------------------------------------------------training start--------------------------------------------------
2022-11-28 17:18:35 NUM_SUB: 83;----------------------------
2022-11-28 17:18:35 Epoch [01000/30000] Loss:0.040510 Loss_1:0.035175 Loss_2:0.001578 Loss_3:0.000000 Lr:0.000909 Time:19.239788s (0.32min in total, 9.30min remains)
2022-11-28 17:18:54 NUM_SUB: 83;----------------------------
2022-11-28 17:18:54 Epoch [02000/30000] Loss:0.034067 Loss_1:0.033208 Loss_2:0.000442 Loss_3:0.000000 Lr:0.000833 Time:19.145127s (0.64min in total, 8.96min remains)
2022-11-28 17:19:15 NUM_SUB: 83;----------------------------
2022-11-28 17:19:15 Epoch [03000/30000] Loss:0.030488 Loss_1:0.030271 Loss_2:0.000135 Loss_3:0.000000 Lr:0.000769 Time:20.249911s (0.98min in total, 8.80min remains)
2022-11-28 17:19:33 NUM_SUB: 83;----------------------------
2022-11-28 17:19:33 Epoch [04000/30000] Loss:0.027052 Loss_1:0.026857 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000714 Time:18.887051s (1.29min in total, 8.40min remains)
2022-11-28 17:19:53 NUM_SUB: 83;----------------------------
2022-11-28 17:19:53 Epoch [05000/30000] Loss:0.022374 Loss_1:0.022213 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000667 Time:19.545357s (1.62min in total, 8.09min remains)
2022-11-28 17:20:12 NUM_SUB: 83;----------------------------
2022-11-28 17:20:12 Epoch [06000/30000] Loss:0.016058 Loss_1:0.015917 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000625 Time:19.373783s (1.94min in total, 7.76min remains)
2022-11-28 17:20:31 NUM_SUB: 83;----------------------------
2022-11-28 17:20:31 Epoch [07000/30000] Loss:0.008815 Loss_1:0.008709 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000588 Time:18.921500s (2.26min in total, 7.41min remains)
2022-11-28 17:20:51 NUM_SUB: 83;----------------------------
2022-11-28 17:20:51 Epoch [08000/30000] Loss:0.003377 Loss_1:0.003300 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000556 Time:19.574478s (2.58min in total, 7.10min remains)
2022-11-28 17:21:11 NUM_SUB: 83;----------------------------
2022-11-28 17:21:11 Epoch [09000/30000] Loss:0.001628 Loss_1:0.001566 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000526 Time:19.858349s (2.91min in total, 6.80min remains)
2022-11-28 17:21:30 NUM_SUB: 83;----------------------------
2022-11-28 17:21:30 Epoch [10000/30000] Loss:0.001421 Loss_1:0.001364 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000500 Time:19.349017s (3.24min in total, 6.47min remains)
2022-11-28 17:21:49 NUM_SUB: 83;----------------------------
2022-11-28 17:21:49 Epoch [11000/30000] Loss:0.001303 Loss_1:0.001254 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000476 Time:19.427746s (3.56min in total, 6.15min remains)
2022-11-28 17:22:09 NUM_SUB: 83;----------------------------
2022-11-28 17:22:09 Epoch [12000/30000] Loss:0.001118 Loss_1:0.001088 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000455 Time:19.036207s (3.88min in total, 5.82min remains)
2022-11-28 17:22:28 NUM_SUB: 83;----------------------------
2022-11-28 17:22:28 Epoch [13000/30000] Loss:0.000869 Loss_1:0.000848 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000435 Time:19.478572s (4.20min in total, 5.49min remains)
2022-11-28 17:22:47 NUM_SUB: 83;----------------------------
2022-11-28 17:22:47 Epoch [14000/30000] Loss:0.000601 Loss_1:0.000581 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:19.412254s (4.53min in total, 5.17min remains)
2022-11-28 17:23:07 NUM_SUB: 83;----------------------------
2022-11-28 17:23:07 Epoch [15000/30000] Loss:0.000446 Loss_1:0.000414 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000400 Time:19.301827s (4.85min in total, 4.85min remains)
2022-11-28 17:23:26 NUM_SUB: 83;----------------------------
2022-11-28 17:23:26 Epoch [16000/30000] Loss:0.000317 Loss_1:0.000297 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:19.449331s (5.17min in total, 4.52min remains)
2022-11-28 17:23:46 NUM_SUB: 83;----------------------------
2022-11-28 17:23:46 Epoch [17000/30000] Loss:0.000301 Loss_1:0.000285 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000370 Time:19.424534s (5.49min in total, 4.20min remains)
2022-11-28 17:24:05 NUM_SUB: 83;----------------------------
2022-11-28 17:24:05 Epoch [18000/30000] Loss:0.000292 Loss_1:0.000279 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:19.320182s (5.82min in total, 3.88min remains)
2022-11-28 17:24:24 NUM_SUB: 83;----------------------------
2022-11-28 17:24:24 Epoch [19000/30000] Loss:0.000284 Loss_1:0.000273 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000345 Time:19.380229s (6.14min in total, 3.55min remains)
2022-11-28 17:24:44 NUM_SUB: 83;----------------------------
2022-11-28 17:24:44 Epoch [20000/30000] Loss:0.000277 Loss_1:0.000268 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:19.312174s (6.46min in total, 3.23min remains)
2022-11-28 17:25:03 NUM_SUB: 83;----------------------------
2022-11-28 17:25:03 Epoch [21000/30000] Loss:0.000273 Loss_1:0.000264 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000323 Time:19.522196s (6.79min in total, 2.91min remains)
2022-11-28 17:25:25 NUM_SUB: 83;----------------------------
2022-11-28 17:25:25 Epoch [22000/30000] Loss:0.000270 Loss_1:0.000262 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:22.180997s (7.16min in total, 2.60min remains)
2022-11-28 17:25:49 NUM_SUB: 83;----------------------------
2022-11-28 17:25:49 Epoch [23000/30000] Loss:0.000268 Loss_1:0.000260 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000303 Time:23.474028s (7.55min in total, 2.30min remains)
2022-11-28 17:26:12 NUM_SUB: 83;----------------------------
2022-11-28 17:26:12 Epoch [24000/30000] Loss:0.000285 Loss_1:0.000278 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:22.817356s (7.93min in total, 1.98min remains)
2022-11-28 17:26:34 NUM_SUB: 83;----------------------------
2022-11-28 17:26:34 Epoch [25000/30000] Loss:0.000265 Loss_1:0.000259 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000286 Time:22.508866s (8.30min in total, 1.66min remains)
2022-11-28 17:26:58 NUM_SUB: 83;----------------------------
2022-11-28 17:26:58 Epoch [26000/30000] Loss:0.000264 Loss_1:0.000258 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:23.765350s (8.70min in total, 1.34min remains)
2022-11-28 17:27:21 NUM_SUB: 83;----------------------------
2022-11-28 17:27:21 Epoch [27000/30000] Loss:0.000274 Loss_1:0.000268 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000270 Time:22.714423s (9.08min in total, 1.01min remains)
2022-11-28 17:27:43 NUM_SUB: 83;----------------------------
2022-11-28 17:27:43 Epoch [28000/30000] Loss:0.000292 Loss_1:0.000286 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:22.867953s (9.46min in total, 0.68min remains)
2022-11-28 17:28:06 NUM_SUB: 83;----------------------------
2022-11-28 17:28:06 Epoch [29000/30000] Loss:0.000261 Loss_1:0.000257 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000256 Time:22.739620s (9.84min in total, 0.34min remains)
2022-11-28 17:28:29 NUM_SUB: 83;----------------------------
2022-11-28 17:28:29 Epoch [30000/30000] Loss:0.000261 Loss_1:0.000256 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:22.605974s (10.22min in total, 0.00min remains)
2022-11-28 17:28:29 Testing & drawing...
2022-11-28 17:28:29 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:28:31 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=83/
2022-11-28 17:28:31 [Loss]
2022-11-28 17:28:31 NUM_SUB: 83; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:28:31 NUM_SUB: 83; Personalized parameter estimation: Parameter containing:
tensor([1.7915e-01, 5.4487e-01, 1.0083e-02, 6.8815e-01, 3.0742e-01, 1.4008e-01,
        9.8943e-01, 8.9644e-01, 4.5563e-01, 1.3932e-02, 1.3055e-01, 1.0662e-01,
        5.9333e-01, 1.6886e-01, 1.7897e-02, 9.7111e-01, 6.9767e-01, 8.0001e-01,
        1.2415e-02, 1.4285e+00, 6.8161e-01, 1.9685e-03, 2.5347e+00, 8.7416e-01,
        2.0843e-02, 2.8703e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 17:28:31 NUM_SUB: 83------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 17:28:31 Testing & drawing...
2022-11-28 17:28:31 Test: save figure in ./figure/20391127_200_1126_id=100_2022-11-27-19-40-13/
2022-11-28 17:28:33 Test: save pred in ./saves/20391127_200_1126_id=100_2022-11-27-19-40-13_sub=83/
2022-11-28 17:28:33 [Loss]
2022-11-28 17:28:33 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 17:28:33 General parameter estimation: Parameter containing:
tensor([1.7915e-01, 5.4487e-01, 1.0083e-02, 6.8815e-01, 3.0742e-01, 1.4008e-01,
        9.8943e-01, 8.9644e-01, 4.5563e-01, 1.3932e-02, 1.3055e-01, 1.0662e-01,
        5.9333e-01, 1.6886e-01, 1.7897e-02, 9.7111e-01, 6.9767e-01, 8.0001e-01,
        1.2415e-02, 1.4285e+00, 6.8161e-01, 1.9685e-03, 2.5347e+00, 8.7416e-01,
        2.0843e-02, 2.8703e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 17:28:33 A: prod, degr, TonA, NonA
2022-11-28 17:28:33 [0.3797719  0.49966165 0.00542786 0.11513861]
2022-11-28 17:28:33 T: prod, degr, AonT, NonT
2022-11-28 17:28:33 [0.12800515 0.51605374 0.2921519  0.06378923]
2022-11-28 17:28:33 N: AonN, TonN, ATonN
2022-11-28 17:28:33 [0.29777393 0.45902848 0.24319758]
2022-11-28 17:28:33 using cpu
2022-11-28 17:28:33 epoch = 30000
2022-11-28 17:28:33 epoch_step = 1000
2022-11-28 17:28:33 model_name = SimpleNetworkAD
2022-11-28 17:28:33 now_string = 2022-11-27-19-40-13
2022-11-28 17:28:33 model_save_path_last = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_last.pt
2022-11-28 17:28:33 model_save_path_best = ./train/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_best.pt
2022-11-28 17:28:33 loss_save_path = ./loss/20391127_200_1126_30000_1000_0.001_2022-11-27-19-40-13_loss_30000.npy
2022-11-28 17:28:33 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1126_1.txt', 'mode': 'origin', 'epoch_step': 1000, 'name': '20391127_200_1126', 'python': 'ModelBYCC.py', 'id': '1', 'lr': 0.001, 'main_path': '.', 'save_step': 30000, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-27-19-40-13'}
2022-11-28 17:28:33 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 17:28:33 --------------------------------------------------training start--------------------------------------------------
2022-11-28 17:28:57 NUM_SUB: 84;----------------------------
2022-11-28 17:28:57 Epoch [01000/30000] Loss:0.083260 Loss_1:0.077732 Loss_2:0.001718 Loss_3:0.000000 Lr:0.000909 Time:23.410750s (0.39min in total, 11.32min remains)
2022-11-28 17:29:20 NUM_SUB: 84;----------------------------
2022-11-28 17:29:20 Epoch [02000/30000] Loss:0.072299 Loss_1:0.071356 Loss_2:0.000511 Loss_3:0.000000 Lr:0.000833 Time:23.341402s (0.78min in total, 10.91min remains)
2022-11-28 17:29:48 NUM_SUB: 84;----------------------------
2022-11-28 17:29:48 Epoch [03000/30000] Loss:0.063466 Loss_1:0.062894 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000769 Time:28.420304s (1.25min in total, 11.28min remains)
