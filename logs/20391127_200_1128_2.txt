2022-11-28 18:17:05 log_path: logs/20391127_200_1128_2.txt
2022-11-28 18:17:05 cuda is available: False
2022-11-28 18:17:05 
--------------------------------------------------
 NEW RUN 
--------------------------------------------------
2022-11-28 18:17:05 using cpu
2022-11-28 18:17:05 epoch = 30000
2022-11-28 18:17:05 epoch_step = 2000
2022-11-28 18:17:05 model_name = SimpleNetworkAD
2022-11-28 18:17:05 now_string = 2022-11-28-18-17-05
2022-11-28 18:17:05 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 18:17:05 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 18:17:05 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 18:17:05 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 18:17:05 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 18:17:05 --------------------------------------------------training start--------------------------------------------------
2022-11-28 18:17:43 NUM_SUB: 83;----------------------------
2022-11-28 18:17:43 Epoch [02000/30000] Loss:0.034067 Loss_1:0.033208 Loss_2:0.000442 Loss_3:0.000000 Lr:0.000833 Time:38.108992s (0.64min in total, 8.89min remains)
2022-11-28 18:18:21 NUM_SUB: 83;----------------------------
2022-11-28 18:18:21 Epoch [04000/30000] Loss:0.027052 Loss_1:0.026857 Loss_2:0.000071 Loss_3:0.000000 Lr:0.000714 Time:38.064238s (1.27min in total, 8.25min remains)
2022-11-28 18:19:00 NUM_SUB: 83;----------------------------
2022-11-28 18:19:00 Epoch [06000/30000] Loss:0.016058 Loss_1:0.015917 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000625 Time:38.428565s (1.91min in total, 7.64min remains)
2022-11-28 18:19:38 NUM_SUB: 83;----------------------------
2022-11-28 18:19:38 Epoch [08000/30000] Loss:0.003377 Loss_1:0.003300 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000556 Time:38.034038s (2.54min in total, 7.00min remains)
2022-11-28 18:20:17 NUM_SUB: 83;----------------------------
2022-11-28 18:20:17 Epoch [10000/30000] Loss:0.001421 Loss_1:0.001364 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000500 Time:38.837526s (3.19min in total, 6.38min remains)
2022-11-28 18:20:55 NUM_SUB: 83;----------------------------
2022-11-28 18:20:55 Epoch [12000/30000] Loss:0.001118 Loss_1:0.001088 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000455 Time:38.062745s (3.83min in total, 5.74min remains)
2022-11-28 18:21:33 NUM_SUB: 83;----------------------------
2022-11-28 18:21:33 Epoch [14000/30000] Loss:0.000601 Loss_1:0.000581 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:38.061090s (4.46min in total, 5.10min remains)
2022-11-28 18:22:11 NUM_SUB: 83;----------------------------
2022-11-28 18:22:11 Epoch [16000/30000] Loss:0.000317 Loss_1:0.000297 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:38.105330s (5.10min in total, 4.46min remains)
2022-11-28 18:22:49 NUM_SUB: 83;----------------------------
2022-11-28 18:22:49 Epoch [18000/30000] Loss:0.000292 Loss_1:0.000279 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:38.264657s (5.73min in total, 3.82min remains)
2022-11-28 18:23:28 NUM_SUB: 83;----------------------------
2022-11-28 18:23:28 Epoch [20000/30000] Loss:0.000277 Loss_1:0.000268 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:38.246538s (6.37min in total, 3.19min remains)
2022-11-28 18:24:06 NUM_SUB: 83;----------------------------
2022-11-28 18:24:06 Epoch [22000/30000] Loss:0.000270 Loss_1:0.000262 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:38.256690s (7.01min in total, 2.55min remains)
2022-11-28 18:24:44 NUM_SUB: 83;----------------------------
2022-11-28 18:24:44 Epoch [24000/30000] Loss:0.000285 Loss_1:0.000278 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:38.432418s (7.65min in total, 1.91min remains)
2022-11-28 18:25:23 NUM_SUB: 83;----------------------------
2022-11-28 18:25:23 Epoch [26000/30000] Loss:0.000264 Loss_1:0.000258 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:38.850818s (8.30min in total, 1.28min remains)
2022-11-28 18:26:02 NUM_SUB: 83;----------------------------
2022-11-28 18:26:02 Epoch [28000/30000] Loss:0.000292 Loss_1:0.000286 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:38.759725s (8.94min in total, 0.64min remains)
2022-11-28 18:26:40 Testing & drawing...
2022-11-28 18:26:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:26:42 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=83/
2022-11-28 18:26:42 [Loss]
2022-11-28 18:26:42 NUM_SUB: 83; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:26:42 NUM_SUB: 83; Personalized parameter estimation: Parameter containing:
tensor([1.7915e-01, 5.4488e-01, 1.0083e-02, 6.8814e-01, 3.0742e-01, 1.4009e-01,
        9.8943e-01, 8.9644e-01, 4.5563e-01, 1.3932e-02, 1.3055e-01, 1.0662e-01,
        5.9333e-01, 1.6886e-01, 1.7897e-02, 9.7109e-01, 6.9767e-01, 8.0001e-01,
        1.2415e-02, 1.4288e+00, 6.8161e-01, 1.9752e-03, 2.5347e+00, 8.7416e-01,
        2.0843e-02, 2.8702e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 18:26:42 NUM_SUB: 83;----------------------------
2022-11-28 18:26:42 Epoch [30000/30000] Loss:0.000261 Loss_1:0.000256 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:40.112398s (9.61min in total, 0.00min remains)
2022-11-28 18:26:42 NUM_SUB: 83------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 18:26:42 Testing & drawing...
2022-11-28 18:26:42 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:26:44 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=83/
2022-11-28 18:26:44 [Loss]
2022-11-28 18:26:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:26:44 General parameter estimation: Parameter containing:
tensor([1.7915e-01, 5.4487e-01, 1.0083e-02, 6.8815e-01, 3.0742e-01, 1.4008e-01,
        9.8943e-01, 8.9644e-01, 4.5563e-01, 1.3932e-02, 1.3055e-01, 1.0662e-01,
        5.9333e-01, 1.6886e-01, 1.7897e-02, 9.7111e-01, 6.9767e-01, 8.0001e-01,
        1.2415e-02, 1.4285e+00, 6.8161e-01, 1.9685e-03, 2.5347e+00, 8.7416e-01,
        2.0843e-02, 2.8703e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 18:26:44 A: prod, degr, TonA, NonA
2022-11-28 18:26:44 [0.3797719  0.49966165 0.00542786 0.11513861]
2022-11-28 18:26:44 T: prod, degr, AonT, NonT
2022-11-28 18:26:44 [0.12800515 0.51605374 0.2921519  0.06378923]
2022-11-28 18:26:44 N: AonN, TonN, ATonN
2022-11-28 18:26:44 [0.29777393 0.45902848 0.24319758]
2022-11-28 18:26:44 using cpu
2022-11-28 18:26:44 epoch = 30000
2022-11-28 18:26:44 epoch_step = 2000
2022-11-28 18:26:44 model_name = SimpleNetworkAD
2022-11-28 18:26:44 now_string = 2022-11-28-18-17-05
2022-11-28 18:26:44 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 18:26:44 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 18:26:44 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 18:26:44 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 18:26:44 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 18:26:44 --------------------------------------------------training start--------------------------------------------------
2022-11-28 18:27:22 NUM_SUB: 84;----------------------------
2022-11-28 18:27:22 Epoch [02000/30000] Loss:0.072299 Loss_1:0.071356 Loss_2:0.000511 Loss_3:0.000000 Lr:0.000833 Time:38.167540s (0.64min in total, 8.91min remains)
2022-11-28 18:28:00 NUM_SUB: 84;----------------------------
2022-11-28 18:28:00 Epoch [04000/30000] Loss:0.052217 Loss_1:0.051801 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000714 Time:38.054064s (1.27min in total, 8.26min remains)
2022-11-28 18:28:38 NUM_SUB: 84;----------------------------
2022-11-28 18:28:38 Epoch [06000/30000] Loss:0.018426 Loss_1:0.018197 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000625 Time:38.013087s (1.90min in total, 7.62min remains)
2022-11-28 18:29:27 NUM_SUB: 84;----------------------------
2022-11-28 18:29:27 Epoch [08000/30000] Loss:0.001882 Loss_1:0.001807 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000556 Time:48.762768s (2.72min in total, 7.47min remains)
2022-11-28 18:30:05 NUM_SUB: 84;----------------------------
2022-11-28 18:30:05 Epoch [10000/30000] Loss:0.001324 Loss_1:0.001271 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000500 Time:38.565320s (3.36min in total, 6.72min remains)
2022-11-28 18:30:44 NUM_SUB: 84;----------------------------
2022-11-28 18:30:44 Epoch [12000/30000] Loss:0.001115 Loss_1:0.001078 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:39.080255s (4.01min in total, 6.02min remains)
2022-11-28 18:31:23 NUM_SUB: 84;----------------------------
2022-11-28 18:31:23 Epoch [14000/30000] Loss:0.000910 Loss_1:0.000889 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:38.705590s (4.66min in total, 5.32min remains)
2022-11-28 18:32:02 NUM_SUB: 84;----------------------------
2022-11-28 18:32:02 Epoch [16000/30000] Loss:0.000745 Loss_1:0.000729 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.537472s (5.30min in total, 4.64min remains)
2022-11-28 18:32:40 NUM_SUB: 84;----------------------------
2022-11-28 18:32:40 Epoch [18000/30000] Loss:0.000733 Loss_1:0.000723 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:38.042461s (5.93min in total, 3.95min remains)
2022-11-28 18:33:18 NUM_SUB: 84;----------------------------
2022-11-28 18:33:18 Epoch [20000/30000] Loss:0.000725 Loss_1:0.000718 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:38.007942s (6.57min in total, 3.28min remains)
2022-11-28 18:33:56 NUM_SUB: 84;----------------------------
2022-11-28 18:33:56 Epoch [22000/30000] Loss:0.000726 Loss_1:0.000720 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.014051s (7.20min in total, 2.62min remains)
2022-11-28 18:34:34 NUM_SUB: 84;----------------------------
2022-11-28 18:34:34 Epoch [24000/30000] Loss:0.000722 Loss_1:0.000717 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.338581s (7.84min in total, 1.96min remains)
2022-11-28 18:35:12 NUM_SUB: 84;----------------------------
2022-11-28 18:35:12 Epoch [26000/30000] Loss:0.000721 Loss_1:0.000717 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.107703s (8.47min in total, 1.30min remains)
2022-11-28 18:35:50 NUM_SUB: 84;----------------------------
2022-11-28 18:35:50 Epoch [28000/30000] Loss:0.000723 Loss_1:0.000718 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.069862s (9.11min in total, 0.65min remains)
2022-11-28 18:36:29 Testing & drawing...
2022-11-28 18:36:29 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:36:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=84/
2022-11-28 18:36:30 [Loss]
2022-11-28 18:36:30 NUM_SUB: 84; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:36:30 NUM_SUB: 84; Personalized parameter estimation: Parameter containing:
tensor([0.1957, 0.6487, 0.0126, 0.3355, 0.3074, 0.3357, 0.7958, 0.8964, 0.4556,
        0.0121, 0.2837, 0.2036, 0.4282, 0.1689, 0.0176, 0.8379, 0.6977, 0.8000,
        0.0117, 4.2349, 0.6816, 0.0225, 3.2354, 0.8742, 0.0168, 4.3028, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 18:36:30 NUM_SUB: 84;----------------------------
2022-11-28 18:36:30 Epoch [30000/30000] Loss:0.000719 Loss_1:0.000716 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:40.130882s (9.78min in total, 0.00min remains)
2022-11-28 18:36:30 NUM_SUB: 84------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 18:36:30 Testing & drawing...
2022-11-28 18:36:30 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:36:32 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=84/
2022-11-28 18:36:32 [Loss]
2022-11-28 18:36:32 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:36:32 General parameter estimation: Parameter containing:
tensor([0.1957, 0.6487, 0.0126, 0.3355, 0.3074, 0.3357, 0.7958, 0.8964, 0.4556,
        0.0121, 0.2837, 0.2036, 0.4282, 0.1689, 0.0176, 0.8379, 0.6977, 0.8000,
        0.0117, 4.2350, 0.6816, 0.0225, 3.2356, 0.8742, 0.0168, 4.3029, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 18:36:32 A: prod, degr, TonA, NonA
2022-11-28 18:36:32 [0.28621298 0.49970797 0.0098727  0.20420632]
2022-11-28 18:36:32 T: prod, degr, AonT, NonT
2022-11-28 18:36:32 [0.04776895 0.5906045  0.33444723 0.02717928]
2022-11-28 18:36:32 N: AonN, TonN, ATonN
2022-11-28 18:36:32 [0.00941243 0.971395   0.01919255]
2022-11-28 18:36:32 using cpu
2022-11-28 18:36:32 epoch = 30000
2022-11-28 18:36:32 epoch_step = 2000
2022-11-28 18:36:32 model_name = SimpleNetworkAD
2022-11-28 18:36:32 now_string = 2022-11-28-18-17-05
2022-11-28 18:36:32 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 18:36:32 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 18:36:32 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 18:36:32 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 18:36:32 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 18:36:32 --------------------------------------------------training start--------------------------------------------------
2022-11-28 18:37:10 NUM_SUB: 85;----------------------------
2022-11-28 18:37:10 Epoch [02000/30000] Loss:0.232053 Loss_1:0.230407 Loss_2:0.000556 Loss_3:0.000000 Lr:0.000833 Time:38.032193s (0.63min in total, 8.87min remains)
2022-11-28 18:37:48 NUM_SUB: 85;----------------------------
2022-11-28 18:37:48 Epoch [04000/30000] Loss:0.172407 Loss_1:0.171016 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000714 Time:38.091120s (1.27min in total, 8.25min remains)
2022-11-28 18:38:27 NUM_SUB: 85;----------------------------
2022-11-28 18:38:27 Epoch [06000/30000] Loss:0.066769 Loss_1:0.065618 Loss_2:0.000514 Loss_3:0.000000 Lr:0.000625 Time:38.841660s (1.92min in total, 7.66min remains)
2022-11-28 18:39:06 NUM_SUB: 85;----------------------------
2022-11-28 18:39:06 Epoch [08000/30000] Loss:0.009781 Loss_1:0.009460 Loss_2:0.000230 Loss_3:0.000000 Lr:0.000556 Time:39.048609s (2.57min in total, 7.06min remains)
2022-11-28 18:39:45 NUM_SUB: 85;----------------------------
2022-11-28 18:39:45 Epoch [10000/30000] Loss:0.003151 Loss_1:0.002974 Loss_2:0.000177 Loss_3:0.000000 Lr:0.000500 Time:38.706217s (3.21min in total, 6.42min remains)
2022-11-28 18:40:23 NUM_SUB: 85;----------------------------
2022-11-28 18:40:23 Epoch [12000/30000] Loss:0.002228 Loss_1:0.002152 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000455 Time:38.185730s (3.85min in total, 5.77min remains)
2022-11-28 18:41:02 NUM_SUB: 85;----------------------------
2022-11-28 18:41:02 Epoch [14000/30000] Loss:0.001836 Loss_1:0.001791 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000417 Time:38.545808s (4.49min in total, 5.13min remains)
2022-11-28 18:41:40 NUM_SUB: 85;----------------------------
2022-11-28 18:41:40 Epoch [16000/30000] Loss:0.001780 Loss_1:0.001758 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000385 Time:38.000311s (5.12min in total, 4.48min remains)
2022-11-28 18:42:19 NUM_SUB: 85;----------------------------
2022-11-28 18:42:19 Epoch [18000/30000] Loss:0.001768 Loss_1:0.001757 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:39.254112s (5.78min in total, 3.85min remains)
2022-11-28 18:42:57 NUM_SUB: 85;----------------------------
2022-11-28 18:42:57 Epoch [20000/30000] Loss:0.001763 Loss_1:0.001756 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.601085s (6.42min in total, 3.21min remains)
2022-11-28 18:43:36 NUM_SUB: 85;----------------------------
2022-11-28 18:43:36 Epoch [22000/30000] Loss:0.001760 Loss_1:0.001756 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:39.008729s (7.07min in total, 2.57min remains)
2022-11-28 18:44:15 NUM_SUB: 85;----------------------------
2022-11-28 18:44:15 Epoch [24000/30000] Loss:0.001758 Loss_1:0.001756 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.446502s (7.71min in total, 1.93min remains)
2022-11-28 18:44:53 NUM_SUB: 85;----------------------------
2022-11-28 18:44:53 Epoch [26000/30000] Loss:0.001756 Loss_1:0.001755 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.381061s (8.35min in total, 1.29min remains)
2022-11-28 18:45:31 NUM_SUB: 85;----------------------------
2022-11-28 18:45:31 Epoch [28000/30000] Loss:0.001755 Loss_1:0.001754 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.003198s (8.99min in total, 0.64min remains)
2022-11-28 18:46:09 Testing & drawing...
2022-11-28 18:46:09 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:46:11 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=85/
2022-11-28 18:46:11 [Loss]
2022-11-28 18:46:11 NUM_SUB: 85; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:46:11 NUM_SUB: 85; Personalized parameter estimation: Parameter containing:
tensor([4.2264e-02, 1.1090e-01, 1.0510e-02, 7.9673e-05, 3.0742e-01, 8.8948e-03,
        3.5904e-01, 8.9644e-01, 4.5563e-01, 1.4166e-02, 3.1342e-02, 1.5301e-02,
        4.3086e-01, 1.6886e-01, 1.7524e-02, 1.6678e+00, 6.9767e-01, 8.0001e-01,
        1.1924e-02, 3.4593e+00, 6.8161e-01, 2.2740e-02, 3.7652e+00, 8.7416e-01,
        1.9320e-02, 4.3203e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 18:46:11 NUM_SUB: 85;----------------------------
2022-11-28 18:46:11 Epoch [30000/30000] Loss:0.001755 Loss_1:0.001753 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.691427s (9.65min in total, 0.00min remains)
2022-11-28 18:46:11 NUM_SUB: 85------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 18:46:11 Testing & drawing...
2022-11-28 18:46:11 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:46:13 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=85/
2022-11-28 18:46:13 [Loss]
2022-11-28 18:46:13 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:46:13 General parameter estimation: Parameter containing:
tensor([4.2263e-02, 1.1090e-01, 1.0509e-02, 7.9439e-05, 3.0742e-01, 8.8948e-03,
        3.5894e-01, 8.9644e-01, 4.5563e-01, 1.4166e-02, 3.1342e-02, 1.5301e-02,
        4.3081e-01, 1.6886e-01, 1.7523e-02, 1.6679e+00, 6.9767e-01, 8.0001e-01,
        1.1924e-02, 3.4591e+00, 6.8161e-01, 2.2740e-02, 3.7650e+00, 8.7416e-01,
        1.9321e-02, 4.3201e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 18:46:13 A: prod, degr, TonA, NonA
2022-11-28 18:46:13 [0.34897682 0.49725673 0.08677895 0.06698754]
2022-11-28 18:46:13 T: prod, degr, AonT, NonT
2022-11-28 18:46:13 [0.28393155 0.34089607 0.2561136  0.11905878]
2022-11-28 18:46:13 N: AonN, TonN, ATonN
2022-11-28 18:46:13 [0.01217314 0.9352387  0.05258818]
2022-11-28 18:46:13 using cpu
2022-11-28 18:46:13 epoch = 30000
2022-11-28 18:46:13 epoch_step = 2000
2022-11-28 18:46:13 model_name = SimpleNetworkAD
2022-11-28 18:46:13 now_string = 2022-11-28-18-17-05
2022-11-28 18:46:13 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 18:46:13 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 18:46:13 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 18:46:13 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 18:46:13 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 18:46:13 --------------------------------------------------training start--------------------------------------------------
2022-11-28 18:46:51 NUM_SUB: 86;----------------------------
2022-11-28 18:46:51 Epoch [02000/30000] Loss:0.074823 Loss_1:0.074123 Loss_2:0.000306 Loss_3:0.000000 Lr:0.000833 Time:38.660316s (0.64min in total, 9.02min remains)
2022-11-28 18:47:30 NUM_SUB: 86;----------------------------
2022-11-28 18:47:30 Epoch [04000/30000] Loss:0.058955 Loss_1:0.058664 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000714 Time:38.117028s (1.28min in total, 8.32min remains)
2022-11-28 18:48:08 NUM_SUB: 86;----------------------------
2022-11-28 18:48:08 Epoch [06000/30000] Loss:0.028516 Loss_1:0.028330 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000625 Time:38.135623s (1.92min in total, 7.66min remains)
2022-11-28 18:48:46 NUM_SUB: 86;----------------------------
2022-11-28 18:48:46 Epoch [08000/30000] Loss:0.003799 Loss_1:0.003746 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000556 Time:38.131469s (2.55min in total, 7.01min remains)
2022-11-28 18:49:24 NUM_SUB: 86;----------------------------
2022-11-28 18:49:24 Epoch [10000/30000] Loss:0.002420 Loss_1:0.002363 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000500 Time:37.981036s (3.18min in total, 6.37min remains)
2022-11-28 18:50:02 NUM_SUB: 86;----------------------------
2022-11-28 18:50:02 Epoch [12000/30000] Loss:0.001368 Loss_1:0.001350 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000455 Time:38.386939s (3.82min in total, 5.74min remains)
2022-11-28 18:50:41 NUM_SUB: 86;----------------------------
2022-11-28 18:50:41 Epoch [14000/30000] Loss:0.000190 Loss_1:0.000164 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.661980s (4.47min in total, 5.11min remains)
2022-11-28 18:51:20 NUM_SUB: 86;----------------------------
2022-11-28 18:51:20 Epoch [16000/30000] Loss:0.000068 Loss_1:0.000059 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:39.345320s (5.12min in total, 4.48min remains)
2022-11-28 18:51:59 NUM_SUB: 86;----------------------------
2022-11-28 18:51:59 Epoch [18000/30000] Loss:0.000036 Loss_1:0.000030 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.816397s (5.77min in total, 3.85min remains)
2022-11-28 18:52:38 NUM_SUB: 86;----------------------------
2022-11-28 18:52:38 Epoch [20000/30000] Loss:0.000235 Loss_1:0.000090 Loss_2:0.000144 Loss_3:0.000000 Lr:0.000333 Time:38.836424s (6.42min in total, 3.21min remains)
2022-11-28 18:53:17 NUM_SUB: 86;----------------------------
2022-11-28 18:53:17 Epoch [22000/30000] Loss:0.000013 Loss_1:0.000011 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.845579s (7.07min in total, 2.57min remains)
2022-11-28 18:53:55 NUM_SUB: 86;----------------------------
2022-11-28 18:53:55 Epoch [24000/30000] Loss:0.000012 Loss_1:0.000010 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.815484s (7.71min in total, 1.93min remains)
2022-11-28 18:54:34 NUM_SUB: 86;----------------------------
2022-11-28 18:54:34 Epoch [26000/30000] Loss:0.000012 Loss_1:0.000010 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.855725s (8.36min in total, 1.29min remains)
2022-11-28 18:55:13 NUM_SUB: 86;----------------------------
2022-11-28 18:55:13 Epoch [28000/30000] Loss:0.000011 Loss_1:0.000010 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.025441s (9.01min in total, 0.64min remains)
2022-11-28 18:55:52 Testing & drawing...
2022-11-28 18:55:52 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:55:54 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=86/
2022-11-28 18:55:54 [Loss]
2022-11-28 18:55:54 NUM_SUB: 86; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:55:54 NUM_SUB: 86; Personalized parameter estimation: Parameter containing:
tensor([0.0122, 0.6921, 0.0113, 0.3396, 0.3074, 0.3247, 0.9799, 0.8964, 0.4556,
        0.0145, 0.1120, 0.1113, 0.6566, 0.1689, 0.0177, 1.6091, 0.6977, 0.8000,
        0.0123, 2.7412, 0.6816, 0.0204, 3.2417, 0.8742, 0.0209, 3.8865, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 18:55:54 NUM_SUB: 86;----------------------------
2022-11-28 18:55:54 Epoch [30000/30000] Loss:0.000011 Loss_1:0.000010 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.695619s (9.69min in total, 0.00min remains)
2022-11-28 18:55:54 NUM_SUB: 86------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 18:55:54 Testing & drawing...
2022-11-28 18:55:54 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 18:55:56 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=86/
2022-11-28 18:55:56 [Loss]
2022-11-28 18:55:56 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 18:55:56 General parameter estimation: Parameter containing:
tensor([0.0122, 0.6920, 0.0113, 0.3396, 0.3074, 0.3247, 0.9800, 0.8964, 0.4556,
        0.0145, 0.1120, 0.1113, 0.6565, 0.1689, 0.0177, 1.6092, 0.6977, 0.8000,
        0.0123, 2.7413, 0.6816, 0.0204, 3.2418, 0.8742, 0.0209, 3.8865, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 18:55:56 A: prod, degr, TonA, NonA
2022-11-28 18:55:56 [0.04120683 0.4992536  0.02373872 0.43580085]
2022-11-28 18:55:56 T: prod, degr, AonT, NonT
2022-11-28 18:55:56 [0.18957092 0.31001708 0.45532364 0.04508834]
2022-11-28 18:55:56 N: AonN, TonN, ATonN
2022-11-28 18:55:56 [0.00418481 0.9743805  0.0214347 ]
2022-11-28 18:55:56 using cpu
2022-11-28 18:55:56 epoch = 30000
2022-11-28 18:55:56 epoch_step = 2000
2022-11-28 18:55:56 model_name = SimpleNetworkAD
2022-11-28 18:55:56 now_string = 2022-11-28-18-17-05
2022-11-28 18:55:56 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 18:55:56 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 18:55:56 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 18:55:56 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 18:55:56 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 18:55:56 --------------------------------------------------training start--------------------------------------------------
2022-11-28 18:56:35 NUM_SUB: 87;----------------------------
2022-11-28 18:56:35 Epoch [02000/30000] Loss:0.071416 Loss_1:0.069686 Loss_2:0.001345 Loss_3:0.000000 Lr:0.000833 Time:39.015050s (0.65min in total, 9.10min remains)
2022-11-28 18:57:14 NUM_SUB: 87;----------------------------
2022-11-28 18:57:14 Epoch [04000/30000] Loss:0.042966 Loss_1:0.042414 Loss_2:0.000298 Loss_3:0.000000 Lr:0.000714 Time:39.015013s (1.30min in total, 8.45min remains)
2022-11-28 18:57:53 NUM_SUB: 87;----------------------------
2022-11-28 18:57:53 Epoch [06000/30000] Loss:0.009308 Loss_1:0.009129 Loss_2:0.000095 Loss_3:0.000000 Lr:0.000625 Time:39.001710s (1.95min in total, 7.80min remains)
2022-11-28 18:58:32 NUM_SUB: 87;----------------------------
2022-11-28 18:58:32 Epoch [08000/30000] Loss:0.002722 Loss_1:0.002613 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000556 Time:39.057347s (2.60min in total, 7.15min remains)
2022-11-28 18:59:11 NUM_SUB: 87;----------------------------
2022-11-28 18:59:11 Epoch [10000/30000] Loss:0.002069 Loss_1:0.001975 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000500 Time:38.974207s (3.25min in total, 6.50min remains)
2022-11-28 18:59:50 NUM_SUB: 87;----------------------------
2022-11-28 18:59:50 Epoch [12000/30000] Loss:0.000958 Loss_1:0.000917 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000455 Time:38.988924s (3.90min in total, 5.85min remains)
2022-11-28 19:00:29 NUM_SUB: 87;----------------------------
2022-11-28 19:00:29 Epoch [14000/30000] Loss:0.000386 Loss_1:0.000354 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000417 Time:38.947432s (4.55min in total, 5.20min remains)
2022-11-28 19:01:07 NUM_SUB: 87;----------------------------
2022-11-28 19:01:07 Epoch [16000/30000] Loss:0.000307 Loss_1:0.000282 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000385 Time:38.512684s (5.19min in total, 4.54min remains)
2022-11-28 19:01:47 NUM_SUB: 87;----------------------------
2022-11-28 19:01:47 Epoch [18000/30000] Loss:0.000286 Loss_1:0.000266 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000357 Time:39.062646s (5.84min in total, 3.90min remains)
2022-11-28 19:02:25 NUM_SUB: 87;----------------------------
2022-11-28 19:02:25 Epoch [20000/30000] Loss:0.000278 Loss_1:0.000261 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000333 Time:38.337973s (6.48min in total, 3.24min remains)
2022-11-28 19:03:03 NUM_SUB: 87;----------------------------
2022-11-28 19:03:03 Epoch [22000/30000] Loss:0.000274 Loss_1:0.000259 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000313 Time:38.318074s (7.12min in total, 2.59min remains)
2022-11-28 19:03:41 NUM_SUB: 87;----------------------------
2022-11-28 19:03:41 Epoch [24000/30000] Loss:0.000287 Loss_1:0.000274 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000294 Time:38.323295s (7.76min in total, 1.94min remains)
2022-11-28 19:04:20 NUM_SUB: 87;----------------------------
2022-11-28 19:04:20 Epoch [26000/30000] Loss:0.000264 Loss_1:0.000256 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:38.313187s (8.40min in total, 1.29min remains)
2022-11-28 19:04:58 NUM_SUB: 87;----------------------------
2022-11-28 19:04:58 Epoch [28000/30000] Loss:0.000259 Loss_1:0.000256 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.297623s (9.04min in total, 0.65min remains)
2022-11-28 19:05:36 Testing & drawing...
2022-11-28 19:05:36 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:05:38 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=87/
2022-11-28 19:05:38 [Loss]
2022-11-28 19:05:38 NUM_SUB: 87; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:05:38 NUM_SUB: 87; Personalized parameter estimation: Parameter containing:
tensor([3.3636e-03, 1.6501e-02, 1.0910e-02, 3.5891e-01, 3.0742e-01, 2.0197e-02,
        4.2645e+00, 8.9644e-01, 4.5563e-01, 1.4837e-02, 1.6946e-01, 1.3360e-01,
        4.9910e-01, 1.6886e-01, 1.7729e-02, 1.4171e+00, 6.9767e-01, 8.0001e-01,
        1.1805e-02, 3.6254e+00, 6.8161e-01, 2.2658e-02, 2.9411e+00, 8.7416e-01,
        2.0869e-02, 3.8877e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:05:38 NUM_SUB: 87;----------------------------
2022-11-28 19:05:38 Epoch [30000/30000] Loss:0.000257 Loss_1:0.000255 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.991189s (9.70min in total, 0.00min remains)
2022-11-28 19:05:38 NUM_SUB: 87------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:05:38 Testing & drawing...
2022-11-28 19:05:38 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:05:40 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=87/
2022-11-28 19:05:40 [Loss]
2022-11-28 19:05:40 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:05:40 General parameter estimation: Parameter containing:
tensor([3.3615e-03, 1.6490e-02, 1.0910e-02, 3.5881e-01, 3.0742e-01, 2.0197e-02,
        4.2646e+00, 8.9644e-01, 4.5563e-01, 1.4837e-02, 1.6946e-01, 1.3360e-01,
        4.9909e-01, 1.6886e-01, 1.7729e-02, 1.4172e+00, 6.9767e-01, 8.0001e-01,
        1.1805e-02, 3.6254e+00, 6.8161e-01, 2.2658e-02, 2.9412e+00, 8.7416e-01,
        2.0869e-02, 3.8877e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:05:40 A: prod, degr, TonA, NonA
2022-11-28 19:05:40 [0.22906698 0.42690614 0.31471735 0.02930948]
2022-11-28 19:05:40 T: prod, degr, AonT, NonT
2022-11-28 19:05:40 [0.12602048 0.53206545 0.31738874 0.02452536]
2022-11-28 19:05:40 N: AonN, TonN, ATonN
2022-11-28 19:05:40 [0.00890145 0.9679972  0.02310141]
2022-11-28 19:05:40 using cpu
2022-11-28 19:05:40 epoch = 30000
2022-11-28 19:05:40 epoch_step = 2000
2022-11-28 19:05:40 model_name = SimpleNetworkAD
2022-11-28 19:05:40 now_string = 2022-11-28-18-17-05
2022-11-28 19:05:40 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:05:40 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:05:40 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:05:40 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:05:40 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:05:40 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:06:18 NUM_SUB: 88;----------------------------
2022-11-28 19:06:18 Epoch [02000/30000] Loss:0.127381 Loss_1:0.126474 Loss_2:0.000458 Loss_3:0.000000 Lr:0.000833 Time:38.383846s (0.64min in total, 8.96min remains)
2022-11-28 19:06:57 NUM_SUB: 88;----------------------------
2022-11-28 19:06:57 Epoch [04000/30000] Loss:0.072899 Loss_1:0.072414 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000714 Time:38.330308s (1.28min in total, 8.31min remains)
2022-11-28 19:07:35 NUM_SUB: 88;----------------------------
2022-11-28 19:07:35 Epoch [06000/30000] Loss:0.012547 Loss_1:0.012370 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000625 Time:38.376647s (1.92min in total, 7.67min remains)
2022-11-28 19:08:13 NUM_SUB: 88;----------------------------
2022-11-28 19:08:13 Epoch [08000/30000] Loss:0.006971 Loss_1:0.006896 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000556 Time:38.518290s (2.56min in total, 7.04min remains)
2022-11-28 19:08:52 NUM_SUB: 88;----------------------------
2022-11-28 19:08:52 Epoch [10000/30000] Loss:0.006451 Loss_1:0.006395 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000500 Time:39.013322s (3.21min in total, 6.42min remains)
2022-11-28 19:09:32 NUM_SUB: 88;----------------------------
2022-11-28 19:09:32 Epoch [12000/30000] Loss:0.005722 Loss_1:0.005707 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000455 Time:39.079045s (3.86min in total, 5.79min remains)
2022-11-28 19:10:11 NUM_SUB: 88;----------------------------
2022-11-28 19:10:11 Epoch [14000/30000] Loss:0.005249 Loss_1:0.005222 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000417 Time:39.086753s (4.51min in total, 5.16min remains)
2022-11-28 19:10:50 NUM_SUB: 88;----------------------------
2022-11-28 19:10:50 Epoch [16000/30000] Loss:0.005144 Loss_1:0.005134 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:39.086525s (5.16min in total, 4.52min remains)
2022-11-28 19:11:29 NUM_SUB: 88;----------------------------
2022-11-28 19:11:29 Epoch [18000/30000] Loss:0.005132 Loss_1:0.005127 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000357 Time:39.615229s (5.82min in total, 3.88min remains)
2022-11-28 19:12:08 NUM_SUB: 88;----------------------------
2022-11-28 19:12:08 Epoch [20000/30000] Loss:0.005130 Loss_1:0.005123 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:39.124214s (6.48min in total, 3.24min remains)
2022-11-28 19:12:48 NUM_SUB: 88;----------------------------
2022-11-28 19:12:48 Epoch [22000/30000] Loss:0.005126 Loss_1:0.005123 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:39.051029s (7.13min in total, 2.59min remains)
2022-11-28 19:13:27 NUM_SUB: 88;----------------------------
2022-11-28 19:13:27 Epoch [24000/30000] Loss:0.005126 Loss_1:0.005124 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:39.045055s (7.78min in total, 1.94min remains)
2022-11-28 19:14:06 NUM_SUB: 88;----------------------------
2022-11-28 19:14:06 Epoch [26000/30000] Loss:0.005125 Loss_1:0.005123 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:39.080132s (8.43min in total, 1.30min remains)
2022-11-28 19:14:45 NUM_SUB: 88;----------------------------
2022-11-28 19:14:45 Epoch [28000/30000] Loss:0.005125 Loss_1:0.005123 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:39.092671s (9.08min in total, 0.65min remains)
2022-11-28 19:15:24 Testing & drawing...
2022-11-28 19:15:24 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:15:25 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=88/
2022-11-28 19:15:25 [Loss]
2022-11-28 19:15:25 NUM_SUB: 88; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:15:25 NUM_SUB: 88; Personalized parameter estimation: Parameter containing:
tensor([3.8701e-01, 9.0159e-01, 1.0148e-02, 2.5538e-03, 3.0742e-01, 8.4960e-03,
        7.0803e-01, 8.9644e-01, 4.5563e-01, 9.3343e-03, 1.8111e-01, 1.1265e-01,
        3.8829e-01, 1.6886e-01, 1.6846e-02, 1.1560e+00, 6.9767e-01, 8.0001e-01,
        1.1948e-02, 3.7261e+00, 6.8161e-01, 2.1581e-02, 2.7623e+00, 8.7416e-01,
        2.0977e-02, 3.8988e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:15:25 NUM_SUB: 88;----------------------------
2022-11-28 19:15:25 Epoch [30000/30000] Loss:0.005125 Loss_1:0.005123 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.734170s (9.76min in total, 0.00min remains)
2022-11-28 19:15:25 NUM_SUB: 88------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:15:25 Testing & drawing...
2022-11-28 19:15:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:15:27 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=88/
2022-11-28 19:15:27 [Loss]
2022-11-28 19:15:27 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:15:27 General parameter estimation: Parameter containing:
tensor([3.8701e-01, 9.0159e-01, 1.0148e-02, 2.5520e-03, 3.0742e-01, 8.4960e-03,
        7.0803e-01, 8.9644e-01, 4.5563e-01, 9.3343e-03, 1.8111e-01, 1.1263e-01,
        3.8830e-01, 1.6886e-01, 1.6846e-02, 1.1561e+00, 6.9767e-01, 8.0001e-01,
        1.1948e-02, 3.7262e+00, 6.8161e-01, 2.1581e-02, 2.7624e+00, 8.7416e-01,
        2.0976e-02, 3.8990e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:15:27 A: prod, degr, TonA, NonA
2022-11-28 19:15:27 [0.48180172 0.50002235 0.01263178 0.00554412]
2022-11-28 19:15:27 T: prod, degr, AonT, NonT
2022-11-28 19:15:27 [0.07227525 0.6247452  0.26500082 0.03797871]
2022-11-28 19:15:27 N: AonN, TonN, ATonN
2022-11-28 19:15:27 [0.01225177 0.9614726  0.02627561]
2022-11-28 19:15:27 using cpu
2022-11-28 19:15:27 epoch = 30000
2022-11-28 19:15:27 epoch_step = 2000
2022-11-28 19:15:27 model_name = SimpleNetworkAD
2022-11-28 19:15:27 now_string = 2022-11-28-18-17-05
2022-11-28 19:15:27 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:15:27 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:15:27 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:15:27 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:15:27 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:15:27 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:16:06 NUM_SUB: 89;----------------------------
2022-11-28 19:16:06 Epoch [02000/30000] Loss:0.101808 Loss_1:0.100693 Loss_2:0.000703 Loss_3:0.000000 Lr:0.000833 Time:39.046599s (0.65min in total, 9.11min remains)
2022-11-28 19:16:44 NUM_SUB: 89;----------------------------
2022-11-28 19:16:44 Epoch [04000/30000] Loss:0.083219 Loss_1:0.082671 Loss_2:0.000200 Loss_3:0.000000 Lr:0.000714 Time:38.147134s (1.29min in total, 8.36min remains)
2022-11-28 19:17:23 NUM_SUB: 89;----------------------------
2022-11-28 19:17:23 Epoch [06000/30000] Loss:0.045705 Loss_1:0.045226 Loss_2:0.000237 Loss_3:0.000000 Lr:0.000625 Time:38.111520s (1.92min in total, 7.69min remains)
2022-11-28 19:18:01 NUM_SUB: 89;----------------------------
2022-11-28 19:18:01 Epoch [08000/30000] Loss:0.007915 Loss_1:0.007736 Loss_2:0.000122 Loss_3:0.000000 Lr:0.000556 Time:38.104826s (2.56min in total, 7.03min remains)
2022-11-28 19:18:40 NUM_SUB: 89;----------------------------
2022-11-28 19:18:40 Epoch [10000/30000] Loss:0.002271 Loss_1:0.002128 Loss_2:0.000143 Loss_3:0.000000 Lr:0.000500 Time:38.937456s (3.21min in total, 6.41min remains)
2022-11-28 19:19:19 NUM_SUB: 89;----------------------------
2022-11-28 19:19:19 Epoch [12000/30000] Loss:0.000778 Loss_1:0.000717 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000455 Time:39.373978s (3.86min in total, 5.79min remains)
2022-11-28 19:19:58 NUM_SUB: 89;----------------------------
2022-11-28 19:19:58 Epoch [14000/30000] Loss:0.000461 Loss_1:0.000417 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000417 Time:38.489432s (4.50min in total, 5.15min remains)
2022-11-28 19:20:37 NUM_SUB: 89;----------------------------
2022-11-28 19:20:37 Epoch [16000/30000] Loss:0.000409 Loss_1:0.000380 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000385 Time:39.250126s (5.16min in total, 4.51min remains)
2022-11-28 19:21:16 NUM_SUB: 89;----------------------------
2022-11-28 19:21:16 Epoch [18000/30000] Loss:0.000364 Loss_1:0.000344 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000357 Time:39.171873s (5.81min in total, 3.87min remains)
2022-11-28 19:21:55 NUM_SUB: 89;----------------------------
2022-11-28 19:21:55 Epoch [20000/30000] Loss:0.000315 Loss_1:0.000299 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000333 Time:38.778726s (6.46min in total, 3.23min remains)
2022-11-28 19:22:36 NUM_SUB: 89;----------------------------
2022-11-28 19:22:36 Epoch [22000/30000] Loss:0.000311 Loss_1:0.000299 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000313 Time:40.842377s (7.14min in total, 2.60min remains)
2022-11-28 19:23:16 NUM_SUB: 89;----------------------------
2022-11-28 19:23:16 Epoch [24000/30000] Loss:0.000309 Loss_1:0.000299 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000294 Time:40.060605s (7.81min in total, 1.95min remains)
2022-11-28 19:23:55 NUM_SUB: 89;----------------------------
2022-11-28 19:23:55 Epoch [26000/30000] Loss:0.000318 Loss_1:0.000310 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000278 Time:39.472704s (8.46min in total, 1.30min remains)
2022-11-28 19:24:34 NUM_SUB: 89;----------------------------
2022-11-28 19:24:34 Epoch [28000/30000] Loss:0.000332 Loss_1:0.000325 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000263 Time:38.839676s (9.11min in total, 0.65min remains)
2022-11-28 19:25:13 Testing & drawing...
2022-11-28 19:25:13 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:25:15 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=89/
2022-11-28 19:25:15 [Loss]
2022-11-28 19:25:15 NUM_SUB: 89; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:25:15 NUM_SUB: 89; Personalized parameter estimation: Parameter containing:
tensor([1.6447e-02, 2.1298e-02, 2.1052e-03, 2.9428e+00, 3.0742e-01, 1.5211e-02,
        4.3757e+00, 8.9644e-01, 4.5563e-01, 1.4221e-02, 2.7515e-02, 1.4222e-02,
        1.0156e+00, 1.6886e-01, 1.7304e-02, 3.1437e+00, 6.9767e-01, 8.0001e-01,
        1.1514e-02, 4.5913e+00, 6.8161e-01, 1.9870e-02, 3.9794e+00, 8.7416e-01,
        2.7216e-03, 4.5945e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:25:15 NUM_SUB: 89;----------------------------
2022-11-28 19:25:15 Epoch [30000/30000] Loss:0.000304 Loss_1:0.000298 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:40.855792s (9.79min in total, 0.00min remains)
2022-11-28 19:25:15 NUM_SUB: 89------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:25:15 Testing & drawing...
2022-11-28 19:25:15 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:25:16 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=89/
2022-11-28 19:25:16 [Loss]
2022-11-28 19:25:16 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:25:16 General parameter estimation: Parameter containing:
tensor([1.6446e-02, 2.1296e-02, 2.1021e-03, 2.9428e+00, 3.0742e-01, 1.5211e-02,
        4.3759e+00, 8.9644e-01, 4.5563e-01, 1.4221e-02, 2.7519e-02, 1.4222e-02,
        1.0156e+00, 1.6886e-01, 1.7304e-02, 3.1438e+00, 6.9767e-01, 8.0001e-01,
        1.1513e-02, 4.5914e+00, 6.8161e-01, 1.9869e-02, 3.9795e+00, 8.7416e-01,
        2.7184e-03, 4.5946e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:25:16 A: prod, degr, TonA, NonA
2022-11-28 19:25:16 [0.5516689  0.42721868 0.0031575  0.01795494]
2022-11-28 19:25:16 T: prod, degr, AonT, NonT
2022-11-28 19:25:16 [0.40020257 0.45731995 0.1103993  0.0320782 ]
2022-11-28 19:25:16 N: AonN, TonN, ATonN
2022-11-28 19:25:16 [0.0120071 0.9824702 0.0055227]
2022-11-28 19:25:17 using cpu
2022-11-28 19:25:17 epoch = 30000
2022-11-28 19:25:17 epoch_step = 2000
2022-11-28 19:25:17 model_name = SimpleNetworkAD
2022-11-28 19:25:17 now_string = 2022-11-28-18-17-05
2022-11-28 19:25:17 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:25:17 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:25:17 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:25:17 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:25:17 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:25:17 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:25:55 NUM_SUB: 90;----------------------------
2022-11-28 19:25:55 Epoch [02000/30000] Loss:0.117703 Loss_1:0.116887 Loss_2:0.000377 Loss_3:0.000000 Lr:0.000833 Time:38.327179s (0.64min in total, 8.94min remains)
2022-11-28 19:26:34 NUM_SUB: 90;----------------------------
2022-11-28 19:26:34 Epoch [04000/30000] Loss:0.088055 Loss_1:0.087635 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000714 Time:38.974579s (1.29min in total, 8.37min remains)
2022-11-28 19:27:14 NUM_SUB: 90;----------------------------
2022-11-28 19:27:14 Epoch [06000/30000] Loss:0.035461 Loss_1:0.035171 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000625 Time:39.917767s (1.95min in total, 7.81min remains)
2022-11-28 19:27:53 NUM_SUB: 90;----------------------------
2022-11-28 19:27:53 Epoch [08000/30000] Loss:0.007599 Loss_1:0.007461 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000556 Time:38.721301s (2.60min in total, 7.15min remains)
2022-11-28 19:28:31 NUM_SUB: 90;----------------------------
2022-11-28 19:28:31 Epoch [10000/30000] Loss:0.001797 Loss_1:0.001692 Loss_2:0.000105 Loss_3:0.000000 Lr:0.000500 Time:38.928441s (3.25min in total, 6.50min remains)
2022-11-28 19:29:12 NUM_SUB: 90;----------------------------
2022-11-28 19:29:12 Epoch [12000/30000] Loss:0.000954 Loss_1:0.000918 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:40.881700s (3.93min in total, 5.89min remains)
2022-11-28 19:29:52 NUM_SUB: 90;----------------------------
2022-11-28 19:29:52 Epoch [14000/30000] Loss:0.000744 Loss_1:0.000722 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:39.862820s (4.59min in total, 5.25min remains)
2022-11-28 19:30:32 NUM_SUB: 90;----------------------------
2022-11-28 19:30:32 Epoch [16000/30000] Loss:0.000697 Loss_1:0.000684 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:39.716574s (5.26min in total, 4.60min remains)
2022-11-28 19:31:12 NUM_SUB: 90;----------------------------
2022-11-28 19:31:12 Epoch [18000/30000] Loss:0.000627 Loss_1:0.000618 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:40.250271s (5.93min in total, 3.95min remains)
2022-11-28 19:31:52 NUM_SUB: 90;----------------------------
2022-11-28 19:31:52 Epoch [20000/30000] Loss:0.000474 Loss_1:0.000468 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:40.277390s (6.60min in total, 3.30min remains)
2022-11-28 19:32:33 NUM_SUB: 90;----------------------------
2022-11-28 19:32:33 Epoch [22000/30000] Loss:0.000352 Loss_1:0.000347 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:40.079830s (7.27min in total, 2.64min remains)
2022-11-28 19:33:13 NUM_SUB: 90;----------------------------
2022-11-28 19:33:13 Epoch [24000/30000] Loss:0.000340 Loss_1:0.000334 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:39.982597s (7.93min in total, 1.98min remains)
2022-11-28 19:33:52 NUM_SUB: 90;----------------------------
2022-11-28 19:33:52 Epoch [26000/30000] Loss:0.000333 Loss_1:0.000329 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:39.838847s (8.60min in total, 1.32min remains)
2022-11-28 19:34:32 NUM_SUB: 90;----------------------------
2022-11-28 19:34:32 Epoch [28000/30000] Loss:0.000330 Loss_1:0.000326 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:39.662639s (9.26min in total, 0.66min remains)
2022-11-28 19:35:12 Testing & drawing...
2022-11-28 19:35:12 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:35:14 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=90/
2022-11-28 19:35:14 [Loss]
2022-11-28 19:35:14 NUM_SUB: 90; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:35:14 NUM_SUB: 90; Personalized parameter estimation: Parameter containing:
tensor([0.1312, 0.8061, 0.0078, 0.3080, 0.3074, 0.2745, 0.9313, 0.8964, 0.4556,
        0.0140, 0.0281, 0.0146, 0.8466, 0.1689, 0.0050, 1.8383, 0.6977, 0.8000,
        0.0122, 2.5205, 0.6816, 0.0227, 1.9553, 0.8742, 0.0215, 2.7744, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 19:35:14 NUM_SUB: 90;----------------------------
2022-11-28 19:35:14 Epoch [30000/30000] Loss:0.000329 Loss_1:0.000324 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:41.795906s (9.95min in total, 0.00min remains)
2022-11-28 19:35:14 NUM_SUB: 90------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:35:14 Testing & drawing...
2022-11-28 19:35:14 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:35:15 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=90/
2022-11-28 19:35:15 [Loss]
2022-11-28 19:35:15 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:35:15 General parameter estimation: Parameter containing:
tensor([0.1312, 0.8061, 0.0078, 0.3080, 0.3074, 0.2745, 0.9313, 0.8964, 0.4556,
        0.0140, 0.0281, 0.0146, 0.8467, 0.1689, 0.0050, 1.8383, 0.6977, 0.8000,
        0.0122, 2.5206, 0.6816, 0.0227, 1.9552, 0.8742, 0.0215, 2.7744, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 19:35:15 A: prod, degr, TonA, NonA
2022-11-28 19:35:15 [0.23256192 0.49955323 0.01137673 0.2565081 ]
2022-11-28 19:35:15 T: prod, degr, AonT, NonT
2022-11-28 19:35:15 [0.4544405  0.3198456  0.18597513 0.03973879]
2022-11-28 19:35:15 N: AonN, TonN, ATonN
2022-11-28 19:35:15 [0.01035728 0.9214086  0.06823419]
2022-11-28 19:35:16 using cpu
2022-11-28 19:35:16 epoch = 30000
2022-11-28 19:35:16 epoch_step = 2000
2022-11-28 19:35:16 model_name = SimpleNetworkAD
2022-11-28 19:35:16 now_string = 2022-11-28-18-17-05
2022-11-28 19:35:16 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:35:16 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:35:16 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:35:16 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:35:16 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:35:16 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:35:56 NUM_SUB: 91;----------------------------
2022-11-28 19:35:56 Epoch [02000/30000] Loss:0.029431 Loss_1:0.028372 Loss_2:0.000669 Loss_3:0.000000 Lr:0.000833 Time:40.004155s (0.67min in total, 9.33min remains)
2022-11-28 19:36:35 NUM_SUB: 91;----------------------------
2022-11-28 19:36:35 Epoch [04000/30000] Loss:0.023994 Loss_1:0.023716 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000714 Time:39.845719s (1.33min in total, 8.65min remains)
2022-11-28 19:37:15 NUM_SUB: 91;----------------------------
2022-11-28 19:37:15 Epoch [06000/30000] Loss:0.016564 Loss_1:0.016359 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000625 Time:39.963082s (2.00min in total, 7.99min remains)
2022-11-28 19:37:55 NUM_SUB: 91;----------------------------
2022-11-28 19:37:55 Epoch [08000/30000] Loss:0.007389 Loss_1:0.007246 Loss_2:0.000122 Loss_3:0.000000 Lr:0.000556 Time:39.752370s (2.66min in total, 7.31min remains)
2022-11-28 19:38:35 NUM_SUB: 91;----------------------------
2022-11-28 19:38:35 Epoch [10000/30000] Loss:0.003658 Loss_1:0.003541 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000500 Time:40.224182s (3.33min in total, 6.66min remains)
2022-11-28 19:39:15 NUM_SUB: 91;----------------------------
2022-11-28 19:39:15 Epoch [12000/30000] Loss:0.001794 Loss_1:0.001747 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:39.531433s (3.99min in total, 5.98min remains)
2022-11-28 19:39:53 NUM_SUB: 91;----------------------------
2022-11-28 19:39:53 Epoch [14000/30000] Loss:0.001016 Loss_1:0.000988 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000417 Time:38.139790s (4.62min in total, 5.29min remains)
2022-11-28 19:40:32 NUM_SUB: 91;----------------------------
2022-11-28 19:40:32 Epoch [16000/30000] Loss:0.001000 Loss_1:0.000983 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.546061s (5.27min in total, 4.61min remains)
2022-11-28 19:41:10 NUM_SUB: 91;----------------------------
2022-11-28 19:41:10 Epoch [18000/30000] Loss:0.000988 Loss_1:0.000977 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.397400s (5.91min in total, 3.94min remains)
2022-11-28 19:41:48 NUM_SUB: 91;----------------------------
2022-11-28 19:41:48 Epoch [20000/30000] Loss:0.000985 Loss_1:0.000977 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.270375s (6.54min in total, 3.27min remains)
2022-11-28 19:42:27 NUM_SUB: 91;----------------------------
2022-11-28 19:42:27 Epoch [22000/30000] Loss:0.000983 Loss_1:0.000977 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.174736s (7.18min in total, 2.61min remains)
2022-11-28 19:43:05 NUM_SUB: 91;----------------------------
2022-11-28 19:43:05 Epoch [24000/30000] Loss:0.000982 Loss_1:0.000976 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.206924s (7.82min in total, 1.95min remains)
2022-11-28 19:43:43 NUM_SUB: 91;----------------------------
2022-11-28 19:43:43 Epoch [26000/30000] Loss:0.000981 Loss_1:0.000977 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.717836s (8.46min in total, 1.30min remains)
2022-11-28 19:44:22 NUM_SUB: 91;----------------------------
2022-11-28 19:44:22 Epoch [28000/30000] Loss:0.000980 Loss_1:0.000977 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.319486s (9.10min in total, 0.65min remains)
2022-11-28 19:45:00 Testing & drawing...
2022-11-28 19:45:00 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:45:02 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=91/
2022-11-28 19:45:02 [Loss]
2022-11-28 19:45:02 NUM_SUB: 91; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:45:02 NUM_SUB: 91; Personalized parameter estimation: Parameter containing:
tensor([0.0187, 0.0445, 0.0080, 0.4547, 0.3074, 0.0135, 2.4189, 0.8964, 0.4556,
        0.0139, 0.0307, 0.0135, 0.8284, 0.1689, 0.0174, 2.8519, 0.6977, 0.8000,
        0.0117, 4.2060, 0.6816, 0.0216, 3.7824, 0.8742, 0.0201, 4.5796, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 19:45:02 NUM_SUB: 91;----------------------------
2022-11-28 19:45:02 Epoch [30000/30000] Loss:0.000980 Loss_1:0.000976 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.839272s (9.77min in total, 0.00min remains)
2022-11-28 19:45:02 NUM_SUB: 91------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:45:02 Testing & drawing...
2022-11-28 19:45:02 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:45:03 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=91/
2022-11-28 19:45:03 [Loss]
2022-11-28 19:45:03 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:45:03 General parameter estimation: Parameter containing:
tensor([0.0187, 0.0444, 0.0080, 0.4547, 0.3074, 0.0135, 2.4191, 0.8964, 0.4556,
        0.0139, 0.0307, 0.0135, 0.8283, 0.1689, 0.0174, 2.8519, 0.6977, 0.8000,
        0.0117, 4.2061, 0.6816, 0.0216, 3.7825, 0.8742, 0.0201, 4.5796, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 19:45:03 A: prod, degr, TonA, NonA
2022-11-28 19:45:03 [0.3999621  0.48672682 0.09835155 0.01495957]
2022-11-28 19:45:03 T: prod, degr, AonT, NonT
2022-11-28 19:45:03 [0.406362   0.4577163  0.11675937 0.01916235]
2022-11-28 19:45:03 N: AonN, TonN, ATonN
2022-11-28 19:45:03 [0.0086574 0.9649881 0.0263545]
2022-11-28 19:45:03 using cpu
2022-11-28 19:45:03 epoch = 30000
2022-11-28 19:45:03 epoch_step = 2000
2022-11-28 19:45:03 model_name = SimpleNetworkAD
2022-11-28 19:45:03 now_string = 2022-11-28-18-17-05
2022-11-28 19:45:03 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:45:03 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:45:03 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:45:03 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:45:03 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:45:03 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:45:42 NUM_SUB: 92;----------------------------
2022-11-28 19:45:42 Epoch [02000/30000] Loss:0.072039 Loss_1:0.071092 Loss_2:0.000449 Loss_3:0.000000 Lr:0.000833 Time:38.238129s (0.64min in total, 8.92min remains)
2022-11-28 19:46:20 NUM_SUB: 92;----------------------------
2022-11-28 19:46:20 Epoch [04000/30000] Loss:0.060449 Loss_1:0.060016 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000714 Time:38.300574s (1.28min in total, 8.29min remains)
2022-11-28 19:46:58 NUM_SUB: 92;----------------------------
2022-11-28 19:46:58 Epoch [06000/30000] Loss:0.039401 Loss_1:0.039052 Loss_2:0.000073 Loss_3:0.000000 Lr:0.000625 Time:38.186158s (1.91min in total, 7.65min remains)
2022-11-28 19:47:36 NUM_SUB: 92;----------------------------
2022-11-28 19:47:36 Epoch [08000/30000] Loss:0.009711 Loss_1:0.009492 Loss_2:0.000115 Loss_3:0.000000 Lr:0.000556 Time:38.199107s (2.55min in total, 7.01min remains)
2022-11-28 19:48:15 NUM_SUB: 92;----------------------------
2022-11-28 19:48:15 Epoch [10000/30000] Loss:0.000647 Loss_1:0.000528 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000500 Time:38.184037s (3.19min in total, 6.37min remains)
2022-11-28 19:48:53 NUM_SUB: 92;----------------------------
2022-11-28 19:48:53 Epoch [12000/30000] Loss:0.000461 Loss_1:0.000414 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000455 Time:38.156067s (3.82min in total, 5.73min remains)
2022-11-28 19:49:31 NUM_SUB: 92;----------------------------
2022-11-28 19:49:31 Epoch [14000/30000] Loss:0.000312 Loss_1:0.000289 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:38.203205s (4.46min in total, 5.10min remains)
2022-11-28 19:50:09 NUM_SUB: 92;----------------------------
2022-11-28 19:50:09 Epoch [16000/30000] Loss:0.000190 Loss_1:0.000179 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:38.206421s (5.09min in total, 4.46min remains)
2022-11-28 19:50:48 NUM_SUB: 92;----------------------------
2022-11-28 19:50:48 Epoch [18000/30000] Loss:0.000179 Loss_1:0.000173 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:38.506641s (5.74min in total, 3.82min remains)
2022-11-28 19:51:34 NUM_SUB: 92;----------------------------
2022-11-28 19:51:34 Epoch [20000/30000] Loss:0.000177 Loss_1:0.000173 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:46.028274s (6.50min in total, 3.25min remains)
2022-11-28 19:52:34 NUM_SUB: 92;----------------------------
2022-11-28 19:52:34 Epoch [22000/30000] Loss:0.000175 Loss_1:0.000172 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:60.222148s (7.51min in total, 2.73min remains)
2022-11-28 19:53:57 NUM_SUB: 92;----------------------------
2022-11-28 19:53:57 Epoch [24000/30000] Loss:0.000174 Loss_1:0.000171 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:82.871777s (8.89min in total, 2.22min remains)
2022-11-28 19:54:58 NUM_SUB: 92;----------------------------
2022-11-28 19:54:58 Epoch [26000/30000] Loss:0.000173 Loss_1:0.000171 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:60.789263s (9.90min in total, 1.52min remains)
2022-11-28 19:56:00 NUM_SUB: 92;----------------------------
2022-11-28 19:56:00 Epoch [28000/30000] Loss:0.000172 Loss_1:0.000169 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:62.131334s (10.94min in total, 0.78min remains)
2022-11-28 19:56:38 Testing & drawing...
2022-11-28 19:56:38 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:56:39 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=92/
2022-11-28 19:56:39 [Loss]
2022-11-28 19:56:40 NUM_SUB: 92; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:56:40 NUM_SUB: 92; Personalized parameter estimation: Parameter containing:
tensor([2.9328e-01, 7.7971e-01, 9.8370e-03, 6.3560e-04, 3.0742e-01, 9.3217e-02,
        9.6221e-01, 8.9644e-01, 4.5563e-01, 5.6448e-03, 4.8707e-02, 1.4099e-02,
        2.7110e-01, 1.6886e-01, 1.7523e-02, 2.1255e-01, 6.9767e-01, 8.0001e-01,
        1.2452e-02, 2.8476e+00, 6.8161e-01, 2.2910e-02, 2.6732e+00, 8.7416e-01,
        2.1586e-02, 3.3409e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:56:40 NUM_SUB: 92;----------------------------
2022-11-28 19:56:40 Epoch [30000/30000] Loss:0.000169 Loss_1:0.000166 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.874616s (11.60min in total, 0.00min remains)
2022-11-28 19:56:40 NUM_SUB: 92------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 19:56:40 Testing & drawing...
2022-11-28 19:56:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 19:56:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=92/
2022-11-28 19:56:41 [Loss]
2022-11-28 19:56:41 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 19:56:41 General parameter estimation: Parameter containing:
tensor([2.9327e-01, 7.7970e-01, 9.8368e-03, 6.3526e-04, 3.0742e-01, 9.3201e-02,
        9.6226e-01, 8.9644e-01, 4.5563e-01, 5.6283e-03, 4.8716e-02, 1.4099e-02,
        2.7112e-01, 1.6886e-01, 1.7523e-02, 2.1253e-01, 6.9767e-01, 8.0001e-01,
        1.2452e-02, 2.8475e+00, 6.8161e-01, 2.2911e-02, 2.6730e+00, 8.7416e-01,
        2.1587e-02, 3.3407e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 19:56:41 A: prod, degr, TonA, NonA
2022-11-28 19:56:41 [0.42484725 0.49989405 0.01425041 0.06100826]
2022-11-28 19:56:41 T: prod, degr, AonT, NonT
2022-11-28 19:56:41 [0.10070439 0.38584554 0.21904609 0.29440397]
2022-11-28 19:56:41 N: AonN, TonN, ATonN
2022-11-28 19:56:41 [0.01269838 0.9336185  0.05368318]
2022-11-28 19:56:41 using cpu
2022-11-28 19:56:41 epoch = 30000
2022-11-28 19:56:41 epoch_step = 2000
2022-11-28 19:56:41 model_name = SimpleNetworkAD
2022-11-28 19:56:41 now_string = 2022-11-28-18-17-05
2022-11-28 19:56:41 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 19:56:41 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 19:56:41 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 19:56:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 19:56:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 19:56:41 --------------------------------------------------training start--------------------------------------------------
2022-11-28 19:57:20 NUM_SUB: 93;----------------------------
2022-11-28 19:57:20 Epoch [02000/30000] Loss:0.056144 Loss_1:0.055241 Loss_2:0.000434 Loss_3:0.000000 Lr:0.000833 Time:38.533707s (0.64min in total, 8.99min remains)
2022-11-28 19:57:58 NUM_SUB: 93;----------------------------
2022-11-28 19:57:58 Epoch [04000/30000] Loss:0.045830 Loss_1:0.045526 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000714 Time:38.164268s (1.28min in total, 8.31min remains)
2022-11-28 19:58:36 NUM_SUB: 93;----------------------------
2022-11-28 19:58:36 Epoch [06000/30000] Loss:0.027755 Loss_1:0.027517 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000625 Time:38.211192s (1.92min in total, 7.66min remains)
2022-11-28 19:59:15 NUM_SUB: 93;----------------------------
2022-11-28 19:59:15 Epoch [08000/30000] Loss:0.006715 Loss_1:0.006597 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000556 Time:38.927939s (2.56min in total, 7.05min remains)
2022-11-28 19:59:53 NUM_SUB: 93;----------------------------
2022-11-28 19:59:53 Epoch [10000/30000] Loss:0.002246 Loss_1:0.002176 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000500 Time:38.272236s (3.20min in total, 6.40min remains)
2022-11-28 20:00:32 NUM_SUB: 93;----------------------------
2022-11-28 20:00:32 Epoch [12000/30000] Loss:0.001983 Loss_1:0.001942 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:38.261368s (3.84min in total, 5.76min remains)
2022-11-28 20:01:10 NUM_SUB: 93;----------------------------
2022-11-28 20:01:10 Epoch [14000/30000] Loss:0.001902 Loss_1:0.001885 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.178420s (4.48min in total, 5.12min remains)
2022-11-28 20:01:48 NUM_SUB: 93;----------------------------
2022-11-28 20:01:48 Epoch [16000/30000] Loss:0.001844 Loss_1:0.001834 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:38.187746s (5.11min in total, 4.47min remains)
2022-11-28 20:02:26 NUM_SUB: 93;----------------------------
2022-11-28 20:02:26 Epoch [18000/30000] Loss:0.001807 Loss_1:0.001801 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.236992s (5.75min in total, 3.83min remains)
2022-11-28 20:03:05 NUM_SUB: 93;----------------------------
2022-11-28 20:03:05 Epoch [20000/30000] Loss:0.001795 Loss_1:0.001790 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.296683s (6.39min in total, 3.19min remains)
2022-11-28 20:03:43 NUM_SUB: 93;----------------------------
2022-11-28 20:03:43 Epoch [22000/30000] Loss:0.001792 Loss_1:0.001790 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.194675s (7.02min in total, 2.55min remains)
2022-11-28 20:04:21 NUM_SUB: 93;----------------------------
2022-11-28 20:04:21 Epoch [24000/30000] Loss:0.001792 Loss_1:0.001790 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.212745s (7.66min in total, 1.92min remains)
2022-11-28 20:04:59 NUM_SUB: 93;----------------------------
2022-11-28 20:04:59 Epoch [26000/30000] Loss:0.001792 Loss_1:0.001791 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:38.268119s (8.30min in total, 1.28min remains)
2022-11-28 20:05:37 NUM_SUB: 93;----------------------------
2022-11-28 20:05:37 Epoch [28000/30000] Loss:0.001793 Loss_1:0.001791 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.230534s (8.94min in total, 0.64min remains)
2022-11-28 20:06:23 Testing & drawing...
2022-11-28 20:06:23 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:06:25 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=93/
2022-11-28 20:06:25 [Loss]
2022-11-28 20:06:25 NUM_SUB: 93; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:06:25 NUM_SUB: 93; Personalized parameter estimation: Parameter containing:
tensor([3.5362e-01, 9.2536e-01, 9.6002e-03, 3.1104e-03, 3.0742e-01, 1.3202e-02,
        7.5544e-01, 8.9644e-01, 4.5563e-01, 1.3057e-02, 3.5074e-02, 1.2305e-02,
        7.6584e-01, 1.6886e-01, 1.7490e-02, 2.0569e+00, 6.9767e-01, 8.0001e-01,
        1.2141e-02, 3.8934e+00, 6.8161e-01, 2.2376e-02, 3.6687e+00, 8.7416e-01,
        2.0198e-02, 4.4324e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 20:06:25 NUM_SUB: 93;----------------------------
2022-11-28 20:06:25 Epoch [30000/30000] Loss:0.001792 Loss_1:0.001791 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:47.186084s (9.72min in total, 0.00min remains)
2022-11-28 20:06:25 NUM_SUB: 93------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 20:06:25 Testing & drawing...
2022-11-28 20:06:25 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:06:26 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=93/
2022-11-28 20:06:26 [Loss]
2022-11-28 20:06:26 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:06:26 General parameter estimation: Parameter containing:
tensor([3.5362e-01, 9.2537e-01, 9.6002e-03, 3.1085e-03, 3.0742e-01, 1.3196e-02,
        7.5545e-01, 8.9644e-01, 4.5563e-01, 1.3057e-02, 3.5138e-02, 1.2305e-02,
        7.6588e-01, 1.6886e-01, 1.7490e-02, 2.0570e+00, 6.9767e-01, 8.0001e-01,
        1.2141e-02, 3.8935e+00, 6.8161e-01, 2.2376e-02, 3.6689e+00, 8.7416e-01,
        2.0197e-02, 4.4325e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 20:06:26 A: prod, degr, TonA, NonA
2022-11-28 20:06:26 [0.47907844 0.5000387  0.01300586 0.00787703]
2022-11-28 20:06:26 T: prod, degr, AonT, NonT
2022-11-28 20:06:26 [0.40115705 0.43058276 0.11662282 0.05163739]
2022-11-28 20:06:26 N: AonN, TonN, ATonN
2022-11-28 20:06:26 [0.00608893 0.9734114  0.02049972]
2022-11-28 20:06:26 using cpu
2022-11-28 20:06:26 epoch = 30000
2022-11-28 20:06:26 epoch_step = 2000
2022-11-28 20:06:26 model_name = SimpleNetworkAD
2022-11-28 20:06:26 now_string = 2022-11-28-18-17-05
2022-11-28 20:06:26 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 20:06:26 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 20:06:26 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 20:06:26 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 20:06:26 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 20:06:26 --------------------------------------------------training start--------------------------------------------------
2022-11-28 20:07:05 NUM_SUB: 94;----------------------------
2022-11-28 20:07:05 Epoch [02000/30000] Loss:0.117733 Loss_1:0.116353 Loss_2:0.000780 Loss_3:0.000000 Lr:0.000833 Time:38.418810s (0.64min in total, 8.96min remains)
2022-11-28 20:07:45 NUM_SUB: 94;----------------------------
2022-11-28 20:07:45 Epoch [04000/30000] Loss:0.094695 Loss_1:0.093937 Loss_2:0.000201 Loss_3:0.000000 Lr:0.000714 Time:40.407282s (1.31min in total, 8.54min remains)
2022-11-28 20:08:41 NUM_SUB: 94;----------------------------
2022-11-28 20:08:41 Epoch [06000/30000] Loss:0.053478 Loss_1:0.052897 Loss_2:0.000195 Loss_3:0.000000 Lr:0.000625 Time:55.378175s (2.24min in total, 8.95min remains)
2022-11-28 20:09:43 NUM_SUB: 94;----------------------------
2022-11-28 20:09:43 Epoch [08000/30000] Loss:0.012796 Loss_1:0.012466 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000556 Time:62.847714s (3.28min in total, 9.03min remains)
2022-11-28 20:10:44 NUM_SUB: 94;----------------------------
2022-11-28 20:10:44 Epoch [10000/30000] Loss:0.003153 Loss_1:0.002961 Loss_2:0.000192 Loss_3:0.000000 Lr:0.000500 Time:60.913130s (4.30min in total, 8.60min remains)
2022-11-28 20:11:46 NUM_SUB: 94;----------------------------
2022-11-28 20:11:46 Epoch [12000/30000] Loss:0.002269 Loss_1:0.002180 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000455 Time:61.343493s (5.32min in total, 7.98min remains)
2022-11-28 20:12:24 NUM_SUB: 94;----------------------------
2022-11-28 20:12:24 Epoch [14000/30000] Loss:0.001878 Loss_1:0.001825 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000417 Time:38.254408s (5.96min in total, 6.81min remains)
2022-11-28 20:13:27 NUM_SUB: 94;----------------------------
2022-11-28 20:13:27 Epoch [16000/30000] Loss:0.001566 Loss_1:0.001531 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000385 Time:62.501247s (7.00min in total, 6.13min remains)
2022-11-28 20:14:28 NUM_SUB: 94;----------------------------
2022-11-28 20:14:28 Epoch [18000/30000] Loss:0.000624 Loss_1:0.000571 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000357 Time:61.180197s (8.02min in total, 5.35min remains)
2022-11-28 20:15:17 NUM_SUB: 94;----------------------------
2022-11-28 20:15:17 Epoch [20000/30000] Loss:0.000280 Loss_1:0.000230 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000333 Time:49.001765s (8.84min in total, 4.42min remains)
2022-11-28 20:16:18 NUM_SUB: 94;----------------------------
2022-11-28 20:16:18 Epoch [22000/30000] Loss:0.000223 Loss_1:0.000194 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000313 Time:61.017328s (9.85min in total, 3.58min remains)
2022-11-28 20:19:47 NUM_SUB: 94;----------------------------
2022-11-28 20:19:47 Epoch [24000/30000] Loss:0.000185 Loss_1:0.000169 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000294 Time:209.262152s (13.34min in total, 3.34min remains)
2022-11-28 20:38:30 NUM_SUB: 94;----------------------------
2022-11-28 20:38:30 Epoch [26000/30000] Loss:0.000173 Loss_1:0.000162 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000278 Time:1123.211235s (32.06min in total, 4.93min remains)
2022-11-28 20:39:09 NUM_SUB: 94;----------------------------
2022-11-28 20:39:09 Epoch [28000/30000] Loss:0.000170 Loss_1:0.000160 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000263 Time:38.512857s (32.70min in total, 2.34min remains)
2022-11-28 20:39:47 Testing & drawing...
2022-11-28 20:39:47 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:39:49 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=94/
2022-11-28 20:39:49 [Loss]
2022-11-28 20:39:49 NUM_SUB: 94; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:39:49 NUM_SUB: 94; Personalized parameter estimation: Parameter containing:
tensor([0.0154, 0.0342, 0.0217, 0.9418, 0.3074, 0.0553, 1.5901, 0.8964, 0.4556,
        0.0137, 0.0248, 0.0150, 0.7828, 0.1689, 0.0175, 1.9472, 0.6977, 0.8000,
        0.0078, 5.2848, 0.6816, 0.0210, 4.5086, 0.8742, 0.0088, 5.2691, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:39:49 NUM_SUB: 94;----------------------------
2022-11-28 20:39:49 Epoch [30000/30000] Loss:0.000169 Loss_1:0.000160 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000250 Time:40.140885s (33.37min in total, 0.00min remains)
2022-11-28 20:39:49 NUM_SUB: 94------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 20:39:49 Testing & drawing...
2022-11-28 20:39:49 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:39:50 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=94/
2022-11-28 20:39:50 [Loss]
2022-11-28 20:39:50 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:39:50 General parameter estimation: Parameter containing:
tensor([0.0154, 0.0342, 0.0217, 0.9418, 0.3074, 0.0553, 1.5901, 0.8964, 0.4556,
        0.0137, 0.0248, 0.0150, 0.7827, 0.1689, 0.0175, 1.9472, 0.6977, 0.8000,
        0.0078, 5.2849, 0.6816, 0.0210, 4.5087, 0.8742, 0.0088, 5.2692, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:39:50 A: prod, degr, TonA, NonA
2022-11-28 20:39:50 [0.22364706 0.4931239  0.15049301 0.13273603]
2022-11-28 20:39:50 T: prod, degr, AonT, NonT
2022-11-28 20:39:50 [0.27967224 0.50413245 0.17435144 0.04184381]
2022-11-28 20:39:50 N: AonN, TonN, ATonN
2022-11-28 20:39:50 [0.01278249 0.96144044 0.0257771 ]
2022-11-28 20:39:51 using cpu
2022-11-28 20:39:51 epoch = 30000
2022-11-28 20:39:51 epoch_step = 2000
2022-11-28 20:39:51 model_name = SimpleNetworkAD
2022-11-28 20:39:51 now_string = 2022-11-28-18-17-05
2022-11-28 20:39:51 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 20:39:51 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 20:39:51 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 20:39:51 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 20:39:51 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 20:39:51 --------------------------------------------------training start--------------------------------------------------
2022-11-28 20:40:29 NUM_SUB: 95;----------------------------
2022-11-28 20:40:29 Epoch [02000/30000] Loss:0.023167 Loss_1:0.022197 Loss_2:0.000508 Loss_3:0.000000 Lr:0.000833 Time:38.234719s (0.64min in total, 8.92min remains)
2022-11-28 20:41:07 NUM_SUB: 95;----------------------------
2022-11-28 20:41:07 Epoch [04000/30000] Loss:0.018638 Loss_1:0.018438 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000714 Time:38.503980s (1.28min in total, 8.31min remains)
2022-11-28 20:41:46 NUM_SUB: 95;----------------------------
2022-11-28 20:41:46 Epoch [06000/30000] Loss:0.012854 Loss_1:0.012657 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000625 Time:38.511116s (1.92min in total, 7.68min remains)
2022-11-28 20:42:24 NUM_SUB: 95;----------------------------
2022-11-28 20:42:24 Epoch [08000/30000] Loss:0.004870 Loss_1:0.004737 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000556 Time:38.231085s (2.56min in total, 7.03min remains)
2022-11-28 20:43:03 NUM_SUB: 95;----------------------------
2022-11-28 20:43:03 Epoch [10000/30000] Loss:0.000982 Loss_1:0.000892 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000500 Time:38.464939s (3.20min in total, 6.40min remains)
2022-11-28 20:43:41 NUM_SUB: 95;----------------------------
2022-11-28 20:43:41 Epoch [12000/30000] Loss:0.000646 Loss_1:0.000587 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000455 Time:38.486198s (3.84min in total, 5.76min remains)
2022-11-28 20:44:19 NUM_SUB: 95;----------------------------
2022-11-28 20:44:19 Epoch [14000/30000] Loss:0.000408 Loss_1:0.000381 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:38.255076s (4.48min in total, 5.12min remains)
2022-11-28 20:44:58 NUM_SUB: 95;----------------------------
2022-11-28 20:44:58 Epoch [16000/30000] Loss:0.000263 Loss_1:0.000248 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:38.403737s (5.12min in total, 4.48min remains)
2022-11-28 20:45:36 NUM_SUB: 95;----------------------------
2022-11-28 20:45:36 Epoch [18000/30000] Loss:0.000238 Loss_1:0.000229 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.284265s (5.76min in total, 3.84min remains)
2022-11-28 20:46:14 NUM_SUB: 95;----------------------------
2022-11-28 20:46:14 Epoch [20000/30000] Loss:0.000237 Loss_1:0.000233 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:38.379443s (6.40min in total, 3.20min remains)
2022-11-28 20:46:53 NUM_SUB: 95;----------------------------
2022-11-28 20:46:53 Epoch [22000/30000] Loss:0.000232 Loss_1:0.000229 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.472263s (7.04min in total, 2.56min remains)
2022-11-28 20:47:31 NUM_SUB: 95;----------------------------
2022-11-28 20:47:31 Epoch [24000/30000] Loss:0.000231 Loss_1:0.000229 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.246805s (7.67min in total, 1.92min remains)
2022-11-28 20:48:10 NUM_SUB: 95;----------------------------
2022-11-28 20:48:10 Epoch [26000/30000] Loss:0.000230 Loss_1:0.000229 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.772923s (8.32min in total, 1.28min remains)
2022-11-28 20:48:48 NUM_SUB: 95;----------------------------
2022-11-28 20:48:48 Epoch [28000/30000] Loss:0.000230 Loss_1:0.000229 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.491749s (8.96min in total, 0.64min remains)
2022-11-28 20:49:27 Testing & drawing...
2022-11-28 20:49:27 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:49:28 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=95/
2022-11-28 20:49:28 [Loss]
2022-11-28 20:49:28 NUM_SUB: 95; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:49:28 NUM_SUB: 95; Personalized parameter estimation: Parameter containing:
tensor([0.0520, 0.1325, 0.0099, 0.0159, 0.3074, 0.0084, 0.7280, 0.8964, 0.4556,
        0.0134, 0.0463, 0.0126, 0.5149, 0.1689, 0.0176, 0.8374, 0.6977, 0.8000,
        0.0123, 2.9706, 0.6816, 0.0226, 3.1407, 0.8742, 0.0209, 3.6762, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:49:28 NUM_SUB: 95;----------------------------
2022-11-28 20:49:28 Epoch [30000/30000] Loss:0.000230 Loss_1:0.000229 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.042979s (9.63min in total, 0.00min remains)
2022-11-28 20:49:28 NUM_SUB: 95------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 20:49:28 Testing & drawing...
2022-11-28 20:49:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:49:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=95/
2022-11-28 20:49:30 [Loss]
2022-11-28 20:49:30 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:49:30 General parameter estimation: Parameter containing:
tensor([0.0520, 0.1325, 0.0099, 0.0158, 0.3074, 0.0084, 0.7281, 0.8964, 0.4556,
        0.0134, 0.0463, 0.0126, 0.5148, 0.1689, 0.0176, 0.8373, 0.6977, 0.8000,
        0.0123, 2.9704, 0.6816, 0.0226, 3.1407, 0.8742, 0.0209, 3.6762, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:49:30 A: prod, degr, TonA, NonA
2022-11-28 20:49:30 [0.39864877 0.49781528 0.07602794 0.02750804]
2022-11-28 20:49:30 T: prod, degr, AonT, NonT
2022-11-28 20:49:30 [0.27352735 0.46232098 0.13559842 0.12855323]
2022-11-28 20:49:30 N: AonN, TonN, ATonN
2022-11-28 20:49:30 [0.01507656 0.94763297 0.03729048]
2022-11-28 20:49:30 using cpu
2022-11-28 20:49:30 epoch = 30000
2022-11-28 20:49:30 epoch_step = 2000
2022-11-28 20:49:30 model_name = SimpleNetworkAD
2022-11-28 20:49:30 now_string = 2022-11-28-18-17-05
2022-11-28 20:49:30 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 20:49:30 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 20:49:30 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 20:49:30 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 20:49:30 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 20:49:30 --------------------------------------------------training start--------------------------------------------------
2022-11-28 20:50:09 NUM_SUB: 96;----------------------------
2022-11-28 20:50:09 Epoch [02000/30000] Loss:0.126679 Loss_1:0.125883 Loss_2:0.000316 Loss_3:0.000000 Lr:0.000833 Time:38.517707s (0.64min in total, 8.99min remains)
2022-11-28 20:50:47 NUM_SUB: 96;----------------------------
2022-11-28 20:50:47 Epoch [04000/30000] Loss:0.100292 Loss_1:0.099794 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000714 Time:38.523517s (1.28min in total, 8.35min remains)
2022-11-28 20:51:25 NUM_SUB: 96;----------------------------
2022-11-28 20:51:25 Epoch [06000/30000] Loss:0.049397 Loss_1:0.049041 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000625 Time:38.237562s (1.92min in total, 7.69min remains)
2022-11-28 20:52:04 NUM_SUB: 96;----------------------------
2022-11-28 20:52:04 Epoch [08000/30000] Loss:0.011356 Loss_1:0.011200 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000556 Time:38.529284s (2.56min in total, 7.05min remains)
2022-11-28 20:52:43 NUM_SUB: 96;----------------------------
2022-11-28 20:52:43 Epoch [10000/30000] Loss:0.005636 Loss_1:0.005498 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000500 Time:38.527267s (3.21min in total, 6.41min remains)
2022-11-28 20:53:21 NUM_SUB: 96;----------------------------
2022-11-28 20:53:21 Epoch [12000/30000] Loss:0.002516 Loss_1:0.002465 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000455 Time:38.243698s (3.84min in total, 5.76min remains)
2022-11-28 20:53:59 NUM_SUB: 96;----------------------------
2022-11-28 20:53:59 Epoch [14000/30000] Loss:0.002326 Loss_1:0.002295 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:38.517828s (4.49min in total, 5.13min remains)
2022-11-28 20:54:38 NUM_SUB: 96;----------------------------
2022-11-28 20:54:38 Epoch [16000/30000] Loss:0.002311 Loss_1:0.002293 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.395612s (5.12min in total, 4.48min remains)
2022-11-28 20:55:16 NUM_SUB: 96;----------------------------
2022-11-28 20:55:16 Epoch [18000/30000] Loss:0.002302 Loss_1:0.002291 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:38.353775s (5.76min in total, 3.84min remains)
2022-11-28 20:55:55 NUM_SUB: 96;----------------------------
2022-11-28 20:55:55 Epoch [20000/30000] Loss:0.002296 Loss_1:0.002288 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.469595s (6.41min in total, 3.20min remains)
2022-11-28 20:56:33 NUM_SUB: 96;----------------------------
2022-11-28 20:56:33 Epoch [22000/30000] Loss:0.002291 Loss_1:0.002285 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.273722s (7.04min in total, 2.56min remains)
2022-11-28 20:57:11 NUM_SUB: 96;----------------------------
2022-11-28 20:57:11 Epoch [24000/30000] Loss:0.002286 Loss_1:0.002281 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.493219s (7.68min in total, 1.92min remains)
2022-11-28 20:57:50 NUM_SUB: 96;----------------------------
2022-11-28 20:57:50 Epoch [26000/30000] Loss:0.002282 Loss_1:0.002278 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.481229s (8.33min in total, 1.28min remains)
2022-11-28 20:58:28 NUM_SUB: 96;----------------------------
2022-11-28 20:58:28 Epoch [28000/30000] Loss:0.002278 Loss_1:0.002275 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.208447s (8.96min in total, 0.64min remains)
2022-11-28 20:59:06 Testing & drawing...
2022-11-28 20:59:06 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:59:08 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=96/
2022-11-28 20:59:08 [Loss]
2022-11-28 20:59:08 NUM_SUB: 96; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:59:08 NUM_SUB: 96; Personalized parameter estimation: Parameter containing:
tensor([0.0085, 0.4414, 0.0096, 1.2515, 0.3074, 0.2142, 1.0327, 0.8964, 0.4556,
        0.0147, 0.0238, 0.0154, 1.0401, 0.1689, 0.0175, 2.6729, 0.6977, 0.8000,
        0.0122, 2.8403, 0.6816, 0.0211, 3.8706, 0.8742, 0.0177, 4.4862, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:59:08 NUM_SUB: 96;----------------------------
2022-11-28 20:59:08 Epoch [30000/30000] Loss:0.002272 Loss_1:0.002271 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.111073s (9.63min in total, 0.00min remains)
2022-11-28 20:59:08 NUM_SUB: 96------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 20:59:08 Testing & drawing...
2022-11-28 20:59:08 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 20:59:10 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=96/
2022-11-28 20:59:10 [Loss]
2022-11-28 20:59:10 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 20:59:10 General parameter estimation: Parameter containing:
tensor([0.0085, 0.4413, 0.0096, 1.2515, 0.3074, 0.2142, 1.0327, 0.8964, 0.4556,
        0.0147, 0.0237, 0.0154, 1.0401, 0.1689, 0.0175, 2.6730, 0.6977, 0.8000,
        0.0122, 2.8402, 0.6816, 0.0211, 3.8704, 0.8742, 0.0177, 4.4861, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 20:59:10 A: prod, degr, TonA, NonA
2022-11-28 20:59:10 [0.04156743 0.49845785 0.01360498 0.44636968]
2022-11-28 20:59:10 T: prod, degr, AonT, NonT
2022-11-28 20:59:10 [0.5294531  0.19889572 0.20637506 0.06527605]
2022-11-28 20:59:10 N: AonN, TonN, ATonN
2022-11-28 20:59:10 [0.00407574 0.9652122  0.03071206]
2022-11-28 20:59:10 using cpu
2022-11-28 20:59:10 epoch = 30000
2022-11-28 20:59:10 epoch_step = 2000
2022-11-28 20:59:10 model_name = SimpleNetworkAD
2022-11-28 20:59:10 now_string = 2022-11-28-18-17-05
2022-11-28 20:59:10 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 20:59:10 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 20:59:10 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 20:59:10 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 20:59:10 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 20:59:10 --------------------------------------------------training start--------------------------------------------------
2022-11-28 20:59:48 NUM_SUB: 97;----------------------------
2022-11-28 20:59:48 Epoch [02000/30000] Loss:0.305061 Loss_1:0.303424 Loss_2:0.000622 Loss_3:0.000000 Lr:0.000833 Time:38.499476s (0.64min in total, 8.98min remains)
2022-11-28 21:00:26 NUM_SUB: 97;----------------------------
2022-11-28 21:00:26 Epoch [04000/30000] Loss:0.241810 Loss_1:0.240192 Loss_2:0.000141 Loss_3:0.000000 Lr:0.000714 Time:38.175946s (1.28min in total, 8.31min remains)
2022-11-28 21:01:05 NUM_SUB: 97;----------------------------
2022-11-28 21:01:05 Epoch [06000/30000] Loss:0.102062 Loss_1:0.100904 Loss_2:0.000203 Loss_3:0.000000 Lr:0.000625 Time:38.396661s (1.92min in total, 7.67min remains)
2022-11-28 21:01:43 NUM_SUB: 97;----------------------------
2022-11-28 21:01:43 Epoch [08000/30000] Loss:0.002993 Loss_1:0.002593 Loss_2:0.000313 Loss_3:0.000000 Lr:0.000556 Time:38.523704s (2.56min in total, 7.04min remains)
2022-11-28 21:02:22 NUM_SUB: 97;----------------------------
2022-11-28 21:02:22 Epoch [10000/30000] Loss:0.000781 Loss_1:0.000601 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000500 Time:38.226356s (3.20min in total, 6.39min remains)
2022-11-28 21:03:00 NUM_SUB: 97;----------------------------
2022-11-28 21:03:00 Epoch [12000/30000] Loss:0.000419 Loss_1:0.000336 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000455 Time:38.385385s (3.84min in total, 5.76min remains)
2022-11-28 21:03:38 NUM_SUB: 97;----------------------------
2022-11-28 21:03:38 Epoch [14000/30000] Loss:0.000189 Loss_1:0.000146 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000417 Time:38.356505s (4.48min in total, 5.12min remains)
2022-11-28 21:04:17 NUM_SUB: 97;----------------------------
2022-11-28 21:04:17 Epoch [16000/30000] Loss:0.000064 Loss_1:0.000040 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000385 Time:38.275727s (5.11min in total, 4.47min remains)
2022-11-28 21:04:55 NUM_SUB: 97;----------------------------
2022-11-28 21:04:55 Epoch [18000/30000] Loss:0.000020 Loss_1:0.000007 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:38.407978s (5.75min in total, 3.84min remains)
2022-11-28 21:05:33 NUM_SUB: 97;----------------------------
2022-11-28 21:05:33 Epoch [20000/30000] Loss:0.000009 Loss_1:0.000001 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.307678s (6.39min in total, 3.20min remains)
2022-11-28 21:06:12 NUM_SUB: 97;----------------------------
2022-11-28 21:06:12 Epoch [22000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.368518s (7.03min in total, 2.56min remains)
2022-11-28 21:06:50 NUM_SUB: 97;----------------------------
2022-11-28 21:06:50 Epoch [24000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.394992s (7.67min in total, 1.92min remains)
2022-11-28 21:07:28 NUM_SUB: 97;----------------------------
2022-11-28 21:07:28 Epoch [26000/30000] Loss:0.000014 Loss_1:0.000012 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.217867s (8.31min in total, 1.28min remains)
2022-11-28 21:08:07 NUM_SUB: 97;----------------------------
2022-11-28 21:08:07 Epoch [28000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.409806s (8.95min in total, 0.64min remains)
2022-11-28 21:08:45 Testing & drawing...
2022-11-28 21:08:45 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:08:47 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=97/
2022-11-28 21:08:47 [Loss]
2022-11-28 21:08:47 NUM_SUB: 97; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:08:47 NUM_SUB: 97; Personalized parameter estimation: Parameter containing:
tensor([0.0153, 0.0570, 0.0237, 1.7641, 0.3074, 0.1044, 2.1486, 0.8964, 0.4556,
        0.0222, 0.0485, 0.0140, 0.1981, 0.1689, 0.0175, 0.6183, 0.6977, 0.8000,
        0.0103, 4.7202, 0.6816, 0.0216, 4.6685, 0.8742, 0.0175, 5.3768, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:08:47 NUM_SUB: 97;----------------------------
2022-11-28 21:08:47 Epoch [30000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.080204s (9.62min in total, 0.00min remains)
2022-11-28 21:08:47 NUM_SUB: 97------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:08:47 Testing & drawing...
2022-11-28 21:08:47 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:08:48 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=97/
2022-11-28 21:08:48 [Loss]
2022-11-28 21:08:48 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:08:48 General parameter estimation: Parameter containing:
tensor([0.0153, 0.0570, 0.0237, 1.7642, 0.3074, 0.1043, 2.1486, 0.8964, 0.4556,
        0.0222, 0.0485, 0.0140, 0.1981, 0.1689, 0.0175, 0.6182, 0.6977, 0.8000,
        0.0103, 4.7203, 0.6816, 0.0216, 4.6686, 0.8742, 0.0175, 5.3769, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:08:48 A: prod, degr, TonA, NonA
2022-11-28 21:08:48 [0.18824975 0.49393645 0.07155358 0.2462602 ]
2022-11-28 21:08:48 T: prod, degr, AonT, NonT
2022-11-28 21:08:48 [0.2688047  0.4119403  0.1631592  0.15609577]
2022-11-28 21:08:48 N: AonN, TonN, ATonN
2022-11-28 21:08:48 [0.01023287 0.95048213 0.03928505]
2022-11-28 21:08:49 using cpu
2022-11-28 21:08:49 epoch = 30000
2022-11-28 21:08:49 epoch_step = 2000
2022-11-28 21:08:49 model_name = SimpleNetworkAD
2022-11-28 21:08:49 now_string = 2022-11-28-18-17-05
2022-11-28 21:08:49 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:08:49 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:08:49 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:08:49 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:08:49 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:08:49 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:09:28 NUM_SUB: 98;----------------------------
2022-11-28 21:09:28 Epoch [02000/30000] Loss:0.060483 Loss_1:0.059143 Loss_2:0.000702 Loss_3:0.000000 Lr:0.000833 Time:38.973730s (0.65min in total, 9.09min remains)
2022-11-28 21:10:07 NUM_SUB: 98;----------------------------
2022-11-28 21:10:07 Epoch [04000/30000] Loss:0.051465 Loss_1:0.050749 Loss_2:0.000254 Loss_3:0.000000 Lr:0.000714 Time:38.928487s (1.30min in total, 8.44min remains)
2022-11-28 21:10:45 NUM_SUB: 98;----------------------------
2022-11-28 21:10:45 Epoch [06000/30000] Loss:0.035963 Loss_1:0.035432 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000625 Time:38.848852s (1.95min in total, 7.78min remains)
2022-11-28 21:11:24 NUM_SUB: 98;----------------------------
2022-11-28 21:11:24 Epoch [08000/30000] Loss:0.009885 Loss_1:0.009559 Loss_2:0.000205 Loss_3:0.000000 Lr:0.000556 Time:38.528761s (2.59min in total, 7.12min remains)
2022-11-28 21:12:03 NUM_SUB: 98;----------------------------
2022-11-28 21:12:03 Epoch [10000/30000] Loss:0.002778 Loss_1:0.002614 Loss_2:0.000162 Loss_3:0.000000 Lr:0.000500 Time:38.846233s (3.24min in total, 6.47min remains)
2022-11-28 21:12:42 NUM_SUB: 98;----------------------------
2022-11-28 21:12:42 Epoch [12000/30000] Loss:0.002623 Loss_1:0.002544 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000455 Time:38.774333s (3.88min in total, 5.82min remains)
2022-11-28 21:13:20 NUM_SUB: 98;----------------------------
2022-11-28 21:13:20 Epoch [14000/30000] Loss:0.002530 Loss_1:0.002494 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:38.642539s (4.53min in total, 5.17min remains)
2022-11-28 21:13:59 NUM_SUB: 98;----------------------------
2022-11-28 21:13:59 Epoch [16000/30000] Loss:0.002509 Loss_1:0.002488 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000385 Time:39.092610s (5.18min in total, 4.53min remains)
2022-11-28 21:14:38 NUM_SUB: 98;----------------------------
2022-11-28 21:14:38 Epoch [18000/30000] Loss:0.002501 Loss_1:0.002488 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:39.022625s (5.83min in total, 3.89min remains)
2022-11-28 21:15:17 NUM_SUB: 98;----------------------------
2022-11-28 21:15:17 Epoch [20000/30000] Loss:0.002497 Loss_1:0.002488 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:39.082569s (6.48min in total, 3.24min remains)
2022-11-28 21:15:57 NUM_SUB: 98;----------------------------
2022-11-28 21:15:57 Epoch [22000/30000] Loss:0.002494 Loss_1:0.002488 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:39.301161s (7.13min in total, 2.59min remains)
2022-11-28 21:16:36 NUM_SUB: 98;----------------------------
2022-11-28 21:16:36 Epoch [24000/30000] Loss:0.002493 Loss_1:0.002488 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:39.262982s (7.79min in total, 1.95min remains)
2022-11-28 21:17:15 NUM_SUB: 98;----------------------------
2022-11-28 21:17:15 Epoch [26000/30000] Loss:0.002492 Loss_1:0.002488 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:39.330904s (8.44min in total, 1.30min remains)
2022-11-28 21:17:55 NUM_SUB: 98;----------------------------
2022-11-28 21:17:55 Epoch [28000/30000] Loss:0.002492 Loss_1:0.002488 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:39.445343s (9.10min in total, 0.65min remains)
2022-11-28 21:18:34 Testing & drawing...
2022-11-28 21:18:34 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:18:35 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=98/
2022-11-28 21:18:35 [Loss]
2022-11-28 21:18:36 NUM_SUB: 98; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:18:36 NUM_SUB: 98; Personalized parameter estimation: Parameter containing:
tensor([0.0127, 0.0185, 0.0165, 2.5886, 0.3074, 0.0118, 1.8158, 0.8964, 0.4556,
        0.0123, 0.0336, 0.0145, 0.2535, 0.1689, 0.0177, 0.8113, 0.6977, 0.8000,
        0.0110, 4.8602, 0.6816, 0.0210, 4.2240, 0.8742, 0.0091, 4.6198, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:18:36 NUM_SUB: 98;----------------------------
2022-11-28 21:18:36 Epoch [30000/30000] Loss:0.002492 Loss_1:0.002488 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:40.892956s (9.78min in total, 0.00min remains)
2022-11-28 21:18:36 NUM_SUB: 98------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:18:36 Testing & drawing...
2022-11-28 21:18:36 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:18:37 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=98/
2022-11-28 21:18:37 [Loss]
2022-11-28 21:18:37 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:18:37 General parameter estimation: Parameter containing:
tensor([0.0127, 0.0185, 0.0164, 2.5887, 0.3074, 0.0118, 1.8159, 0.8964, 0.4556,
        0.0123, 0.0335, 0.0145, 0.2535, 0.1689, 0.0177, 0.8114, 0.6977, 0.8000,
        0.0110, 4.8603, 0.6816, 0.0210, 4.2241, 0.8742, 0.0091, 4.6200, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:18:37 A: prod, degr, TonA, NonA
2022-11-28 21:18:37 [0.45317194 0.48148268 0.05185734 0.013488  ]
2022-11-28 21:18:37 T: prod, degr, AonT, NonT
2022-11-28 21:18:37 [0.23395394 0.46773538 0.25067824 0.04763244]
2022-11-28 21:18:37 N: AonN, TonN, ATonN
2022-11-28 21:18:37 [0.01199479 0.9647845  0.02322072]
2022-11-28 21:18:37 using cpu
2022-11-28 21:18:37 epoch = 30000
2022-11-28 21:18:37 epoch_step = 2000
2022-11-28 21:18:37 model_name = SimpleNetworkAD
2022-11-28 21:18:37 now_string = 2022-11-28-18-17-05
2022-11-28 21:18:37 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:18:37 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:18:37 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:18:37 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:18:37 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:18:37 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:19:17 NUM_SUB: 99;----------------------------
2022-11-28 21:19:17 Epoch [02000/30000] Loss:0.080424 Loss_1:0.079487 Loss_2:0.000494 Loss_3:0.000000 Lr:0.000833 Time:39.316639s (0.66min in total, 9.17min remains)
2022-11-28 21:19:56 NUM_SUB: 99;----------------------------
2022-11-28 21:19:56 Epoch [04000/30000] Loss:0.059535 Loss_1:0.059165 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000714 Time:39.471013s (1.31min in total, 8.54min remains)
2022-11-28 21:20:35 NUM_SUB: 99;----------------------------
2022-11-28 21:20:35 Epoch [06000/30000] Loss:0.024381 Loss_1:0.024114 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000625 Time:39.249396s (1.97min in total, 7.87min remains)
2022-11-28 21:21:15 NUM_SUB: 99;----------------------------
2022-11-28 21:21:15 Epoch [08000/30000] Loss:0.002799 Loss_1:0.002666 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000556 Time:39.330760s (2.62min in total, 7.21min remains)
2022-11-28 21:21:54 NUM_SUB: 99;----------------------------
2022-11-28 21:21:54 Epoch [10000/30000] Loss:0.000396 Loss_1:0.000302 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000500 Time:39.459859s (3.28min in total, 6.56min remains)
2022-11-28 21:22:33 NUM_SUB: 99;----------------------------
2022-11-28 21:22:33 Epoch [12000/30000] Loss:0.000112 Loss_1:0.000074 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000455 Time:39.243419s (3.93min in total, 5.90min remains)
2022-11-28 21:23:13 NUM_SUB: 99;----------------------------
2022-11-28 21:23:13 Epoch [14000/30000] Loss:0.000041 Loss_1:0.000025 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000417 Time:39.414334s (4.59min in total, 5.25min remains)
2022-11-28 21:23:52 NUM_SUB: 99;----------------------------
2022-11-28 21:23:52 Epoch [16000/30000] Loss:0.000034 Loss_1:0.000025 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:39.465692s (5.25min in total, 4.59min remains)
2022-11-28 21:24:32 NUM_SUB: 99;----------------------------
2022-11-28 21:24:32 Epoch [18000/30000] Loss:0.000027 Loss_1:0.000022 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:39.177083s (5.90min in total, 3.93min remains)
2022-11-28 21:25:11 NUM_SUB: 99;----------------------------
2022-11-28 21:25:11 Epoch [20000/30000] Loss:0.000023 Loss_1:0.000020 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:39.470605s (6.56min in total, 3.28min remains)
2022-11-28 21:25:51 NUM_SUB: 99;----------------------------
2022-11-28 21:25:51 Epoch [22000/30000] Loss:0.000022 Loss_1:0.000020 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:39.540353s (7.22min in total, 2.63min remains)
2022-11-28 21:26:30 NUM_SUB: 99;----------------------------
2022-11-28 21:26:30 Epoch [24000/30000] Loss:0.000021 Loss_1:0.000020 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:39.263729s (7.87min in total, 1.97min remains)
2022-11-28 21:27:09 NUM_SUB: 99;----------------------------
2022-11-28 21:27:09 Epoch [26000/30000] Loss:0.000021 Loss_1:0.000020 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:39.449533s (8.53min in total, 1.31min remains)
2022-11-28 21:27:49 NUM_SUB: 99;----------------------------
2022-11-28 21:27:49 Epoch [28000/30000] Loss:0.000021 Loss_1:0.000021 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:39.498645s (9.19min in total, 0.66min remains)
2022-11-28 21:28:28 Testing & drawing...
2022-11-28 21:28:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:28:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=99/
2022-11-28 21:28:30 [Loss]
2022-11-28 21:28:30 NUM_SUB: 99; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:28:30 NUM_SUB: 99; Personalized parameter estimation: Parameter containing:
tensor([4.1223e-01, 8.7360e-01, 1.0402e-02, 4.0122e-02, 3.0742e-01, 2.0868e-03,
        7.5800e-01, 8.9644e-01, 4.5563e-01, 1.3881e-02, 3.5952e-02, 1.3443e-02,
        8.4587e-01, 1.6886e-01, 1.7613e-02, 1.6890e+00, 6.9767e-01, 8.0001e-01,
        1.0636e-02, 3.9072e+00, 6.8161e-01, 2.2054e-02, 3.6025e+00, 8.7416e-01,
        1.9662e-02, 4.3681e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 21:28:30 NUM_SUB: 99;----------------------------
2022-11-28 21:28:30 Epoch [30000/30000] Loss:0.000021 Loss_1:0.000020 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.934904s (9.87min in total, 0.00min remains)
2022-11-28 21:28:30 NUM_SUB: 99------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:28:30 Testing & drawing...
2022-11-28 21:28:30 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:28:31 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=99/
2022-11-28 21:28:31 [Loss]
2022-11-28 21:28:31 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:28:31 General parameter estimation: Parameter containing:
tensor([4.1223e-01, 8.7360e-01, 1.0402e-02, 4.0114e-02, 3.0742e-01, 2.0887e-03,
        7.5800e-01, 8.9644e-01, 4.5563e-01, 1.3881e-02, 3.5922e-02, 1.3443e-02,
        8.4587e-01, 1.6886e-01, 1.7613e-02, 1.6890e+00, 6.9767e-01, 8.0001e-01,
        1.0636e-02, 3.9073e+00, 6.8161e-01, 2.2054e-02, 3.6026e+00, 8.7416e-01,
        1.9662e-02, 4.3682e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 21:28:31 A: prod, degr, TonA, NonA
2022-11-28 21:28:31 [0.48662323 0.49998888 0.01221291 0.00117497]
2022-11-28 21:28:31 T: prod, degr, AonT, NonT
2022-11-28 21:28:31 [0.36510232 0.45807433 0.10476022 0.07206313]
2022-11-28 21:28:31 N: AonN, TonN, ATonN
2022-11-28 21:28:31 [0.00774931 0.9663002  0.02595055]
2022-11-28 21:28:31 using cpu
2022-11-28 21:28:31 epoch = 30000
2022-11-28 21:28:31 epoch_step = 2000
2022-11-28 21:28:31 model_name = SimpleNetworkAD
2022-11-28 21:28:31 now_string = 2022-11-28-18-17-05
2022-11-28 21:28:31 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:28:31 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:28:31 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:28:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:28:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:28:31 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:29:11 NUM_SUB: 100;----------------------------
2022-11-28 21:29:11 Epoch [02000/30000] Loss:0.018281 Loss_1:0.017454 Loss_2:0.000414 Loss_3:0.000000 Lr:0.000833 Time:39.450546s (0.66min in total, 9.21min remains)
2022-11-28 21:29:50 NUM_SUB: 100;----------------------------
2022-11-28 21:29:50 Epoch [04000/30000] Loss:0.014919 Loss_1:0.014839 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000714 Time:39.430855s (1.31min in total, 8.55min remains)
2022-11-28 21:30:30 NUM_SUB: 100;----------------------------
2022-11-28 21:30:30 Epoch [06000/30000] Loss:0.011146 Loss_1:0.011042 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000625 Time:39.341161s (1.97min in total, 7.88min remains)
2022-11-28 21:31:09 NUM_SUB: 100;----------------------------
2022-11-28 21:31:09 Epoch [08000/30000] Loss:0.006988 Loss_1:0.006910 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000556 Time:39.486661s (2.63min in total, 7.23min remains)
2022-11-28 21:31:49 NUM_SUB: 100;----------------------------
2022-11-28 21:31:49 Epoch [10000/30000] Loss:0.004853 Loss_1:0.004784 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000500 Time:39.522409s (3.29min in total, 6.57min remains)
2022-11-28 21:32:28 NUM_SUB: 100;----------------------------
2022-11-28 21:32:28 Epoch [12000/30000] Loss:0.004114 Loss_1:0.004070 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:39.190302s (3.94min in total, 5.91min remains)
2022-11-28 21:33:07 NUM_SUB: 100;----------------------------
2022-11-28 21:33:07 Epoch [14000/30000] Loss:0.003613 Loss_1:0.003595 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:39.222276s (4.59min in total, 5.25min remains)
2022-11-28 21:33:46 NUM_SUB: 100;----------------------------
2022-11-28 21:33:46 Epoch [16000/30000] Loss:0.003551 Loss_1:0.003539 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:38.978670s (5.24min in total, 4.59min remains)
2022-11-28 21:34:25 NUM_SUB: 100;----------------------------
2022-11-28 21:34:25 Epoch [18000/30000] Loss:0.003540 Loss_1:0.003531 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:38.515304s (5.89min in total, 3.92min remains)
2022-11-28 21:35:04 NUM_SUB: 100;----------------------------
2022-11-28 21:35:04 Epoch [20000/30000] Loss:0.003528 Loss_1:0.003523 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.900805s (6.53min in total, 3.27min remains)
2022-11-28 21:35:42 NUM_SUB: 100;----------------------------
2022-11-28 21:35:42 Epoch [22000/30000] Loss:0.003527 Loss_1:0.003524 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.855366s (7.18min in total, 2.61min remains)
2022-11-28 21:36:21 NUM_SUB: 100;----------------------------
2022-11-28 21:36:21 Epoch [24000/30000] Loss:0.003526 Loss_1:0.003521 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.605041s (7.83min in total, 1.96min remains)
2022-11-28 21:37:00 NUM_SUB: 100;----------------------------
2022-11-28 21:37:00 Epoch [26000/30000] Loss:0.003526 Loss_1:0.003521 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:39.145909s (8.48min in total, 1.30min remains)
2022-11-28 21:37:39 NUM_SUB: 100;----------------------------
2022-11-28 21:37:39 Epoch [28000/30000] Loss:0.003526 Loss_1:0.003521 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.555164s (9.12min in total, 0.65min remains)
2022-11-28 21:38:17 Testing & drawing...
2022-11-28 21:38:17 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:38:19 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=100/
2022-11-28 21:38:19 [Loss]
2022-11-28 21:38:19 NUM_SUB: 100; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:38:19 NUM_SUB: 100; Personalized parameter estimation: Parameter containing:
tensor([3.3626e-01, 9.4342e-01, 9.8630e-03, 3.0128e-09, 3.0742e-01, 1.5185e-02,
        7.9018e-01, 8.9644e-01, 4.5563e-01, 1.3830e-02, 1.0560e-01, 1.0209e-01,
        6.5510e-01, 1.6886e-01, 1.7682e-02, 9.4488e-01, 6.9767e-01, 8.0001e-01,
        1.0796e-02, 3.8411e+00, 6.8161e-01, 2.1716e-02, 3.6682e+00, 8.7416e-01,
        2.0284e-02, 4.4374e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 21:38:19 NUM_SUB: 100;----------------------------
2022-11-28 21:38:19 Epoch [30000/30000] Loss:0.003526 Loss_1:0.003521 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.031553s (9.79min in total, 0.00min remains)
2022-11-28 21:38:19 NUM_SUB: 100------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:38:19 Testing & drawing...
2022-11-28 21:38:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:38:20 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=100/
2022-11-28 21:38:20 [Loss]
2022-11-28 21:38:20 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:38:20 General parameter estimation: Parameter containing:
tensor([3.3623e-01, 9.4346e-01, 9.8625e-03, 3.0320e-09, 3.0742e-01, 1.5148e-02,
        7.9022e-01, 8.9644e-01, 4.5563e-01, 1.3830e-02, 1.0560e-01, 1.0209e-01,
        6.5511e-01, 1.6886e-01, 1.7682e-02, 9.4488e-01, 6.9767e-01, 8.0001e-01,
        1.0795e-02, 3.8413e+00, 6.8161e-01, 2.1716e-02, 3.6684e+00, 8.7416e-01,
        2.0284e-02, 4.4376e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 21:38:20 A: prod, degr, TonA, NonA
2022-11-28 21:38:20 [0.48170418 0.50022924 0.01412986 0.00393667]
2022-11-28 21:38:20 T: prod, degr, AonT, NonT
2022-11-28 21:38:20 [0.15329452 0.43317422 0.38723624 0.026295  ]
2022-11-28 21:38:20 N: AonN, TonN, ATonN
2022-11-28 21:38:20 [0.00505182 0.97605    0.01889809]
2022-11-28 21:38:21 using cpu
2022-11-28 21:38:21 epoch = 30000
2022-11-28 21:38:21 epoch_step = 2000
2022-11-28 21:38:21 model_name = SimpleNetworkAD
2022-11-28 21:38:21 now_string = 2022-11-28-18-17-05
2022-11-28 21:38:21 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:38:21 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:38:21 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:38:21 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:38:21 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:38:21 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:38:59 NUM_SUB: 101;----------------------------
2022-11-28 21:38:59 Epoch [02000/30000] Loss:0.055771 Loss_1:0.054808 Loss_2:0.000612 Loss_3:0.000000 Lr:0.000833 Time:38.667218s (0.64min in total, 9.02min remains)
2022-11-28 21:39:38 NUM_SUB: 101;----------------------------
2022-11-28 21:39:38 Epoch [04000/30000] Loss:0.041150 Loss_1:0.040929 Loss_2:0.000134 Loss_3:0.000000 Lr:0.000714 Time:38.494916s (1.29min in total, 8.36min remains)
2022-11-28 21:40:16 NUM_SUB: 101;----------------------------
2022-11-28 21:40:16 Epoch [06000/30000] Loss:0.018133 Loss_1:0.017957 Loss_2:0.000126 Loss_3:0.000000 Lr:0.000625 Time:38.565742s (1.93min in total, 7.72min remains)
2022-11-28 21:40:55 NUM_SUB: 101;----------------------------
2022-11-28 21:40:55 Epoch [08000/30000] Loss:0.005128 Loss_1:0.004992 Loss_2:0.000135 Loss_3:0.000000 Lr:0.000556 Time:38.714665s (2.57min in total, 7.08min remains)
2022-11-28 21:41:33 NUM_SUB: 101;----------------------------
2022-11-28 21:41:33 Epoch [10000/30000] Loss:0.003025 Loss_1:0.002960 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000500 Time:38.451256s (3.21min in total, 6.43min remains)
2022-11-28 21:42:12 NUM_SUB: 101;----------------------------
2022-11-28 21:42:12 Epoch [12000/30000] Loss:0.000497 Loss_1:0.000463 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000455 Time:38.615350s (3.86min in total, 5.79min remains)
2022-11-28 21:42:51 NUM_SUB: 101;----------------------------
2022-11-28 21:42:51 Epoch [14000/30000] Loss:0.000020 Loss_1:0.000000 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:38.639293s (4.50min in total, 5.15min remains)
2022-11-28 21:43:29 NUM_SUB: 101;----------------------------
2022-11-28 21:43:29 Epoch [16000/30000] Loss:0.000010 Loss_1:0.000000 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:38.339401s (5.14min in total, 4.50min remains)
2022-11-28 21:44:08 NUM_SUB: 101;----------------------------
2022-11-28 21:44:08 Epoch [18000/30000] Loss:0.000005 Loss_1:0.000000 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.636587s (5.79min in total, 3.86min remains)
2022-11-28 21:44:46 NUM_SUB: 101;----------------------------
2022-11-28 21:44:46 Epoch [20000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.706409s (6.43min in total, 3.22min remains)
2022-11-28 21:45:25 NUM_SUB: 101;----------------------------
2022-11-28 21:45:25 Epoch [22000/30000] Loss:0.000003 Loss_1:0.000001 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.747823s (7.08min in total, 2.57min remains)
2022-11-28 21:46:04 NUM_SUB: 101;----------------------------
2022-11-28 21:46:04 Epoch [24000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:39.190555s (7.73min in total, 1.93min remains)
2022-11-28 21:46:43 NUM_SUB: 101;----------------------------
2022-11-28 21:46:43 Epoch [26000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.661857s (8.37min in total, 1.29min remains)
2022-11-28 21:47:21 NUM_SUB: 101;----------------------------
2022-11-28 21:47:21 Epoch [28000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.407670s (9.01min in total, 0.64min remains)
2022-11-28 21:48:00 Testing & drawing...
2022-11-28 21:48:00 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:48:02 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=101/
2022-11-28 21:48:02 [Loss]
2022-11-28 21:48:02 NUM_SUB: 101; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:48:02 NUM_SUB: 101; Personalized parameter estimation: Parameter containing:
tensor([0.2206, 0.8901, 0.0241, 0.0670, 0.3074, 0.9494, 0.8022, 0.8964, 0.4556,
        0.0152, 0.1226, 0.1149, 0.6123, 0.1689, 0.0176, 1.7090, 0.6977, 0.8000,
        0.0114, 4.3980, 0.6816, 0.0213, 3.5268, 0.8742, 0.0191, 4.5018, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:48:02 NUM_SUB: 101;----------------------------
2022-11-28 21:48:02 Epoch [30000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.207873s (9.68min in total, 0.00min remains)
2022-11-28 21:48:02 NUM_SUB: 101------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:48:02 Testing & drawing...
2022-11-28 21:48:02 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:48:03 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=101/
2022-11-28 21:48:03 [Loss]
2022-11-28 21:48:03 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:48:03 General parameter estimation: Parameter containing:
tensor([0.2206, 0.8901, 0.0241, 0.0670, 0.3074, 0.9494, 0.8022, 0.8964, 0.4556,
        0.0152, 0.1226, 0.1149, 0.6123, 0.1689, 0.0176, 1.7090, 0.6977, 0.8000,
        0.0114, 4.3981, 0.6816, 0.0213, 3.5269, 0.8742, 0.0191, 4.5020, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:48:03 A: prod, degr, TonA, NonA
2022-11-28 21:48:03 [0.17208768 0.49957067 0.01802703 0.31031463]
2022-11-28 21:48:03 T: prod, degr, AonT, NonT
2022-11-28 21:48:03 [0.10882347 0.6266858  0.24737    0.01712078]
2022-11-28 21:48:03 N: AonN, TonN, ATonN
2022-11-28 21:48:03 [0.01648211 0.9480071  0.03551077]
2022-11-28 21:48:03 using cpu
2022-11-28 21:48:03 epoch = 30000
2022-11-28 21:48:03 epoch_step = 2000
2022-11-28 21:48:03 model_name = SimpleNetworkAD
2022-11-28 21:48:03 now_string = 2022-11-28-18-17-05
2022-11-28 21:48:03 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:48:03 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:48:03 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:48:03 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:48:03 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:48:03 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:48:42 NUM_SUB: 102;----------------------------
2022-11-28 21:48:42 Epoch [02000/30000] Loss:0.049876 Loss_1:0.048880 Loss_2:0.000582 Loss_3:0.000000 Lr:0.000833 Time:38.579536s (0.64min in total, 9.00min remains)
2022-11-28 21:49:20 NUM_SUB: 102;----------------------------
2022-11-28 21:49:20 Epoch [04000/30000] Loss:0.038757 Loss_1:0.038520 Loss_2:0.000141 Loss_3:0.000000 Lr:0.000714 Time:38.299462s (1.28min in total, 8.33min remains)
2022-11-28 21:49:59 NUM_SUB: 102;----------------------------
2022-11-28 21:49:59 Epoch [06000/30000] Loss:0.019597 Loss_1:0.019434 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000625 Time:38.476105s (1.92min in total, 7.69min remains)
2022-11-28 21:50:37 NUM_SUB: 102;----------------------------
2022-11-28 21:50:37 Epoch [08000/30000] Loss:0.002602 Loss_1:0.002507 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000556 Time:38.342881s (2.56min in total, 7.04min remains)
2022-11-28 21:51:16 NUM_SUB: 102;----------------------------
2022-11-28 21:51:16 Epoch [10000/30000] Loss:0.001227 Loss_1:0.001148 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000500 Time:38.400068s (3.20min in total, 6.40min remains)
2022-11-28 21:51:54 NUM_SUB: 102;----------------------------
2022-11-28 21:51:54 Epoch [12000/30000] Loss:0.000824 Loss_1:0.000773 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:38.462828s (3.84min in total, 5.76min remains)
2022-11-28 21:52:32 NUM_SUB: 102;----------------------------
2022-11-28 21:52:32 Epoch [14000/30000] Loss:0.000439 Loss_1:0.000409 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:38.237692s (4.48min in total, 5.12min remains)
2022-11-28 21:53:11 NUM_SUB: 102;----------------------------
2022-11-28 21:53:11 Epoch [16000/30000] Loss:0.000347 Loss_1:0.000324 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000385 Time:38.465987s (5.12min in total, 4.48min remains)
2022-11-28 21:53:49 NUM_SUB: 102;----------------------------
2022-11-28 21:53:49 Epoch [18000/30000] Loss:0.000314 Loss_1:0.000297 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:38.407610s (5.76min in total, 3.84min remains)
2022-11-28 21:54:27 NUM_SUB: 102;----------------------------
2022-11-28 21:54:27 Epoch [20000/30000] Loss:0.000304 Loss_1:0.000291 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000333 Time:38.226372s (6.40min in total, 3.20min remains)
2022-11-28 21:55:06 NUM_SUB: 102;----------------------------
2022-11-28 21:55:06 Epoch [22000/30000] Loss:0.000311 Loss_1:0.000302 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:38.530130s (7.04min in total, 2.56min remains)
2022-11-28 21:55:44 NUM_SUB: 102;----------------------------
2022-11-28 21:55:44 Epoch [24000/30000] Loss:0.000290 Loss_1:0.000281 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000294 Time:38.394205s (7.68min in total, 1.92min remains)
2022-11-28 21:56:23 NUM_SUB: 102;----------------------------
2022-11-28 21:56:23 Epoch [26000/30000] Loss:0.000286 Loss_1:0.000277 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:38.294983s (8.32min in total, 1.28min remains)
2022-11-28 21:57:01 NUM_SUB: 102;----------------------------
2022-11-28 21:57:01 Epoch [28000/30000] Loss:0.000277 Loss_1:0.000271 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:38.477311s (8.96min in total, 0.64min remains)
2022-11-28 21:57:39 Testing & drawing...
2022-11-28 21:57:39 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:57:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=102/
2022-11-28 21:57:41 [Loss]
2022-11-28 21:57:41 NUM_SUB: 102; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:57:41 NUM_SUB: 102; Personalized parameter estimation: Parameter containing:
tensor([0.1263, 0.3159, 0.0184, 0.6401, 0.3074, 0.2338, 1.0698, 0.8964, 0.4556,
        0.0141, 0.1666, 0.1278, 0.5403, 0.1689, 0.0177, 0.8138, 0.6977, 0.8000,
        0.0118, 4.0242, 0.6816, 0.0226, 3.0545, 0.8742, 0.0199, 4.0739, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:57:41 NUM_SUB: 102;----------------------------
2022-11-28 21:57:41 Epoch [30000/30000] Loss:0.000274 Loss_1:0.000270 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:40.006524s (9.63min in total, 0.00min remains)
2022-11-28 21:57:41 NUM_SUB: 102------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 21:57:41 Testing & drawing...
2022-11-28 21:57:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 21:57:43 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=102/
2022-11-28 21:57:43 [Loss]
2022-11-28 21:57:43 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 21:57:43 General parameter estimation: Parameter containing:
tensor([0.1263, 0.3159, 0.0184, 0.6401, 0.3074, 0.2338, 1.0698, 0.8964, 0.4556,
        0.0141, 0.1666, 0.1278, 0.5404, 0.1689, 0.0177, 0.8138, 0.6977, 0.8000,
        0.0118, 4.0242, 0.6816, 0.0226, 3.0546, 0.8742, 0.0199, 4.0739, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 21:57:43 A: prod, degr, TonA, NonA
2022-11-28 21:57:43 [0.30611938 0.49925244 0.01046311 0.18416505]
2022-11-28 21:57:43 T: prod, degr, AonT, NonT
2022-11-28 21:57:43 [0.08380233 0.6454653  0.22325735 0.04747497]
2022-11-28 21:57:43 N: AonN, TonN, ATonN
2022-11-28 21:57:43 [0.0159357  0.9499571  0.03410722]
2022-11-28 21:57:43 using cpu
2022-11-28 21:57:43 epoch = 30000
2022-11-28 21:57:43 epoch_step = 2000
2022-11-28 21:57:43 model_name = SimpleNetworkAD
2022-11-28 21:57:43 now_string = 2022-11-28-18-17-05
2022-11-28 21:57:43 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 21:57:43 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 21:57:43 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 21:57:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 21:57:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 21:57:43 --------------------------------------------------training start--------------------------------------------------
2022-11-28 21:58:21 NUM_SUB: 103;----------------------------
2022-11-28 21:58:21 Epoch [02000/30000] Loss:0.048025 Loss_1:0.047250 Loss_2:0.000428 Loss_3:0.000000 Lr:0.000833 Time:38.230302s (0.64min in total, 8.92min remains)
2022-11-28 21:58:59 NUM_SUB: 103;----------------------------
2022-11-28 21:58:59 Epoch [04000/30000] Loss:0.036411 Loss_1:0.036233 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000714 Time:38.415795s (1.28min in total, 8.30min remains)
2022-11-28 21:59:38 NUM_SUB: 103;----------------------------
2022-11-28 21:59:38 Epoch [06000/30000] Loss:0.018869 Loss_1:0.018725 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000625 Time:38.361143s (1.92min in total, 7.67min remains)
2022-11-28 22:00:16 NUM_SUB: 103;----------------------------
2022-11-28 22:00:16 Epoch [08000/30000] Loss:0.007667 Loss_1:0.007543 Loss_2:0.000115 Loss_3:0.000000 Lr:0.000556 Time:38.327495s (2.56min in total, 7.03min remains)
2022-11-28 22:00:55 NUM_SUB: 103;----------------------------
2022-11-28 22:00:55 Epoch [10000/30000] Loss:0.005148 Loss_1:0.005117 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000500 Time:38.440266s (3.20min in total, 6.39min remains)
2022-11-28 22:01:33 NUM_SUB: 103;----------------------------
2022-11-28 22:01:33 Epoch [12000/30000] Loss:0.001291 Loss_1:0.001261 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000455 Time:38.279646s (3.83min in total, 5.75min remains)
2022-11-28 22:02:11 NUM_SUB: 103;----------------------------
2022-11-28 22:02:11 Epoch [14000/30000] Loss:0.000078 Loss_1:0.000057 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:38.496174s (4.48min in total, 5.12min remains)
2022-11-28 22:02:50 NUM_SUB: 103;----------------------------
2022-11-28 22:02:50 Epoch [16000/30000] Loss:0.000018 Loss_1:0.000006 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:38.430878s (5.12min in total, 4.48min remains)
2022-11-28 22:03:28 NUM_SUB: 103;----------------------------
2022-11-28 22:03:28 Epoch [18000/30000] Loss:0.000007 Loss_1:0.000000 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.186893s (5.75min in total, 3.84min remains)
2022-11-28 22:04:06 NUM_SUB: 103;----------------------------
2022-11-28 22:04:06 Epoch [20000/30000] Loss:0.000005 Loss_1:0.000000 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.365517s (6.39min in total, 3.20min remains)
2022-11-28 22:04:45 NUM_SUB: 103;----------------------------
2022-11-28 22:04:45 Epoch [22000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.440555s (7.03min in total, 2.56min remains)
2022-11-28 22:05:23 NUM_SUB: 103;----------------------------
2022-11-28 22:05:23 Epoch [24000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.246163s (7.67min in total, 1.92min remains)
2022-11-28 22:06:02 NUM_SUB: 103;----------------------------
2022-11-28 22:06:02 Epoch [26000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.926208s (8.32min in total, 1.28min remains)
2022-11-28 22:06:41 NUM_SUB: 103;----------------------------
2022-11-28 22:06:41 Epoch [28000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.091144s (8.97min in total, 0.64min remains)
2022-11-28 22:07:20 Testing & drawing...
2022-11-28 22:07:20 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:07:22 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=103/
2022-11-28 22:07:22 [Loss]
2022-11-28 22:07:22 NUM_SUB: 103; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:07:22 NUM_SUB: 103; Personalized parameter estimation: Parameter containing:
tensor([0.1853, 0.8245, 0.0161, 0.1644, 0.3074, 0.3992, 0.7474, 0.8964, 0.4556,
        0.0150, 0.1076, 0.1079, 0.6278, 0.1689, 0.0174, 2.6763, 0.6977, 0.8000,
        0.0103, 3.8778, 0.6816, 0.0218, 3.6593, 0.8742, 0.0202, 4.4219, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:07:22 NUM_SUB: 103;----------------------------
2022-11-28 22:07:22 Epoch [30000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.669721s (9.65min in total, 0.00min remains)
2022-11-28 22:07:22 NUM_SUB: 103------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 22:07:22 Testing & drawing...
2022-11-28 22:07:22 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:07:23 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=103/
2022-11-28 22:07:23 [Loss]
2022-11-28 22:07:23 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:07:23 General parameter estimation: Parameter containing:
tensor([0.1853, 0.8245, 0.0161, 0.1644, 0.3074, 0.3992, 0.7474, 0.8964, 0.4556,
        0.0150, 0.1076, 0.1078, 0.6279, 0.1689, 0.0174, 2.6764, 0.6977, 0.8000,
        0.0103, 3.8779, 0.6816, 0.0218, 3.6594, 0.8742, 0.0202, 4.4220, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:07:23 A: prod, degr, TonA, NonA
2022-11-28 22:07:23 [0.26516962 0.49979186 0.01871545 0.2163231 ]
2022-11-28 22:07:23 T: prod, degr, AonT, NonT
2022-11-28 22:07:23 [0.15946537 0.48270404 0.34950128 0.00832933]
2022-11-28 22:07:23 N: AonN, TonN, ATonN
2022-11-28 22:07:23 [0.00733476 0.96932447 0.02334079]
2022-11-28 22:07:24 using cpu
2022-11-28 22:07:24 epoch = 30000
2022-11-28 22:07:24 epoch_step = 2000
2022-11-28 22:07:24 model_name = SimpleNetworkAD
2022-11-28 22:07:24 now_string = 2022-11-28-18-17-05
2022-11-28 22:07:24 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 22:07:24 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 22:07:24 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 22:07:24 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 22:07:24 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 22:07:24 --------------------------------------------------training start--------------------------------------------------
2022-11-28 22:08:03 NUM_SUB: 104;----------------------------
2022-11-28 22:08:03 Epoch [02000/30000] Loss:0.081973 Loss_1:0.080593 Loss_2:0.000805 Loss_3:0.000000 Lr:0.000833 Time:39.536145s (0.66min in total, 9.23min remains)
2022-11-28 22:08:43 NUM_SUB: 104;----------------------------
2022-11-28 22:08:43 Epoch [04000/30000] Loss:0.064933 Loss_1:0.064244 Loss_2:0.000209 Loss_3:0.000000 Lr:0.000714 Time:39.442480s (1.32min in total, 8.56min remains)
2022-11-28 22:09:22 NUM_SUB: 104;----------------------------
2022-11-28 22:09:22 Epoch [06000/30000] Loss:0.034654 Loss_1:0.034131 Loss_2:0.000206 Loss_3:0.000000 Lr:0.000625 Time:39.395415s (1.97min in total, 7.89min remains)
2022-11-28 22:10:01 NUM_SUB: 104;----------------------------
2022-11-28 22:10:01 Epoch [08000/30000] Loss:0.003312 Loss_1:0.003017 Loss_2:0.000244 Loss_3:0.000000 Lr:0.000556 Time:39.458382s (2.63min in total, 7.23min remains)
2022-11-28 22:10:41 NUM_SUB: 104;----------------------------
2022-11-28 22:10:41 Epoch [10000/30000] Loss:0.000306 Loss_1:0.000145 Loss_2:0.000161 Loss_3:0.000000 Lr:0.000500 Time:39.346244s (3.29min in total, 6.57min remains)
2022-11-28 22:11:20 NUM_SUB: 104;----------------------------
2022-11-28 22:11:20 Epoch [12000/30000] Loss:0.000079 Loss_1:0.000012 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000455 Time:39.238965s (3.94min in total, 5.91min remains)
2022-11-28 22:11:59 NUM_SUB: 104;----------------------------
2022-11-28 22:11:59 Epoch [14000/30000] Loss:0.000035 Loss_1:0.000000 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000417 Time:39.428612s (4.60min in total, 5.25min remains)
2022-11-28 22:12:39 NUM_SUB: 104;----------------------------
2022-11-28 22:12:39 Epoch [16000/30000] Loss:0.000019 Loss_1:0.000000 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:39.295074s (5.25min in total, 4.60min remains)
2022-11-28 22:13:18 NUM_SUB: 104;----------------------------
2022-11-28 22:13:18 Epoch [18000/30000] Loss:0.000011 Loss_1:0.000000 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:39.372098s (5.91min in total, 3.94min remains)
2022-11-28 22:13:58 NUM_SUB: 104;----------------------------
2022-11-28 22:13:58 Epoch [20000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:39.453972s (6.57min in total, 3.28min remains)
2022-11-28 22:14:37 NUM_SUB: 104;----------------------------
2022-11-28 22:14:37 Epoch [22000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:39.376081s (7.22min in total, 2.63min remains)
2022-11-28 22:15:16 NUM_SUB: 104;----------------------------
2022-11-28 22:15:16 Epoch [24000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:39.317833s (7.88min in total, 1.97min remains)
2022-11-28 22:15:56 NUM_SUB: 104;----------------------------
2022-11-28 22:15:56 Epoch [26000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:39.522798s (8.54min in total, 1.31min remains)
2022-11-28 22:16:35 NUM_SUB: 104;----------------------------
2022-11-28 22:16:35 Epoch [28000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:39.336274s (9.19min in total, 0.66min remains)
2022-11-28 22:17:15 Testing & drawing...
2022-11-28 22:17:15 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:17:16 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=104/
2022-11-28 22:17:16 [Loss]
2022-11-28 22:17:16 NUM_SUB: 104; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:17:16 NUM_SUB: 104; Personalized parameter estimation: Parameter containing:
tensor([5.2108e-01, 6.6168e-01, 1.3946e-01, 1.1776e-02, 3.0742e-01, 4.0163e-03,
        7.7101e-01, 8.9644e-01, 4.5563e-01, 1.1148e-02, 3.3447e-02, 1.5050e-02,
        4.3651e-01, 1.6886e-01, 1.7699e-02, 1.0733e+00, 6.9767e-01, 8.0001e-01,
        1.0016e-02, 5.2106e+00, 6.8161e-01, 2.1899e-02, 4.1614e+00, 8.7416e-01,
        9.1672e-03, 5.0608e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 22:17:16 NUM_SUB: 104;----------------------------
2022-11-28 22:17:16 Epoch [30000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:41.094940s (9.88min in total, 0.00min remains)
2022-11-28 22:17:16 NUM_SUB: 104------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 22:17:16 Testing & drawing...
2022-11-28 22:17:16 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:17:18 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=104/
2022-11-28 22:17:18 [Loss]
2022-11-28 22:17:18 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:17:18 General parameter estimation: Parameter containing:
tensor([5.2108e-01, 6.6167e-01, 1.3946e-01, 1.1769e-02, 3.0742e-01, 4.0117e-03,
        7.7101e-01, 8.9644e-01, 4.5563e-01, 1.1148e-02, 3.3438e-02, 1.5050e-02,
        4.3651e-01, 1.6886e-01, 1.7698e-02, 1.0734e+00, 6.9767e-01, 8.0001e-01,
        1.0016e-02, 5.2107e+00, 6.8161e-01, 2.1899e-02, 4.1615e+00, 8.7416e-01,
        9.1656e-03, 5.0609e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 22:17:18 A: prod, degr, TonA, NonA
2022-11-28 22:17:18 [0.39363617 0.49999592 0.10532188 0.00104605]
2022-11-28 22:17:18 T: prod, degr, AonT, NonT
2022-11-28 22:17:18 [0.18704493 0.56117356 0.18815167 0.06362983]
2022-11-28 22:17:18 N: AonN, TonN, ATonN
2022-11-28 22:17:18 [0.01639547 0.9592455  0.02435903]
2022-11-28 22:17:18 using cpu
2022-11-28 22:17:18 epoch = 30000
2022-11-28 22:17:18 epoch_step = 2000
2022-11-28 22:17:18 model_name = SimpleNetworkAD
2022-11-28 22:17:18 now_string = 2022-11-28-18-17-05
2022-11-28 22:17:18 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 22:17:18 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 22:17:18 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 22:17:18 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 22:17:18 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 22:17:18 --------------------------------------------------training start--------------------------------------------------
2022-11-28 22:17:57 NUM_SUB: 105;----------------------------
2022-11-28 22:17:57 Epoch [02000/30000] Loss:0.027951 Loss_1:0.026845 Loss_2:0.000701 Loss_3:0.000000 Lr:0.000833 Time:39.416828s (0.66min in total, 9.20min remains)
2022-11-28 22:18:37 NUM_SUB: 105;----------------------------
2022-11-28 22:18:37 Epoch [04000/30000] Loss:0.023132 Loss_1:0.022886 Loss_2:0.000160 Loss_3:0.000000 Lr:0.000714 Time:39.260978s (1.31min in total, 8.52min remains)
2022-11-28 22:19:16 NUM_SUB: 105;----------------------------
2022-11-28 22:19:16 Epoch [06000/30000] Loss:0.016184 Loss_1:0.016006 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000625 Time:39.278750s (1.97min in total, 7.86min remains)
2022-11-28 22:19:55 NUM_SUB: 105;----------------------------
2022-11-28 22:19:55 Epoch [08000/30000] Loss:0.007111 Loss_1:0.006959 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000556 Time:39.376363s (2.62min in total, 7.21min remains)
2022-11-28 22:20:35 NUM_SUB: 105;----------------------------
2022-11-28 22:20:35 Epoch [10000/30000] Loss:0.002412 Loss_1:0.002294 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000500 Time:39.257808s (3.28min in total, 6.55min remains)
2022-11-28 22:21:14 NUM_SUB: 105;----------------------------
2022-11-28 22:21:14 Epoch [12000/30000] Loss:0.001784 Loss_1:0.001741 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000455 Time:39.311772s (3.93min in total, 5.90min remains)
2022-11-28 22:21:53 NUM_SUB: 105;----------------------------
2022-11-28 22:21:53 Epoch [14000/30000] Loss:0.001627 Loss_1:0.001604 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:39.329441s (4.59min in total, 5.24min remains)
2022-11-28 22:22:32 NUM_SUB: 105;----------------------------
2022-11-28 22:22:32 Epoch [16000/30000] Loss:0.001523 Loss_1:0.001510 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:39.063727s (5.24min in total, 4.58min remains)
2022-11-28 22:23:11 NUM_SUB: 105;----------------------------
2022-11-28 22:23:11 Epoch [18000/30000] Loss:0.001120 Loss_1:0.001114 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.867428s (5.89min in total, 3.92min remains)
2022-11-28 22:23:50 NUM_SUB: 105;----------------------------
2022-11-28 22:23:50 Epoch [20000/30000] Loss:0.000920 Loss_1:0.000917 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.822918s (6.53min in total, 3.27min remains)
2022-11-28 22:24:29 NUM_SUB: 105;----------------------------
2022-11-28 22:24:29 Epoch [22000/30000] Loss:0.000915 Loss_1:0.000914 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.560959s (7.18min in total, 2.61min remains)
2022-11-28 22:25:07 NUM_SUB: 105;----------------------------
2022-11-28 22:25:07 Epoch [24000/30000] Loss:0.000911 Loss_1:0.000909 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.704597s (7.82min in total, 1.96min remains)
2022-11-28 22:25:46 NUM_SUB: 105;----------------------------
2022-11-28 22:25:46 Epoch [26000/30000] Loss:0.000909 Loss_1:0.000906 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.772324s (8.47min in total, 1.30min remains)
2022-11-28 22:26:25 NUM_SUB: 105;----------------------------
2022-11-28 22:26:25 Epoch [28000/30000] Loss:0.000907 Loss_1:0.000905 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.574046s (9.11min in total, 0.65min remains)
2022-11-28 22:27:03 Testing & drawing...
2022-11-28 22:27:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:27:05 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=105/
2022-11-28 22:27:05 [Loss]
2022-11-28 22:27:05 NUM_SUB: 105; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:27:05 NUM_SUB: 105; Personalized parameter estimation: Parameter containing:
tensor([0.0180, 0.0419, 0.0105, 1.0896, 0.3074, 0.0208, 1.0242, 0.8964, 0.4556,
        0.0138, 0.0296, 0.0137, 0.8117, 0.1689, 0.0175, 2.2425, 0.6977, 0.8000,
        0.0123, 2.8735, 0.6816, 0.0229, 2.5378, 0.8742, 0.0212, 3.2208, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:27:05 NUM_SUB: 105;----------------------------
2022-11-28 22:27:05 Epoch [30000/30000] Loss:0.000905 Loss_1:0.000903 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.508371s (9.79min in total, 0.00min remains)
2022-11-28 22:27:05 NUM_SUB: 105------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 22:27:05 Testing & drawing...
2022-11-28 22:27:05 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:27:07 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=105/
2022-11-28 22:27:07 [Loss]
2022-11-28 22:27:07 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:27:07 General parameter estimation: Parameter containing:
tensor([0.0180, 0.0419, 0.0105, 1.0896, 0.3074, 0.0208, 1.0242, 0.8964, 0.4556,
        0.0138, 0.0296, 0.0137, 0.8118, 0.1689, 0.0175, 2.2426, 0.6977, 0.8000,
        0.0123, 2.8735, 0.6816, 0.0229, 2.5378, 0.8742, 0.0212, 3.2207, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:27:07 A: prod, degr, TonA, NonA
2022-11-28 22:27:07 [0.38048425 0.47780818 0.05335051 0.08835702]
2022-11-28 22:27:07 T: prod, degr, AonT, NonT
2022-11-28 22:27:07 [0.38542402 0.44803265 0.13956511 0.02697827]
2022-11-28 22:27:07 N: AonN, TonN, ATonN
2022-11-28 22:27:07 [0.01925081 0.92273647 0.05801269]
2022-11-28 22:27:07 using cpu
2022-11-28 22:27:07 epoch = 30000
2022-11-28 22:27:07 epoch_step = 2000
2022-11-28 22:27:07 model_name = SimpleNetworkAD
2022-11-28 22:27:07 now_string = 2022-11-28-18-17-05
2022-11-28 22:27:07 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 22:27:07 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 22:27:07 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 22:27:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 22:27:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 22:27:07 --------------------------------------------------training start--------------------------------------------------
2022-11-28 22:27:46 NUM_SUB: 106;----------------------------
2022-11-28 22:27:46 Epoch [02000/30000] Loss:0.069629 Loss_1:0.068446 Loss_2:0.000719 Loss_3:0.000000 Lr:0.000833 Time:38.830697s (0.65min in total, 9.06min remains)
2022-11-28 22:28:24 NUM_SUB: 106;----------------------------
2022-11-28 22:28:24 Epoch [04000/30000] Loss:0.054849 Loss_1:0.054294 Loss_2:0.000186 Loss_3:0.000000 Lr:0.000714 Time:38.656690s (1.29min in total, 8.39min remains)
2022-11-28 22:29:03 NUM_SUB: 106;----------------------------
2022-11-28 22:29:03 Epoch [06000/30000] Loss:0.029689 Loss_1:0.029305 Loss_2:0.000148 Loss_3:0.000000 Lr:0.000625 Time:38.845857s (1.94min in total, 7.76min remains)
2022-11-28 22:29:42 NUM_SUB: 106;----------------------------
2022-11-28 22:29:42 Epoch [08000/30000] Loss:0.006642 Loss_1:0.006456 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000556 Time:38.838898s (2.59min in total, 7.11min remains)
2022-11-28 22:30:21 NUM_SUB: 106;----------------------------
2022-11-28 22:30:21 Epoch [10000/30000] Loss:0.002568 Loss_1:0.002445 Loss_2:0.000122 Loss_3:0.000000 Lr:0.000500 Time:38.589423s (3.23min in total, 6.46min remains)
2022-11-28 22:31:00 NUM_SUB: 106;----------------------------
2022-11-28 22:31:00 Epoch [12000/30000] Loss:0.001732 Loss_1:0.001683 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:38.847438s (3.88min in total, 5.82min remains)
2022-11-28 22:31:38 NUM_SUB: 106;----------------------------
2022-11-28 22:31:38 Epoch [14000/30000] Loss:0.001188 Loss_1:0.001158 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:38.798358s (4.52min in total, 5.17min remains)
2022-11-28 22:32:17 NUM_SUB: 106;----------------------------
2022-11-28 22:32:17 Epoch [16000/30000] Loss:0.001028 Loss_1:0.001011 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.607963s (5.17min in total, 4.52min remains)
2022-11-28 22:32:56 NUM_SUB: 106;----------------------------
2022-11-28 22:32:56 Epoch [18000/30000] Loss:0.001019 Loss_1:0.001007 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:38.842907s (5.81min in total, 3.88min remains)
2022-11-28 22:33:34 NUM_SUB: 106;----------------------------
2022-11-28 22:33:34 Epoch [20000/30000] Loss:0.001012 Loss_1:0.001006 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.714950s (6.46min in total, 3.23min remains)
2022-11-28 22:34:13 NUM_SUB: 106;----------------------------
2022-11-28 22:34:13 Epoch [22000/30000] Loss:0.001011 Loss_1:0.001006 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.815573s (7.11min in total, 2.58min remains)
2022-11-28 22:34:52 NUM_SUB: 106;----------------------------
2022-11-28 22:34:52 Epoch [24000/30000] Loss:0.001008 Loss_1:0.001006 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.898772s (7.75min in total, 1.94min remains)
2022-11-28 22:35:31 NUM_SUB: 106;----------------------------
2022-11-28 22:35:31 Epoch [26000/30000] Loss:0.001008 Loss_1:0.001006 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.626256s (8.40min in total, 1.29min remains)
2022-11-28 22:36:10 NUM_SUB: 106;----------------------------
2022-11-28 22:36:10 Epoch [28000/30000] Loss:0.001006 Loss_1:0.001005 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.309478s (9.05min in total, 0.65min remains)
2022-11-28 22:36:50 Testing & drawing...
2022-11-28 22:36:50 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:36:51 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=106/
2022-11-28 22:36:51 [Loss]
2022-11-28 22:36:51 NUM_SUB: 106; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:36:51 NUM_SUB: 106; Personalized parameter estimation: Parameter containing:
tensor([0.0820, 0.2673, 0.0249, 0.0086, 0.3074, 0.2075, 0.8286, 0.8964, 0.4556,
        0.0138, 0.0281, 0.0140, 0.9743, 0.1689, 0.0175, 2.7165, 0.6977, 0.8000,
        0.0106, 4.8334, 0.6816, 0.0214, 4.1297, 0.8742, 0.0183, 5.0164, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:36:51 NUM_SUB: 106;----------------------------
2022-11-28 22:36:51 Epoch [30000/30000] Loss:0.001006 Loss_1:0.001005 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:41.159394s (9.74min in total, 0.00min remains)
2022-11-28 22:36:51 NUM_SUB: 106------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 22:36:51 Testing & drawing...
2022-11-28 22:36:51 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:36:53 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=106/
2022-11-28 22:36:53 [Loss]
2022-11-28 22:36:53 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:36:53 General parameter estimation: Parameter containing:
tensor([0.0820, 0.2673, 0.0249, 0.0086, 0.3074, 0.2075, 0.8286, 0.8964, 0.4556,
        0.0138, 0.0281, 0.0140, 0.9743, 0.1689, 0.0175, 2.7166, 0.6977, 0.8000,
        0.0106, 4.8335, 0.6816, 0.0214, 4.1299, 0.8742, 0.0183, 5.0166, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 22:36:53 A: prod, degr, TonA, NonA
2022-11-28 22:36:53 [0.22928305 0.4982148  0.06964192 0.20286024]
2022-11-28 22:36:53 T: prod, degr, AonT, NonT
2022-11-28 22:36:53 [0.37008318 0.5010464  0.10663443 0.02223598]
2022-11-28 22:36:53 N: AonN, TonN, ATonN
2022-11-28 22:36:53 [0.00955701 0.96213686 0.02830616]
2022-11-28 22:36:53 using cpu
2022-11-28 22:36:53 epoch = 30000
2022-11-28 22:36:53 epoch_step = 2000
2022-11-28 22:36:53 model_name = SimpleNetworkAD
2022-11-28 22:36:53 now_string = 2022-11-28-18-17-05
2022-11-28 22:36:53 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 22:36:53 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 22:36:53 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 22:36:53 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 22:36:53 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 22:36:53 --------------------------------------------------training start--------------------------------------------------
2022-11-28 22:37:32 NUM_SUB: 107;----------------------------
2022-11-28 22:37:32 Epoch [02000/30000] Loss:0.267887 Loss_1:0.266191 Loss_2:0.000709 Loss_3:0.000000 Lr:0.000833 Time:39.354098s (0.66min in total, 9.18min remains)
2022-11-28 22:38:12 NUM_SUB: 107;----------------------------
2022-11-28 22:38:12 Epoch [04000/30000] Loss:0.213764 Loss_1:0.212166 Loss_2:0.000176 Loss_3:0.000000 Lr:0.000714 Time:39.495215s (1.31min in total, 8.54min remains)
2022-11-28 22:38:52 NUM_SUB: 107;----------------------------
2022-11-28 22:38:52 Epoch [06000/30000] Loss:0.094369 Loss_1:0.093271 Loss_2:0.000224 Loss_3:0.000000 Lr:0.000625 Time:40.001255s (1.98min in total, 7.92min remains)
2022-11-28 22:39:31 NUM_SUB: 107;----------------------------
2022-11-28 22:39:31 Epoch [08000/30000] Loss:0.002797 Loss_1:0.002395 Loss_2:0.000326 Loss_3:0.000000 Lr:0.000556 Time:38.742515s (2.63min in total, 7.22min remains)
2022-11-28 22:40:10 NUM_SUB: 107;----------------------------
2022-11-28 22:40:10 Epoch [10000/30000] Loss:0.000462 Loss_1:0.000247 Loss_2:0.000213 Loss_3:0.000000 Lr:0.000500 Time:38.825053s (3.27min in total, 6.55min remains)
2022-11-28 22:40:48 NUM_SUB: 107;----------------------------
2022-11-28 22:40:48 Epoch [12000/30000] Loss:0.000283 Loss_1:0.000172 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000455 Time:38.602300s (3.92min in total, 5.88min remains)
2022-11-28 22:41:26 NUM_SUB: 107;----------------------------
2022-11-28 22:41:26 Epoch [14000/30000] Loss:0.000208 Loss_1:0.000150 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000417 Time:38.275329s (4.56min in total, 5.21min remains)
2022-11-28 22:42:05 NUM_SUB: 107;----------------------------
2022-11-28 22:42:05 Epoch [16000/30000] Loss:0.000165 Loss_1:0.000131 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000385 Time:38.650693s (5.20min in total, 4.55min remains)
2022-11-28 22:42:44 NUM_SUB: 107;----------------------------
2022-11-28 22:42:44 Epoch [18000/30000] Loss:0.000140 Loss_1:0.000116 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000357 Time:38.611003s (5.84min in total, 3.90min remains)
2022-11-28 22:43:22 NUM_SUB: 107;----------------------------
2022-11-28 22:43:22 Epoch [20000/30000] Loss:0.000113 Loss_1:0.000095 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000333 Time:38.245194s (6.48min in total, 3.24min remains)
2022-11-28 22:44:00 NUM_SUB: 107;----------------------------
2022-11-28 22:44:00 Epoch [22000/30000] Loss:0.000033 Loss_1:0.000021 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000313 Time:38.513964s (7.12min in total, 2.59min remains)
2022-11-28 22:44:39 NUM_SUB: 107;----------------------------
2022-11-28 22:44:39 Epoch [24000/30000] Loss:0.000032 Loss_1:0.000023 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000294 Time:38.445084s (7.76min in total, 1.94min remains)
2022-11-28 22:45:17 NUM_SUB: 107;----------------------------
2022-11-28 22:45:17 Epoch [26000/30000] Loss:0.000021 Loss_1:0.000016 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.399461s (8.40min in total, 1.29min remains)
2022-11-28 22:45:56 NUM_SUB: 107;----------------------------
2022-11-28 22:45:56 Epoch [28000/30000] Loss:0.000018 Loss_1:0.000015 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.558864s (9.05min in total, 0.65min remains)
2022-11-28 22:46:34 Testing & drawing...
2022-11-28 22:46:34 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:46:36 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=107/
2022-11-28 22:46:36 [Loss]
2022-11-28 22:46:36 NUM_SUB: 107; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:46:36 NUM_SUB: 107; Personalized parameter estimation: Parameter containing:
tensor([1.1806e-02, 3.5187e-01, 2.0318e-02, 1.2186e+00, 3.0742e-01, 9.1956e-01,
        1.4359e+00, 8.9644e-01, 4.5563e-01, 8.5985e-03, 3.7756e-02, 1.4940e-02,
        3.4874e-01, 1.6886e-01, 1.7492e-02, 2.8406e-01, 6.9767e-01, 8.0001e-01,
        4.9690e-03, 5.0510e+00, 6.8161e-01, 2.2301e-02, 4.4247e+00, 8.7416e-01,
        1.5606e-02, 5.2567e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 22:46:36 NUM_SUB: 107;----------------------------
2022-11-28 22:46:36 Epoch [30000/30000] Loss:0.000022 Loss_1:0.000017 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:39.871356s (9.71min in total, 0.00min remains)
2022-11-28 22:46:36 NUM_SUB: 107------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 22:46:36 Testing & drawing...
2022-11-28 22:46:36 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 22:46:37 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=107/
2022-11-28 22:46:37 [Loss]
2022-11-28 22:46:37 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 22:46:37 General parameter estimation: Parameter containing:
tensor([1.1806e-02, 3.5193e-01, 2.0317e-02, 1.2187e+00, 3.0742e-01, 9.1950e-01,
        1.4360e+00, 8.9644e-01, 4.5563e-01, 8.5985e-03, 3.7753e-02, 1.4940e-02,
        3.4880e-01, 1.6886e-01, 1.7492e-02, 2.8404e-01, 6.9767e-01, 8.0001e-01,
        4.9680e-03, 5.0511e+00, 6.8161e-01, 2.2301e-02, 4.4247e+00, 8.7416e-01,
        1.5606e-02, 5.2568e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 22:46:37 A: prod, degr, TonA, NonA
2022-11-28 22:46:37 [0.01681892 0.4967445  0.01159076 0.47484583]
2022-11-28 22:46:37 T: prod, degr, AonT, NonT
2022-11-28 22:46:37 [0.11300031 0.49725756 0.17493212 0.21480998]
2022-11-28 22:46:37 N: AonN, TonN, ATonN
2022-11-28 22:46:37 [0.00851795 0.94463503 0.04684702]
2022-11-28 22:46:38 using cpu
2022-11-28 22:46:38 epoch = 30000
2022-11-28 22:46:38 epoch_step = 2000
2022-11-28 22:46:38 model_name = SimpleNetworkAD
2022-11-28 22:46:38 now_string = 2022-11-28-18-17-05
2022-11-28 22:46:38 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 22:46:38 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 22:46:38 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 22:46:38 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 22:46:38 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 22:46:38 --------------------------------------------------training start--------------------------------------------------
2022-11-28 22:47:16 NUM_SUB: 108;----------------------------
2022-11-28 22:47:16 Epoch [02000/30000] Loss:0.100067 Loss_1:0.098768 Loss_2:0.000814 Loss_3:0.000000 Lr:0.000833 Time:38.361041s (0.64min in total, 8.95min remains)
2022-11-28 22:47:54 NUM_SUB: 108;----------------------------
2022-11-28 22:47:54 Epoch [04000/30000] Loss:0.078825 Loss_1:0.078081 Loss_2:0.000322 Loss_3:0.000000 Lr:0.000714 Time:38.512099s (1.28min in total, 8.33min remains)
2022-11-28 22:48:33 NUM_SUB: 108;----------------------------
2022-11-28 22:48:33 Epoch [06000/30000] Loss:0.037558 Loss_1:0.037093 Loss_2:0.000172 Loss_3:0.000000 Lr:0.000625 Time:38.251070s (1.92min in total, 7.68min remains)
2022-11-28 22:49:27 NUM_SUB: 108;----------------------------
2022-11-28 22:49:27 Epoch [08000/30000] Loss:0.004134 Loss_1:0.003966 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000556 Time:54.375557s (2.83min in total, 7.77min remains)
2022-11-28 22:50:05 NUM_SUB: 108;----------------------------
2022-11-28 22:50:05 Epoch [10000/30000] Loss:0.000294 Loss_1:0.000202 Loss_2:0.000087 Loss_3:0.000000 Lr:0.000500 Time:38.415187s (3.47min in total, 6.93min remains)
2022-11-28 22:59:41 NUM_SUB: 108;----------------------------
2022-11-28 22:59:41 Epoch [12000/30000] Loss:0.000130 Loss_1:0.000081 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:575.886781s (13.06min in total, 19.60min remains)
2022-11-28 23:00:38 NUM_SUB: 108;----------------------------
2022-11-28 23:00:38 Epoch [14000/30000] Loss:0.000089 Loss_1:0.000066 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:56.950025s (14.01min in total, 16.01min remains)
2022-11-28 23:01:41 NUM_SUB: 108;----------------------------
2022-11-28 23:01:41 Epoch [16000/30000] Loss:0.000062 Loss_1:0.000047 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:62.247088s (15.05min in total, 13.17min remains)
2022-11-28 23:02:42 NUM_SUB: 108;----------------------------
2022-11-28 23:02:42 Epoch [18000/30000] Loss:0.000042 Loss_1:0.000033 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:61.213818s (16.07min in total, 10.71min remains)
2022-11-28 23:03:43 NUM_SUB: 108;----------------------------
2022-11-28 23:03:43 Epoch [20000/30000] Loss:0.000039 Loss_1:0.000033 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:61.334235s (17.09min in total, 8.55min remains)
2022-11-28 23:04:21 NUM_SUB: 108;----------------------------
2022-11-28 23:04:21 Epoch [22000/30000] Loss:0.000033 Loss_1:0.000029 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.299558s (17.73min in total, 6.45min remains)
2022-11-28 23:05:23 NUM_SUB: 108;----------------------------
2022-11-28 23:05:23 Epoch [24000/30000] Loss:0.000032 Loss_1:0.000028 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:61.178459s (18.75min in total, 4.69min remains)
2022-11-28 23:06:25 NUM_SUB: 108;----------------------------
2022-11-28 23:06:25 Epoch [26000/30000] Loss:0.000030 Loss_1:0.000027 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:62.193378s (19.79min in total, 3.04min remains)
2022-11-28 23:07:27 NUM_SUB: 108;----------------------------
2022-11-28 23:07:27 Epoch [28000/30000] Loss:0.000032 Loss_1:0.000030 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:61.996738s (20.82min in total, 1.49min remains)
2022-11-28 23:08:27 Testing & drawing...
2022-11-28 23:08:27 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 23:08:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=108/
2022-11-28 23:08:29 [Loss]
2022-11-28 23:08:29 NUM_SUB: 108; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 23:08:29 NUM_SUB: 108; Personalized parameter estimation: Parameter containing:
tensor([0.0151, 0.0232, 0.0108, 2.4134, 0.3074, 0.0169, 3.2874, 0.8964, 0.4556,
        0.0123, 0.0433, 0.0114, 0.4160, 0.1689, 0.0175, 1.7414, 0.6977, 0.8000,
        0.0114, 4.4283, 0.6816, 0.0219, 3.5726, 0.8742, 0.0169, 4.5346, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 23:08:29 NUM_SUB: 108;----------------------------
2022-11-28 23:08:29 Epoch [30000/30000] Loss:0.000028 Loss_1:0.000027 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:61.971823s (21.85min in total, 0.00min remains)
2022-11-28 23:08:29 NUM_SUB: 108------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 23:08:29 Testing & drawing...
2022-11-28 23:08:29 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 23:08:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=108/
2022-11-28 23:08:30 [Loss]
2022-11-28 23:08:30 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 23:08:30 General parameter estimation: Parameter containing:
tensor([0.0151, 0.0232, 0.0108, 2.4135, 0.3074, 0.0169, 3.2875, 0.8964, 0.4556,
        0.0123, 0.0433, 0.0114, 0.4160, 0.1689, 0.0175, 1.7415, 0.6977, 0.8000,
        0.0114, 4.4284, 0.6816, 0.0219, 3.5727, 0.8742, 0.0169, 4.5347, 0.9527,
        0.0362], requires_grad=True);
2022-11-28 23:08:30 A: prod, degr, TonA, NonA
2022-11-28 23:08:30 [0.4780996  0.4716397  0.01501209 0.03524865]
2022-11-28 23:08:30 T: prod, degr, AonT, NonT
2022-11-28 23:08:30 [0.24401373 0.54979223 0.13684656 0.06934746]
2022-11-28 23:08:30 N: AonN, TonN, ATonN
2022-11-28 23:08:30 [0.01190552 0.96105653 0.02703801]
2022-11-28 23:08:31 using cpu
2022-11-28 23:08:31 epoch = 30000
2022-11-28 23:08:31 epoch_step = 2000
2022-11-28 23:08:31 model_name = SimpleNetworkAD
2022-11-28 23:08:31 now_string = 2022-11-28-18-17-05
2022-11-28 23:08:31 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 23:08:31 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 23:08:31 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 23:08:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 23:08:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 23:08:31 --------------------------------------------------training start--------------------------------------------------
2022-11-28 23:09:34 NUM_SUB: 109;----------------------------
2022-11-28 23:09:34 Epoch [02000/30000] Loss:0.121186 Loss_1:0.120284 Loss_2:0.000493 Loss_3:0.000000 Lr:0.000833 Time:63.130107s (1.05min in total, 14.73min remains)
2022-11-28 23:10:12 NUM_SUB: 109;----------------------------
2022-11-28 23:10:12 Epoch [04000/30000] Loss:0.089290 Loss_1:0.088934 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000714 Time:38.086216s (1.69min in total, 10.97min remains)
2022-11-28 23:11:12 NUM_SUB: 109;----------------------------
2022-11-28 23:11:12 Epoch [06000/30000] Loss:0.033237 Loss_1:0.032989 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000625 Time:60.450927s (2.69min in total, 10.78min remains)
2022-11-28 23:12:13 NUM_SUB: 109;----------------------------
2022-11-28 23:12:13 Epoch [08000/30000] Loss:0.008546 Loss_1:0.008423 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000556 Time:61.251310s (3.72min in total, 10.22min remains)
2022-11-28 23:13:16 NUM_SUB: 109;----------------------------
2022-11-28 23:13:16 Epoch [10000/30000] Loss:0.004254 Loss_1:0.004159 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000500 Time:62.130029s (4.75min in total, 9.50min remains)
2022-11-28 23:14:17 NUM_SUB: 109;----------------------------
2022-11-28 23:14:17 Epoch [12000/30000] Loss:0.003757 Loss_1:0.003721 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:61.446698s (5.77min in total, 8.66min remains)
2022-11-28 23:15:18 NUM_SUB: 109;----------------------------
2022-11-28 23:15:19 Epoch [14000/30000] Loss:0.003712 Loss_1:0.003696 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000417 Time:61.427263s (6.80min in total, 7.77min remains)
2022-11-28 23:15:57 NUM_SUB: 109;----------------------------
2022-11-28 23:15:57 Epoch [16000/30000] Loss:0.003705 Loss_1:0.003694 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:38.067476s (7.44min in total, 6.51min remains)
2022-11-28 23:16:58 NUM_SUB: 109;----------------------------
2022-11-28 23:16:58 Epoch [18000/30000] Loss:0.003699 Loss_1:0.003693 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:61.425789s (8.46min in total, 5.64min remains)
2022-11-28 23:18:00 NUM_SUB: 109;----------------------------
2022-11-28 23:18:00 Epoch [20000/30000] Loss:0.003696 Loss_1:0.003689 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:61.632202s (9.49min in total, 4.74min remains)
2022-11-28 23:19:02 NUM_SUB: 109;----------------------------
2022-11-28 23:19:02 Epoch [22000/30000] Loss:0.003694 Loss_1:0.003691 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:61.899042s (10.52min in total, 3.82min remains)
2022-11-28 23:20:03 NUM_SUB: 109;----------------------------
2022-11-28 23:20:03 Epoch [24000/30000] Loss:0.003694 Loss_1:0.003689 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:61.377406s (11.54min in total, 2.89min remains)
2022-11-28 23:20:41 NUM_SUB: 109;----------------------------
2022-11-28 23:20:41 Epoch [26000/30000] Loss:0.003694 Loss_1:0.003689 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.248843s (12.18min in total, 1.87min remains)
2022-11-28 23:21:42 NUM_SUB: 109;----------------------------
2022-11-28 23:21:42 Epoch [28000/30000] Loss:0.003693 Loss_1:0.003691 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:61.052226s (13.20min in total, 0.94min remains)
2022-11-28 23:22:45 Testing & drawing...
2022-11-28 23:22:45 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 23:22:46 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=109/
2022-11-28 23:22:46 [Loss]
2022-11-28 23:22:46 NUM_SUB: 109; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 23:22:46 NUM_SUB: 109; Personalized parameter estimation: Parameter containing:
tensor([3.9973e-01, 8.8676e-01, 9.8852e-03, 5.2148e-24, 3.0742e-01, 1.3614e-02,
        1.1691e-01, 8.9644e-01, 4.5563e-01, 1.3215e-02, 4.3883e-02, 1.2521e-02,
        5.8846e-01, 1.6886e-01, 1.7883e-02, 1.2483e+00, 6.9767e-01, 8.0001e-01,
        1.2189e-02, 3.4925e+00, 6.8161e-01, 2.2641e-02, 3.3760e+00, 8.7416e-01,
        2.0987e-02, 4.0619e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 23:22:46 NUM_SUB: 109;----------------------------
2022-11-28 23:22:46 Epoch [30000/30000] Loss:0.003693 Loss_1:0.003691 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:64.046449s (14.26min in total, 0.00min remains)
2022-11-28 23:22:46 NUM_SUB: 109------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-28 23:22:46 Testing & drawing...
2022-11-28 23:22:46 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-28 23:22:48 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=109/
2022-11-28 23:22:48 [Loss]
2022-11-28 23:22:48 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-28 23:22:48 General parameter estimation: Parameter containing:
tensor([3.9975e-01, 8.8674e-01, 9.9062e-03, 5.1621e-24, 3.0742e-01, 1.3614e-02,
        1.1688e-01, 8.9644e-01, 4.5563e-01, 1.3215e-02, 4.3876e-02, 1.2521e-02,
        5.8844e-01, 1.6886e-01, 1.7883e-02, 1.2483e+00, 6.9767e-01, 8.0001e-01,
        1.2189e-02, 3.4924e+00, 6.8161e-01, 2.2641e-02, 3.3761e+00, 8.7416e-01,
        2.0987e-02, 4.0619e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-28 23:22:48 A: prod, degr, TonA, NonA
2022-11-28 23:22:48 [0.4725742  0.49990267 0.01171076 0.01581233]
2022-11-28 23:22:48 T: prod, degr, AonT, NonT
2022-11-28 23:22:48 [0.28718603 0.45472237 0.12827355 0.12981808]
2022-11-28 23:22:48 N: AonN, TonN, ATonN
2022-11-28 23:22:48 [0.01032817 0.95892525 0.03074663]
2022-11-28 23:22:48 using cpu
2022-11-28 23:22:48 epoch = 30000
2022-11-28 23:22:48 epoch_step = 2000
2022-11-28 23:22:48 model_name = SimpleNetworkAD
2022-11-28 23:22:48 now_string = 2022-11-28-18-17-05
2022-11-28 23:22:48 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-28 23:22:48 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-28 23:22:48 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-28 23:22:48 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-28 23:22:48 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-28 23:22:48 --------------------------------------------------training start--------------------------------------------------
2022-11-28 23:23:50 NUM_SUB: 110;----------------------------
2022-11-28 23:23:50 Epoch [02000/30000] Loss:0.061950 Loss_1:0.060808 Loss_2:0.000703 Loss_3:0.000000 Lr:0.000833 Time:62.328723s (1.04min in total, 14.54min remains)
2022-11-28 23:24:52 NUM_SUB: 110;----------------------------
2022-11-28 23:24:52 Epoch [04000/30000] Loss:0.050533 Loss_1:0.050083 Loss_2:0.000229 Loss_3:0.000000 Lr:0.000714 Time:61.102653s (2.06min in total, 13.37min remains)
2022-11-28 23:25:52 NUM_SUB: 110;----------------------------
2022-11-28 23:25:52 Epoch [06000/30000] Loss:0.030820 Loss_1:0.030475 Loss_2:0.000178 Loss_3:0.000000 Lr:0.000625 Time:60.386242s (3.06min in total, 12.25min remains)
2022-11-28 23:26:30 NUM_SUB: 110;----------------------------
2022-11-28 23:26:30 Epoch [08000/30000] Loss:0.007917 Loss_1:0.007706 Loss_2:0.000158 Loss_3:0.000000 Lr:0.000556 Time:38.092622s (3.70min in total, 10.17min remains)
2022-11-28 23:27:31 NUM_SUB: 110;----------------------------
2022-11-28 23:27:31 Epoch [10000/30000] Loss:0.002771 Loss_1:0.002652 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000500 Time:61.371626s (4.72min in total, 9.44min remains)
2022-11-28 23:39:13 NUM_SUB: 110;----------------------------
2022-11-28 23:39:13 Epoch [12000/30000] Loss:0.002425 Loss_1:0.002364 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000455 Time:701.864500s (16.42min in total, 24.63min remains)
2022-11-28 23:53:21 NUM_SUB: 110;----------------------------
2022-11-28 23:53:21 Epoch [14000/30000] Loss:0.001626 Loss_1:0.001594 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000417 Time:847.512038s (30.54min in total, 34.91min remains)
2022-11-28 23:53:59 NUM_SUB: 110;----------------------------
2022-11-28 23:53:59 Epoch [16000/30000] Loss:0.001476 Loss_1:0.001458 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:38.327555s (31.18min in total, 27.29min remains)
2022-11-28 23:54:39 NUM_SUB: 110;----------------------------
2022-11-28 23:54:39 Epoch [18000/30000] Loss:0.001465 Loss_1:0.001452 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:39.651068s (31.84min in total, 21.23min remains)
2022-11-28 23:55:41 NUM_SUB: 110;----------------------------
2022-11-28 23:55:41 Epoch [20000/30000] Loss:0.001460 Loss_1:0.001451 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:61.746555s (32.87min in total, 16.44min remains)
2022-11-28 23:56:41 NUM_SUB: 110;----------------------------
2022-11-28 23:56:41 Epoch [22000/30000] Loss:0.001457 Loss_1:0.001450 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:60.759981s (33.89min in total, 12.32min remains)
2022-11-28 23:57:43 NUM_SUB: 110;----------------------------
2022-11-28 23:57:43 Epoch [24000/30000] Loss:0.001456 Loss_1:0.001450 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:61.390676s (34.91min in total, 8.73min remains)
2022-11-28 23:58:21 NUM_SUB: 110;----------------------------
2022-11-28 23:58:21 Epoch [26000/30000] Loss:0.001455 Loss_1:0.001450 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.204535s (35.55min in total, 5.47min remains)
2022-11-28 23:59:20 NUM_SUB: 110;----------------------------
2022-11-28 23:59:20 Epoch [28000/30000] Loss:0.001462 Loss_1:0.001457 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:59.542639s (36.54min in total, 2.61min remains)
2022-11-28 23:59:59 Testing & drawing...
2022-11-28 23:59:59 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 00:00:00 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=110/
2022-11-29 00:00:00 [Loss]
2022-11-29 00:00:00 NUM_SUB: 110; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 00:00:00 NUM_SUB: 110; Personalized parameter estimation: Parameter containing:
tensor([0.0181, 0.0280, 0.0231, 1.9093, 0.3074, 0.0162, 2.4533, 0.8964, 0.4556,
        0.0139, 0.0390, 0.0134, 0.8782, 0.1689, 0.0183, 1.3021, 0.6977, 0.8000,
        0.0118, 3.9881, 0.6816, 0.0229, 2.9535, 0.8742, 0.0202, 3.9234, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 00:00:00 NUM_SUB: 110;----------------------------
2022-11-29 00:00:00 Epoch [30000/30000] Loss:0.001454 Loss_1:0.001448 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:40.055035s (37.21min in total, 0.00min remains)
2022-11-29 00:00:00 NUM_SUB: 110------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 00:00:00 Testing & drawing...
2022-11-29 00:00:01 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 00:00:02 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=110/
2022-11-29 00:00:02 [Loss]
2022-11-29 00:00:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 00:00:02 General parameter estimation: Parameter containing:
tensor([0.0181, 0.0280, 0.0231, 1.9094, 0.3074, 0.0162, 2.4533, 0.8964, 0.4556,
        0.0139, 0.0390, 0.0134, 0.8782, 0.1689, 0.0183, 1.3021, 0.6977, 0.8000,
        0.0118, 3.9880, 0.6816, 0.0229, 2.9534, 0.8742, 0.0202, 3.9232, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 00:00:02 A: prod, degr, TonA, NonA
2022-11-29 00:00:02 [0.43103662 0.4730559  0.04681823 0.04908926]
2022-11-29 00:00:02 T: prod, degr, AonT, NonT
2022-11-29 00:00:02 [0.2692884  0.5346351  0.07806497 0.11801153]
2022-11-29 00:00:02 N: AonN, TonN, ATonN
2022-11-29 00:00:02 [0.01675032 0.93529344 0.04795624]
2022-11-29 00:00:02 using cpu
2022-11-29 00:00:02 epoch = 30000
2022-11-29 00:00:02 epoch_step = 2000
2022-11-29 00:00:02 model_name = SimpleNetworkAD
2022-11-29 00:00:02 now_string = 2022-11-28-18-17-05
2022-11-29 00:00:02 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 00:00:02 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 00:00:02 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 00:00:02 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 00:00:02 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 00:00:02 --------------------------------------------------training start--------------------------------------------------
2022-11-29 00:14:24 NUM_SUB: 111;----------------------------
2022-11-29 00:14:24 Epoch [02000/30000] Loss:0.079616 Loss_1:0.078540 Loss_2:0.000699 Loss_3:0.000000 Lr:0.000833 Time:862.178553s (14.37min in total, 201.17min remains)
2022-11-29 00:30:36 NUM_SUB: 111;----------------------------
2022-11-29 00:30:37 Epoch [04000/30000] Loss:0.063325 Loss_1:0.062796 Loss_2:0.000263 Loss_3:0.000000 Lr:0.000714 Time:971.956306s (30.57min in total, 198.70min remains)
2022-11-29 00:31:26 NUM_SUB: 111;----------------------------
2022-11-29 00:31:26 Epoch [06000/30000] Loss:0.032260 Loss_1:0.031913 Loss_2:0.000174 Loss_3:0.000000 Lr:0.000625 Time:49.350787s (31.39min in total, 125.58min remains)
2022-11-29 01:19:21 NUM_SUB: 111;----------------------------
2022-11-29 01:19:21 Epoch [08000/30000] Loss:0.005068 Loss_1:0.004955 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000556 Time:2874.966145s (79.31min in total, 218.10min remains)
2022-11-29 01:19:59 NUM_SUB: 111;----------------------------
2022-11-29 01:19:59 Epoch [10000/30000] Loss:0.001513 Loss_1:0.001405 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000500 Time:38.343388s (79.95min in total, 159.90min remains)
2022-11-29 01:20:38 NUM_SUB: 111;----------------------------
2022-11-29 01:20:38 Epoch [12000/30000] Loss:0.000316 Loss_1:0.000275 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000455 Time:38.374236s (80.59min in total, 120.88min remains)
2022-11-29 01:21:16 NUM_SUB: 111;----------------------------
2022-11-29 01:21:16 Epoch [14000/30000] Loss:0.000149 Loss_1:0.000123 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:38.340182s (81.23min in total, 92.83min remains)
2022-11-29 01:21:54 NUM_SUB: 111;----------------------------
2022-11-29 01:21:54 Epoch [16000/30000] Loss:0.000113 Loss_1:0.000094 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:38.295826s (81.87min in total, 71.63min remains)
2022-11-29 01:22:33 NUM_SUB: 111;----------------------------
2022-11-29 01:22:33 Epoch [18000/30000] Loss:0.000092 Loss_1:0.000081 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.387350s (82.51min in total, 55.00min remains)
2022-11-29 01:23:11 NUM_SUB: 111;----------------------------
2022-11-29 01:23:11 Epoch [20000/30000] Loss:0.000101 Loss_1:0.000093 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:38.296518s (83.14min in total, 41.57min remains)
2022-11-29 01:23:49 NUM_SUB: 111;----------------------------
2022-11-29 01:23:49 Epoch [22000/30000] Loss:0.000100 Loss_1:0.000093 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.422882s (83.78min in total, 30.47min remains)
2022-11-29 01:24:28 NUM_SUB: 111;----------------------------
2022-11-29 01:24:28 Epoch [24000/30000] Loss:0.000085 Loss_1:0.000079 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.386636s (84.42min in total, 21.11min remains)
2022-11-29 01:25:06 NUM_SUB: 111;----------------------------
2022-11-29 01:25:06 Epoch [26000/30000] Loss:0.000081 Loss_1:0.000076 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.322530s (85.06min in total, 13.09min remains)
2022-11-29 01:25:44 NUM_SUB: 111;----------------------------
2022-11-29 01:25:44 Epoch [28000/30000] Loss:0.000089 Loss_1:0.000086 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.318319s (85.70min in total, 6.12min remains)
2022-11-29 01:26:23 Testing & drawing...
2022-11-29 01:26:23 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:26:24 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=111/
2022-11-29 01:26:24 [Loss]
2022-11-29 01:26:24 NUM_SUB: 111; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:26:24 NUM_SUB: 111; Personalized parameter estimation: Parameter containing:
tensor([0.0150, 0.0425, 0.0099, 1.1792, 0.3074, 0.0173, 3.6071, 0.8964, 0.4556,
        0.0144, 0.0330, 0.0139, 0.8590, 0.1689, 0.0173, 3.0779, 0.6977, 0.8000,
        0.0120, 3.6789, 0.6816, 0.0222, 3.5663, 0.8742, 0.0201, 4.3103, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:26:24 NUM_SUB: 111;----------------------------
2022-11-29 01:26:24 Epoch [30000/30000] Loss:0.000078 Loss_1:0.000075 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:40.052071s (86.37min in total, 0.00min remains)
2022-11-29 01:26:24 NUM_SUB: 111------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 01:26:24 Testing & drawing...
2022-11-29 01:26:24 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:26:26 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=111/
2022-11-29 01:26:26 [Loss]
2022-11-29 01:26:26 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:26:26 General parameter estimation: Parameter containing:
tensor([0.0150, 0.0425, 0.0099, 1.1793, 0.3074, 0.0173, 3.6072, 0.8964, 0.4556,
        0.0144, 0.0331, 0.0139, 0.8589, 0.1689, 0.0173, 3.0779, 0.6977, 0.8000,
        0.0120, 3.6789, 0.6816, 0.0222, 3.5663, 0.8742, 0.0201, 4.3103, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:26:26 A: prod, degr, TonA, NonA
2022-11-29 01:26:26 [0.44988218 0.47378916 0.05098524 0.02534345]
2022-11-29 01:26:26 T: prod, degr, AonT, NonT
2022-11-29 01:26:26 [0.4541855  0.38780987 0.12211574 0.03588891]
2022-11-29 01:26:26 N: AonN, TonN, ATonN
2022-11-29 01:26:26 [0.00620381 0.97111255 0.02268362]
2022-11-29 01:26:26 using cpu
2022-11-29 01:26:26 epoch = 30000
2022-11-29 01:26:26 epoch_step = 2000
2022-11-29 01:26:26 model_name = SimpleNetworkAD
2022-11-29 01:26:26 now_string = 2022-11-28-18-17-05
2022-11-29 01:26:26 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 01:26:26 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 01:26:26 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 01:26:26 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 01:26:26 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 01:26:26 --------------------------------------------------training start--------------------------------------------------
2022-11-29 01:27:05 NUM_SUB: 112;----------------------------
2022-11-29 01:27:05 Epoch [02000/30000] Loss:0.083770 Loss_1:0.082985 Loss_2:0.000399 Loss_3:0.000000 Lr:0.000833 Time:38.330839s (0.64min in total, 8.94min remains)
2022-11-29 01:27:43 NUM_SUB: 112;----------------------------
2022-11-29 01:27:43 Epoch [04000/30000] Loss:0.058330 Loss_1:0.058086 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000714 Time:38.304209s (1.28min in total, 8.30min remains)
2022-11-29 01:28:21 NUM_SUB: 112;----------------------------
2022-11-29 01:28:21 Epoch [06000/30000] Loss:0.017738 Loss_1:0.017594 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000625 Time:38.252982s (1.91min in total, 7.66min remains)
2022-11-29 01:28:59 NUM_SUB: 112;----------------------------
2022-11-29 01:28:59 Epoch [08000/30000] Loss:0.004289 Loss_1:0.004147 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000556 Time:38.271729s (2.55min in total, 7.02min remains)
2022-11-29 01:29:38 NUM_SUB: 112;----------------------------
2022-11-29 01:29:38 Epoch [10000/30000] Loss:0.003448 Loss_1:0.003382 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000500 Time:38.263709s (3.19min in total, 6.38min remains)
2022-11-29 01:30:17 NUM_SUB: 112;----------------------------
2022-11-29 01:30:17 Epoch [12000/30000] Loss:0.002282 Loss_1:0.002263 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000455 Time:39.328902s (3.85min in total, 5.77min remains)
2022-11-29 01:30:59 NUM_SUB: 112;----------------------------
2022-11-29 01:30:59 Epoch [14000/30000] Loss:0.001700 Loss_1:0.001688 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000417 Time:41.490469s (4.54min in total, 5.19min remains)
2022-11-29 01:31:39 NUM_SUB: 112;----------------------------
2022-11-29 01:31:39 Epoch [16000/30000] Loss:0.001671 Loss_1:0.001665 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:40.542691s (5.21min in total, 4.56min remains)
2022-11-29 01:32:20 NUM_SUB: 112;----------------------------
2022-11-29 01:32:20 Epoch [18000/30000] Loss:0.001644 Loss_1:0.001640 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:41.319593s (5.90min in total, 3.93min remains)
2022-11-29 01:33:01 NUM_SUB: 112;----------------------------
2022-11-29 01:33:01 Epoch [20000/30000] Loss:0.001605 Loss_1:0.001603 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:40.447801s (6.58min in total, 3.29min remains)
2022-11-29 01:33:42 NUM_SUB: 112;----------------------------
2022-11-29 01:33:42 Epoch [22000/30000] Loss:0.001573 Loss_1:0.001572 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000313 Time:41.195408s (7.26min in total, 2.64min remains)
2022-11-29 01:34:23 NUM_SUB: 112;----------------------------
2022-11-29 01:34:23 Epoch [24000/30000] Loss:0.001572 Loss_1:0.001570 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:41.172125s (7.95min in total, 1.99min remains)
2022-11-29 01:35:05 NUM_SUB: 112;----------------------------
2022-11-29 01:35:05 Epoch [26000/30000] Loss:0.001572 Loss_1:0.001570 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:41.727606s (8.64min in total, 1.33min remains)
2022-11-29 01:35:46 NUM_SUB: 112;----------------------------
2022-11-29 01:35:46 Epoch [28000/30000] Loss:0.001572 Loss_1:0.001571 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:40.692823s (9.32min in total, 0.67min remains)
2022-11-29 01:36:26 Testing & drawing...
2022-11-29 01:36:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:36:27 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=112/
2022-11-29 01:36:27 [Loss]
2022-11-29 01:36:27 NUM_SUB: 112; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:36:27 NUM_SUB: 112; Personalized parameter estimation: Parameter containing:
tensor([0.3125, 0.9667, 0.0067, 0.0103, 0.3074, 0.0139, 0.1794, 0.8964, 0.4556,
        0.0147, 0.1392, 0.1107, 0.5410, 0.1689, 0.0177, 1.4506, 0.6977, 0.8000,
        0.0128, 1.3360, 0.6816, 0.0221, 2.5868, 0.8742, 0.0219, 2.9301, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:36:27 NUM_SUB: 112;----------------------------
2022-11-29 01:36:27 Epoch [30000/30000] Loss:0.001572 Loss_1:0.001571 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:41.727516s (10.02min in total, 0.00min remains)
2022-11-29 01:36:27 NUM_SUB: 112------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 01:36:27 Testing & drawing...
2022-11-29 01:36:27 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:36:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=112/
2022-11-29 01:36:29 [Loss]
2022-11-29 01:36:29 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:36:29 General parameter estimation: Parameter containing:
tensor([0.3125, 0.9667, 0.0067, 0.0103, 0.3074, 0.0139, 0.1794, 0.8964, 0.4556,
        0.0147, 0.1392, 0.1107, 0.5410, 0.1689, 0.0177, 1.4507, 0.6977, 0.8000,
        0.0128, 1.3358, 0.6816, 0.0221, 2.5869, 0.8742, 0.0219, 2.9302, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:36:29 A: prod, degr, TonA, NonA
2022-11-29 01:36:29 [0.4701306  0.49997473 0.01002426 0.01987044]
2022-11-29 01:36:29 T: prod, degr, AonT, NonT
2022-11-29 01:36:29 [0.14229883 0.46279597 0.35442936 0.04047586]
2022-11-29 01:36:29 N: AonN, TonN, ATonN
2022-11-29 01:36:29 [0.04135531 0.9226951  0.03594954]
2022-11-29 01:36:29 using cpu
2022-11-29 01:36:29 epoch = 30000
2022-11-29 01:36:29 epoch_step = 2000
2022-11-29 01:36:29 model_name = SimpleNetworkAD
2022-11-29 01:36:29 now_string = 2022-11-28-18-17-05
2022-11-29 01:36:29 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 01:36:29 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 01:36:29 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 01:36:29 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 01:36:29 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 01:36:29 --------------------------------------------------training start--------------------------------------------------
2022-11-29 01:37:08 NUM_SUB: 113;----------------------------
2022-11-29 01:37:08 Epoch [02000/30000] Loss:0.024348 Loss_1:0.023445 Loss_2:0.000452 Loss_3:0.000000 Lr:0.000833 Time:38.434598s (0.64min in total, 8.97min remains)
2022-11-29 01:37:46 NUM_SUB: 113;----------------------------
2022-11-29 01:37:46 Epoch [04000/30000] Loss:0.021517 Loss_1:0.021319 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000714 Time:38.284538s (1.28min in total, 8.31min remains)
2022-11-29 01:38:24 NUM_SUB: 113;----------------------------
2022-11-29 01:38:24 Epoch [06000/30000] Loss:0.017201 Loss_1:0.017008 Loss_2:0.000093 Loss_3:0.000000 Lr:0.000625 Time:38.227814s (1.92min in total, 7.66min remains)
2022-11-29 01:39:02 NUM_SUB: 113;----------------------------
2022-11-29 01:39:02 Epoch [08000/30000] Loss:0.011273 Loss_1:0.011126 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000556 Time:38.268658s (2.55min in total, 7.02min remains)
2022-11-29 01:39:41 NUM_SUB: 113;----------------------------
2022-11-29 01:39:41 Epoch [10000/30000] Loss:0.008028 Loss_1:0.007925 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000500 Time:38.252070s (3.19min in total, 6.38min remains)
2022-11-29 01:40:19 NUM_SUB: 113;----------------------------
2022-11-29 01:40:19 Epoch [12000/30000] Loss:0.007712 Loss_1:0.007658 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000455 Time:38.212815s (3.83min in total, 5.74min remains)
2022-11-29 01:40:57 NUM_SUB: 113;----------------------------
2022-11-29 01:40:57 Epoch [14000/30000] Loss:0.007398 Loss_1:0.007360 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000417 Time:38.178297s (4.46min in total, 5.10min remains)
2022-11-29 01:41:35 NUM_SUB: 113;----------------------------
2022-11-29 01:41:35 Epoch [16000/30000] Loss:0.007157 Loss_1:0.007139 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.147892s (5.10min in total, 4.46min remains)
2022-11-29 01:42:13 NUM_SUB: 113;----------------------------
2022-11-29 01:42:13 Epoch [18000/30000] Loss:0.007201 Loss_1:0.007193 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:38.203242s (5.74min in total, 3.82min remains)
2022-11-29 01:42:52 NUM_SUB: 113;----------------------------
2022-11-29 01:42:52 Epoch [20000/30000] Loss:0.007169 Loss_1:0.007165 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.224055s (6.37min in total, 3.19min remains)
2022-11-29 01:43:30 NUM_SUB: 113;----------------------------
2022-11-29 01:43:30 Epoch [22000/30000] Loss:0.007140 Loss_1:0.007135 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.193701s (7.01min in total, 2.55min remains)
2022-11-29 01:44:08 NUM_SUB: 113;----------------------------
2022-11-29 01:44:08 Epoch [24000/30000] Loss:0.007139 Loss_1:0.007135 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.149354s (7.65min in total, 1.91min remains)
2022-11-29 01:44:46 NUM_SUB: 113;----------------------------
2022-11-29 01:44:46 Epoch [26000/30000] Loss:0.007151 Loss_1:0.007137 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.198598s (8.28min in total, 1.27min remains)
2022-11-29 01:45:24 NUM_SUB: 113;----------------------------
2022-11-29 01:45:24 Epoch [28000/30000] Loss:0.007138 Loss_1:0.007134 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.200197s (8.92min in total, 0.64min remains)
2022-11-29 01:46:03 Testing & drawing...
2022-11-29 01:46:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:46:04 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=113/
2022-11-29 01:46:04 [Loss]
2022-11-29 01:46:04 NUM_SUB: 113; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:46:04 NUM_SUB: 113; Personalized parameter estimation: Parameter containing:
tensor([0.0141, 0.0372, 0.0097, 1.9622, 0.3074, 0.0104, 1.1218, 0.8964, 0.4556,
        0.0124, 0.0340, 0.0111, 0.5871, 0.1689, 0.0178, 0.9749, 0.6977, 0.8000,
        0.0118, 3.9708, 0.6816, 0.0212, 3.7735, 0.8742, 0.0178, 4.5251, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:46:04 NUM_SUB: 113;----------------------------
2022-11-29 01:46:04 Epoch [30000/30000] Loss:0.007138 Loss_1:0.007132 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.910050s (9.58min in total, 0.00min remains)
2022-11-29 01:46:04 NUM_SUB: 113------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 01:46:04 Testing & drawing...
2022-11-29 01:46:04 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:46:06 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=113/
2022-11-29 01:46:06 [Loss]
2022-11-29 01:46:06 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:46:06 General parameter estimation: Parameter containing:
tensor([0.0141, 0.0372, 0.0097, 1.9623, 0.3074, 0.0104, 1.1219, 0.8964, 0.4556,
        0.0124, 0.0340, 0.0111, 0.5871, 0.1689, 0.0178, 0.9749, 0.6977, 0.8000,
        0.0118, 3.9709, 0.6816, 0.0212, 3.7736, 0.8742, 0.0178, 4.5252, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:46:06 A: prod, degr, TonA, NonA
2022-11-29 01:46:06 [0.47600606 0.48956448 0.02179611 0.01263336]
2022-11-29 01:46:06 T: prod, degr, AonT, NonT
2022-11-29 01:46:06 [0.39467818 0.42199767 0.15663332 0.02669086]
2022-11-29 01:46:06 N: AonN, TonN, ATonN
2022-11-29 01:46:06 [0.00584159 0.9755575  0.01860095]
2022-11-29 01:46:06 using cpu
2022-11-29 01:46:06 epoch = 30000
2022-11-29 01:46:06 epoch_step = 2000
2022-11-29 01:46:06 model_name = SimpleNetworkAD
2022-11-29 01:46:06 now_string = 2022-11-28-18-17-05
2022-11-29 01:46:06 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 01:46:06 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 01:46:06 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 01:46:06 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 01:46:06 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 01:46:06 --------------------------------------------------training start--------------------------------------------------
2022-11-29 01:46:44 NUM_SUB: 114;----------------------------
2022-11-29 01:46:44 Epoch [02000/30000] Loss:0.051096 Loss_1:0.050003 Loss_2:0.000687 Loss_3:0.000000 Lr:0.000833 Time:38.285209s (0.64min in total, 8.93min remains)
2022-11-29 01:47:22 NUM_SUB: 114;----------------------------
2022-11-29 01:47:22 Epoch [04000/30000] Loss:0.040814 Loss_1:0.040348 Loss_2:0.000345 Loss_3:0.000000 Lr:0.000714 Time:38.195354s (1.27min in total, 8.29min remains)
2022-11-29 01:48:01 NUM_SUB: 114;----------------------------
2022-11-29 01:48:01 Epoch [06000/30000] Loss:0.025183 Loss_1:0.024900 Loss_2:0.000167 Loss_3:0.000000 Lr:0.000625 Time:38.181854s (1.91min in total, 7.64min remains)
2022-11-29 01:48:39 NUM_SUB: 114;----------------------------
2022-11-29 01:48:39 Epoch [08000/30000] Loss:0.008442 Loss_1:0.008255 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000556 Time:38.217401s (2.55min in total, 7.01min remains)
2022-11-29 01:49:17 NUM_SUB: 114;----------------------------
2022-11-29 01:49:17 Epoch [10000/30000] Loss:0.001962 Loss_1:0.001838 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000500 Time:38.270761s (3.19min in total, 6.37min remains)
2022-11-29 01:49:55 NUM_SUB: 114;----------------------------
2022-11-29 01:49:55 Epoch [12000/30000] Loss:0.001302 Loss_1:0.001254 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000455 Time:38.186711s (3.82min in total, 5.73min remains)
2022-11-29 01:50:34 NUM_SUB: 114;----------------------------
2022-11-29 01:50:34 Epoch [14000/30000] Loss:0.001159 Loss_1:0.001129 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000417 Time:38.174075s (4.46min in total, 5.10min remains)
2022-11-29 01:51:12 NUM_SUB: 114;----------------------------
2022-11-29 01:51:12 Epoch [16000/30000] Loss:0.001246 Loss_1:0.001228 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:38.284392s (5.10min in total, 4.46min remains)
2022-11-29 01:51:50 NUM_SUB: 114;----------------------------
2022-11-29 01:51:50 Epoch [18000/30000] Loss:0.001058 Loss_1:0.001047 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.238482s (5.73min in total, 3.82min remains)
2022-11-29 01:52:29 NUM_SUB: 114;----------------------------
2022-11-29 01:52:29 Epoch [20000/30000] Loss:0.000928 Loss_1:0.000921 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:39.403505s (6.39min in total, 3.20min remains)
2022-11-29 01:53:08 NUM_SUB: 114;----------------------------
2022-11-29 01:53:08 Epoch [22000/30000] Loss:0.000904 Loss_1:0.000899 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.345336s (7.03min in total, 2.56min remains)
2022-11-29 01:53:46 NUM_SUB: 114;----------------------------
2022-11-29 01:53:46 Epoch [24000/30000] Loss:0.000901 Loss_1:0.000896 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.334814s (7.67min in total, 1.92min remains)
2022-11-29 01:54:24 NUM_SUB: 114;----------------------------
2022-11-29 01:54:24 Epoch [26000/30000] Loss:0.000899 Loss_1:0.000894 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.365232s (8.31min in total, 1.28min remains)
2022-11-29 01:55:03 NUM_SUB: 114;----------------------------
2022-11-29 01:55:03 Epoch [28000/30000] Loss:0.000897 Loss_1:0.000893 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.303375s (8.95min in total, 0.64min remains)
2022-11-29 01:55:41 Testing & drawing...
2022-11-29 01:55:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:55:43 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=114/
2022-11-29 01:55:43 [Loss]
2022-11-29 01:55:43 NUM_SUB: 114; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:55:43 NUM_SUB: 114; Personalized parameter estimation: Parameter containing:
tensor([0.0166, 0.0396, 0.0103, 1.6108, 0.3074, 0.0159, 1.4535, 0.8964, 0.4556,
        0.0139, 0.0284, 0.0144, 0.9008, 0.1689, 0.0173, 2.1291, 0.6977, 0.8000,
        0.0123, 3.2487, 0.6816, 0.0223, 3.1267, 0.8742, 0.0203, 3.7860, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:55:43 NUM_SUB: 114;----------------------------
2022-11-29 01:55:43 Epoch [30000/30000] Loss:0.000896 Loss_1:0.000892 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:40.001167s (9.61min in total, 0.00min remains)
2022-11-29 01:55:43 NUM_SUB: 114------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 01:55:43 Testing & drawing...
2022-11-29 01:55:43 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 01:55:44 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=114/
2022-11-29 01:55:44 [Loss]
2022-11-29 01:55:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 01:55:44 General parameter estimation: Parameter containing:
tensor([0.0166, 0.0396, 0.0103, 1.6108, 0.3074, 0.0159, 1.4536, 0.8964, 0.4556,
        0.0139, 0.0284, 0.0144, 0.9008, 0.1689, 0.0173, 2.1292, 0.6977, 0.8000,
        0.0123, 3.2487, 0.6816, 0.0223, 3.1267, 0.8742, 0.0203, 3.7859, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 01:55:44 A: prod, degr, TonA, NonA
2022-11-29 01:55:44 [0.4163975  0.48295438 0.03751571 0.06313235]
2022-11-29 01:55:44 T: prod, degr, AonT, NonT
2022-11-29 01:55:44 [0.40722558 0.40455127 0.14697292 0.04125024]
2022-11-29 01:55:44 N: AonN, TonN, ATonN
2022-11-29 01:55:44 [0.01278869 0.9443951  0.04281619]
2022-11-29 01:55:45 using cpu
2022-11-29 01:55:45 epoch = 30000
2022-11-29 01:55:45 epoch_step = 2000
2022-11-29 01:55:45 model_name = SimpleNetworkAD
2022-11-29 01:55:45 now_string = 2022-11-28-18-17-05
2022-11-29 01:55:45 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 01:55:45 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 01:55:45 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 01:55:45 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 01:55:45 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 01:55:45 --------------------------------------------------training start--------------------------------------------------
2022-11-29 01:56:23 NUM_SUB: 115;----------------------------
2022-11-29 01:56:23 Epoch [02000/30000] Loss:0.034011 Loss_1:0.033170 Loss_2:0.000424 Loss_3:0.000000 Lr:0.000833 Time:38.442071s (0.64min in total, 8.97min remains)
2022-11-29 01:57:01 NUM_SUB: 115;----------------------------
2022-11-29 01:57:01 Epoch [04000/30000] Loss:0.026597 Loss_1:0.026392 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000714 Time:38.317003s (1.28min in total, 8.32min remains)
2022-11-29 01:57:40 NUM_SUB: 115;----------------------------
2022-11-29 01:57:40 Epoch [06000/30000] Loss:0.015484 Loss_1:0.015323 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000625 Time:38.316717s (1.92min in total, 7.67min remains)
2022-11-29 01:58:18 NUM_SUB: 115;----------------------------
2022-11-29 01:58:18 Epoch [08000/30000] Loss:0.003612 Loss_1:0.003520 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000556 Time:38.326672s (2.56min in total, 7.03min remains)
2022-11-29 01:58:56 NUM_SUB: 115;----------------------------
2022-11-29 01:58:56 Epoch [10000/30000] Loss:0.001185 Loss_1:0.001112 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000500 Time:38.266573s (3.19min in total, 6.39min remains)
2022-11-29 01:59:35 NUM_SUB: 115;----------------------------
2022-11-29 01:59:35 Epoch [12000/30000] Loss:0.000732 Loss_1:0.000686 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:38.390867s (3.83min in total, 5.75min remains)
2022-11-29 02:00:15 NUM_SUB: 115;----------------------------
2022-11-29 02:00:15 Epoch [14000/30000] Loss:0.000357 Loss_1:0.000332 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:39.931311s (4.50min in total, 5.14min remains)
2022-11-29 02:00:54 NUM_SUB: 115;----------------------------
2022-11-29 02:00:54 Epoch [16000/30000] Loss:0.000312 Loss_1:0.000297 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:39.269920s (5.15min in total, 4.51min remains)
2022-11-29 02:01:34 NUM_SUB: 115;----------------------------
2022-11-29 02:01:34 Epoch [18000/30000] Loss:0.000294 Loss_1:0.000285 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:39.736065s (5.82min in total, 3.88min remains)
2022-11-29 02:02:13 NUM_SUB: 115;----------------------------
2022-11-29 02:02:13 Epoch [20000/30000] Loss:0.000283 Loss_1:0.000277 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:39.718695s (6.48min in total, 3.24min remains)
2022-11-29 02:02:53 NUM_SUB: 115;----------------------------
2022-11-29 02:02:53 Epoch [22000/30000] Loss:0.000280 Loss_1:0.000276 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:39.348818s (7.13min in total, 2.59min remains)
2022-11-29 02:03:31 NUM_SUB: 115;----------------------------
2022-11-29 02:03:31 Epoch [24000/30000] Loss:0.000279 Loss_1:0.000276 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.375393s (7.77min in total, 1.94min remains)
2022-11-29 02:04:09 NUM_SUB: 115;----------------------------
2022-11-29 02:04:09 Epoch [26000/30000] Loss:0.000284 Loss_1:0.000282 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.327246s (8.41min in total, 1.29min remains)
2022-11-29 02:04:48 NUM_SUB: 115;----------------------------
2022-11-29 02:04:48 Epoch [28000/30000] Loss:0.000277 Loss_1:0.000276 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.247673s (9.05min in total, 0.65min remains)
2022-11-29 02:05:26 Testing & drawing...
2022-11-29 02:05:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 02:05:27 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=115/
2022-11-29 02:05:27 [Loss]
2022-11-29 02:05:27 NUM_SUB: 115; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 02:05:27 NUM_SUB: 115; Personalized parameter estimation: Parameter containing:
tensor([0.0079, 0.3158, 0.0088, 0.1850, 0.3074, 0.3504, 0.8158, 0.8964, 0.4556,
        0.0140, 0.1016, 0.1041, 0.7106, 0.1689, 0.0175, 1.0517, 0.6977, 0.8000,
        0.0120, 3.8857, 0.6816, 0.0221, 3.6988, 0.8742, 0.0197, 4.4555, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 02:05:28 NUM_SUB: 115;----------------------------
2022-11-29 02:05:28 Epoch [30000/30000] Loss:0.000276 Loss_1:0.000276 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.894130s (9.72min in total, 0.00min remains)
2022-11-29 02:05:28 NUM_SUB: 115------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 02:05:28 Testing & drawing...
2022-11-29 02:05:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 02:05:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=115/
2022-11-29 02:05:29 [Loss]
2022-11-29 02:05:29 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 02:05:29 General parameter estimation: Parameter containing:
tensor([0.0079, 0.3159, 0.0088, 0.1851, 0.3074, 0.3503, 0.8158, 0.8964, 0.4556,
        0.0140, 0.1016, 0.1041, 0.7106, 0.1689, 0.0175, 1.0517, 0.6977, 0.8000,
        0.0120, 3.8858, 0.6816, 0.0221, 3.6990, 0.8742, 0.0197, 4.4556, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 02:05:29 A: prod, degr, TonA, NonA
2022-11-29 02:05:29 [0.03272646 0.49880245 0.03153164 0.43693945]
2022-11-29 02:05:29 T: prod, degr, AonT, NonT
2022-11-29 02:05:29 [0.15866695 0.43739933 0.36314216 0.0407916 ]
2022-11-29 02:05:29 N: AonN, TonN, ATonN
2022-11-29 02:05:29 [0.00573797 0.97566575 0.01859628]
2022-11-29 02:05:29 using cpu
2022-11-29 02:05:29 epoch = 30000
2022-11-29 02:05:29 epoch_step = 2000
2022-11-29 02:05:29 model_name = SimpleNetworkAD
2022-11-29 02:05:29 now_string = 2022-11-28-18-17-05
2022-11-29 02:05:29 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 02:05:29 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 02:05:29 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 02:05:29 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 02:05:29 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 02:05:29 --------------------------------------------------training start--------------------------------------------------
2022-11-29 02:06:07 NUM_SUB: 116;----------------------------
2022-11-29 02:06:07 Epoch [02000/30000] Loss:0.027664 Loss_1:0.026833 Loss_2:0.000411 Loss_3:0.000000 Lr:0.000833 Time:38.207185s (0.64min in total, 8.92min remains)
2022-11-29 02:06:46 NUM_SUB: 116;----------------------------
2022-11-29 02:06:46 Epoch [04000/30000] Loss:0.022208 Loss_1:0.022026 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000714 Time:38.214056s (1.27min in total, 8.28min remains)
2022-11-29 02:07:24 NUM_SUB: 116;----------------------------
2022-11-29 02:07:24 Epoch [06000/30000] Loss:0.014743 Loss_1:0.014591 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000625 Time:38.252385s (1.91min in total, 7.65min remains)
2022-11-29 02:08:02 NUM_SUB: 116;----------------------------
2022-11-29 02:08:02 Epoch [08000/30000] Loss:0.005438 Loss_1:0.005342 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000556 Time:38.147851s (2.55min in total, 7.00min remains)
2022-11-29 02:08:40 NUM_SUB: 116;----------------------------
2022-11-29 02:08:40 Epoch [10000/30000] Loss:0.002071 Loss_1:0.001989 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000500 Time:38.185466s (3.18min in total, 6.37min remains)
2022-11-29 02:19:21 NUM_SUB: 116;----------------------------
2022-11-29 02:19:21 Epoch [12000/30000] Loss:0.001156 Loss_1:0.001124 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000455 Time:640.506674s (13.86min in total, 20.79min remains)
2022-11-29 02:20:00 NUM_SUB: 116;----------------------------
2022-11-29 02:20:00 Epoch [14000/30000] Loss:0.000641 Loss_1:0.000621 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000417 Time:38.772176s (14.50min in total, 16.58min remains)
2022-11-29 02:20:38 NUM_SUB: 116;----------------------------
2022-11-29 02:20:38 Epoch [16000/30000] Loss:0.000514 Loss_1:0.000502 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:38.484892s (15.15min in total, 13.25min remains)
2022-11-29 02:21:16 NUM_SUB: 116;----------------------------
2022-11-29 02:21:16 Epoch [18000/30000] Loss:0.000454 Loss_1:0.000447 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:38.347864s (15.79min in total, 10.52min remains)
2022-11-29 02:21:55 NUM_SUB: 116;----------------------------
2022-11-29 02:21:55 Epoch [20000/30000] Loss:0.000450 Loss_1:0.000447 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:38.267585s (16.42min in total, 8.21min remains)
2022-11-29 02:22:33 NUM_SUB: 116;----------------------------
2022-11-29 02:22:33 Epoch [22000/30000] Loss:0.000449 Loss_1:0.000446 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.377275s (17.06min in total, 6.20min remains)
2022-11-29 02:23:11 NUM_SUB: 116;----------------------------
2022-11-29 02:23:11 Epoch [24000/30000] Loss:0.000448 Loss_1:0.000446 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.384348s (17.70min in total, 4.43min remains)
2022-11-29 02:23:50 NUM_SUB: 116;----------------------------
2022-11-29 02:23:50 Epoch [26000/30000] Loss:0.000448 Loss_1:0.000446 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.243458s (18.34min in total, 2.82min remains)
2022-11-29 02:24:28 NUM_SUB: 116;----------------------------
2022-11-29 02:24:28 Epoch [28000/30000] Loss:0.000447 Loss_1:0.000447 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.291324s (18.98min in total, 1.36min remains)
2022-11-29 02:25:06 Testing & drawing...
2022-11-29 02:25:06 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 02:25:08 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=116/
2022-11-29 02:25:08 [Loss]
2022-11-29 02:25:08 NUM_SUB: 116; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 02:25:08 NUM_SUB: 116; Personalized parameter estimation: Parameter containing:
tensor([3.2957e-01, 9.4581e-01, 9.9260e-03, 7.2443e-09, 3.0742e-01, 7.8950e-03,
        8.0066e-01, 8.9644e-01, 4.5563e-01, 1.4096e-02, 3.1114e-02, 1.3531e-02,
        8.7210e-01, 1.6886e-01, 1.7488e-02, 2.6642e+00, 6.9767e-01, 8.0001e-01,
        1.2158e-02, 3.8438e+00, 6.8161e-01, 2.0762e-02, 3.8497e+00, 8.7416e-01,
        2.0232e-02, 4.5733e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 02:25:08 NUM_SUB: 116;----------------------------
2022-11-29 02:25:08 Epoch [30000/30000] Loss:0.000447 Loss_1:0.000446 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.935213s (19.64min in total, 0.00min remains)
2022-11-29 02:25:08 NUM_SUB: 116------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 02:25:08 Testing & drawing...
2022-11-29 02:25:08 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 02:25:10 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=116/
2022-11-29 02:25:10 [Loss]
2022-11-29 02:25:10 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 02:25:10 General parameter estimation: Parameter containing:
tensor([3.2957e-01, 9.4580e-01, 9.9261e-03, 7.2184e-09, 3.0742e-01, 7.9004e-03,
        8.0066e-01, 8.9644e-01, 4.5563e-01, 1.4096e-02, 3.1115e-02, 1.3531e-02,
        8.7207e-01, 1.6886e-01, 1.7488e-02, 2.6643e+00, 6.9767e-01, 8.0001e-01,
        1.2158e-02, 3.8440e+00, 6.8161e-01, 2.0761e-02, 3.8499e+00, 8.7416e-01,
        2.0231e-02, 4.5735e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 02:25:10 A: prod, degr, TonA, NonA
2022-11-29 02:25:10 [0.4827116  0.4999452  0.01453822 0.00280496]
2022-11-29 02:25:10 T: prod, degr, AonT, NonT
2022-11-29 02:25:10 [0.47603887 0.3792204  0.12816289 0.01657783]
2022-11-29 02:25:10 N: AonN, TonN, ATonN
2022-11-29 02:25:10 [0.00549205 0.9733595  0.0211484 ]
2022-11-29 02:25:10 using cpu
2022-11-29 02:25:10 epoch = 30000
2022-11-29 02:25:10 epoch_step = 2000
2022-11-29 02:25:10 model_name = SimpleNetworkAD
2022-11-29 02:25:10 now_string = 2022-11-28-18-17-05
2022-11-29 02:25:10 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 02:25:10 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 02:25:10 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 02:25:10 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 02:25:10 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 02:25:10 --------------------------------------------------training start--------------------------------------------------
2022-11-29 02:25:48 NUM_SUB: 117;----------------------------
2022-11-29 02:25:48 Epoch [02000/30000] Loss:0.039320 Loss_1:0.038471 Loss_2:0.000445 Loss_3:0.000000 Lr:0.000833 Time:38.263006s (0.64min in total, 8.93min remains)
2022-11-29 02:26:26 NUM_SUB: 117;----------------------------
2022-11-29 02:26:26 Epoch [04000/30000] Loss:0.030546 Loss_1:0.030297 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000714 Time:38.339279s (1.28min in total, 8.30min remains)
2022-11-29 02:27:05 NUM_SUB: 117;----------------------------
2022-11-29 02:27:05 Epoch [06000/30000] Loss:0.017402 Loss_1:0.017226 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000625 Time:38.250173s (1.91min in total, 7.66min remains)
2022-11-29 02:27:43 NUM_SUB: 117;----------------------------
2022-11-29 02:27:43 Epoch [08000/30000] Loss:0.005181 Loss_1:0.005089 Loss_2:0.000073 Loss_3:0.000000 Lr:0.000556 Time:38.245706s (2.55min in total, 7.02min remains)
2022-11-29 02:28:21 NUM_SUB: 117;----------------------------
2022-11-29 02:28:21 Epoch [10000/30000] Loss:0.002834 Loss_1:0.002702 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000500 Time:38.229053s (3.19min in total, 6.38min remains)
2022-11-29 02:28:59 NUM_SUB: 117;----------------------------
2022-11-29 02:28:59 Epoch [12000/30000] Loss:0.001161 Loss_1:0.001119 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000455 Time:38.335495s (3.83min in total, 5.74min remains)
2022-11-29 02:29:38 NUM_SUB: 117;----------------------------
2022-11-29 02:29:38 Epoch [14000/30000] Loss:0.000290 Loss_1:0.000262 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000417 Time:38.325138s (4.47min in total, 5.10min remains)
2022-11-29 02:46:42 NUM_SUB: 117;----------------------------
2022-11-29 02:46:42 Epoch [16000/30000] Loss:0.000231 Loss_1:0.000214 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:1023.916142s (21.53min in total, 18.84min remains)
2022-11-29 02:47:20 NUM_SUB: 117;----------------------------
2022-11-29 02:47:20 Epoch [18000/30000] Loss:0.000163 Loss_1:0.000150 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:38.450842s (22.17min in total, 14.78min remains)
2022-11-29 03:03:19 NUM_SUB: 117;----------------------------
2022-11-29 03:03:19 Epoch [20000/30000] Loss:0.000148 Loss_1:0.000139 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:959.327964s (38.16min in total, 19.08min remains)
2022-11-29 03:07:37 NUM_SUB: 117;----------------------------
2022-11-29 03:07:37 Epoch [22000/30000] Loss:0.000145 Loss_1:0.000138 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:257.279125s (42.45min in total, 15.44min remains)
2022-11-29 03:24:34 NUM_SUB: 117;----------------------------
2022-11-29 03:24:34 Epoch [24000/30000] Loss:0.000148 Loss_1:0.000142 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:1017.256375s (59.40min in total, 14.85min remains)
2022-11-29 03:41:10 NUM_SUB: 117;----------------------------
2022-11-29 03:41:10 Epoch [26000/30000] Loss:0.000142 Loss_1:0.000138 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:996.326585s (76.01min in total, 11.69min remains)
2022-11-29 03:41:49 NUM_SUB: 117;----------------------------
2022-11-29 03:41:49 Epoch [28000/30000] Loss:0.000141 Loss_1:0.000138 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.253962s (76.65min in total, 5.47min remains)
2022-11-29 04:00:23 Testing & drawing...
2022-11-29 04:00:23 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:00:25 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=117/
2022-11-29 04:00:25 [Loss]
2022-11-29 04:00:25 NUM_SUB: 117; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:00:25 NUM_SUB: 117; Personalized parameter estimation: Parameter containing:
tensor([0.1819, 0.7184, 0.0128, 0.3428, 0.3074, 0.3610, 0.7503, 0.8964, 0.4556,
        0.0140, 0.0311, 0.0135, 0.8274, 0.1689, 0.0152, 3.0247, 0.6977, 0.8000,
        0.0059, 3.9009, 0.6816, 0.0214, 3.8215, 0.8742, 0.0199, 4.5769, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:00:25 NUM_SUB: 117;----------------------------
2022-11-29 04:00:25 Epoch [30000/30000] Loss:0.000142 Loss_1:0.000140 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:1116.247948s (95.25min in total, 0.00min remains)
2022-11-29 04:00:25 NUM_SUB: 117------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 04:00:25 Testing & drawing...
2022-11-29 04:00:25 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:00:26 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=117/
2022-11-29 04:00:26 [Loss]
2022-11-29 04:00:26 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:00:26 General parameter estimation: Parameter containing:
tensor([0.1819, 0.7184, 0.0128, 0.3428, 0.3074, 0.3609, 0.7503, 0.8964, 0.4556,
        0.0140, 0.0311, 0.0135, 0.8273, 0.1689, 0.0152, 3.0247, 0.6977, 0.8000,
        0.0059, 3.9009, 0.6816, 0.0214, 3.8216, 0.8742, 0.0199, 4.5771, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:00:26 A: prod, degr, TonA, NonA
2022-11-29 04:00:26 [0.29141644 0.50003046 0.01421093 0.19434217]
2022-11-29 04:00:26 T: prod, degr, AonT, NonT
2022-11-29 04:00:26 [0.43976703 0.42311195 0.12274378 0.01437731]
2022-11-29 04:00:26 N: AonN, TonN, ATonN
2022-11-29 04:00:26 [0.00368141 0.9738683  0.02245031]
2022-11-29 04:00:27 using cpu
2022-11-29 04:00:27 epoch = 30000
2022-11-29 04:00:27 epoch_step = 2000
2022-11-29 04:00:27 model_name = SimpleNetworkAD
2022-11-29 04:00:27 now_string = 2022-11-28-18-17-05
2022-11-29 04:00:27 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 04:00:27 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 04:00:27 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 04:00:27 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 04:00:27 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 04:00:27 --------------------------------------------------training start--------------------------------------------------
2022-11-29 04:01:09 NUM_SUB: 118;----------------------------
2022-11-29 04:01:09 Epoch [02000/30000] Loss:0.107145 Loss_1:0.106043 Loss_2:0.000504 Loss_3:0.000000 Lr:0.000833 Time:42.294883s (0.70min in total, 9.87min remains)
2022-11-29 04:01:47 NUM_SUB: 118;----------------------------
2022-11-29 04:01:47 Epoch [04000/30000] Loss:0.088072 Loss_1:0.087381 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000714 Time:38.170423s (1.34min in total, 8.72min remains)
2022-11-29 04:17:29 NUM_SUB: 118;----------------------------
2022-11-29 04:17:29 Epoch [06000/30000] Loss:0.051145 Loss_1:0.050639 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000625 Time:942.394091s (17.05min in total, 68.19min remains)
2022-11-29 04:23:08 NUM_SUB: 118;----------------------------
2022-11-29 04:23:08 Epoch [08000/30000] Loss:0.008253 Loss_1:0.008010 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000556 Time:338.418005s (22.69min in total, 62.39min remains)
2022-11-29 04:23:46 NUM_SUB: 118;----------------------------
2022-11-29 04:23:46 Epoch [10000/30000] Loss:0.000506 Loss_1:0.000378 Loss_2:0.000128 Loss_3:0.000000 Lr:0.000500 Time:38.201144s (23.32min in total, 46.65min remains)
2022-11-29 04:24:24 NUM_SUB: 118;----------------------------
2022-11-29 04:24:24 Epoch [12000/30000] Loss:0.000229 Loss_1:0.000172 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000455 Time:38.207860s (23.96min in total, 35.94min remains)
2022-11-29 04:25:02 NUM_SUB: 118;----------------------------
2022-11-29 04:25:02 Epoch [14000/30000] Loss:0.000074 Loss_1:0.000045 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:38.142688s (24.60min in total, 28.11min remains)
2022-11-29 04:25:41 NUM_SUB: 118;----------------------------
2022-11-29 04:25:41 Epoch [16000/30000] Loss:0.000053 Loss_1:0.000035 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:38.234777s (25.23min in total, 22.08min remains)
2022-11-29 04:26:19 NUM_SUB: 118;----------------------------
2022-11-29 04:26:19 Epoch [18000/30000] Loss:0.000039 Loss_1:0.000029 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:38.142614s (25.87min in total, 17.25min remains)
2022-11-29 04:26:57 NUM_SUB: 118;----------------------------
2022-11-29 04:26:57 Epoch [20000/30000] Loss:0.000035 Loss_1:0.000030 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.107139s (26.51min in total, 13.25min remains)
2022-11-29 04:27:35 NUM_SUB: 118;----------------------------
2022-11-29 04:27:35 Epoch [22000/30000] Loss:0.000031 Loss_1:0.000028 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.167062s (27.14min in total, 9.87min remains)
2022-11-29 04:28:13 NUM_SUB: 118;----------------------------
2022-11-29 04:28:13 Epoch [24000/30000] Loss:0.000030 Loss_1:0.000028 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.173494s (27.78min in total, 6.94min remains)
2022-11-29 04:28:51 NUM_SUB: 118;----------------------------
2022-11-29 04:28:51 Epoch [26000/30000] Loss:0.000030 Loss_1:0.000029 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.175818s (28.41min in total, 4.37min remains)
2022-11-29 04:29:30 NUM_SUB: 118;----------------------------
2022-11-29 04:29:30 Epoch [28000/30000] Loss:0.000029 Loss_1:0.000028 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.163453s (29.05min in total, 2.08min remains)
2022-11-29 04:30:08 Testing & drawing...
2022-11-29 04:30:08 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:30:09 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=118/
2022-11-29 04:30:09 [Loss]
2022-11-29 04:30:09 NUM_SUB: 118; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:30:09 NUM_SUB: 118; Personalized parameter estimation: Parameter containing:
tensor([0.4012, 0.8953, 0.0119, 0.0080, 0.3074, 0.0470, 0.7462, 0.8964, 0.4556,
        0.0137, 0.0265, 0.0147, 0.8567, 0.1689, 0.0177, 1.9978, 0.6977, 0.8000,
        0.0118, 4.2303, 0.6816, 0.0221, 4.2202, 0.8742, 0.0085, 4.4659, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:30:09 NUM_SUB: 118;----------------------------
2022-11-29 04:30:09 Epoch [30000/30000] Loss:0.000029 Loss_1:0.000028 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.723962s (29.71min in total, 0.00min remains)
2022-11-29 04:30:09 NUM_SUB: 118------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 04:30:09 Testing & drawing...
2022-11-29 04:30:09 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:30:11 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=118/
2022-11-29 04:30:11 [Loss]
2022-11-29 04:30:11 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:30:11 General parameter estimation: Parameter containing:
tensor([0.4012, 0.8953, 0.0119, 0.0080, 0.3074, 0.0470, 0.7462, 0.8964, 0.4556,
        0.0137, 0.0265, 0.0147, 0.8567, 0.1689, 0.0177, 1.9978, 0.6977, 0.8000,
        0.0118, 4.2304, 0.6816, 0.0221, 4.2203, 0.8742, 0.0085, 4.4660, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:30:11 A: prod, degr, TonA, NonA
2022-11-29 04:30:11 [0.45919335 0.50001997 0.01360041 0.02718626]
2022-11-29 04:30:11 T: prod, degr, AonT, NonT
2022-11-29 04:30:11 [0.38237646 0.3611497  0.19459918 0.06187467]
2022-11-29 04:30:11 N: AonN, TonN, ATonN
2022-11-29 04:30:11 [0.00713953 0.97581446 0.017046  ]
2022-11-29 04:30:11 using cpu
2022-11-29 04:30:11 epoch = 30000
2022-11-29 04:30:11 epoch_step = 2000
2022-11-29 04:30:11 model_name = SimpleNetworkAD
2022-11-29 04:30:11 now_string = 2022-11-28-18-17-05
2022-11-29 04:30:11 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 04:30:11 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 04:30:11 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 04:30:11 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 04:30:11 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 04:30:11 --------------------------------------------------training start--------------------------------------------------
2022-11-29 04:30:49 NUM_SUB: 119;----------------------------
2022-11-29 04:30:49 Epoch [02000/30000] Loss:0.023305 Loss_1:0.022244 Loss_2:0.000683 Loss_3:0.000000 Lr:0.000833 Time:38.104769s (0.64min in total, 8.89min remains)
2022-11-29 04:31:27 NUM_SUB: 119;----------------------------
2022-11-29 04:31:27 Epoch [04000/30000] Loss:0.017279 Loss_1:0.016975 Loss_2:0.000249 Loss_3:0.000000 Lr:0.000714 Time:38.059229s (1.27min in total, 8.25min remains)
2022-11-29 04:32:05 NUM_SUB: 119;----------------------------
2022-11-29 04:32:05 Epoch [06000/30000] Loss:0.010528 Loss_1:0.010311 Loss_2:0.000185 Loss_3:0.000000 Lr:0.000625 Time:38.079862s (1.90min in total, 7.62min remains)
2022-11-29 04:32:43 NUM_SUB: 119;----------------------------
2022-11-29 04:32:43 Epoch [08000/30000] Loss:0.006466 Loss_1:0.006366 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000556 Time:38.158571s (2.54min in total, 6.99min remains)
2022-11-29 04:33:21 NUM_SUB: 119;----------------------------
2022-11-29 04:33:21 Epoch [10000/30000] Loss:0.004453 Loss_1:0.004365 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000500 Time:38.099882s (3.18min in total, 6.35min remains)
2022-11-29 04:34:00 NUM_SUB: 119;----------------------------
2022-11-29 04:34:00 Epoch [12000/30000] Loss:0.003228 Loss_1:0.003183 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000455 Time:38.020231s (3.81min in total, 5.71min remains)
2022-11-29 04:34:38 NUM_SUB: 119;----------------------------
2022-11-29 04:34:38 Epoch [14000/30000] Loss:0.002775 Loss_1:0.002749 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:38.172560s (4.45min in total, 5.08min remains)
2022-11-29 04:35:16 NUM_SUB: 119;----------------------------
2022-11-29 04:35:16 Epoch [16000/30000] Loss:0.002721 Loss_1:0.002704 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.642077s (5.09min in total, 4.45min remains)
2022-11-29 04:35:54 NUM_SUB: 119;----------------------------
2022-11-29 04:35:54 Epoch [18000/30000] Loss:0.002687 Loss_1:0.002675 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:38.164687s (5.73min in total, 3.82min remains)
2022-11-29 04:36:33 NUM_SUB: 119;----------------------------
2022-11-29 04:36:33 Epoch [20000/30000] Loss:0.002682 Loss_1:0.002673 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.115768s (6.36min in total, 3.18min remains)
2022-11-29 04:37:11 NUM_SUB: 119;----------------------------
2022-11-29 04:37:11 Epoch [22000/30000] Loss:0.002679 Loss_1:0.002672 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.106408s (7.00min in total, 2.54min remains)
2022-11-29 04:37:49 NUM_SUB: 119;----------------------------
2022-11-29 04:37:49 Epoch [24000/30000] Loss:0.002677 Loss_1:0.002670 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.090697s (7.63min in total, 1.91min remains)
2022-11-29 04:38:27 NUM_SUB: 119;----------------------------
2022-11-29 04:38:27 Epoch [26000/30000] Loss:0.002681 Loss_1:0.002675 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.315477s (8.27min in total, 1.27min remains)
2022-11-29 04:39:05 NUM_SUB: 119;----------------------------
2022-11-29 04:39:05 Epoch [28000/30000] Loss:0.002672 Loss_1:0.002667 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.100207s (8.90min in total, 0.64min remains)
2022-11-29 04:39:43 Testing & drawing...
2022-11-29 04:39:43 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:39:45 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=119/
2022-11-29 04:39:45 [Loss]
2022-11-29 04:39:45 NUM_SUB: 119; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:39:45 NUM_SUB: 119; Personalized parameter estimation: Parameter containing:
tensor([0.0113, 0.0257, 0.0122, 1.0277, 0.3074, 0.0163, 3.2940, 0.8964, 0.4556,
        0.0142, 0.1175, 0.1157, 0.6511, 0.1689, 0.0178, 0.9157, 0.6977, 0.8000,
        0.0117, 4.2423, 0.6816, 0.0223, 3.6510, 0.8742, 0.0084, 4.3718, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:39:45 NUM_SUB: 119;----------------------------
2022-11-29 04:39:45 Epoch [30000/30000] Loss:0.002668 Loss_1:0.002664 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:39.694725s (9.57min in total, 0.00min remains)
2022-11-29 04:39:45 NUM_SUB: 119------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 04:39:45 Testing & drawing...
2022-11-29 04:39:45 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:39:47 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=119/
2022-11-29 04:39:47 [Loss]
2022-11-29 04:39:47 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:39:47 General parameter estimation: Parameter containing:
tensor([0.0113, 0.0256, 0.0122, 1.0277, 0.3074, 0.0163, 3.2942, 0.8964, 0.4556,
        0.0142, 0.1175, 0.1157, 0.6511, 0.1689, 0.0178, 0.9157, 0.6977, 0.8000,
        0.0117, 4.2424, 0.6816, 0.0223, 3.6512, 0.8742, 0.0084, 4.3719, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:39:47 A: prod, degr, TonA, NonA
2022-11-29 04:39:47 [0.43771803 0.47288373 0.0810353  0.00836296]
2022-11-29 04:39:47 T: prod, degr, AonT, NonT
2022-11-29 04:39:47 [0.12796189 0.4992724  0.34895918 0.02380656]
2022-11-29 04:39:47 N: AonN, TonN, ATonN
2022-11-29 04:39:47 [0.00764395 0.9823415  0.0100145 ]
2022-11-29 04:39:47 using cpu
2022-11-29 04:39:47 epoch = 30000
2022-11-29 04:39:47 epoch_step = 2000
2022-11-29 04:39:47 model_name = SimpleNetworkAD
2022-11-29 04:39:47 now_string = 2022-11-28-18-17-05
2022-11-29 04:39:47 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 04:39:47 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 04:39:47 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 04:39:47 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 04:39:47 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 04:39:47 --------------------------------------------------training start--------------------------------------------------
2022-11-29 04:40:25 NUM_SUB: 120;----------------------------
2022-11-29 04:40:25 Epoch [02000/30000] Loss:0.044063 Loss_1:0.043296 Loss_2:0.000356 Loss_3:0.000000 Lr:0.000833 Time:38.156793s (0.64min in total, 8.90min remains)
2022-11-29 04:41:03 NUM_SUB: 120;----------------------------
2022-11-29 04:41:03 Epoch [04000/30000] Loss:0.034597 Loss_1:0.034437 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000714 Time:38.122562s (1.27min in total, 8.26min remains)
2022-11-29 04:41:41 NUM_SUB: 120;----------------------------
2022-11-29 04:41:41 Epoch [06000/30000] Loss:0.018938 Loss_1:0.018810 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000625 Time:38.198613s (1.91min in total, 7.63min remains)
2022-11-29 04:42:19 NUM_SUB: 120;----------------------------
2022-11-29 04:42:19 Epoch [08000/30000] Loss:0.004300 Loss_1:0.004222 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000556 Time:38.262283s (2.55min in total, 7.00min remains)
2022-11-29 04:42:58 NUM_SUB: 120;----------------------------
2022-11-29 04:42:58 Epoch [10000/30000] Loss:0.002905 Loss_1:0.002847 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000500 Time:38.092765s (3.18min in total, 6.36min remains)
2022-11-29 04:43:36 NUM_SUB: 120;----------------------------
2022-11-29 04:43:36 Epoch [12000/30000] Loss:0.002386 Loss_1:0.002364 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000455 Time:38.157802s (3.82min in total, 5.72min remains)
2022-11-29 04:44:14 NUM_SUB: 120;----------------------------
2022-11-29 04:44:14 Epoch [14000/30000] Loss:0.001697 Loss_1:0.001678 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000417 Time:38.162637s (4.45min in total, 5.09min remains)
2022-11-29 04:44:52 NUM_SUB: 120;----------------------------
2022-11-29 04:44:52 Epoch [16000/30000] Loss:0.001442 Loss_1:0.001427 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000385 Time:38.137091s (5.09min in total, 4.45min remains)
2022-11-29 04:45:30 NUM_SUB: 120;----------------------------
2022-11-29 04:45:30 Epoch [18000/30000] Loss:0.001434 Loss_1:0.001425 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.138238s (5.72min in total, 3.82min remains)
2022-11-29 04:46:08 NUM_SUB: 120;----------------------------
2022-11-29 04:46:08 Epoch [20000/30000] Loss:0.001431 Loss_1:0.001423 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.096254s (6.36min in total, 3.18min remains)
2022-11-29 04:46:46 NUM_SUB: 120;----------------------------
2022-11-29 04:46:46 Epoch [22000/30000] Loss:0.001429 Loss_1:0.001423 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.122184s (6.99min in total, 2.54min remains)
2022-11-29 04:47:24 NUM_SUB: 120;----------------------------
2022-11-29 04:47:24 Epoch [24000/30000] Loss:0.001428 Loss_1:0.001424 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.112263s (7.63min in total, 1.91min remains)
2022-11-29 04:48:03 NUM_SUB: 120;----------------------------
2022-11-29 04:48:03 Epoch [26000/30000] Loss:0.001446 Loss_1:0.001443 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:38.127664s (8.26min in total, 1.27min remains)
2022-11-29 04:48:41 NUM_SUB: 120;----------------------------
2022-11-29 04:48:41 Epoch [28000/30000] Loss:0.001426 Loss_1:0.001424 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.020902s (8.90min in total, 0.64min remains)
2022-11-29 04:49:19 Testing & drawing...
2022-11-29 04:49:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:49:20 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=120/
2022-11-29 04:49:20 [Loss]
2022-11-29 04:49:20 NUM_SUB: 120; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:49:20 NUM_SUB: 120; Personalized parameter estimation: Parameter containing:
tensor([0.1112, 0.4277, 0.0097, 0.1015, 0.3074, 0.0080, 0.7442, 0.8964, 0.4556,
        0.0143, 0.1288, 0.1107, 0.5831, 0.1689, 0.0178, 1.3177, 0.6977, 0.8000,
        0.0125, 1.5484, 0.6816, 0.0206, 3.0906, 0.8742, 0.0209, 3.5719, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:49:20 NUM_SUB: 120;----------------------------
2022-11-29 04:49:20 Epoch [30000/30000] Loss:0.001426 Loss_1:0.001424 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.745365s (9.56min in total, 0.00min remains)
2022-11-29 04:49:20 NUM_SUB: 120------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 04:49:20 Testing & drawing...
2022-11-29 04:49:20 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:49:22 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=120/
2022-11-29 04:49:22 [Loss]
2022-11-29 04:49:22 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:49:22 General parameter estimation: Parameter containing:
tensor([0.1111, 0.4277, 0.0097, 0.1014, 0.3074, 0.0080, 0.7442, 0.8964, 0.4556,
        0.0143, 0.1288, 0.1106, 0.5831, 0.1689, 0.0178, 1.3178, 0.6977, 0.8000,
        0.0125, 1.5481, 0.6816, 0.0206, 3.0907, 0.8742, 0.0209, 3.5720, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 04:49:22 A: prod, degr, TonA, NonA
2022-11-29 04:49:22 [0.448982   0.49919912 0.03593495 0.01588394]
2022-11-29 04:49:22 T: prod, degr, AonT, NonT
2022-11-29 04:49:22 [0.16212778 0.42214203 0.3692731  0.04645708]
2022-11-29 04:49:22 N: AonN, TonN, ATonN
2022-11-29 04:49:22 [0.02456826 0.952544   0.02288781]
2022-11-29 04:49:22 using cpu
2022-11-29 04:49:22 epoch = 30000
2022-11-29 04:49:22 epoch_step = 2000
2022-11-29 04:49:22 model_name = SimpleNetworkAD
2022-11-29 04:49:22 now_string = 2022-11-28-18-17-05
2022-11-29 04:49:22 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 04:49:22 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 04:49:22 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 04:49:22 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 04:49:22 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 04:49:22 --------------------------------------------------training start--------------------------------------------------
2022-11-29 04:50:00 NUM_SUB: 121;----------------------------
2022-11-29 04:50:00 Epoch [02000/30000] Loss:0.106106 Loss_1:0.105022 Loss_2:0.000617 Loss_3:0.000000 Lr:0.000833 Time:38.253772s (0.64min in total, 8.93min remains)
2022-11-29 04:50:39 NUM_SUB: 121;----------------------------
2022-11-29 04:50:39 Epoch [04000/30000] Loss:0.087277 Loss_1:0.086813 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000714 Time:38.195437s (1.27min in total, 8.28min remains)
2022-11-29 04:51:17 NUM_SUB: 121;----------------------------
2022-11-29 04:51:17 Epoch [06000/30000] Loss:0.051771 Loss_1:0.051394 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000625 Time:38.363347s (1.91min in total, 7.65min remains)
2022-11-29 04:51:55 NUM_SUB: 121;----------------------------
2022-11-29 04:51:55 Epoch [08000/30000] Loss:0.013660 Loss_1:0.013405 Loss_2:0.000155 Loss_3:0.000000 Lr:0.000556 Time:38.168140s (2.55min in total, 7.01min remains)
2022-11-29 04:52:33 NUM_SUB: 121;----------------------------
2022-11-29 04:52:33 Epoch [10000/30000] Loss:0.001753 Loss_1:0.001600 Loss_2:0.000150 Loss_3:0.000000 Lr:0.000500 Time:38.287479s (3.19min in total, 6.38min remains)
2022-11-29 04:53:12 NUM_SUB: 121;----------------------------
2022-11-29 04:53:12 Epoch [12000/30000] Loss:0.001406 Loss_1:0.001346 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000455 Time:38.243116s (3.83min in total, 5.74min remains)
2022-11-29 04:53:50 NUM_SUB: 121;----------------------------
2022-11-29 04:53:50 Epoch [14000/30000] Loss:0.001315 Loss_1:0.001287 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000417 Time:38.066421s (4.46min in total, 5.10min remains)
2022-11-29 04:54:28 NUM_SUB: 121;----------------------------
2022-11-29 04:54:28 Epoch [16000/30000] Loss:0.001263 Loss_1:0.001249 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.160165s (5.10min in total, 4.46min remains)
2022-11-29 04:55:06 NUM_SUB: 121;----------------------------
2022-11-29 04:55:06 Epoch [18000/30000] Loss:0.001179 Loss_1:0.001172 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.062459s (5.73min in total, 3.82min remains)
2022-11-29 04:55:44 NUM_SUB: 121;----------------------------
2022-11-29 04:55:44 Epoch [20000/30000] Loss:0.000945 Loss_1:0.000942 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.175198s (6.37min in total, 3.18min remains)
2022-11-29 04:56:22 NUM_SUB: 121;----------------------------
2022-11-29 04:56:22 Epoch [22000/30000] Loss:0.000799 Loss_1:0.000796 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.116219s (7.00min in total, 2.55min remains)
2022-11-29 04:57:00 NUM_SUB: 121;----------------------------
2022-11-29 04:57:00 Epoch [24000/30000] Loss:0.000796 Loss_1:0.000794 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.069121s (7.64min in total, 1.91min remains)
2022-11-29 04:57:38 NUM_SUB: 121;----------------------------
2022-11-29 04:57:38 Epoch [26000/30000] Loss:0.000796 Loss_1:0.000794 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.157904s (8.27min in total, 1.27min remains)
2022-11-29 04:58:17 NUM_SUB: 121;----------------------------
2022-11-29 04:58:17 Epoch [28000/30000] Loss:0.000796 Loss_1:0.000794 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.169260s (8.91min in total, 0.64min remains)
2022-11-29 04:58:55 Testing & drawing...
2022-11-29 04:58:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:58:56 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=121/
2022-11-29 04:58:56 [Loss]
2022-11-29 04:58:56 NUM_SUB: 121; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:58:56 NUM_SUB: 121; Personalized parameter estimation: Parameter containing:
tensor([4.7150e-01, 7.9041e-01, 2.4944e-02, 3.4806e-13, 3.0742e-01, 1.3658e-02,
        6.6326e-02, 8.9644e-01, 4.5563e-01, 9.8886e-03, 3.9634e-02, 1.4825e-02,
        7.2269e-01, 1.6886e-01, 1.7383e-02, 2.9991e-01, 6.9767e-01, 8.0001e-01,
        1.1269e-02, 3.5956e+00, 6.8161e-01, 2.3134e-02, 2.3622e+00, 8.7416e-01,
        2.0209e-02, 3.4795e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 04:58:56 NUM_SUB: 121;----------------------------
2022-11-29 04:58:56 Epoch [30000/30000] Loss:0.000796 Loss_1:0.000793 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.706268s (9.57min in total, 0.00min remains)
2022-11-29 04:58:56 NUM_SUB: 121------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 04:58:56 Testing & drawing...
2022-11-29 04:58:56 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 04:58:58 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=121/
2022-11-29 04:58:58 [Loss]
2022-11-29 04:58:58 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 04:58:58 General parameter estimation: Parameter containing:
tensor([4.7151e-01, 7.9039e-01, 2.4962e-02, 3.4491e-13, 3.0742e-01, 1.3658e-02,
        6.6310e-02, 8.9644e-01, 4.5563e-01, 9.8886e-03, 3.9635e-02, 1.4825e-02,
        7.2277e-01, 1.6886e-01, 1.7383e-02, 2.9990e-01, 6.9767e-01, 8.0001e-01,
        1.1269e-02, 3.5958e+00, 6.8161e-01, 2.3134e-02, 2.3622e+00, 8.7416e-01,
        2.0208e-02, 3.4796e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 04:58:58 A: prod, degr, TonA, NonA
2022-11-29 04:58:58 [0.46230286 0.49990818 0.02447414 0.01331486]
2022-11-29 04:58:58 T: prod, degr, AonT, NonT
2022-11-29 04:58:58 [0.16637753 0.43018326 0.14109823 0.26234093]
2022-11-29 04:58:58 N: AonN, TonN, ATonN
2022-11-29 04:58:58 [0.01449688 0.91577554 0.0697276 ]
2022-11-29 04:58:58 using cpu
2022-11-29 04:58:58 epoch = 30000
2022-11-29 04:58:58 epoch_step = 2000
2022-11-29 04:58:58 model_name = SimpleNetworkAD
2022-11-29 04:58:58 now_string = 2022-11-28-18-17-05
2022-11-29 04:58:58 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 04:58:58 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 04:58:58 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 04:58:58 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 04:58:58 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 04:58:58 --------------------------------------------------training start--------------------------------------------------
2022-11-29 04:59:36 NUM_SUB: 122;----------------------------
2022-11-29 04:59:36 Epoch [02000/30000] Loss:0.135899 Loss_1:0.134888 Loss_2:0.000567 Loss_3:0.000000 Lr:0.000833 Time:38.077424s (0.63min in total, 8.88min remains)
2022-11-29 05:00:14 NUM_SUB: 122;----------------------------
2022-11-29 05:00:14 Epoch [04000/30000] Loss:0.103159 Loss_1:0.102633 Loss_2:0.000124 Loss_3:0.000000 Lr:0.000714 Time:38.065917s (1.27min in total, 8.25min remains)
2022-11-29 05:00:52 NUM_SUB: 122;----------------------------
2022-11-29 05:00:52 Epoch [06000/30000] Loss:0.038403 Loss_1:0.037980 Loss_2:0.000153 Loss_3:0.000000 Lr:0.000625 Time:38.084056s (1.90min in total, 7.62min remains)
2022-11-29 05:01:31 NUM_SUB: 122;----------------------------
2022-11-29 05:01:31 Epoch [08000/30000] Loss:0.005464 Loss_1:0.005281 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000556 Time:38.160538s (2.54min in total, 6.98min remains)
2022-11-29 05:02:09 NUM_SUB: 122;----------------------------
2022-11-29 05:02:09 Epoch [10000/30000] Loss:0.002288 Loss_1:0.002162 Loss_2:0.000125 Loss_3:0.000000 Lr:0.000500 Time:38.098273s (3.17min in total, 6.35min remains)
2022-11-29 05:02:47 NUM_SUB: 122;----------------------------
2022-11-29 05:02:47 Epoch [12000/30000] Loss:0.000825 Loss_1:0.000773 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:38.103982s (3.81min in total, 5.71min remains)
2022-11-29 05:03:25 NUM_SUB: 122;----------------------------
2022-11-29 05:03:25 Epoch [14000/30000] Loss:0.000249 Loss_1:0.000212 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000417 Time:38.224738s (4.45min in total, 5.08min remains)
2022-11-29 05:04:03 NUM_SUB: 122;----------------------------
2022-11-29 05:04:03 Epoch [16000/30000] Loss:0.000230 Loss_1:0.000207 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000385 Time:38.060070s (5.08min in total, 4.45min remains)
2022-11-29 05:04:41 NUM_SUB: 122;----------------------------
2022-11-29 05:04:41 Epoch [18000/30000] Loss:0.000221 Loss_1:0.000207 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:38.171693s (5.72min in total, 3.81min remains)
2022-11-29 05:05:19 NUM_SUB: 122;----------------------------
2022-11-29 05:05:19 Epoch [20000/30000] Loss:0.000215 Loss_1:0.000206 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:38.100464s (6.35min in total, 3.18min remains)
2022-11-29 05:05:57 NUM_SUB: 122;----------------------------
2022-11-29 05:05:57 Epoch [22000/30000] Loss:0.000217 Loss_1:0.000211 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.201613s (6.99min in total, 2.54min remains)
2022-11-29 05:06:36 NUM_SUB: 122;----------------------------
2022-11-29 05:06:36 Epoch [24000/30000] Loss:0.000210 Loss_1:0.000206 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.145512s (7.63min in total, 1.91min remains)
2022-11-29 05:07:14 NUM_SUB: 122;----------------------------
2022-11-29 05:07:14 Epoch [26000/30000] Loss:0.000209 Loss_1:0.000206 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:38.087278s (8.26min in total, 1.27min remains)
2022-11-29 05:07:52 NUM_SUB: 122;----------------------------
2022-11-29 05:07:52 Epoch [28000/30000] Loss:0.000208 Loss_1:0.000206 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.071049s (8.89min in total, 0.64min remains)
2022-11-29 05:08:30 Testing & drawing...
2022-11-29 05:08:30 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:08:32 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=122/
2022-11-29 05:08:32 [Loss]
2022-11-29 05:08:32 NUM_SUB: 122; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:08:32 NUM_SUB: 122; Personalized parameter estimation: Parameter containing:
tensor([0.0172, 0.0557, 0.0133, 0.6769, 0.3074, 0.0461, 1.6045, 0.8964, 0.4556,
        0.0142, 0.0328, 0.0138, 0.9139, 0.1689, 0.0177, 2.5500, 0.6977, 0.8000,
        0.0115, 3.8388, 0.6816, 0.0222, 3.3896, 0.8742, 0.0201, 4.1254, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:08:32 NUM_SUB: 122;----------------------------
2022-11-29 05:08:32 Epoch [30000/30000] Loss:0.000208 Loss_1:0.000206 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.769353s (9.56min in total, 0.00min remains)
2022-11-29 05:08:32 NUM_SUB: 122------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:08:32 Testing & drawing...
2022-11-29 05:08:32 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:08:33 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=122/
2022-11-29 05:08:33 [Loss]
2022-11-29 05:08:33 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:08:33 General parameter estimation: Parameter containing:
tensor([0.0172, 0.0557, 0.0133, 0.6769, 0.3074, 0.0461, 1.6045, 0.8964, 0.4556,
        0.0142, 0.0328, 0.0138, 0.9139, 0.1689, 0.0177, 2.5500, 0.6977, 0.8000,
        0.0115, 3.8387, 0.6816, 0.0222, 3.3895, 0.8742, 0.0201, 4.1253, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:08:33 A: prod, degr, TonA, NonA
2022-11-29 05:08:33 [0.24007949 0.49196222 0.07744904 0.19050926]
2022-11-29 05:08:33 T: prod, degr, AonT, NonT
2022-11-29 05:08:33 [0.34252617 0.50062984 0.09532533 0.06151868]
2022-11-29 05:08:33 N: AonN, TonN, ATonN
2022-11-29 05:08:33 [0.01453552 0.9456396  0.03982489]
2022-11-29 05:08:33 using cpu
2022-11-29 05:08:33 epoch = 30000
2022-11-29 05:08:33 epoch_step = 2000
2022-11-29 05:08:33 model_name = SimpleNetworkAD
2022-11-29 05:08:33 now_string = 2022-11-28-18-17-05
2022-11-29 05:08:33 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:08:33 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:08:33 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:08:33 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:08:33 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:08:33 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:09:12 NUM_SUB: 123;----------------------------
2022-11-29 05:09:12 Epoch [02000/30000] Loss:0.025214 Loss_1:0.024319 Loss_2:0.000445 Loss_3:0.000000 Lr:0.000833 Time:38.265365s (0.64min in total, 8.93min remains)
2022-11-29 05:09:50 NUM_SUB: 123;----------------------------
2022-11-29 05:09:50 Epoch [04000/30000] Loss:0.020499 Loss_1:0.020290 Loss_2:0.000075 Loss_3:0.000000 Lr:0.000714 Time:38.190072s (1.27min in total, 8.28min remains)
2022-11-29 05:10:28 NUM_SUB: 123;----------------------------
2022-11-29 05:10:28 Epoch [06000/30000] Loss:0.014040 Loss_1:0.013837 Loss_2:0.000072 Loss_3:0.000000 Lr:0.000625 Time:38.184055s (1.91min in total, 7.64min remains)
2022-11-29 05:11:06 NUM_SUB: 123;----------------------------
2022-11-29 05:11:06 Epoch [08000/30000] Loss:0.004931 Loss_1:0.004781 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000556 Time:38.070609s (2.55min in total, 7.00min remains)
2022-11-29 05:11:44 NUM_SUB: 123;----------------------------
2022-11-29 05:11:44 Epoch [10000/30000] Loss:0.000716 Loss_1:0.000619 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000500 Time:38.106149s (3.18min in total, 6.36min remains)
2022-11-29 05:12:22 NUM_SUB: 123;----------------------------
2022-11-29 05:12:22 Epoch [12000/30000] Loss:0.000537 Loss_1:0.000491 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:38.061857s (3.81min in total, 5.72min remains)
2022-11-29 05:13:00 NUM_SUB: 123;----------------------------
2022-11-29 05:13:00 Epoch [14000/30000] Loss:0.000454 Loss_1:0.000430 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:38.074169s (4.45min in total, 5.08min remains)
2022-11-29 05:13:38 NUM_SUB: 123;----------------------------
2022-11-29 05:13:38 Epoch [16000/30000] Loss:0.000370 Loss_1:0.000353 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.050662s (5.08min in total, 4.45min remains)
2022-11-29 05:14:17 NUM_SUB: 123;----------------------------
2022-11-29 05:14:17 Epoch [18000/30000] Loss:0.000295 Loss_1:0.000279 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000357 Time:38.360412s (5.72min in total, 3.82min remains)
2022-11-29 05:14:55 NUM_SUB: 123;----------------------------
2022-11-29 05:14:55 Epoch [20000/30000] Loss:0.000274 Loss_1:0.000268 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.074028s (6.36min in total, 3.18min remains)
2022-11-29 05:15:33 NUM_SUB: 123;----------------------------
2022-11-29 05:15:33 Epoch [22000/30000] Loss:0.000268 Loss_1:0.000265 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.152533s (6.99min in total, 2.54min remains)
2022-11-29 05:16:11 NUM_SUB: 123;----------------------------
2022-11-29 05:16:11 Epoch [24000/30000] Loss:0.000265 Loss_1:0.000263 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.066816s (7.63min in total, 1.91min remains)
2022-11-29 05:16:49 NUM_SUB: 123;----------------------------
2022-11-29 05:16:49 Epoch [26000/30000] Loss:0.000262 Loss_1:0.000260 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.070197s (8.26min in total, 1.27min remains)
2022-11-29 05:17:27 NUM_SUB: 123;----------------------------
2022-11-29 05:17:27 Epoch [28000/30000] Loss:0.000259 Loss_1:0.000258 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.152737s (8.90min in total, 0.64min remains)
2022-11-29 05:18:05 Testing & drawing...
2022-11-29 05:18:05 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:18:07 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=123/
2022-11-29 05:18:07 [Loss]
2022-11-29 05:18:07 NUM_SUB: 123; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:18:07 NUM_SUB: 123; Personalized parameter estimation: Parameter containing:
tensor([0.0114, 0.2349, 0.0094, 0.7966, 0.3074, 0.5019, 0.8038, 0.8964, 0.4556,
        0.0045, 0.0429, 0.0229, 0.2776, 0.1689, 0.0177, 1.5546, 0.6977, 0.8000,
        0.0120, 3.9186, 0.6816, 0.0221, 3.6884, 0.8742, 0.0197, 4.4618, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:18:07 NUM_SUB: 123;----------------------------
2022-11-29 05:18:07 Epoch [30000/30000] Loss:0.000256 Loss_1:0.000255 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.805041s (9.56min in total, 0.00min remains)
2022-11-29 05:18:07 NUM_SUB: 123------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:18:07 Testing & drawing...
2022-11-29 05:18:07 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:18:09 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=123/
2022-11-29 05:18:09 [Loss]
2022-11-29 05:18:09 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:18:09 General parameter estimation: Parameter containing:
tensor([0.0114, 0.2349, 0.0094, 0.7966, 0.3074, 0.5019, 0.8038, 0.8964, 0.4556,
        0.0045, 0.0429, 0.0229, 0.2776, 0.1689, 0.0177, 1.5547, 0.6977, 0.8000,
        0.0120, 3.9187, 0.6816, 0.0221, 3.6886, 0.8742, 0.0197, 4.4619, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:18:09 A: prod, degr, TonA, NonA
2022-11-29 05:18:09 [0.05518416 0.49617255 0.01459712 0.43404615]
2022-11-29 05:18:09 T: prod, degr, AonT, NonT
2022-11-29 05:18:09 [0.10573686 0.4440165  0.4270573  0.02318938]
2022-11-29 05:18:09 N: AonN, TonN, ATonN
2022-11-29 05:18:09 [0.00750025 0.96927816 0.0232216 ]
2022-11-29 05:18:09 using cpu
2022-11-29 05:18:09 epoch = 30000
2022-11-29 05:18:09 epoch_step = 2000
2022-11-29 05:18:09 model_name = SimpleNetworkAD
2022-11-29 05:18:09 now_string = 2022-11-28-18-17-05
2022-11-29 05:18:09 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:18:09 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:18:09 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:18:09 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:18:09 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:18:09 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:18:47 NUM_SUB: 124;----------------------------
2022-11-29 05:18:47 Epoch [02000/30000] Loss:0.086073 Loss_1:0.085219 Loss_2:0.000444 Loss_3:0.000000 Lr:0.000833 Time:38.071228s (0.63min in total, 8.88min remains)
2022-11-29 05:19:25 NUM_SUB: 124;----------------------------
2022-11-29 05:19:25 Epoch [04000/30000] Loss:0.062383 Loss_1:0.062060 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000714 Time:38.048508s (1.27min in total, 8.25min remains)
2022-11-29 05:20:03 NUM_SUB: 124;----------------------------
2022-11-29 05:20:03 Epoch [06000/30000] Loss:0.022068 Loss_1:0.021814 Loss_2:0.000110 Loss_3:0.000000 Lr:0.000625 Time:38.123254s (1.90min in total, 7.62min remains)
2022-11-29 05:20:41 NUM_SUB: 124;----------------------------
2022-11-29 05:20:41 Epoch [08000/30000] Loss:0.003161 Loss_1:0.003008 Loss_2:0.000130 Loss_3:0.000000 Lr:0.000556 Time:38.173136s (2.54min in total, 6.99min remains)
2022-11-29 05:21:19 NUM_SUB: 124;----------------------------
2022-11-29 05:21:19 Epoch [10000/30000] Loss:0.001283 Loss_1:0.001163 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000500 Time:38.194413s (3.18min in total, 6.35min remains)
2022-11-29 05:21:58 NUM_SUB: 124;----------------------------
2022-11-29 05:21:58 Epoch [12000/30000] Loss:0.000770 Loss_1:0.000709 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000455 Time:38.124037s (3.81min in total, 5.72min remains)
2022-11-29 05:22:36 NUM_SUB: 124;----------------------------
2022-11-29 05:22:36 Epoch [14000/30000] Loss:0.000535 Loss_1:0.000513 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:38.171325s (4.45min in total, 5.08min remains)
2022-11-29 05:23:14 NUM_SUB: 124;----------------------------
2022-11-29 05:23:14 Epoch [16000/30000] Loss:0.000436 Loss_1:0.000424 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:38.149987s (5.08min in total, 4.45min remains)
2022-11-29 05:23:52 NUM_SUB: 124;----------------------------
2022-11-29 05:23:52 Epoch [18000/30000] Loss:0.000410 Loss_1:0.000402 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.018208s (5.72min in total, 3.81min remains)
2022-11-29 05:24:30 NUM_SUB: 124;----------------------------
2022-11-29 05:24:30 Epoch [20000/30000] Loss:0.000363 Loss_1:0.000358 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:38.119234s (6.35min in total, 3.18min remains)
2022-11-29 05:25:08 NUM_SUB: 124;----------------------------
2022-11-29 05:25:08 Epoch [22000/30000] Loss:0.000344 Loss_1:0.000341 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.078522s (6.99min in total, 2.54min remains)
2022-11-29 05:25:46 NUM_SUB: 124;----------------------------
2022-11-29 05:25:46 Epoch [24000/30000] Loss:0.000349 Loss_1:0.000347 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.067651s (7.62min in total, 1.91min remains)
2022-11-29 05:26:24 NUM_SUB: 124;----------------------------
2022-11-29 05:26:24 Epoch [26000/30000] Loss:0.000342 Loss_1:0.000340 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.076475s (8.26min in total, 1.27min remains)
2022-11-29 05:27:02 NUM_SUB: 124;----------------------------
2022-11-29 05:27:02 Epoch [28000/30000] Loss:0.000342 Loss_1:0.000340 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.184719s (8.89min in total, 0.64min remains)
2022-11-29 05:27:41 Testing & drawing...
2022-11-29 05:27:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:27:42 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=124/
2022-11-29 05:27:42 [Loss]
2022-11-29 05:27:42 NUM_SUB: 124; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:27:42 NUM_SUB: 124; Personalized parameter estimation: Parameter containing:
tensor([0.0161, 0.0445, 0.0106, 0.8894, 0.3074, 0.0133, 2.2832, 0.8964, 0.4556,
        0.0139, 0.0385, 0.0119, 0.7637, 0.1689, 0.0175, 2.1779, 0.6977, 0.8000,
        0.0122, 3.4003, 0.6816, 0.0220, 3.0046, 0.8742, 0.0215, 3.8232, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:27:42 NUM_SUB: 124;----------------------------
2022-11-29 05:27:42 Epoch [30000/30000] Loss:0.000344 Loss_1:0.000342 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.818284s (9.56min in total, 0.00min remains)
2022-11-29 05:27:42 NUM_SUB: 124------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:27:42 Testing & drawing...
2022-11-29 05:27:42 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:27:44 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=124/
2022-11-29 05:27:44 [Loss]
2022-11-29 05:27:44 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:27:44 General parameter estimation: Parameter containing:
tensor([0.0161, 0.0446, 0.0106, 0.8895, 0.3074, 0.0133, 2.2834, 0.8964, 0.4556,
        0.0139, 0.0385, 0.0119, 0.7637, 0.1689, 0.0175, 2.1780, 0.6977, 0.8000,
        0.0122, 3.4003, 0.6816, 0.0220, 3.0046, 0.8742, 0.0215, 3.8232, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:27:44 A: prod, degr, TonA, NonA
2022-11-29 05:27:44 [0.41652146 0.48688203 0.05995709 0.03663943]
2022-11-29 05:27:44 T: prod, degr, AonT, NonT
2022-11-29 05:27:44 [0.39175367 0.45874706 0.09239318 0.05710604]
2022-11-29 05:27:44 N: AonN, TonN, ATonN
2022-11-29 05:27:44 [0.00943162 0.96162945 0.02893891]
2022-11-29 05:27:44 using cpu
2022-11-29 05:27:44 epoch = 30000
2022-11-29 05:27:44 epoch_step = 2000
2022-11-29 05:27:44 model_name = SimpleNetworkAD
2022-11-29 05:27:44 now_string = 2022-11-28-18-17-05
2022-11-29 05:27:44 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:27:44 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:27:44 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:27:44 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:27:44 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:27:44 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:28:22 NUM_SUB: 125;----------------------------
2022-11-29 05:28:22 Epoch [02000/30000] Loss:0.042730 Loss_1:0.041915 Loss_2:0.000418 Loss_3:0.000000 Lr:0.000833 Time:38.140693s (0.64min in total, 8.90min remains)
2022-11-29 05:29:00 NUM_SUB: 125;----------------------------
2022-11-29 05:29:00 Epoch [04000/30000] Loss:0.033735 Loss_1:0.033517 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000714 Time:38.034760s (1.27min in total, 8.25min remains)
2022-11-29 05:29:39 NUM_SUB: 125;----------------------------
2022-11-29 05:29:39 Epoch [06000/30000] Loss:0.019134 Loss_1:0.018982 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000625 Time:38.380111s (1.91min in total, 7.64min remains)
2022-11-29 05:30:17 NUM_SUB: 125;----------------------------
2022-11-29 05:30:17 Epoch [08000/30000] Loss:0.004869 Loss_1:0.004780 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000556 Time:38.032232s (2.54min in total, 6.99min remains)
2022-11-29 05:30:55 NUM_SUB: 125;----------------------------
2022-11-29 05:30:55 Epoch [10000/30000] Loss:0.003181 Loss_1:0.003137 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000500 Time:38.570429s (3.19min in total, 6.37min remains)
2022-11-29 05:31:33 NUM_SUB: 125;----------------------------
2022-11-29 05:31:33 Epoch [12000/30000] Loss:0.002424 Loss_1:0.002408 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000455 Time:38.128970s (3.82min in total, 5.73min remains)
2022-11-29 05:32:12 NUM_SUB: 125;----------------------------
2022-11-29 05:32:12 Epoch [14000/30000] Loss:0.001810 Loss_1:0.001800 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000417 Time:38.375932s (4.46min in total, 5.10min remains)
2022-11-29 05:32:50 NUM_SUB: 125;----------------------------
2022-11-29 05:32:50 Epoch [16000/30000] Loss:0.001745 Loss_1:0.001739 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:38.093456s (5.10min in total, 4.46min remains)
2022-11-29 05:33:28 NUM_SUB: 125;----------------------------
2022-11-29 05:33:28 Epoch [18000/30000] Loss:0.001739 Loss_1:0.001737 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000357 Time:38.375412s (5.74min in total, 3.82min remains)
2022-11-29 05:34:06 NUM_SUB: 125;----------------------------
2022-11-29 05:34:06 Epoch [20000/30000] Loss:0.001738 Loss_1:0.001736 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:38.298895s (6.37min in total, 3.19min remains)
2022-11-29 05:34:45 NUM_SUB: 125;----------------------------
2022-11-29 05:34:45 Epoch [22000/30000] Loss:0.001737 Loss_1:0.001736 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.300735s (7.01min in total, 2.55min remains)
2022-11-29 05:35:23 NUM_SUB: 125;----------------------------
2022-11-29 05:35:23 Epoch [24000/30000] Loss:0.001737 Loss_1:0.001736 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.324750s (7.65min in total, 1.91min remains)
2022-11-29 05:36:01 NUM_SUB: 125;----------------------------
2022-11-29 05:36:01 Epoch [26000/30000] Loss:0.001737 Loss_1:0.001735 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.198982s (8.29min in total, 1.28min remains)
2022-11-29 05:36:39 NUM_SUB: 125;----------------------------
2022-11-29 05:36:39 Epoch [28000/30000] Loss:0.001737 Loss_1:0.001736 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.106577s (8.92min in total, 0.64min remains)
2022-11-29 05:37:18 Testing & drawing...
2022-11-29 05:37:18 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:37:19 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=125/
2022-11-29 05:37:19 [Loss]
2022-11-29 05:37:19 NUM_SUB: 125; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:37:19 NUM_SUB: 125; Personalized parameter estimation: Parameter containing:
tensor([3.4223e-01, 9.3547e-01, 1.0053e-02, 3.4255e-37, 3.0742e-01, 5.0184e-04,
        7.9274e-01, 8.9644e-01, 4.5563e-01, 1.4283e-02, 1.5433e-01, 1.1935e-01,
        5.0302e-01, 1.6886e-01, 1.7704e-02, 1.5713e+00, 6.9767e-01, 8.0001e-01,
        1.2350e-02, 2.2673e+00, 6.8161e-01, 2.2412e-02, 3.0227e+00, 8.7416e-01,
        2.1740e-02, 3.5036e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 05:37:19 NUM_SUB: 125;----------------------------
2022-11-29 05:37:19 Epoch [30000/30000] Loss:0.001737 Loss_1:0.001736 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.836628s (9.59min in total, 0.00min remains)
2022-11-29 05:37:19 NUM_SUB: 125------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:37:19 Testing & drawing...
2022-11-29 05:37:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:37:21 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=125/
2022-11-29 05:37:21 [Loss]
2022-11-29 05:37:21 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:37:21 General parameter estimation: Parameter containing:
tensor([3.4224e-01, 9.3546e-01, 1.0053e-02, 3.4255e-37, 3.0742e-01, 5.0737e-04,
        7.9274e-01, 8.9644e-01, 4.5563e-01, 1.4283e-02, 1.5436e-01, 1.1931e-01,
        5.0305e-01, 1.6886e-01, 1.7704e-02, 1.5714e+00, 6.9767e-01, 8.0001e-01,
        1.2350e-02, 2.2670e+00, 6.8161e-01, 2.2412e-02, 3.0228e+00, 8.7416e-01,
        2.1740e-02, 3.5037e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 05:37:21 A: prod, degr, TonA, NonA
2022-11-29 05:37:21 [4.8551291e-01 4.9989843e-01 1.4262411e-02 3.2619174e-04]
2022-11-29 05:37:21 T: prod, degr, AonT, NonT
2022-11-29 05:37:21 [0.1289639  0.5250086  0.31866175 0.02736572]
2022-11-29 05:37:21 N: AonN, TonN, ATonN
2022-11-29 05:37:21 [0.01955405 0.95407265 0.02637335]
2022-11-29 05:37:21 using cpu
2022-11-29 05:37:21 epoch = 30000
2022-11-29 05:37:21 epoch_step = 2000
2022-11-29 05:37:21 model_name = SimpleNetworkAD
2022-11-29 05:37:21 now_string = 2022-11-28-18-17-05
2022-11-29 05:37:21 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:37:21 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:37:21 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:37:21 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:37:21 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:37:21 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:37:59 NUM_SUB: 126;----------------------------
2022-11-29 05:37:59 Epoch [02000/30000] Loss:0.056550 Loss_1:0.055727 Loss_2:0.000368 Loss_3:0.000000 Lr:0.000833 Time:38.414568s (0.64min in total, 8.96min remains)
2022-11-29 05:38:38 NUM_SUB: 126;----------------------------
2022-11-29 05:38:38 Epoch [04000/30000] Loss:0.044940 Loss_1:0.044622 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000714 Time:38.346027s (1.28min in total, 8.32min remains)
2022-11-29 05:39:16 NUM_SUB: 126;----------------------------
2022-11-29 05:39:16 Epoch [06000/30000] Loss:0.024884 Loss_1:0.024644 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000625 Time:38.186258s (1.92min in total, 7.66min remains)
2022-11-29 05:39:54 NUM_SUB: 126;----------------------------
2022-11-29 05:39:54 Epoch [08000/30000] Loss:0.004368 Loss_1:0.004246 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000556 Time:38.170590s (2.55min in total, 7.02min remains)
2022-11-29 05:40:32 NUM_SUB: 126;----------------------------
2022-11-29 05:40:32 Epoch [10000/30000] Loss:0.000626 Loss_1:0.000552 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000500 Time:38.055135s (3.19min in total, 6.37min remains)
2022-11-29 05:41:10 NUM_SUB: 126;----------------------------
2022-11-29 05:41:10 Epoch [12000/30000] Loss:0.000457 Loss_1:0.000418 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000455 Time:38.109192s (3.82min in total, 5.73min remains)
2022-11-29 05:41:49 NUM_SUB: 126;----------------------------
2022-11-29 05:41:49 Epoch [14000/30000] Loss:0.000406 Loss_1:0.000386 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:38.213731s (4.46min in total, 5.10min remains)
2022-11-29 05:42:27 NUM_SUB: 126;----------------------------
2022-11-29 05:42:27 Epoch [16000/30000] Loss:0.000370 Loss_1:0.000354 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.180265s (5.09min in total, 4.46min remains)
2022-11-29 05:43:05 NUM_SUB: 126;----------------------------
2022-11-29 05:43:05 Epoch [18000/30000] Loss:0.000350 Loss_1:0.000337 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:38.093900s (5.73min in total, 3.82min remains)
2022-11-29 05:43:43 NUM_SUB: 126;----------------------------
2022-11-29 05:43:43 Epoch [20000/30000] Loss:0.000334 Loss_1:0.000325 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:38.202573s (6.37min in total, 3.18min remains)
2022-11-29 05:44:21 NUM_SUB: 126;----------------------------
2022-11-29 05:44:21 Epoch [22000/30000] Loss:0.000332 Loss_1:0.000327 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:38.147188s (7.00min in total, 2.55min remains)
2022-11-29 05:44:59 NUM_SUB: 126;----------------------------
2022-11-29 05:44:59 Epoch [24000/30000] Loss:0.000329 Loss_1:0.000327 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.184860s (7.64min in total, 1.91min remains)
2022-11-29 05:45:38 NUM_SUB: 126;----------------------------
2022-11-29 05:45:38 Epoch [26000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.219795s (8.28min in total, 1.27min remains)
2022-11-29 05:46:16 NUM_SUB: 126;----------------------------
2022-11-29 05:46:16 Epoch [28000/30000] Loss:0.000322 Loss_1:0.000322 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.175623s (8.91min in total, 0.64min remains)
2022-11-29 05:46:54 Testing & drawing...
2022-11-29 05:46:54 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:46:55 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=126/
2022-11-29 05:46:55 [Loss]
2022-11-29 05:46:55 NUM_SUB: 126; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:46:55 NUM_SUB: 126; Personalized parameter estimation: Parameter containing:
tensor([0.0140, 0.0594, 0.0094, 1.1877, 0.3074, 0.0085, 1.3534, 0.8964, 0.4556,
        0.0111, 0.0829, 0.0312, 0.2704, 0.1689, 0.0174, 0.9984, 0.6977, 0.8000,
        0.0123, 3.2598, 0.6816, 0.0221, 3.4001, 0.8742, 0.0217, 4.1081, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:46:55 NUM_SUB: 126;----------------------------
2022-11-29 05:46:55 Epoch [30000/30000] Loss:0.000322 Loss_1:0.000321 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.687602s (9.57min in total, 0.00min remains)
2022-11-29 05:46:55 NUM_SUB: 126------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:46:55 Testing & drawing...
2022-11-29 05:46:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:46:57 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=126/
2022-11-29 05:46:57 [Loss]
2022-11-29 05:46:57 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:46:57 General parameter estimation: Parameter containing:
tensor([0.0140, 0.0594, 0.0094, 1.1877, 0.3074, 0.0085, 1.3534, 0.8964, 0.4556,
        0.0111, 0.0829, 0.0312, 0.2704, 0.1689, 0.0174, 0.9985, 0.6977, 0.8000,
        0.0123, 3.2598, 0.6816, 0.0221, 3.4002, 0.8742, 0.0217, 4.1082, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 05:46:57 A: prod, degr, TonA, NonA
2022-11-29 05:46:57 [0.41544414 0.49385503 0.03973644 0.05096439]
2022-11-29 05:46:57 T: prod, degr, AonT, NonT
2022-11-29 05:46:57 [0.17475897 0.36475515 0.37398997 0.08649591]
2022-11-29 05:46:57 N: AonN, TonN, ATonN
2022-11-29 05:46:57 [0.00451142 0.97582465 0.01966394]
2022-11-29 05:46:57 using cpu
2022-11-29 05:46:57 epoch = 30000
2022-11-29 05:46:57 epoch_step = 2000
2022-11-29 05:46:57 model_name = SimpleNetworkAD
2022-11-29 05:46:57 now_string = 2022-11-28-18-17-05
2022-11-29 05:46:57 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:46:57 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:46:57 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:46:57 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:46:57 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:46:57 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:47:35 NUM_SUB: 127;----------------------------
2022-11-29 05:47:35 Epoch [02000/30000] Loss:0.028299 Loss_1:0.027327 Loss_2:0.000556 Loss_3:0.000000 Lr:0.000833 Time:38.167180s (0.64min in total, 8.91min remains)
2022-11-29 05:48:14 NUM_SUB: 127;----------------------------
2022-11-29 05:48:14 Epoch [04000/30000] Loss:0.022029 Loss_1:0.021877 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000714 Time:38.260948s (1.27min in total, 8.28min remains)
2022-11-29 05:48:52 NUM_SUB: 127;----------------------------
2022-11-29 05:48:52 Epoch [06000/30000] Loss:0.012795 Loss_1:0.012652 Loss_2:0.000088 Loss_3:0.000000 Lr:0.000625 Time:38.079436s (1.91min in total, 7.63min remains)
2022-11-29 05:49:30 NUM_SUB: 127;----------------------------
2022-11-29 05:49:30 Epoch [08000/30000] Loss:0.003146 Loss_1:0.003049 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000556 Time:38.154503s (2.54min in total, 7.00min remains)
2022-11-29 05:50:08 NUM_SUB: 127;----------------------------
2022-11-29 05:50:08 Epoch [10000/30000] Loss:0.001096 Loss_1:0.001022 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000500 Time:38.143311s (3.18min in total, 6.36min remains)
2022-11-29 05:50:46 NUM_SUB: 127;----------------------------
2022-11-29 05:50:46 Epoch [12000/30000] Loss:0.000730 Loss_1:0.000682 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000455 Time:38.080303s (3.81min in total, 5.72min remains)
2022-11-29 05:51:24 NUM_SUB: 127;----------------------------
2022-11-29 05:51:24 Epoch [14000/30000] Loss:0.000442 Loss_1:0.000417 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:38.127464s (4.45min in total, 5.09min remains)
2022-11-29 05:52:02 NUM_SUB: 127;----------------------------
2022-11-29 05:52:02 Epoch [16000/30000] Loss:0.000413 Loss_1:0.000397 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:38.130607s (5.09min in total, 4.45min remains)
2022-11-29 05:52:41 NUM_SUB: 127;----------------------------
2022-11-29 05:52:41 Epoch [18000/30000] Loss:0.000406 Loss_1:0.000395 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.141961s (5.72min in total, 3.81min remains)
2022-11-29 05:53:19 NUM_SUB: 127;----------------------------
2022-11-29 05:53:19 Epoch [20000/30000] Loss:0.000402 Loss_1:0.000391 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.212960s (6.36min in total, 3.18min remains)
2022-11-29 05:53:57 NUM_SUB: 127;----------------------------
2022-11-29 05:53:57 Epoch [22000/30000] Loss:0.000397 Loss_1:0.000389 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:38.080533s (6.99min in total, 2.54min remains)
2022-11-29 05:54:35 NUM_SUB: 127;----------------------------
2022-11-29 05:54:35 Epoch [24000/30000] Loss:0.000391 Loss_1:0.000383 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:38.181870s (7.63min in total, 1.91min remains)
2022-11-29 05:55:13 NUM_SUB: 127;----------------------------
2022-11-29 05:55:13 Epoch [26000/30000] Loss:0.000380 Loss_1:0.000375 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.194587s (8.27min in total, 1.27min remains)
2022-11-29 05:55:51 NUM_SUB: 127;----------------------------
2022-11-29 05:55:51 Epoch [28000/30000] Loss:0.000372 Loss_1:0.000370 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.071330s (8.90min in total, 0.64min remains)
2022-11-29 05:56:29 Testing & drawing...
2022-11-29 05:56:29 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:56:31 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=127/
2022-11-29 05:56:31 [Loss]
2022-11-29 05:56:31 NUM_SUB: 127; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:56:31 NUM_SUB: 127; Personalized parameter estimation: Parameter containing:
tensor([1.3661e-01, 4.7248e-01, 1.3168e-03, 8.4647e-01, 3.0742e-01, 5.5008e-01,
        8.6013e-01, 8.9644e-01, 4.5563e-01, 1.3945e-02, 1.8875e-01, 1.4088e-01,
        4.6093e-01, 1.6886e-01, 1.7162e-02, 1.1790e+00, 6.9767e-01, 8.0001e-01,
        1.2245e-02, 3.2353e+00, 6.8161e-01, 2.3060e-02, 2.2620e+00, 8.7416e-01,
        2.1113e-02, 3.2277e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 05:56:31 NUM_SUB: 127;----------------------------
2022-11-29 05:56:31 Epoch [30000/30000] Loss:0.000368 Loss_1:0.000367 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.787065s (9.56min in total, 0.00min remains)
2022-11-29 05:56:31 NUM_SUB: 127------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 05:56:31 Testing & drawing...
2022-11-29 05:56:31 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 05:56:33 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=127/
2022-11-29 05:56:33 [Loss]
2022-11-29 05:56:33 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 05:56:33 General parameter estimation: Parameter containing:
tensor([1.3661e-01, 4.7246e-01, 1.3140e-03, 8.4647e-01, 3.0742e-01, 5.5010e-01,
        8.6012e-01, 8.9644e-01, 4.5563e-01, 1.3945e-02, 1.8874e-01, 1.4090e-01,
        4.6091e-01, 1.6886e-01, 1.7161e-02, 1.1790e+00, 6.9767e-01, 8.0001e-01,
        1.2245e-02, 3.2352e+00, 6.8161e-01, 2.3060e-02, 2.2618e+00, 8.7416e-01,
        2.1113e-02, 3.2276e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 05:56:33 A: prod, degr, TonA, NonA
2022-11-29 05:56:33 [1.9958206e-01 4.9817279e-01 4.1529839e-04 3.0182984e-01]
2022-11-29 05:56:33 T: prod, degr, AonT, NonT
2022-11-29 05:56:33 [0.06285265 0.6159723  0.30171582 0.01945925]
2022-11-29 05:56:33 N: AonN, TonN, ATonN
2022-11-29 05:56:33 [0.0283613  0.9057622  0.06587652]
2022-11-29 05:56:33 using cpu
2022-11-29 05:56:33 epoch = 30000
2022-11-29 05:56:33 epoch_step = 2000
2022-11-29 05:56:33 model_name = SimpleNetworkAD
2022-11-29 05:56:33 now_string = 2022-11-28-18-17-05
2022-11-29 05:56:33 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 05:56:33 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 05:56:33 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 05:56:33 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 05:56:33 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 05:56:33 --------------------------------------------------training start--------------------------------------------------
2022-11-29 05:57:11 NUM_SUB: 128;----------------------------
2022-11-29 05:57:11 Epoch [02000/30000] Loss:0.175388 Loss_1:0.174665 Loss_2:0.000346 Loss_3:0.000000 Lr:0.000833 Time:38.094177s (0.63min in total, 8.89min remains)
2022-11-29 05:57:49 NUM_SUB: 128;----------------------------
2022-11-29 05:57:49 Epoch [04000/30000] Loss:0.091532 Loss_1:0.091151 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000714 Time:38.026507s (1.27min in total, 8.25min remains)
2022-11-29 05:58:27 NUM_SUB: 128;----------------------------
2022-11-29 05:58:27 Epoch [06000/30000] Loss:0.008182 Loss_1:0.008073 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000625 Time:38.065316s (1.90min in total, 7.61min remains)
2022-11-29 05:59:05 NUM_SUB: 128;----------------------------
2022-11-29 05:59:05 Epoch [08000/30000] Loss:0.002622 Loss_1:0.002574 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000556 Time:38.036239s (2.54min in total, 6.98min remains)
2022-11-29 05:59:43 NUM_SUB: 128;----------------------------
2022-11-29 05:59:43 Epoch [10000/30000] Loss:0.001316 Loss_1:0.001252 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000500 Time:38.044668s (3.17min in total, 6.34min remains)
2022-11-29 06:00:21 NUM_SUB: 128;----------------------------
2022-11-29 06:00:21 Epoch [12000/30000] Loss:0.000541 Loss_1:0.000519 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000455 Time:38.065220s (3.81min in total, 5.71min remains)
2022-11-29 06:00:59 NUM_SUB: 128;----------------------------
2022-11-29 06:00:59 Epoch [14000/30000] Loss:0.000426 Loss_1:0.000411 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.076640s (4.44min in total, 5.07min remains)
2022-11-29 06:01:37 NUM_SUB: 128;----------------------------
2022-11-29 06:01:37 Epoch [16000/30000] Loss:0.000376 Loss_1:0.000370 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000385 Time:38.138260s (5.08min in total, 4.44min remains)
2022-11-29 06:02:15 NUM_SUB: 128;----------------------------
2022-11-29 06:02:15 Epoch [18000/30000] Loss:0.000375 Loss_1:0.000370 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.068691s (5.71min in total, 3.81min remains)
2022-11-29 06:02:54 NUM_SUB: 128;----------------------------
2022-11-29 06:02:54 Epoch [20000/30000] Loss:0.000340 Loss_1:0.000338 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.170127s (6.35min in total, 3.17min remains)
2022-11-29 06:03:32 NUM_SUB: 128;----------------------------
2022-11-29 06:03:32 Epoch [22000/30000] Loss:0.000326 Loss_1:0.000324 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.079962s (6.98min in total, 2.54min remains)
2022-11-29 06:04:10 NUM_SUB: 128;----------------------------
2022-11-29 06:04:10 Epoch [24000/30000] Loss:0.000259 Loss_1:0.000257 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.112823s (7.62min in total, 1.90min remains)
2022-11-29 06:04:48 NUM_SUB: 128;----------------------------
2022-11-29 06:04:48 Epoch [26000/30000] Loss:0.000255 Loss_1:0.000253 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.045212s (8.25min in total, 1.27min remains)
2022-11-29 06:05:26 NUM_SUB: 128;----------------------------
2022-11-29 06:05:26 Epoch [28000/30000] Loss:0.000254 Loss_1:0.000253 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.106713s (8.89min in total, 0.63min remains)
2022-11-29 06:06:04 Testing & drawing...
2022-11-29 06:06:04 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:06:06 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=128/
2022-11-29 06:06:06 [Loss]
2022-11-29 06:06:06 NUM_SUB: 128; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:06:06 NUM_SUB: 128; Personalized parameter estimation: Parameter containing:
tensor([0.2154, 0.8992, 0.0091, 0.1261, 0.3074, 0.0373, 0.7732, 0.8964, 0.4556,
        0.0143, 0.1183, 0.1105, 0.6835, 0.1689, 0.0176, 1.1370, 0.6977, 0.8000,
        0.0125, 2.7731, 0.6816, 0.0218, 3.0898, 0.8742, 0.0218, 3.7470, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:06:06 NUM_SUB: 128;----------------------------
2022-11-29 06:06:06 Epoch [30000/30000] Loss:0.000254 Loss_1:0.000252 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.679573s (9.55min in total, 0.00min remains)
2022-11-29 06:06:06 NUM_SUB: 128------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:06:06 Testing & drawing...
2022-11-29 06:06:06 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:06:07 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=128/
2022-11-29 06:06:07 [Loss]
2022-11-29 06:06:07 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:06:07 General parameter estimation: Parameter containing:
tensor([0.2154, 0.8992, 0.0091, 0.1261, 0.3074, 0.0373, 0.7732, 0.8964, 0.4556,
        0.0143, 0.1183, 0.1105, 0.6835, 0.1689, 0.0176, 1.1370, 0.6977, 0.8000,
        0.0125, 2.7732, 0.6816, 0.0218, 3.0899, 0.8742, 0.0218, 3.7471, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:06:07 A: prod, degr, TonA, NonA
2022-11-29 06:06:07 [0.43988743 0.49994177 0.01715082 0.04301998]
2022-11-29 06:06:07 T: prod, degr, AonT, NonT
2022-11-29 06:06:07 [0.16786593 0.37732014 0.37800023 0.07681366]
2022-11-29 06:06:07 N: AonN, TonN, ATonN
2022-11-29 06:06:07 [0.0061206  0.97239286 0.02148654]
2022-11-29 06:06:07 using cpu
2022-11-29 06:06:07 epoch = 30000
2022-11-29 06:06:07 epoch_step = 2000
2022-11-29 06:06:07 model_name = SimpleNetworkAD
2022-11-29 06:06:07 now_string = 2022-11-28-18-17-05
2022-11-29 06:06:07 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:06:07 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:06:07 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:06:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:06:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:06:07 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:06:46 NUM_SUB: 129;----------------------------
2022-11-29 06:06:46 Epoch [02000/30000] Loss:0.085020 Loss_1:0.083823 Loss_2:0.000709 Loss_3:0.000000 Lr:0.000833 Time:38.118140s (0.64min in total, 8.89min remains)
2022-11-29 06:07:24 NUM_SUB: 129;----------------------------
2022-11-29 06:07:24 Epoch [04000/30000] Loss:0.067458 Loss_1:0.066899 Loss_2:0.000163 Loss_3:0.000000 Lr:0.000714 Time:38.196910s (1.27min in total, 8.27min remains)
2022-11-29 06:08:02 NUM_SUB: 129;----------------------------
2022-11-29 06:08:02 Epoch [06000/30000] Loss:0.036498 Loss_1:0.036075 Loss_2:0.000170 Loss_3:0.000000 Lr:0.000625 Time:38.065284s (1.91min in total, 7.63min remains)
2022-11-29 06:08:40 NUM_SUB: 129;----------------------------
2022-11-29 06:08:40 Epoch [08000/30000] Loss:0.005664 Loss_1:0.005404 Loss_2:0.000232 Loss_3:0.000000 Lr:0.000556 Time:38.144655s (2.54min in total, 6.99min remains)
2022-11-29 06:09:18 NUM_SUB: 129;----------------------------
2022-11-29 06:09:18 Epoch [10000/30000] Loss:0.001374 Loss_1:0.001214 Loss_2:0.000158 Loss_3:0.000000 Lr:0.000500 Time:38.127414s (3.18min in total, 6.36min remains)
2022-11-29 06:09:56 NUM_SUB: 129;----------------------------
2022-11-29 06:09:56 Epoch [12000/30000] Loss:0.000268 Loss_1:0.000200 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000455 Time:38.135072s (3.81min in total, 5.72min remains)
2022-11-29 06:10:34 NUM_SUB: 129;----------------------------
2022-11-29 06:10:34 Epoch [14000/30000] Loss:0.000155 Loss_1:0.000115 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000417 Time:38.106336s (4.45min in total, 5.08min remains)
2022-11-29 06:11:13 NUM_SUB: 129;----------------------------
2022-11-29 06:11:13 Epoch [16000/30000] Loss:0.000115 Loss_1:0.000092 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000385 Time:38.201996s (5.09min in total, 4.45min remains)
2022-11-29 06:11:51 NUM_SUB: 129;----------------------------
2022-11-29 06:11:51 Epoch [18000/30000] Loss:0.000104 Loss_1:0.000091 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:38.120763s (5.72min in total, 3.81min remains)
2022-11-29 06:12:29 NUM_SUB: 129;----------------------------
2022-11-29 06:12:29 Epoch [20000/30000] Loss:0.000101 Loss_1:0.000092 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.293794s (6.36min in total, 3.18min remains)
2022-11-29 06:13:07 NUM_SUB: 129;----------------------------
2022-11-29 06:13:07 Epoch [22000/30000] Loss:0.000096 Loss_1:0.000091 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:38.139938s (6.99min in total, 2.54min remains)
2022-11-29 06:13:45 NUM_SUB: 129;----------------------------
2022-11-29 06:13:45 Epoch [24000/30000] Loss:0.000094 Loss_1:0.000091 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.134769s (7.63min in total, 1.91min remains)
2022-11-29 06:14:23 NUM_SUB: 129;----------------------------
2022-11-29 06:14:23 Epoch [26000/30000] Loss:0.000093 Loss_1:0.000091 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.273924s (8.27min in total, 1.27min remains)
2022-11-29 06:15:02 NUM_SUB: 129;----------------------------
2022-11-29 06:15:02 Epoch [28000/30000] Loss:0.000092 Loss_1:0.000091 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.117630s (8.90min in total, 0.64min remains)
2022-11-29 06:15:40 Testing & drawing...
2022-11-29 06:15:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:15:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=129/
2022-11-29 06:15:41 [Loss]
2022-11-29 06:15:41 NUM_SUB: 129; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:15:41 NUM_SUB: 129; Personalized parameter estimation: Parameter containing:
tensor([4.9908e-01, 7.1199e-01, 8.8670e-02, 9.2397e-04, 3.0742e-01, 2.1936e-03,
        7.4637e-01, 8.9644e-01, 4.5563e-01, 1.4663e-02, 2.4073e-02, 1.5709e-02,
        1.0943e+00, 1.6886e-01, 1.7597e-02, 2.3138e+00, 6.9767e-01, 8.0001e-01,
        1.0702e-02, 5.1201e+00, 6.8161e-01, 2.0981e-02, 4.3472e+00, 8.7416e-01,
        1.6223e-02, 5.2185e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 06:15:41 NUM_SUB: 129;----------------------------
2022-11-29 06:15:41 Epoch [30000/30000] Loss:0.000091 Loss_1:0.000091 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.850005s (9.57min in total, 0.00min remains)
2022-11-29 06:15:41 NUM_SUB: 129------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:15:41 Testing & drawing...
2022-11-29 06:15:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:15:43 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=129/
2022-11-29 06:15:43 [Loss]
2022-11-29 06:15:43 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:15:43 General parameter estimation: Parameter containing:
tensor([4.9908e-01, 7.1198e-01, 8.8675e-02, 9.2235e-04, 3.0742e-01, 2.1990e-03,
        7.4636e-01, 8.9644e-01, 4.5563e-01, 1.4663e-02, 2.4097e-02, 1.5709e-02,
        1.0943e+00, 1.6886e-01, 1.7597e-02, 2.3139e+00, 6.9767e-01, 8.0001e-01,
        1.0702e-02, 5.1202e+00, 6.8161e-01, 2.0980e-02, 4.3474e+00, 8.7416e-01,
        1.6222e-02, 5.2186e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 06:15:43 A: prod, degr, TonA, NonA
2022-11-29 06:15:43 [0.42400867 0.499982   0.0753359  0.00067342]
2022-11-29 06:15:43 T: prod, degr, AonT, NonT
2022-11-29 06:15:43 [0.35844117 0.48688218 0.13066332 0.02401338]
2022-11-29 06:15:43 N: AonN, TonN, ATonN
2022-11-29 06:15:43 [0.01292992 0.95147127 0.03559882]
2022-11-29 06:15:43 using cpu
2022-11-29 06:15:43 epoch = 30000
2022-11-29 06:15:43 epoch_step = 2000
2022-11-29 06:15:43 model_name = SimpleNetworkAD
2022-11-29 06:15:43 now_string = 2022-11-28-18-17-05
2022-11-29 06:15:43 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:15:43 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:15:43 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:15:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:15:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:15:43 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:16:21 NUM_SUB: 130;----------------------------
2022-11-29 06:16:21 Epoch [02000/30000] Loss:0.176867 Loss_1:0.175380 Loss_2:0.000780 Loss_3:0.000000 Lr:0.000833 Time:38.238356s (0.64min in total, 8.92min remains)
2022-11-29 06:17:00 NUM_SUB: 130;----------------------------
2022-11-29 06:17:00 Epoch [04000/30000] Loss:0.149194 Loss_1:0.148188 Loss_2:0.000231 Loss_3:0.000000 Lr:0.000714 Time:38.090914s (1.27min in total, 8.27min remains)
2022-11-29 06:17:38 NUM_SUB: 130;----------------------------
2022-11-29 06:17:38 Epoch [06000/30000] Loss:0.087588 Loss_1:0.086725 Loss_2:0.000277 Loss_3:0.000000 Lr:0.000625 Time:38.147082s (1.91min in total, 7.63min remains)
2022-11-29 06:18:16 NUM_SUB: 130;----------------------------
2022-11-29 06:18:16 Epoch [08000/30000] Loss:0.007400 Loss_1:0.006916 Loss_2:0.000353 Loss_3:0.000000 Lr:0.000556 Time:38.179562s (2.54min in total, 7.00min remains)
2022-11-29 06:18:54 NUM_SUB: 130;----------------------------
2022-11-29 06:18:54 Epoch [10000/30000] Loss:0.002123 Loss_1:0.001894 Loss_2:0.000217 Loss_3:0.000000 Lr:0.000500 Time:38.050434s (3.18min in total, 6.36min remains)
2022-11-29 06:19:32 NUM_SUB: 130;----------------------------
2022-11-29 06:19:32 Epoch [12000/30000] Loss:0.001292 Loss_1:0.001181 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000455 Time:38.170606s (3.81min in total, 5.72min remains)
2022-11-29 06:20:10 NUM_SUB: 130;----------------------------
2022-11-29 06:20:10 Epoch [14000/30000] Loss:0.000973 Loss_1:0.000907 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000417 Time:38.108481s (4.45min in total, 5.09min remains)
2022-11-29 06:20:48 NUM_SUB: 130;----------------------------
2022-11-29 06:20:48 Epoch [16000/30000] Loss:0.000813 Loss_1:0.000770 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000385 Time:38.036845s (5.08min in total, 4.45min remains)
2022-11-29 06:21:26 NUM_SUB: 130;----------------------------
2022-11-29 06:21:26 Epoch [18000/30000] Loss:0.000746 Loss_1:0.000715 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000357 Time:38.101592s (5.72min in total, 3.81min remains)
2022-11-29 06:22:04 NUM_SUB: 130;----------------------------
2022-11-29 06:22:04 Epoch [20000/30000] Loss:0.000723 Loss_1:0.000700 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000333 Time:38.081430s (6.35min in total, 3.18min remains)
2022-11-29 06:22:43 NUM_SUB: 130;----------------------------
2022-11-29 06:22:43 Epoch [22000/30000] Loss:0.000711 Loss_1:0.000694 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000313 Time:38.136256s (6.99min in total, 2.54min remains)
2022-11-29 06:23:21 NUM_SUB: 130;----------------------------
2022-11-29 06:23:21 Epoch [24000/30000] Loss:0.000704 Loss_1:0.000691 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000294 Time:38.083636s (7.62min in total, 1.91min remains)
2022-11-29 06:23:59 NUM_SUB: 130;----------------------------
2022-11-29 06:23:59 Epoch [26000/30000] Loss:0.000699 Loss_1:0.000689 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000278 Time:38.174252s (8.26min in total, 1.27min remains)
2022-11-29 06:24:37 NUM_SUB: 130;----------------------------
2022-11-29 06:24:37 Epoch [28000/30000] Loss:0.000695 Loss_1:0.000686 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000263 Time:38.185779s (8.90min in total, 0.64min remains)
2022-11-29 06:25:15 Testing & drawing...
2022-11-29 06:25:15 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:25:17 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=130/
2022-11-29 06:25:17 [Loss]
2022-11-29 06:25:17 NUM_SUB: 130; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:25:17 NUM_SUB: 130; Personalized parameter estimation: Parameter containing:
tensor([0.0132, 0.2887, 0.0194, 0.9610, 0.3074, 1.0428, 1.1321, 0.8964, 0.4556,
        0.0481, 0.0676, 0.0142, 0.2149, 0.1689, 0.0175, 0.9070, 0.6977, 0.8000,
        0.0099, 5.5828, 0.6816, 0.0181, 4.7103, 0.8742, 0.0139, 5.6091, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:25:17 NUM_SUB: 130;----------------------------
2022-11-29 06:25:17 Epoch [30000/30000] Loss:0.000692 Loss_1:0.000685 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:39.742528s (9.56min in total, 0.00min remains)
2022-11-29 06:25:17 NUM_SUB: 130------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:25:17 Testing & drawing...
2022-11-29 06:25:17 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:25:18 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=130/
2022-11-29 06:25:18 [Loss]
2022-11-29 06:25:18 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:25:18 General parameter estimation: Parameter containing:
tensor([0.0132, 0.2887, 0.0194, 0.9610, 0.3074, 1.0428, 1.1321, 0.8964, 0.4556,
        0.0481, 0.0676, 0.0142, 0.2149, 0.1689, 0.0175, 0.9070, 0.6977, 0.8000,
        0.0099, 5.5830, 0.6816, 0.0181, 4.7104, 0.8742, 0.0139, 5.6093, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:25:18 A: prod, degr, TonA, NonA
2022-11-29 06:25:18 [0.02295812 0.49913582 0.01752547 0.4603806 ]
2022-11-29 06:25:18 T: prod, degr, AonT, NonT
2022-11-29 06:25:18 [0.3563816  0.49845245 0.1003003  0.04486565]
2022-11-29 06:25:18 N: AonN, TonN, ATonN
2022-11-29 06:25:18 [0.01635665 0.93908376 0.04455963]
2022-11-29 06:25:19 using cpu
2022-11-29 06:25:19 epoch = 30000
2022-11-29 06:25:19 epoch_step = 2000
2022-11-29 06:25:19 model_name = SimpleNetworkAD
2022-11-29 06:25:19 now_string = 2022-11-28-18-17-05
2022-11-29 06:25:19 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:25:19 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:25:19 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:25:19 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:25:19 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:25:19 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:25:57 NUM_SUB: 131;----------------------------
2022-11-29 06:25:57 Epoch [02000/30000] Loss:0.048145 Loss_1:0.047274 Loss_2:0.000440 Loss_3:0.000000 Lr:0.000833 Time:38.676218s (0.64min in total, 9.02min remains)
2022-11-29 06:26:36 NUM_SUB: 131;----------------------------
2022-11-29 06:26:36 Epoch [04000/30000] Loss:0.036910 Loss_1:0.036686 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000714 Time:38.575903s (1.29min in total, 8.37min remains)
2022-11-29 06:27:14 NUM_SUB: 131;----------------------------
2022-11-29 06:27:14 Epoch [06000/30000] Loss:0.018676 Loss_1:0.018494 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000625 Time:38.184257s (1.92min in total, 7.70min remains)
2022-11-29 06:27:52 NUM_SUB: 131;----------------------------
2022-11-29 06:27:52 Epoch [08000/30000] Loss:0.003360 Loss_1:0.003259 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000556 Time:38.387795s (2.56min in total, 7.05min remains)
2022-11-29 06:28:31 NUM_SUB: 131;----------------------------
2022-11-29 06:28:31 Epoch [10000/30000] Loss:0.001069 Loss_1:0.001000 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000500 Time:38.319449s (3.20min in total, 6.40min remains)
2022-11-29 06:29:09 NUM_SUB: 131;----------------------------
2022-11-29 06:29:09 Epoch [12000/30000] Loss:0.000621 Loss_1:0.000574 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000455 Time:38.129540s (3.84min in total, 5.76min remains)
2022-11-29 06:29:47 NUM_SUB: 131;----------------------------
2022-11-29 06:29:47 Epoch [14000/30000] Loss:0.000261 Loss_1:0.000238 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:38.156207s (4.47min in total, 5.11min remains)
2022-11-29 06:30:25 NUM_SUB: 131;----------------------------
2022-11-29 06:30:25 Epoch [16000/30000] Loss:0.000168 Loss_1:0.000151 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.154208s (5.11min in total, 4.47min remains)
2022-11-29 06:31:03 NUM_SUB: 131;----------------------------
2022-11-29 06:31:03 Epoch [18000/30000] Loss:0.000157 Loss_1:0.000143 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000357 Time:38.134927s (5.75min in total, 3.83min remains)
2022-11-29 06:31:41 NUM_SUB: 131;----------------------------
2022-11-29 06:31:41 Epoch [20000/30000] Loss:0.000150 Loss_1:0.000135 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000333 Time:38.209394s (6.38min in total, 3.19min remains)
2022-11-29 06:32:20 NUM_SUB: 131;----------------------------
2022-11-29 06:32:20 Epoch [22000/30000] Loss:0.000139 Loss_1:0.000130 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:38.236851s (7.02min in total, 2.55min remains)
2022-11-29 06:32:58 NUM_SUB: 131;----------------------------
2022-11-29 06:32:58 Epoch [24000/30000] Loss:0.000135 Loss_1:0.000129 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.190600s (7.66min in total, 1.91min remains)
2022-11-29 06:33:36 NUM_SUB: 131;----------------------------
2022-11-29 06:33:36 Epoch [26000/30000] Loss:0.000132 Loss_1:0.000128 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.273284s (8.29min in total, 1.28min remains)
2022-11-29 06:34:14 NUM_SUB: 131;----------------------------
2022-11-29 06:34:14 Epoch [28000/30000] Loss:0.000129 Loss_1:0.000125 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.206030s (8.93min in total, 0.64min remains)
2022-11-29 06:34:53 Testing & drawing...
2022-11-29 06:34:53 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:34:54 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=131/
2022-11-29 06:34:54 [Loss]
2022-11-29 06:34:54 NUM_SUB: 131; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:34:54 NUM_SUB: 131; Personalized parameter estimation: Parameter containing:
tensor([0.0095, 0.1963, 0.0150, 0.5110, 0.3074, 0.2971, 1.0661, 0.8964, 0.4556,
        0.0135, 0.0364, 0.0112, 0.7552, 0.1689, 0.0174, 2.4683, 0.6977, 0.8000,
        0.0110, 4.0392, 0.6816, 0.0208, 3.5832, 0.8742, 0.0207, 4.4451, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:34:54 NUM_SUB: 131;----------------------------
2022-11-29 06:34:54 Epoch [30000/30000] Loss:0.000126 Loss_1:0.000123 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:39.858764s (9.60min in total, 0.00min remains)
2022-11-29 06:34:54 NUM_SUB: 131------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:34:54 Testing & drawing...
2022-11-29 06:34:54 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:34:56 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=131/
2022-11-29 06:34:56 [Loss]
2022-11-29 06:34:56 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:34:56 General parameter estimation: Parameter containing:
tensor([0.0095, 0.1963, 0.0150, 0.5111, 0.3074, 0.2970, 1.0662, 0.8964, 0.4556,
        0.0135, 0.0364, 0.0112, 0.7553, 0.1689, 0.0174, 2.4685, 0.6977, 0.8000,
        0.0110, 4.0393, 0.6816, 0.0208, 3.5833, 0.8742, 0.0207, 4.4453, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:34:56 A: prod, degr, TonA, NonA
2022-11-29 06:34:56 [0.0553708  0.4987956  0.03872395 0.40710962]
2022-11-29 06:34:56 T: prod, degr, AonT, NonT
2022-11-29 06:34:56 [0.40390313 0.4771345  0.09046292 0.02849947]
2022-11-29 06:34:56 N: AonN, TonN, ATonN
2022-11-29 06:34:56 [0.00683112 0.9711173  0.0220515 ]
2022-11-29 06:34:56 using cpu
2022-11-29 06:34:56 epoch = 30000
2022-11-29 06:34:56 epoch_step = 2000
2022-11-29 06:34:56 model_name = SimpleNetworkAD
2022-11-29 06:34:56 now_string = 2022-11-28-18-17-05
2022-11-29 06:34:56 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:34:56 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:34:56 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:34:56 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:34:56 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:34:56 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:35:34 NUM_SUB: 132;----------------------------
2022-11-29 06:35:34 Epoch [02000/30000] Loss:0.018025 Loss_1:0.017229 Loss_2:0.000365 Loss_3:0.000000 Lr:0.000833 Time:38.039065s (0.63min in total, 8.88min remains)
2022-11-29 06:36:12 NUM_SUB: 132;----------------------------
2022-11-29 06:36:12 Epoch [04000/30000] Loss:0.014504 Loss_1:0.014409 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000714 Time:38.082045s (1.27min in total, 8.25min remains)
2022-11-29 06:36:50 NUM_SUB: 132;----------------------------
2022-11-29 06:36:50 Epoch [06000/30000] Loss:0.010040 Loss_1:0.009925 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000625 Time:38.029949s (1.90min in total, 7.61min remains)
2022-11-29 06:37:28 NUM_SUB: 132;----------------------------
2022-11-29 06:37:28 Epoch [08000/30000] Loss:0.004408 Loss_1:0.004327 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000556 Time:38.062896s (2.54min in total, 6.98min remains)
2022-11-29 06:38:06 NUM_SUB: 132;----------------------------
2022-11-29 06:38:06 Epoch [10000/30000] Loss:0.001703 Loss_1:0.001636 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000500 Time:38.191873s (3.17min in total, 6.35min remains)
2022-11-29 06:38:45 NUM_SUB: 132;----------------------------
2022-11-29 06:38:45 Epoch [12000/30000] Loss:0.000988 Loss_1:0.000949 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000455 Time:38.107780s (3.81min in total, 5.71min remains)
2022-11-29 06:39:23 NUM_SUB: 132;----------------------------
2022-11-29 06:39:23 Epoch [14000/30000] Loss:0.000320 Loss_1:0.000301 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:38.137643s (4.44min in total, 5.08min remains)
2022-11-29 06:40:01 NUM_SUB: 132;----------------------------
2022-11-29 06:40:01 Epoch [16000/30000] Loss:0.000162 Loss_1:0.000152 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:38.197093s (5.08min in total, 4.45min remains)
2022-11-29 06:40:39 NUM_SUB: 132;----------------------------
2022-11-29 06:40:39 Epoch [18000/30000] Loss:0.000156 Loss_1:0.000148 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.181456s (5.72min in total, 3.81min remains)
2022-11-29 06:41:17 NUM_SUB: 132;----------------------------
2022-11-29 06:41:17 Epoch [20000/30000] Loss:0.000147 Loss_1:0.000143 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.140451s (6.35min in total, 3.18min remains)
2022-11-29 06:41:55 NUM_SUB: 132;----------------------------
2022-11-29 06:41:55 Epoch [22000/30000] Loss:0.000143 Loss_1:0.000140 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.047395s (6.99min in total, 2.54min remains)
2022-11-29 06:42:33 NUM_SUB: 132;----------------------------
2022-11-29 06:42:33 Epoch [24000/30000] Loss:0.000142 Loss_1:0.000140 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.046903s (7.62min in total, 1.91min remains)
2022-11-29 06:43:11 NUM_SUB: 132;----------------------------
2022-11-29 06:43:11 Epoch [26000/30000] Loss:0.000158 Loss_1:0.000157 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.138647s (8.26min in total, 1.27min remains)
2022-11-29 06:43:50 NUM_SUB: 132;----------------------------
2022-11-29 06:43:50 Epoch [28000/30000] Loss:0.000141 Loss_1:0.000140 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.223131s (8.89min in total, 0.64min remains)
2022-11-29 06:44:28 Testing & drawing...
2022-11-29 06:44:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:44:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=132/
2022-11-29 06:44:29 [Loss]
2022-11-29 06:44:30 NUM_SUB: 132; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:44:30 NUM_SUB: 132; Personalized parameter estimation: Parameter containing:
tensor([0.2563, 1.0036, 0.0097, 0.0752, 0.3074, 0.0848, 0.8130, 0.8964, 0.4556,
        0.0138, 0.0318, 0.0131, 0.8410, 0.1689, 0.0175, 2.5592, 0.6977, 0.8000,
        0.0121, 3.5063, 0.6816, 0.0157, 3.7216, 0.8742, 0.0201, 4.4595, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:44:30 NUM_SUB: 132;----------------------------
2022-11-29 06:44:30 Epoch [30000/30000] Loss:0.000143 Loss_1:0.000143 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.876217s (9.56min in total, 0.00min remains)
2022-11-29 06:44:30 NUM_SUB: 132------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:44:30 Testing & drawing...
2022-11-29 06:44:30 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:44:31 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=132/
2022-11-29 06:44:31 [Loss]
2022-11-29 06:44:31 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:44:31 General parameter estimation: Parameter containing:
tensor([0.2563, 1.0036, 0.0097, 0.0752, 0.3074, 0.0848, 0.8130, 0.8964, 0.4556,
        0.0138, 0.0318, 0.0131, 0.8410, 0.1689, 0.0175, 2.5592, 0.6977, 0.8000,
        0.0121, 3.5064, 0.6816, 0.0157, 3.7218, 0.8742, 0.0201, 4.4597, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:44:31 A: prod, degr, TonA, NonA
2022-11-29 06:44:31 [0.45536026 0.49998766 0.01685817 0.02779388]
2022-11-29 06:44:31 T: prod, degr, AonT, NonT
2022-11-29 06:44:31 [0.5161045  0.33361444 0.1356515  0.01462957]
2022-11-29 06:44:31 N: AonN, TonN, ATonN
2022-11-29 06:44:31 [0.00529519 0.9705926  0.02411224]
2022-11-29 06:44:31 using cpu
2022-11-29 06:44:31 epoch = 30000
2022-11-29 06:44:31 epoch_step = 2000
2022-11-29 06:44:31 model_name = SimpleNetworkAD
2022-11-29 06:44:31 now_string = 2022-11-28-18-17-05
2022-11-29 06:44:31 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:44:31 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:44:31 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:44:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:44:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:44:31 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:45:09 NUM_SUB: 133;----------------------------
2022-11-29 06:45:09 Epoch [02000/30000] Loss:0.064126 Loss_1:0.062171 Loss_2:0.001561 Loss_3:0.000000 Lr:0.000833 Time:38.142966s (0.64min in total, 8.90min remains)
2022-11-29 06:45:48 NUM_SUB: 133;----------------------------
2022-11-29 06:45:48 Epoch [04000/30000] Loss:0.043451 Loss_1:0.043089 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000714 Time:38.179186s (1.27min in total, 8.27min remains)
2022-11-29 06:46:26 NUM_SUB: 133;----------------------------
2022-11-29 06:46:26 Epoch [06000/30000] Loss:0.018418 Loss_1:0.018225 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000625 Time:38.170773s (1.91min in total, 7.63min remains)
2022-11-29 06:47:04 NUM_SUB: 133;----------------------------
2022-11-29 06:47:04 Epoch [08000/30000] Loss:0.009150 Loss_1:0.009013 Loss_2:0.000119 Loss_3:0.000000 Lr:0.000556 Time:38.071287s (2.54min in total, 6.99min remains)
2022-11-29 06:47:42 NUM_SUB: 133;----------------------------
2022-11-29 06:47:42 Epoch [10000/30000] Loss:0.005143 Loss_1:0.005007 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000500 Time:38.270642s (3.18min in total, 6.36min remains)
2022-11-29 06:48:20 NUM_SUB: 133;----------------------------
2022-11-29 06:48:20 Epoch [12000/30000] Loss:0.003665 Loss_1:0.003585 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000455 Time:38.170328s (3.82min in total, 5.73min remains)
2022-11-29 06:48:58 NUM_SUB: 133;----------------------------
2022-11-29 06:48:58 Epoch [14000/30000] Loss:0.003358 Loss_1:0.003308 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000417 Time:38.041462s (4.45min in total, 5.09min remains)
2022-11-29 06:49:37 NUM_SUB: 133;----------------------------
2022-11-29 06:49:37 Epoch [16000/30000] Loss:0.003082 Loss_1:0.003044 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000385 Time:38.245610s (5.09min in total, 4.45min remains)
2022-11-29 06:50:15 NUM_SUB: 133;----------------------------
2022-11-29 06:50:15 Epoch [18000/30000] Loss:0.002483 Loss_1:0.002453 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000357 Time:38.109642s (5.72min in total, 3.82min remains)
2022-11-29 06:50:53 NUM_SUB: 133;----------------------------
2022-11-29 06:50:53 Epoch [20000/30000] Loss:0.002407 Loss_1:0.002380 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000333 Time:38.039816s (6.36min in total, 3.18min remains)
2022-11-29 06:51:31 NUM_SUB: 133;----------------------------
2022-11-29 06:51:31 Epoch [22000/30000] Loss:0.002373 Loss_1:0.002348 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000313 Time:38.136879s (6.99min in total, 2.54min remains)
2022-11-29 06:52:09 NUM_SUB: 133;----------------------------
2022-11-29 06:52:09 Epoch [24000/30000] Loss:0.002363 Loss_1:0.002339 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000294 Time:38.121362s (7.63min in total, 1.91min remains)
2022-11-29 06:52:47 NUM_SUB: 133;----------------------------
2022-11-29 06:52:47 Epoch [26000/30000] Loss:0.002359 Loss_1:0.002337 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000278 Time:38.110065s (8.26min in total, 1.27min remains)
2022-11-29 06:53:25 NUM_SUB: 133;----------------------------
2022-11-29 06:53:25 Epoch [28000/30000] Loss:0.002356 Loss_1:0.002337 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000263 Time:38.108490s (8.90min in total, 0.64min remains)
2022-11-29 06:54:03 Testing & drawing...
2022-11-29 06:54:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:54:05 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=133/
2022-11-29 06:54:05 [Loss]
2022-11-29 06:54:05 NUM_SUB: 133; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:54:05 NUM_SUB: 133; Personalized parameter estimation: Parameter containing:
tensor([0.0078, 0.0107, 0.0081, 3.4003, 0.3074, 0.0198, 4.5806, 0.8964, 0.4556,
        0.0139, 0.0297, 0.0134, 0.8689, 0.1689, 0.0173, 2.5682, 0.6977, 0.8000,
        0.0121, 2.7455, 0.6816, 0.0230, 2.4472, 0.8742, 0.0202, 3.1188, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:54:05 NUM_SUB: 133;----------------------------
2022-11-29 06:54:05 Epoch [30000/30000] Loss:0.002354 Loss_1:0.002334 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000250 Time:39.768285s (9.56min in total, 0.00min remains)
2022-11-29 06:54:05 NUM_SUB: 133------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 06:54:05 Testing & drawing...
2022-11-29 06:54:05 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 06:54:07 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=133/
2022-11-29 06:54:07 [Loss]
2022-11-29 06:54:07 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 06:54:07 General parameter estimation: Parameter containing:
tensor([0.0078, 0.0107, 0.0081, 3.4005, 0.3074, 0.0198, 4.5808, 0.8964, 0.4556,
        0.0139, 0.0297, 0.0134, 0.8690, 0.1689, 0.0173, 2.5683, 0.6977, 0.8000,
        0.0121, 2.7454, 0.6816, 0.0230, 2.4472, 0.8742, 0.0202, 3.1188, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 06:54:07 A: prod, degr, TonA, NonA
2022-11-29 06:54:07 [0.5304287  0.42087    0.01698579 0.03171553]
2022-11-29 06:54:07 T: prod, degr, AonT, NonT
2022-11-29 06:54:07 [0.38177648 0.4671129  0.11826696 0.03284365]
2022-11-29 06:54:07 N: AonN, TonN, ATonN
2022-11-29 06:54:07 [0.02493837 0.9125301  0.06253152]
2022-11-29 06:54:07 using cpu
2022-11-29 06:54:07 epoch = 30000
2022-11-29 06:54:07 epoch_step = 2000
2022-11-29 06:54:07 model_name = SimpleNetworkAD
2022-11-29 06:54:07 now_string = 2022-11-28-18-17-05
2022-11-29 06:54:07 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 06:54:07 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 06:54:07 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 06:54:07 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 06:54:07 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 06:54:07 --------------------------------------------------training start--------------------------------------------------
2022-11-29 06:54:45 NUM_SUB: 134;----------------------------
2022-11-29 06:54:45 Epoch [02000/30000] Loss:0.026277 Loss_1:0.025340 Loss_2:0.000542 Loss_3:0.000000 Lr:0.000833 Time:38.151604s (0.64min in total, 8.90min remains)
2022-11-29 06:55:23 NUM_SUB: 134;----------------------------
2022-11-29 06:55:23 Epoch [04000/30000] Loss:0.021465 Loss_1:0.021203 Loss_2:0.000194 Loss_3:0.000000 Lr:0.000714 Time:38.140385s (1.27min in total, 8.27min remains)
2022-11-29 06:56:01 NUM_SUB: 134;----------------------------
2022-11-29 06:56:01 Epoch [06000/30000] Loss:0.014638 Loss_1:0.014363 Loss_2:0.000207 Loss_3:0.000000 Lr:0.000625 Time:38.133352s (1.91min in total, 7.63min remains)
2022-11-29 06:56:39 NUM_SUB: 134;----------------------------
2022-11-29 06:56:39 Epoch [08000/30000] Loss:0.005136 Loss_1:0.004988 Loss_2:0.000114 Loss_3:0.000000 Lr:0.000556 Time:38.079268s (2.54min in total, 6.99min remains)
2022-11-29 06:57:17 NUM_SUB: 134;----------------------------
2022-11-29 06:57:17 Epoch [10000/30000] Loss:0.000494 Loss_1:0.000398 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000500 Time:38.155160s (3.18min in total, 6.36min remains)
2022-11-29 06:57:56 NUM_SUB: 134;----------------------------
2022-11-29 06:57:56 Epoch [12000/30000] Loss:0.000161 Loss_1:0.000112 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:38.194631s (3.81min in total, 5.72min remains)
2022-11-29 06:58:34 NUM_SUB: 134;----------------------------
2022-11-29 06:58:34 Epoch [14000/30000] Loss:0.000114 Loss_1:0.000089 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000417 Time:38.174002s (4.45min in total, 5.09min remains)
2022-11-29 06:59:12 NUM_SUB: 134;----------------------------
2022-11-29 06:59:12 Epoch [16000/30000] Loss:0.000087 Loss_1:0.000071 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.208737s (5.09min in total, 4.45min remains)
2022-11-29 06:59:50 NUM_SUB: 134;----------------------------
2022-11-29 06:59:50 Epoch [18000/30000] Loss:0.000061 Loss_1:0.000049 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.200478s (5.72min in total, 3.82min remains)
2022-11-29 07:00:28 NUM_SUB: 134;----------------------------
2022-11-29 07:00:28 Epoch [20000/30000] Loss:0.000045 Loss_1:0.000035 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.199960s (6.36min in total, 3.18min remains)
2022-11-29 07:01:07 NUM_SUB: 134;----------------------------
2022-11-29 07:01:07 Epoch [22000/30000] Loss:0.000040 Loss_1:0.000032 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:38.207208s (7.00min in total, 2.54min remains)
2022-11-29 07:01:45 NUM_SUB: 134;----------------------------
2022-11-29 07:01:45 Epoch [24000/30000] Loss:0.000038 Loss_1:0.000031 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:38.141258s (7.63min in total, 1.91min remains)
2022-11-29 07:02:23 NUM_SUB: 134;----------------------------
2022-11-29 07:02:23 Epoch [26000/30000] Loss:0.000037 Loss_1:0.000031 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:38.147955s (8.27min in total, 1.27min remains)
2022-11-29 07:03:01 NUM_SUB: 134;----------------------------
2022-11-29 07:03:01 Epoch [28000/30000] Loss:0.000036 Loss_1:0.000031 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:38.129431s (8.90min in total, 0.64min remains)
2022-11-29 07:03:39 Testing & drawing...
2022-11-29 07:03:39 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:03:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=134/
2022-11-29 07:03:41 [Loss]
2022-11-29 07:03:41 NUM_SUB: 134; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:03:41 NUM_SUB: 134; Personalized parameter estimation: Parameter containing:
tensor([0.0115, 0.0227, 0.0079, 3.2380, 0.3074, 0.0166, 3.5311, 0.8964, 0.4556,
        0.0133, 0.0360, 0.0121, 0.7471, 0.1689, 0.0176, 1.5606, 0.6977, 0.8000,
        0.0120, 4.0305, 0.6816, 0.0206, 3.5945, 0.8742, 0.0184, 4.4450, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:03:41 NUM_SUB: 134;----------------------------
2022-11-29 07:03:41 Epoch [30000/30000] Loss:0.000033 Loss_1:0.000030 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:39.722174s (9.57min in total, 0.00min remains)
2022-11-29 07:03:41 NUM_SUB: 134------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 07:03:41 Testing & drawing...
2022-11-29 07:03:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:03:42 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=134/
2022-11-29 07:03:42 [Loss]
2022-11-29 07:03:42 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:03:42 General parameter estimation: Parameter containing:
tensor([0.0115, 0.0227, 0.0079, 3.2381, 0.3074, 0.0166, 3.5313, 0.8964, 0.4556,
        0.0133, 0.0360, 0.0121, 0.7471, 0.1689, 0.0176, 1.5607, 0.6977, 0.8000,
        0.0120, 4.0306, 0.6816, 0.0206, 3.5946, 0.8742, 0.0184, 4.4452, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:03:42 A: prod, degr, TonA, NonA
2022-11-29 07:03:42 [0.5232852  0.4537095  0.00843943 0.01456586]
2022-11-29 07:03:42 T: prod, degr, AonT, NonT
2022-11-29 07:03:42 [0.38685477 0.45734704 0.10917372 0.04662448]
2022-11-29 07:03:42 N: AonN, TonN, ATonN
2022-11-29 07:03:42 [0.0080899  0.9696538  0.02225632]
2022-11-29 07:03:43 using cpu
2022-11-29 07:03:43 epoch = 30000
2022-11-29 07:03:43 epoch_step = 2000
2022-11-29 07:03:43 model_name = SimpleNetworkAD
2022-11-29 07:03:43 now_string = 2022-11-28-18-17-05
2022-11-29 07:03:43 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 07:03:43 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 07:03:43 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 07:03:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 07:03:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 07:03:43 --------------------------------------------------training start--------------------------------------------------
2022-11-29 07:04:21 NUM_SUB: 135;----------------------------
2022-11-29 07:04:21 Epoch [02000/30000] Loss:0.080331 Loss_1:0.079390 Loss_2:0.000495 Loss_3:0.000000 Lr:0.000833 Time:38.338636s (0.64min in total, 8.95min remains)
2022-11-29 07:04:59 NUM_SUB: 135;----------------------------
2022-11-29 07:04:59 Epoch [04000/30000] Loss:0.065741 Loss_1:0.065332 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000714 Time:38.286661s (1.28min in total, 8.30min remains)
2022-11-29 07:05:38 NUM_SUB: 135;----------------------------
2022-11-29 07:05:38 Epoch [06000/30000] Loss:0.037838 Loss_1:0.037523 Loss_2:0.000076 Loss_3:0.000000 Lr:0.000625 Time:38.437235s (1.92min in total, 7.67min remains)
2022-11-29 07:06:16 NUM_SUB: 135;----------------------------
2022-11-29 07:06:16 Epoch [08000/30000] Loss:0.007200 Loss_1:0.006861 Loss_2:0.000268 Loss_3:0.000000 Lr:0.000556 Time:38.278829s (2.56min in total, 7.03min remains)
2022-11-29 07:06:54 NUM_SUB: 135;----------------------------
2022-11-29 07:06:54 Epoch [10000/30000] Loss:0.000611 Loss_1:0.000503 Loss_2:0.000105 Loss_3:0.000000 Lr:0.000500 Time:38.165030s (3.19min in total, 6.38min remains)
2022-11-29 07:07:32 NUM_SUB: 135;----------------------------
2022-11-29 07:07:32 Epoch [12000/30000] Loss:0.000324 Loss_1:0.000267 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000455 Time:38.303338s (3.83min in total, 5.75min remains)
2022-11-29 07:08:11 NUM_SUB: 135;----------------------------
2022-11-29 07:08:11 Epoch [14000/30000] Loss:0.000169 Loss_1:0.000144 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:38.295058s (4.47min in total, 5.11min remains)
2022-11-29 07:08:49 NUM_SUB: 135;----------------------------
2022-11-29 07:08:49 Epoch [16000/30000] Loss:0.000116 Loss_1:0.000099 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.162913s (5.10min in total, 4.47min remains)
2022-11-29 07:09:27 NUM_SUB: 135;----------------------------
2022-11-29 07:09:27 Epoch [18000/30000] Loss:0.000076 Loss_1:0.000064 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.347343s (5.74min in total, 3.83min remains)
2022-11-29 07:10:05 NUM_SUB: 135;----------------------------
2022-11-29 07:10:05 Epoch [20000/30000] Loss:0.000057 Loss_1:0.000047 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:38.268646s (6.38min in total, 3.19min remains)
2022-11-29 07:10:44 NUM_SUB: 135;----------------------------
2022-11-29 07:10:44 Epoch [22000/30000] Loss:0.000054 Loss_1:0.000048 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.184944s (7.02min in total, 2.55min remains)
2022-11-29 07:11:22 NUM_SUB: 135;----------------------------
2022-11-29 07:11:22 Epoch [24000/30000] Loss:0.000053 Loss_1:0.000048 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.320188s (7.66min in total, 1.91min remains)
2022-11-29 07:12:00 NUM_SUB: 135;----------------------------
2022-11-29 07:12:00 Epoch [26000/30000] Loss:0.000054 Loss_1:0.000050 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.398779s (8.30min in total, 1.28min remains)
2022-11-29 07:12:39 NUM_SUB: 135;----------------------------
2022-11-29 07:12:39 Epoch [28000/30000] Loss:0.000050 Loss_1:0.000047 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.225459s (8.93min in total, 0.64min remains)
2022-11-29 07:13:17 Testing & drawing...
2022-11-29 07:13:17 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:13:18 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=135/
2022-11-29 07:13:18 [Loss]
2022-11-29 07:13:19 NUM_SUB: 135; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:13:19 NUM_SUB: 135; Personalized parameter estimation: Parameter containing:
tensor([0.1907, 0.6707, 0.0213, 0.5194, 0.3074, 0.3033, 0.8286, 0.8964, 0.4556,
        0.0125, 0.0291, 0.0130, 0.8666, 0.1689, 0.0176, 2.3856, 0.6977, 0.8000,
        0.0116, 4.3824, 0.6816, 0.0199, 3.9861, 0.8742, 0.0190, 4.7851, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:13:19 NUM_SUB: 135;----------------------------
2022-11-29 07:13:19 Epoch [30000/30000] Loss:0.000050 Loss_1:0.000047 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.937967s (9.60min in total, 0.00min remains)
2022-11-29 07:13:19 NUM_SUB: 135------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 07:13:19 Testing & drawing...
2022-11-29 07:13:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:13:20 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=135/
2022-11-29 07:13:20 [Loss]
2022-11-29 07:13:20 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:13:20 General parameter estimation: Parameter containing:
tensor([0.1907, 0.6707, 0.0213, 0.5194, 0.3074, 0.3033, 0.8286, 0.8964, 0.4556,
        0.0125, 0.0291, 0.0130, 0.8666, 0.1689, 0.0176, 2.3856, 0.6977, 0.8000,
        0.0116, 4.3826, 0.6816, 0.0199, 3.9862, 0.8742, 0.0190, 4.7853, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:13:20 A: prod, degr, TonA, NonA
2022-11-29 07:13:20 [0.2834246  0.49992463 0.01802693 0.19862387]
2022-11-29 07:13:20 T: prod, degr, AonT, NonT
2022-11-29 07:13:20 [0.38134736 0.44465774 0.12749799 0.04649688]
2022-11-29 07:13:20 N: AonN, TonN, ATonN
2022-11-29 07:13:20 [0.00787627 0.966173   0.02595076]
2022-11-29 07:13:20 using cpu
2022-11-29 07:13:20 epoch = 30000
2022-11-29 07:13:20 epoch_step = 2000
2022-11-29 07:13:20 model_name = SimpleNetworkAD
2022-11-29 07:13:20 now_string = 2022-11-28-18-17-05
2022-11-29 07:13:20 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 07:13:20 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 07:13:20 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 07:13:20 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 07:13:20 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 07:13:20 --------------------------------------------------training start--------------------------------------------------
2022-11-29 07:13:59 NUM_SUB: 136;----------------------------
2022-11-29 07:13:59 Epoch [02000/30000] Loss:0.108726 Loss_1:0.107405 Loss_2:0.000776 Loss_3:0.000000 Lr:0.000833 Time:38.225438s (0.64min in total, 8.92min remains)
2022-11-29 07:14:37 NUM_SUB: 136;----------------------------
2022-11-29 07:14:37 Epoch [04000/30000] Loss:0.084277 Loss_1:0.083631 Loss_2:0.000182 Loss_3:0.000000 Lr:0.000714 Time:38.163404s (1.27min in total, 8.28min remains)
2022-11-29 07:15:15 NUM_SUB: 136;----------------------------
2022-11-29 07:15:15 Epoch [06000/30000] Loss:0.041639 Loss_1:0.041161 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000625 Time:38.170213s (1.91min in total, 7.64min remains)
2022-11-29 07:15:53 NUM_SUB: 136;----------------------------
2022-11-29 07:15:53 Epoch [08000/30000] Loss:0.010157 Loss_1:0.009898 Loss_2:0.000168 Loss_3:0.000000 Lr:0.000556 Time:38.135718s (2.54min in total, 7.00min remains)
2022-11-29 07:16:31 NUM_SUB: 136;----------------------------
2022-11-29 07:16:31 Epoch [10000/30000] Loss:0.002195 Loss_1:0.002041 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000500 Time:38.241126s (3.18min in total, 6.36min remains)
2022-11-29 07:17:10 NUM_SUB: 136;----------------------------
2022-11-29 07:17:10 Epoch [12000/30000] Loss:0.001876 Loss_1:0.001796 Loss_2:0.000080 Loss_3:0.000000 Lr:0.000455 Time:38.252337s (3.82min in total, 5.73min remains)
2022-11-29 07:17:48 NUM_SUB: 136;----------------------------
2022-11-29 07:17:48 Epoch [14000/30000] Loss:0.001488 Loss_1:0.001452 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000417 Time:38.100245s (4.45min in total, 5.09min remains)
2022-11-29 07:18:26 NUM_SUB: 136;----------------------------
2022-11-29 07:18:26 Epoch [16000/30000] Loss:0.001462 Loss_1:0.001442 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:38.224687s (5.09min in total, 4.46min remains)
2022-11-29 07:19:04 NUM_SUB: 136;----------------------------
2022-11-29 07:19:04 Epoch [18000/30000] Loss:0.001446 Loss_1:0.001434 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.183497s (5.73min in total, 3.82min remains)
2022-11-29 07:19:42 NUM_SUB: 136;----------------------------
2022-11-29 07:19:42 Epoch [20000/30000] Loss:0.001430 Loss_1:0.001424 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.222446s (6.37min in total, 3.18min remains)
2022-11-29 07:20:20 NUM_SUB: 136;----------------------------
2022-11-29 07:20:20 Epoch [22000/30000] Loss:0.001413 Loss_1:0.001410 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.241943s (7.00min in total, 2.55min remains)
2022-11-29 07:20:59 NUM_SUB: 136;----------------------------
2022-11-29 07:20:59 Epoch [24000/30000] Loss:0.001407 Loss_1:0.001405 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.063298s (7.64min in total, 1.91min remains)
2022-11-29 07:21:37 NUM_SUB: 136;----------------------------
2022-11-29 07:21:37 Epoch [26000/30000] Loss:0.001406 Loss_1:0.001405 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:38.232179s (8.27min in total, 1.27min remains)
2022-11-29 07:22:15 NUM_SUB: 136;----------------------------
2022-11-29 07:22:15 Epoch [28000/30000] Loss:0.001406 Loss_1:0.001406 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.087842s (8.91min in total, 0.64min remains)
2022-11-29 07:22:53 Testing & drawing...
2022-11-29 07:22:53 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:22:55 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=136/
2022-11-29 07:22:55 [Loss]
2022-11-29 07:22:55 NUM_SUB: 136; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:22:55 NUM_SUB: 136; Personalized parameter estimation: Parameter containing:
tensor([5.1225e-01, 6.8261e-01, 1.1810e-01, 6.0933e-27, 3.0742e-01, 1.5231e-03,
        7.3291e-01, 8.9644e-01, 4.5563e-01, 1.3551e-02, 2.5436e-02, 1.4586e-02,
        8.0701e-01, 1.6886e-01, 4.3121e-03, 1.4582e+00, 6.9767e-01, 8.0001e-01,
        1.1073e-02, 4.8183e+00, 6.8161e-01, 2.2670e-02, 3.9062e+00, 8.7416e-01,
        1.5298e-02, 4.8028e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 07:22:55 NUM_SUB: 136;----------------------------
2022-11-29 07:22:55 Epoch [30000/30000] Loss:0.001406 Loss_1:0.001405 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:39.815079s (9.57min in total, 0.00min remains)
2022-11-29 07:22:55 NUM_SUB: 136------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 07:22:55 Testing & drawing...
2022-11-29 07:22:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:22:56 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=136/
2022-11-29 07:22:56 [Loss]
2022-11-29 07:22:56 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:22:56 General parameter estimation: Parameter containing:
tensor([5.1226e-01, 6.8261e-01, 1.1810e-01, 5.8914e-27, 3.0742e-01, 1.5278e-03,
        7.3291e-01, 8.9644e-01, 4.5563e-01, 1.3551e-02, 2.5433e-02, 1.4586e-02,
        8.0704e-01, 1.6886e-01, 4.3109e-03, 1.4582e+00, 6.9767e-01, 8.0001e-01,
        1.1073e-02, 4.8183e+00, 6.8161e-01, 2.2669e-02, 3.9063e+00, 8.7416e-01,
        1.5298e-02, 4.8028e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 07:22:56 A: prod, degr, TonA, NonA
2022-11-29 07:22:56 [0.4057951  0.4999768  0.09355669 0.00067138]
2022-11-29 07:22:56 T: prod, degr, AonT, NonT
2022-11-29 07:22:56 [0.29953557 0.5198247  0.15741651 0.02322321]
2022-11-29 07:22:56 N: AonN, TonN, ATonN
2022-11-29 07:22:56 [0.01711859 0.9424569  0.04042452]
2022-11-29 07:22:56 using cpu
2022-11-29 07:22:56 epoch = 30000
2022-11-29 07:22:56 epoch_step = 2000
2022-11-29 07:22:56 model_name = SimpleNetworkAD
2022-11-29 07:22:56 now_string = 2022-11-28-18-17-05
2022-11-29 07:22:56 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 07:22:56 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 07:22:56 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 07:22:56 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 07:22:56 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 07:22:56 --------------------------------------------------training start--------------------------------------------------
2022-11-29 07:23:35 NUM_SUB: 137;----------------------------
2022-11-29 07:23:35 Epoch [02000/30000] Loss:0.115390 Loss_1:0.113875 Loss_2:0.000860 Loss_3:0.000000 Lr:0.000833 Time:38.299735s (0.64min in total, 8.94min remains)
2022-11-29 07:24:13 NUM_SUB: 137;----------------------------
2022-11-29 07:24:13 Epoch [04000/30000] Loss:0.088929 Loss_1:0.087911 Loss_2:0.000239 Loss_3:0.000000 Lr:0.000714 Time:38.427159s (1.28min in total, 8.31min remains)
2022-11-29 07:24:52 NUM_SUB: 137;----------------------------
2022-11-29 07:24:52 Epoch [06000/30000] Loss:0.041561 Loss_1:0.040911 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000625 Time:38.305670s (1.92min in total, 7.67min remains)
2022-11-29 07:25:30 NUM_SUB: 137;----------------------------
2022-11-29 07:25:30 Epoch [08000/30000] Loss:0.003748 Loss_1:0.003478 Loss_2:0.000206 Loss_3:0.000000 Lr:0.000556 Time:38.273807s (2.56min in total, 7.03min remains)
2022-11-29 07:26:08 NUM_SUB: 137;----------------------------
2022-11-29 07:26:08 Epoch [10000/30000] Loss:0.000477 Loss_1:0.000327 Loss_2:0.000150 Loss_3:0.000000 Lr:0.000500 Time:38.326302s (3.19min in total, 6.39min remains)
2022-11-29 07:26:46 NUM_SUB: 137;----------------------------
2022-11-29 07:26:46 Epoch [12000/30000] Loss:0.000148 Loss_1:0.000083 Loss_2:0.000065 Loss_3:0.000000 Lr:0.000455 Time:38.310128s (3.83min in total, 5.75min remains)
2022-11-29 07:27:25 NUM_SUB: 137;----------------------------
2022-11-29 07:27:25 Epoch [14000/30000] Loss:0.000036 Loss_1:0.000002 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000417 Time:38.460290s (4.47min in total, 5.11min remains)
2022-11-29 07:43:07 NUM_SUB: 137;----------------------------
2022-11-29 07:43:07 Epoch [16000/30000] Loss:0.000019 Loss_1:0.000000 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000385 Time:941.737794s (20.17min in total, 17.65min remains)
2022-11-29 07:43:45 NUM_SUB: 137;----------------------------
2022-11-29 07:43:45 Epoch [18000/30000] Loss:0.000011 Loss_1:0.000000 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.435909s (20.81min in total, 13.87min remains)
2022-11-29 07:44:23 NUM_SUB: 137;----------------------------
2022-11-29 07:44:23 Epoch [20000/30000] Loss:0.000007 Loss_1:0.000001 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.154027s (21.45min in total, 10.72min remains)
2022-11-29 07:45:02 NUM_SUB: 137;----------------------------
2022-11-29 07:45:02 Epoch [22000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.407647s (22.09min in total, 8.03min remains)
2022-11-29 07:45:40 NUM_SUB: 137;----------------------------
2022-11-29 07:45:40 Epoch [24000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.390547s (22.73min in total, 5.68min remains)
2022-11-29 07:46:18 NUM_SUB: 137;----------------------------
2022-11-29 07:46:18 Epoch [26000/30000] Loss:0.000001 Loss_1:0.000000 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.415281s (23.37min in total, 3.59min remains)
2022-11-29 07:46:57 NUM_SUB: 137;----------------------------
2022-11-29 07:46:57 Epoch [28000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.250551s (24.00min in total, 1.71min remains)
2022-11-29 07:47:35 Testing & drawing...
2022-11-29 07:47:35 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:47:37 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=137/
2022-11-29 07:47:37 [Loss]
2022-11-29 07:47:37 NUM_SUB: 137; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:47:37 NUM_SUB: 137; Personalized parameter estimation: Parameter containing:
tensor([1.4174e-01, 1.9547e-01, 2.4431e-02, 4.5335e-16, 3.0742e-01, 1.3419e-02,
        8.8351e-01, 8.9644e-01, 4.5563e-01, 1.3801e-02, 3.1470e-02, 1.4883e-02,
        6.4971e-01, 1.6886e-01, 1.7556e-02, 1.7968e+00, 6.9767e-01, 8.0001e-01,
        1.0923e-02, 4.9787e+00, 6.8161e-01, 2.2652e-02, 4.1865e+00, 8.7416e-01,
        1.7454e-02, 5.0765e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 07:47:37 NUM_SUB: 137;----------------------------
2022-11-29 07:47:37 Epoch [30000/30000] Loss:0.000000 Loss_1:0.000000 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.169061s (24.67min in total, 0.00min remains)
2022-11-29 07:47:37 NUM_SUB: 137------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 07:47:37 Testing & drawing...
2022-11-29 07:47:37 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:47:38 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=137/
2022-11-29 07:47:38 [Loss]
2022-11-29 07:47:38 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:47:38 General parameter estimation: Parameter containing:
tensor([1.4173e-01, 1.9547e-01, 2.4431e-02, 4.5332e-16, 3.0742e-01, 1.3419e-02,
        8.8351e-01, 8.9644e-01, 4.5563e-01, 1.3801e-02, 3.1471e-02, 1.4883e-02,
        6.4966e-01, 1.6886e-01, 1.7556e-02, 1.7969e+00, 6.9767e-01, 8.0001e-01,
        1.0923e-02, 4.9788e+00, 6.8161e-01, 2.2651e-02, 4.1866e+00, 8.7416e-01,
        1.7453e-02, 5.0766e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 07:47:38 A: prod, degr, TonA, NonA
2022-11-29 07:47:38 [0.41396758 0.4974377  0.07135881 0.01723589]
2022-11-29 07:47:38 T: prod, degr, AonT, NonT
2022-11-29 07:47:38 [0.26243058 0.5210354  0.16280071 0.05373326]
2022-11-29 07:47:38 N: AonN, TonN, ATonN
2022-11-29 07:47:38 [0.0143009  0.9476391  0.03806002]
2022-11-29 07:47:39 using cpu
2022-11-29 07:47:39 epoch = 30000
2022-11-29 07:47:39 epoch_step = 2000
2022-11-29 07:47:39 model_name = SimpleNetworkAD
2022-11-29 07:47:39 now_string = 2022-11-28-18-17-05
2022-11-29 07:47:39 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 07:47:39 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 07:47:39 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 07:47:39 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 07:47:39 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 07:47:39 --------------------------------------------------training start--------------------------------------------------
2022-11-29 07:48:17 NUM_SUB: 138;----------------------------
2022-11-29 07:48:17 Epoch [02000/30000] Loss:0.098178 Loss_1:0.097355 Loss_2:0.000408 Loss_3:0.000000 Lr:0.000833 Time:38.095643s (0.63min in total, 8.89min remains)
2022-11-29 07:48:55 NUM_SUB: 138;----------------------------
2022-11-29 07:48:55 Epoch [04000/30000] Loss:0.072687 Loss_1:0.072396 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000714 Time:38.192787s (1.27min in total, 8.26min remains)
2022-11-29 07:49:33 NUM_SUB: 138;----------------------------
2022-11-29 07:49:33 Epoch [06000/30000] Loss:0.025427 Loss_1:0.025237 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000625 Time:38.245079s (1.91min in total, 7.64min remains)
2022-11-29 07:50:11 NUM_SUB: 138;----------------------------
2022-11-29 07:50:11 Epoch [08000/30000] Loss:0.002653 Loss_1:0.002600 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000556 Time:38.217163s (2.55min in total, 7.00min remains)
2022-11-29 07:50:50 NUM_SUB: 138;----------------------------
2022-11-29 07:50:50 Epoch [10000/30000] Loss:0.001802 Loss_1:0.001756 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000500 Time:38.157487s (3.18min in total, 6.36min remains)
2022-11-29 07:51:28 NUM_SUB: 138;----------------------------
2022-11-29 07:51:28 Epoch [12000/30000] Loss:0.001267 Loss_1:0.001234 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000455 Time:38.178377s (3.82min in total, 5.73min remains)
2022-11-29 07:52:06 NUM_SUB: 138;----------------------------
2022-11-29 07:52:06 Epoch [14000/30000] Loss:0.000517 Loss_1:0.000502 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.113276s (4.45min in total, 5.09min remains)
2022-11-29 07:52:44 NUM_SUB: 138;----------------------------
2022-11-29 07:52:44 Epoch [16000/30000] Loss:0.000356 Loss_1:0.000348 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:38.400220s (5.09min in total, 4.46min remains)
2022-11-29 07:53:22 NUM_SUB: 138;----------------------------
2022-11-29 07:53:22 Epoch [18000/30000] Loss:0.000348 Loss_1:0.000344 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:38.239062s (5.73min in total, 3.82min remains)
2022-11-29 07:54:01 NUM_SUB: 138;----------------------------
2022-11-29 07:54:01 Epoch [20000/30000] Loss:0.000340 Loss_1:0.000337 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.377326s (6.37min in total, 3.19min remains)
2022-11-29 07:54:39 NUM_SUB: 138;----------------------------
2022-11-29 07:54:39 Epoch [22000/30000] Loss:0.000335 Loss_1:0.000332 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.090253s (7.01min in total, 2.55min remains)
2022-11-29 07:55:17 NUM_SUB: 138;----------------------------
2022-11-29 07:55:17 Epoch [24000/30000] Loss:0.000331 Loss_1:0.000329 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.150546s (7.64min in total, 1.91min remains)
2022-11-29 07:55:55 NUM_SUB: 138;----------------------------
2022-11-29 07:55:55 Epoch [26000/30000] Loss:0.000329 Loss_1:0.000328 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.208785s (8.28min in total, 1.27min remains)
2022-11-29 07:56:34 NUM_SUB: 138;----------------------------
2022-11-29 07:56:34 Epoch [28000/30000] Loss:0.000328 Loss_1:0.000327 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.405652s (8.92min in total, 0.64min remains)
2022-11-29 07:57:12 Testing & drawing...
2022-11-29 07:57:12 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:57:13 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=138/
2022-11-29 07:57:13 [Loss]
2022-11-29 07:57:14 NUM_SUB: 138; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:57:14 NUM_SUB: 138; Personalized parameter estimation: Parameter containing:
tensor([0.2890, 0.9334, 0.0108, 0.4561, 0.3074, 0.1021, 0.7600, 0.8964, 0.4556,
        0.0140, 0.1089, 0.1140, 0.7312, 0.1689, 0.0169, 1.1270, 0.6977, 0.8000,
        0.0123, 3.1386, 0.6816, 0.0213, 3.4509, 0.8742, 0.0189, 4.0508, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:57:14 NUM_SUB: 138;----------------------------
2022-11-29 07:57:14 Epoch [30000/30000] Loss:0.000380 Loss_1:0.000364 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000250 Time:39.856632s (9.58min in total, 0.00min remains)
2022-11-29 07:57:14 NUM_SUB: 138------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 07:57:14 Testing & drawing...
2022-11-29 07:57:14 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 07:57:15 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=138/
2022-11-29 07:57:15 [Loss]
2022-11-29 07:57:15 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 07:57:15 General parameter estimation: Parameter containing:
tensor([0.2892, 0.9332, 0.0108, 0.4558, 0.3074, 0.1024, 0.7598, 0.8964, 0.4556,
        0.0140, 0.1089, 0.1139, 0.7312, 0.1689, 0.0169, 1.1270, 0.6977, 0.8000,
        0.0123, 3.1385, 0.6816, 0.0213, 3.4509, 0.8742, 0.0189, 4.0508, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 07:57:15 A: prod, degr, TonA, NonA
2022-11-29 07:57:15 [0.4113869  0.49763885 0.00798134 0.0829929 ]
2022-11-29 07:57:15 T: prod, degr, AonT, NonT
2022-11-29 07:57:15 [0.1477417  0.42993322 0.3558544  0.06647068]
2022-11-29 07:57:15 N: AonN, TonN, ATonN
2022-11-29 07:57:15 [0.00898019 0.9682926  0.02272725]
2022-11-29 07:57:15 using cpu
2022-11-29 07:57:15 epoch = 30000
2022-11-29 07:57:15 epoch_step = 2000
2022-11-29 07:57:15 model_name = SimpleNetworkAD
2022-11-29 07:57:15 now_string = 2022-11-28-18-17-05
2022-11-29 07:57:15 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 07:57:15 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 07:57:15 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 07:57:15 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 07:57:15 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 07:57:15 --------------------------------------------------training start--------------------------------------------------
2022-11-29 07:57:54 NUM_SUB: 139;----------------------------
2022-11-29 07:57:54 Epoch [02000/30000] Loss:0.057942 Loss_1:0.057022 Loss_2:0.000519 Loss_3:0.000000 Lr:0.000833 Time:38.178342s (0.64min in total, 8.91min remains)
2022-11-29 07:58:32 NUM_SUB: 139;----------------------------
2022-11-29 07:58:32 Epoch [04000/30000] Loss:0.047423 Loss_1:0.047112 Loss_2:0.000090 Loss_3:0.000000 Lr:0.000714 Time:38.263494s (1.27min in total, 8.28min remains)
2022-11-29 07:59:10 NUM_SUB: 139;----------------------------
2022-11-29 07:59:10 Epoch [06000/30000] Loss:0.030758 Loss_1:0.030500 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000625 Time:38.159601s (1.91min in total, 7.64min remains)
2022-11-29 07:59:48 NUM_SUB: 139;----------------------------
2022-11-29 07:59:48 Epoch [08000/30000] Loss:0.011407 Loss_1:0.011210 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000556 Time:38.227711s (2.55min in total, 7.00min remains)
2022-11-29 08:00:27 NUM_SUB: 139;----------------------------
2022-11-29 08:00:27 Epoch [10000/30000] Loss:0.004285 Loss_1:0.004141 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000500 Time:38.381197s (3.19min in total, 6.37min remains)
2022-11-29 08:01:05 NUM_SUB: 139;----------------------------
2022-11-29 08:01:05 Epoch [12000/30000] Loss:0.002958 Loss_1:0.002900 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000455 Time:38.254679s (3.82min in total, 5.74min remains)
2022-11-29 08:01:43 NUM_SUB: 139;----------------------------
2022-11-29 08:01:43 Epoch [14000/30000] Loss:0.002525 Loss_1:0.002486 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000417 Time:38.209520s (4.46min in total, 5.10min remains)
2022-11-29 08:02:21 NUM_SUB: 139;----------------------------
2022-11-29 08:02:21 Epoch [16000/30000] Loss:0.002496 Loss_1:0.002471 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000385 Time:38.211936s (5.10min in total, 4.46min remains)
2022-11-29 08:02:59 NUM_SUB: 139;----------------------------
2022-11-29 08:02:59 Epoch [18000/30000] Loss:0.002475 Loss_1:0.002456 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:38.245873s (5.74min in total, 3.82min remains)
2022-11-29 08:03:38 NUM_SUB: 139;----------------------------
2022-11-29 08:03:38 Epoch [20000/30000] Loss:0.002461 Loss_1:0.002449 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.213097s (6.37min in total, 3.19min remains)
2022-11-29 08:04:16 NUM_SUB: 139;----------------------------
2022-11-29 08:04:16 Epoch [22000/30000] Loss:0.002458 Loss_1:0.002448 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.169617s (7.01min in total, 2.55min remains)
2022-11-29 08:04:54 NUM_SUB: 139;----------------------------
2022-11-29 08:04:54 Epoch [24000/30000] Loss:0.002455 Loss_1:0.002449 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.241814s (7.65min in total, 1.91min remains)
2022-11-29 08:05:32 NUM_SUB: 139;----------------------------
2022-11-29 08:05:32 Epoch [26000/30000] Loss:0.002457 Loss_1:0.002448 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.298004s (8.28min in total, 1.27min remains)
2022-11-29 08:06:11 NUM_SUB: 139;----------------------------
2022-11-29 08:06:11 Epoch [28000/30000] Loss:0.002453 Loss_1:0.002448 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.262588s (8.92min in total, 0.64min remains)
2022-11-29 08:06:49 Testing & drawing...
2022-11-29 08:06:49 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:06:50 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=139/
2022-11-29 08:06:50 [Loss]
2022-11-29 08:06:51 NUM_SUB: 139; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:06:51 NUM_SUB: 139; Personalized parameter estimation: Parameter containing:
tensor([0.2492, 0.6475, 0.0133, 0.6169, 0.3074, 0.3290, 0.7531, 0.8964, 0.4556,
        0.0142, 0.0255, 0.0149, 1.0532, 0.1689, 0.0171, 2.3712, 0.6977, 0.8000,
        0.0095, 4.5637, 0.6816, 0.0216, 4.2839, 0.8742, 0.0188, 5.0331, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:06:51 NUM_SUB: 139;----------------------------
2022-11-29 08:06:51 Epoch [30000/30000] Loss:0.002453 Loss_1:0.002448 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:39.891198s (9.59min in total, 0.00min remains)
2022-11-29 08:06:51 NUM_SUB: 139------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:06:51 Testing & drawing...
2022-11-29 08:06:51 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:06:52 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=139/
2022-11-29 08:06:52 [Loss]
2022-11-29 08:06:52 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:06:52 General parameter estimation: Parameter containing:
tensor([0.2492, 0.6475, 0.0133, 0.6169, 0.3074, 0.3290, 0.7531, 0.8964, 0.4556,
        0.0142, 0.0255, 0.0149, 1.0532, 0.1689, 0.0171, 2.3713, 0.6977, 0.8000,
        0.0095, 4.5639, 0.6816, 0.0216, 4.2841, 0.8742, 0.0188, 5.0332, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:06:52 A: prod, degr, TonA, NonA
2022-11-29 08:06:52 [0.35513073 0.49970666 0.01073667 0.13442594]
2022-11-29 08:06:52 T: prod, degr, AonT, NonT
2022-11-29 08:06:52 [0.42558533 0.41530946 0.13906537 0.02003986]
2022-11-29 08:06:52 N: AonN, TonN, ATonN
2022-11-29 08:06:52 [0.00626563 0.9664547  0.02727965]
2022-11-29 08:06:52 using cpu
2022-11-29 08:06:52 epoch = 30000
2022-11-29 08:06:52 epoch_step = 2000
2022-11-29 08:06:52 model_name = SimpleNetworkAD
2022-11-29 08:06:52 now_string = 2022-11-28-18-17-05
2022-11-29 08:06:52 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:06:52 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:06:52 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:06:52 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:06:52 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:06:52 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:07:31 NUM_SUB: 140;----------------------------
2022-11-29 08:07:31 Epoch [02000/30000] Loss:0.057476 Loss_1:0.056468 Loss_2:0.000534 Loss_3:0.000000 Lr:0.000833 Time:38.279452s (0.64min in total, 8.93min remains)
2022-11-29 08:08:09 NUM_SUB: 140;----------------------------
2022-11-29 08:08:09 Epoch [04000/30000] Loss:0.046835 Loss_1:0.046488 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000714 Time:38.262732s (1.28min in total, 8.29min remains)
2022-11-29 08:08:47 NUM_SUB: 140;----------------------------
2022-11-29 08:08:47 Epoch [06000/30000] Loss:0.028216 Loss_1:0.027940 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000625 Time:38.207053s (1.91min in total, 7.65min remains)
2022-11-29 08:09:25 NUM_SUB: 140;----------------------------
2022-11-29 08:09:25 Epoch [08000/30000] Loss:0.006197 Loss_1:0.006045 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000556 Time:38.253942s (2.55min in total, 7.01min remains)
2022-11-29 08:10:04 NUM_SUB: 140;----------------------------
2022-11-29 08:10:04 Epoch [10000/30000] Loss:0.001039 Loss_1:0.000945 Loss_2:0.000091 Loss_3:0.000000 Lr:0.000500 Time:38.272613s (3.19min in total, 6.38min remains)
2022-11-29 08:10:42 NUM_SUB: 140;----------------------------
2022-11-29 08:10:42 Epoch [12000/30000] Loss:0.000662 Loss_1:0.000607 Loss_2:0.000055 Loss_3:0.000000 Lr:0.000455 Time:38.232503s (3.83min in total, 5.74min remains)
2022-11-29 08:11:20 NUM_SUB: 140;----------------------------
2022-11-29 08:11:20 Epoch [14000/30000] Loss:0.000365 Loss_1:0.000341 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:38.327746s (4.46min in total, 5.10min remains)
2022-11-29 08:11:58 NUM_SUB: 140;----------------------------
2022-11-29 08:11:58 Epoch [16000/30000] Loss:0.000233 Loss_1:0.000213 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:38.156923s (5.10min in total, 4.46min remains)
2022-11-29 08:12:37 NUM_SUB: 140;----------------------------
2022-11-29 08:12:37 Epoch [18000/30000] Loss:0.000219 Loss_1:0.000202 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:38.327298s (5.74min in total, 3.83min remains)
2022-11-29 08:13:15 NUM_SUB: 140;----------------------------
2022-11-29 08:13:15 Epoch [20000/30000] Loss:0.000164 Loss_1:0.000152 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000333 Time:38.228030s (6.38min in total, 3.19min remains)
2022-11-29 08:13:53 NUM_SUB: 140;----------------------------
2022-11-29 08:13:53 Epoch [22000/30000] Loss:0.000138 Loss_1:0.000127 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000313 Time:38.135104s (7.01min in total, 2.55min remains)
2022-11-29 08:14:31 NUM_SUB: 140;----------------------------
2022-11-29 08:14:31 Epoch [24000/30000] Loss:0.000119 Loss_1:0.000109 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000294 Time:38.296242s (7.65min in total, 1.91min remains)
2022-11-29 08:15:09 NUM_SUB: 140;----------------------------
2022-11-29 08:15:09 Epoch [26000/30000] Loss:0.000111 Loss_1:0.000102 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000278 Time:38.181529s (8.29min in total, 1.27min remains)
2022-11-29 08:15:48 NUM_SUB: 140;----------------------------
2022-11-29 08:15:48 Epoch [28000/30000] Loss:0.000102 Loss_1:0.000093 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000263 Time:38.220416s (8.92min in total, 0.64min remains)
2022-11-29 08:16:26 Testing & drawing...
2022-11-29 08:16:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:16:28 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=140/
2022-11-29 08:16:28 [Loss]
2022-11-29 08:16:28 NUM_SUB: 140; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:16:28 NUM_SUB: 140; Personalized parameter estimation: Parameter containing:
tensor([2.4100e-01, 6.0133e-01, 1.1160e-02, 3.7814e-06, 3.0742e-01, 2.1861e-01,
        9.8185e-01, 8.9644e-01, 4.5563e-01, 1.3430e-02, 4.0858e-02, 1.3061e-02,
        7.0649e-01, 1.6886e-01, 1.7913e-02, 1.1593e+00, 6.9767e-01, 8.0001e-01,
        1.2043e-02, 3.0934e+00, 6.8161e-01, 1.9283e-02, 2.9970e+00, 8.7416e-01,
        1.9949e-02, 3.5507e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 08:16:28 NUM_SUB: 140;----------------------------
2022-11-29 08:16:28 Epoch [30000/30000] Loss:0.000092 Loss_1:0.000084 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000250 Time:39.927541s (9.59min in total, 0.00min remains)
2022-11-29 08:16:28 NUM_SUB: 140------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:16:28 Testing & drawing...
2022-11-29 08:16:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:16:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=140/
2022-11-29 08:16:29 [Loss]
2022-11-29 08:16:29 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:16:29 General parameter estimation: Parameter containing:
tensor([2.4099e-01, 6.0132e-01, 1.1160e-02, 3.7726e-06, 3.0742e-01, 2.1859e-01,
        9.8187e-01, 8.9644e-01, 4.5563e-01, 1.3430e-02, 4.0863e-02, 1.3061e-02,
        7.0644e-01, 1.6886e-01, 1.7913e-02, 1.1592e+00, 6.9767e-01, 8.0001e-01,
        1.2043e-02, 3.0932e+00, 6.8161e-01, 1.9283e-02, 2.9971e+00, 8.7416e-01,
        1.9949e-02, 3.5507e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 08:16:29 A: prod, degr, TonA, NonA
2022-11-29 08:16:29 [0.34559217 0.49966034 0.01600362 0.13874383]
2022-11-29 08:16:29 T: prod, degr, AonT, NonT
2022-11-29 08:16:29 [0.27457437 0.48368427 0.10860547 0.1331359 ]
2022-11-29 08:16:29 N: AonN, TonN, ATonN
2022-11-29 08:16:29 [0.02134457 0.9248336  0.05382187]
2022-11-29 08:16:29 using cpu
2022-11-29 08:16:29 epoch = 30000
2022-11-29 08:16:29 epoch_step = 2000
2022-11-29 08:16:29 model_name = SimpleNetworkAD
2022-11-29 08:16:29 now_string = 2022-11-28-18-17-05
2022-11-29 08:16:29 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:16:29 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:16:29 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:16:29 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:16:29 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:16:29 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:17:08 NUM_SUB: 141;----------------------------
2022-11-29 08:17:08 Epoch [02000/30000] Loss:0.061267 Loss_1:0.060096 Loss_2:0.000694 Loss_3:0.000000 Lr:0.000833 Time:38.231790s (0.64min in total, 8.92min remains)
2022-11-29 08:17:46 NUM_SUB: 141;----------------------------
2022-11-29 08:17:46 Epoch [04000/30000] Loss:0.049132 Loss_1:0.048803 Loss_2:0.000143 Loss_3:0.000000 Lr:0.000714 Time:38.216258s (1.27min in total, 8.28min remains)
2022-11-29 08:18:24 NUM_SUB: 141;----------------------------
2022-11-29 08:18:24 Epoch [06000/30000] Loss:0.028049 Loss_1:0.027788 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000625 Time:38.240505s (1.91min in total, 7.65min remains)
2022-11-29 08:19:02 NUM_SUB: 141;----------------------------
2022-11-29 08:19:02 Epoch [08000/30000] Loss:0.007565 Loss_1:0.007422 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000556 Time:38.136858s (2.55min in total, 7.00min remains)
2022-11-29 08:19:40 NUM_SUB: 141;----------------------------
2022-11-29 08:19:40 Epoch [10000/30000] Loss:0.003308 Loss_1:0.003220 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000500 Time:38.191279s (3.18min in total, 6.37min remains)
2022-11-29 08:20:19 NUM_SUB: 141;----------------------------
2022-11-29 08:20:19 Epoch [12000/30000] Loss:0.001935 Loss_1:0.001888 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000455 Time:38.220188s (3.82min in total, 5.73min remains)
2022-11-29 08:20:57 NUM_SUB: 141;----------------------------
2022-11-29 08:20:57 Epoch [14000/30000] Loss:0.001714 Loss_1:0.001694 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:38.180252s (4.46min in total, 5.09min remains)
2022-11-29 08:21:35 NUM_SUB: 141;----------------------------
2022-11-29 08:21:35 Epoch [16000/30000] Loss:0.001667 Loss_1:0.001657 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:38.298222s (5.10min in total, 4.46min remains)
2022-11-29 08:22:13 NUM_SUB: 141;----------------------------
2022-11-29 08:22:13 Epoch [18000/30000] Loss:0.001662 Loss_1:0.001655 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.250983s (5.73min in total, 3.82min remains)
2022-11-29 08:22:52 NUM_SUB: 141;----------------------------
2022-11-29 08:22:52 Epoch [20000/30000] Loss:0.001660 Loss_1:0.001655 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.244991s (6.37min in total, 3.19min remains)
2022-11-29 08:23:30 NUM_SUB: 141;----------------------------
2022-11-29 08:23:30 Epoch [22000/30000] Loss:0.001659 Loss_1:0.001655 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.297058s (7.01min in total, 2.55min remains)
2022-11-29 08:24:08 NUM_SUB: 141;----------------------------
2022-11-29 08:24:08 Epoch [24000/30000] Loss:0.001658 Loss_1:0.001655 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.315338s (7.65min in total, 1.91min remains)
2022-11-29 08:24:46 NUM_SUB: 141;----------------------------
2022-11-29 08:24:46 Epoch [26000/30000] Loss:0.001658 Loss_1:0.001655 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.139313s (8.28min in total, 1.27min remains)
2022-11-29 08:25:25 NUM_SUB: 141;----------------------------
2022-11-29 08:25:25 Epoch [28000/30000] Loss:0.001657 Loss_1:0.001656 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.301900s (8.92min in total, 0.64min remains)
2022-11-29 08:26:03 Testing & drawing...
2022-11-29 08:26:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:26:04 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=141/
2022-11-29 08:26:04 [Loss]
2022-11-29 08:26:05 NUM_SUB: 141; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:26:05 NUM_SUB: 141; Personalized parameter estimation: Parameter containing:
tensor([0.4945, 0.7308, 0.0755, 0.0050, 0.3074, 0.0142, 1.8101, 0.8964, 0.4556,
        0.0133, 0.0495, 0.0125, 0.4111, 0.1689, 0.0177, 1.1085, 0.6977, 0.8000,
        0.0118, 3.2161, 0.6816, 0.0228, 3.1133, 0.8742, 0.0204, 3.4931, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:26:05 NUM_SUB: 141;----------------------------
2022-11-29 08:26:05 Epoch [30000/30000] Loss:0.001657 Loss_1:0.001656 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.829350s (9.59min in total, 0.00min remains)
2022-11-29 08:26:05 NUM_SUB: 141------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:26:05 Testing & drawing...
2022-11-29 08:26:05 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:26:06 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=141/
2022-11-29 08:26:06 [Loss]
2022-11-29 08:26:06 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:26:06 General parameter estimation: Parameter containing:
tensor([0.4945, 0.7308, 0.0755, 0.0050, 0.3074, 0.0142, 1.8102, 0.8964, 0.4556,
        0.0133, 0.0495, 0.0125, 0.4111, 0.1689, 0.0177, 1.1084, 0.6977, 0.8000,
        0.0118, 3.2159, 0.6816, 0.0228, 3.1134, 0.8742, 0.0204, 3.4930, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:26:06 A: prod, degr, TonA, NonA
2022-11-29 08:26:06 [0.43174836 0.4999625  0.06593572 0.00235343]
2022-11-29 08:26:06 T: prod, degr, AonT, NonT
2022-11-29 08:26:06 [0.19967449 0.5830293  0.11784095 0.09945522]
2022-11-29 08:26:06 N: AonN, TonN, ATonN
2022-11-29 08:26:06 [0.02896048 0.908782   0.06225758]
2022-11-29 08:26:06 using cpu
2022-11-29 08:26:06 epoch = 30000
2022-11-29 08:26:06 epoch_step = 2000
2022-11-29 08:26:06 model_name = SimpleNetworkAD
2022-11-29 08:26:06 now_string = 2022-11-28-18-17-05
2022-11-29 08:26:06 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:26:06 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:26:06 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:26:06 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:26:06 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:26:06 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:26:45 NUM_SUB: 142;----------------------------
2022-11-29 08:26:45 Epoch [02000/30000] Loss:0.092638 Loss_1:0.091882 Loss_2:0.000325 Loss_3:0.000000 Lr:0.000833 Time:38.222223s (0.64min in total, 8.92min remains)
2022-11-29 08:27:23 NUM_SUB: 142;----------------------------
2022-11-29 08:27:23 Epoch [04000/30000] Loss:0.068999 Loss_1:0.068769 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000714 Time:38.243901s (1.27min in total, 8.28min remains)
2022-11-29 08:28:01 NUM_SUB: 142;----------------------------
2022-11-29 08:28:01 Epoch [06000/30000] Loss:0.025658 Loss_1:0.025485 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000625 Time:38.237356s (1.91min in total, 7.65min remains)
2022-11-29 08:28:39 NUM_SUB: 142;----------------------------
2022-11-29 08:28:39 Epoch [08000/30000] Loss:0.004195 Loss_1:0.004126 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000556 Time:38.217046s (2.55min in total, 7.01min remains)
2022-11-29 08:29:17 NUM_SUB: 142;----------------------------
2022-11-29 08:29:17 Epoch [10000/30000] Loss:0.003572 Loss_1:0.003512 Loss_2:0.000058 Loss_3:0.000000 Lr:0.000500 Time:38.154299s (3.18min in total, 6.37min remains)
2022-11-29 08:29:56 NUM_SUB: 142;----------------------------
2022-11-29 08:29:56 Epoch [12000/30000] Loss:0.003422 Loss_1:0.003376 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:38.163608s (3.82min in total, 5.73min remains)
2022-11-29 08:30:34 NUM_SUB: 142;----------------------------
2022-11-29 08:30:34 Epoch [14000/30000] Loss:0.003287 Loss_1:0.003267 Loss_2:0.000019 Loss_3:0.000000 Lr:0.000417 Time:38.171436s (4.46min in total, 5.09min remains)
2022-11-29 08:31:12 NUM_SUB: 142;----------------------------
2022-11-29 08:31:12 Epoch [16000/30000] Loss:0.003065 Loss_1:0.003058 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000385 Time:38.211600s (5.09min in total, 4.46min remains)
2022-11-29 08:31:50 NUM_SUB: 142;----------------------------
2022-11-29 08:31:50 Epoch [18000/30000] Loss:0.001932 Loss_1:0.001924 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:38.236860s (5.73min in total, 3.82min remains)
2022-11-29 08:32:29 NUM_SUB: 142;----------------------------
2022-11-29 08:32:29 Epoch [20000/30000] Loss:0.001522 Loss_1:0.001513 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.361087s (6.37min in total, 3.19min remains)
2022-11-29 08:33:07 NUM_SUB: 142;----------------------------
2022-11-29 08:33:07 Epoch [22000/30000] Loss:0.001416 Loss_1:0.001407 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.185860s (7.01min in total, 2.55min remains)
2022-11-29 08:33:45 NUM_SUB: 142;----------------------------
2022-11-29 08:33:45 Epoch [24000/30000] Loss:0.001390 Loss_1:0.001380 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000294 Time:38.235138s (7.64min in total, 1.91min remains)
2022-11-29 08:34:23 NUM_SUB: 142;----------------------------
2022-11-29 08:34:23 Epoch [26000/30000] Loss:0.001386 Loss_1:0.001376 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000278 Time:38.295021s (8.28min in total, 1.27min remains)
2022-11-29 08:35:02 NUM_SUB: 142;----------------------------
2022-11-29 08:35:02 Epoch [28000/30000] Loss:0.001383 Loss_1:0.001374 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000263 Time:38.241997s (8.92min in total, 0.64min remains)
2022-11-29 08:35:40 Testing & drawing...
2022-11-29 08:35:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:35:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=142/
2022-11-29 08:35:41 [Loss]
2022-11-29 08:35:41 NUM_SUB: 142; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:35:41 NUM_SUB: 142; Personalized parameter estimation: Parameter containing:
tensor([0.0069, 0.0348, 0.0094, 1.2524, 0.3074, 0.0119, 2.6316, 0.8964, 0.4556,
        0.0129, 0.2117, 0.1519, 0.4608, 0.1689, 0.0175, 1.1178, 0.6977, 0.8000,
        0.0124, 2.6945, 0.6816, 0.0220, 2.6286, 0.8742, 0.0219, 3.3702, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:35:41 NUM_SUB: 142;----------------------------
2022-11-29 08:35:41 Epoch [30000/30000] Loss:0.001382 Loss_1:0.001370 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000250 Time:39.897744s (9.58min in total, 0.00min remains)
2022-11-29 08:35:41 NUM_SUB: 142------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:35:41 Testing & drawing...
2022-11-29 08:35:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:35:43 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=142/
2022-11-29 08:35:43 [Loss]
2022-11-29 08:35:43 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:35:43 General parameter estimation: Parameter containing:
tensor([0.0069, 0.0348, 0.0094, 1.2524, 0.3074, 0.0119, 2.6317, 0.8964, 0.4556,
        0.0129, 0.2117, 0.1519, 0.4607, 0.1689, 0.0175, 1.1179, 0.6977, 0.8000,
        0.0124, 2.6946, 0.6816, 0.0220, 2.6287, 0.8742, 0.0219, 3.3702, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:35:43 A: prod, degr, TonA, NonA
2022-11-29 08:35:43 [0.40856072 0.4850973  0.04175133 0.06459066]
2022-11-29 08:35:43 T: prod, degr, AonT, NonT
2022-11-29 08:35:43 [0.10262711 0.3962973  0.4510419  0.05003366]
2022-11-29 08:35:43 N: AonN, TonN, ATonN
2022-11-29 08:35:43 [0.0052633  0.9755886  0.01914808]
2022-11-29 08:35:43 using cpu
2022-11-29 08:35:43 epoch = 30000
2022-11-29 08:35:43 epoch_step = 2000
2022-11-29 08:35:43 model_name = SimpleNetworkAD
2022-11-29 08:35:43 now_string = 2022-11-28-18-17-05
2022-11-29 08:35:43 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:35:43 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:35:43 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:35:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:35:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:35:43 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:36:21 NUM_SUB: 143;----------------------------
2022-11-29 08:36:21 Epoch [02000/30000] Loss:0.013127 Loss_1:0.012290 Loss_2:0.000454 Loss_3:0.000000 Lr:0.000833 Time:38.123766s (0.64min in total, 8.90min remains)
2022-11-29 08:36:59 NUM_SUB: 143;----------------------------
2022-11-29 08:36:59 Epoch [04000/30000] Loss:0.009696 Loss_1:0.009584 Loss_2:0.000109 Loss_3:0.000000 Lr:0.000714 Time:38.148939s (1.27min in total, 8.26min remains)
2022-11-29 08:37:38 NUM_SUB: 143;----------------------------
2022-11-29 08:37:38 Epoch [06000/30000] Loss:0.005977 Loss_1:0.005862 Loss_2:0.000102 Loss_3:0.000000 Lr:0.000625 Time:38.403427s (1.91min in total, 7.65min remains)
2022-11-29 08:38:16 NUM_SUB: 143;----------------------------
2022-11-29 08:38:16 Epoch [08000/30000] Loss:0.002930 Loss_1:0.002823 Loss_2:0.000104 Loss_3:0.000000 Lr:0.000556 Time:38.236138s (2.55min in total, 7.01min remains)
2022-11-29 08:38:54 NUM_SUB: 143;----------------------------
2022-11-29 08:38:54 Epoch [10000/30000] Loss:0.001942 Loss_1:0.001848 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000500 Time:38.128688s (3.18min in total, 6.37min remains)
2022-11-29 08:39:32 NUM_SUB: 143;----------------------------
2022-11-29 08:39:32 Epoch [12000/30000] Loss:0.000881 Loss_1:0.000853 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000455 Time:38.261360s (3.82min in total, 5.73min remains)
2022-11-29 08:40:11 NUM_SUB: 143;----------------------------
2022-11-29 08:40:11 Epoch [14000/30000] Loss:0.000372 Loss_1:0.000357 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.237277s (4.46min in total, 5.10min remains)
2022-11-29 08:40:49 NUM_SUB: 143;----------------------------
2022-11-29 08:40:49 Epoch [16000/30000] Loss:0.000308 Loss_1:0.000301 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:38.184561s (5.10min in total, 4.46min remains)
2022-11-29 08:41:27 NUM_SUB: 143;----------------------------
2022-11-29 08:41:27 Epoch [18000/30000] Loss:0.000245 Loss_1:0.000241 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:38.167585s (5.73min in total, 3.82min remains)
2022-11-29 08:42:05 NUM_SUB: 143;----------------------------
2022-11-29 08:42:05 Epoch [20000/30000] Loss:0.000194 Loss_1:0.000192 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.153749s (6.37min in total, 3.18min remains)
2022-11-29 08:42:43 NUM_SUB: 143;----------------------------
2022-11-29 08:42:43 Epoch [22000/30000] Loss:0.000193 Loss_1:0.000191 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.183237s (7.00min in total, 2.55min remains)
2022-11-29 08:43:22 NUM_SUB: 143;----------------------------
2022-11-29 08:43:22 Epoch [24000/30000] Loss:0.000191 Loss_1:0.000189 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.173979s (7.64min in total, 1.91min remains)
2022-11-29 08:45:41 NUM_SUB: 143;----------------------------
2022-11-29 08:45:41 Epoch [26000/30000] Loss:0.000190 Loss_1:0.000189 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:139.693302s (9.97min in total, 1.53min remains)
2022-11-29 08:46:20 NUM_SUB: 143;----------------------------
2022-11-29 08:46:20 Epoch [28000/30000] Loss:0.000190 Loss_1:0.000189 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.217295s (10.61min in total, 0.76min remains)
2022-11-29 08:46:58 Testing & drawing...
2022-11-29 08:46:58 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:46:59 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=143/
2022-11-29 08:46:59 [Loss]
2022-11-29 08:46:59 NUM_SUB: 143; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:46:59 NUM_SUB: 143; Personalized parameter estimation: Parameter containing:
tensor([0.0168, 0.0561, 0.0119, 0.4534, 0.3074, 0.0126, 1.6229, 0.8964, 0.4556,
        0.0147, 0.1510, 0.1204, 0.5208, 0.1689, 0.0176, 0.8690, 0.6977, 0.8000,
        0.0121, 3.4469, 0.6816, 0.0224, 3.0239, 0.8742, 0.0215, 3.8738, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:46:59 NUM_SUB: 143;----------------------------
2022-11-29 08:46:59 Epoch [30000/30000] Loss:0.000189 Loss_1:0.000188 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.804108s (11.27min in total, 0.00min remains)
2022-11-29 08:46:59 NUM_SUB: 143------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:46:59 Testing & drawing...
2022-11-29 08:46:59 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:47:01 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=143/
2022-11-29 08:47:01 [Loss]
2022-11-29 08:47:01 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:47:01 General parameter estimation: Parameter containing:
tensor([0.0168, 0.0561, 0.0119, 0.4534, 0.3074, 0.0126, 1.6230, 0.8964, 0.4556,
        0.0147, 0.1510, 0.1204, 0.5208, 0.1689, 0.0176, 0.8690, 0.6977, 0.8000,
        0.0121, 3.4470, 0.6816, 0.0224, 3.0240, 0.8742, 0.0215, 3.8739, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:47:01 A: prod, degr, TonA, NonA
2022-11-29 08:47:01 [0.38376963 0.48946276 0.10892647 0.01784116]
2022-11-29 08:47:01 T: prod, degr, AonT, NonT
2022-11-29 08:47:01 [0.1287402  0.49846426 0.34452575 0.02826971]
2022-11-29 08:47:01 N: AonN, TonN, ATonN
2022-11-29 08:47:01 [0.00806169 0.9692307  0.0227076 ]
2022-11-29 08:47:01 using cpu
2022-11-29 08:47:01 epoch = 30000
2022-11-29 08:47:01 epoch_step = 2000
2022-11-29 08:47:01 model_name = SimpleNetworkAD
2022-11-29 08:47:01 now_string = 2022-11-28-18-17-05
2022-11-29 08:47:01 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:47:01 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:47:01 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:47:01 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:47:01 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:47:01 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:47:39 NUM_SUB: 144;----------------------------
2022-11-29 08:47:39 Epoch [02000/30000] Loss:0.058791 Loss_1:0.057297 Loss_2:0.001111 Loss_3:0.000000 Lr:0.000833 Time:38.232225s (0.64min in total, 8.92min remains)
2022-11-29 08:48:18 NUM_SUB: 144;----------------------------
2022-11-29 08:48:18 Epoch [04000/30000] Loss:0.040990 Loss_1:0.040631 Loss_2:0.000260 Loss_3:0.000000 Lr:0.000714 Time:38.193810s (1.27min in total, 8.28min remains)
2022-11-29 08:48:56 NUM_SUB: 144;----------------------------
2022-11-29 08:48:56 Epoch [06000/30000] Loss:0.017133 Loss_1:0.016881 Loss_2:0.000187 Loss_3:0.000000 Lr:0.000625 Time:38.176424s (1.91min in total, 7.64min remains)
2022-11-29 08:49:34 NUM_SUB: 144;----------------------------
2022-11-29 08:49:34 Epoch [08000/30000] Loss:0.003381 Loss_1:0.003252 Loss_2:0.000123 Loss_3:0.000000 Lr:0.000556 Time:38.240512s (2.55min in total, 7.01min remains)
2022-11-29 08:50:12 NUM_SUB: 144;----------------------------
2022-11-29 08:50:12 Epoch [10000/30000] Loss:0.001906 Loss_1:0.001790 Loss_2:0.000116 Loss_3:0.000000 Lr:0.000500 Time:38.158772s (3.18min in total, 6.37min remains)
2022-11-29 08:50:50 NUM_SUB: 144;----------------------------
2022-11-29 08:50:50 Epoch [12000/30000] Loss:0.000941 Loss_1:0.000889 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:38.154202s (3.82min in total, 5.73min remains)
2022-11-29 08:51:29 NUM_SUB: 144;----------------------------
2022-11-29 08:51:29 Epoch [14000/30000] Loss:0.000636 Loss_1:0.000606 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:38.254022s (4.46min in total, 5.09min remains)
2022-11-29 08:52:07 NUM_SUB: 144;----------------------------
2022-11-29 08:52:07 Epoch [16000/30000] Loss:0.000545 Loss_1:0.000527 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:38.281109s (5.09min in total, 4.46min remains)
2022-11-29 08:52:45 NUM_SUB: 144;----------------------------
2022-11-29 08:52:45 Epoch [18000/30000] Loss:0.000476 Loss_1:0.000464 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.206539s (5.73min in total, 3.82min remains)
2022-11-29 08:53:23 NUM_SUB: 144;----------------------------
2022-11-29 08:53:23 Epoch [20000/30000] Loss:0.000237 Loss_1:0.000227 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.259481s (6.37min in total, 3.18min remains)
2022-11-29 08:54:01 NUM_SUB: 144;----------------------------
2022-11-29 08:54:01 Epoch [22000/30000] Loss:0.000111 Loss_1:0.000103 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000313 Time:38.187393s (7.01min in total, 2.55min remains)
2022-11-29 08:54:40 NUM_SUB: 144;----------------------------
2022-11-29 08:54:40 Epoch [24000/30000] Loss:0.000097 Loss_1:0.000089 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000294 Time:38.148574s (7.64min in total, 1.91min remains)
2022-11-29 08:55:18 NUM_SUB: 144;----------------------------
2022-11-29 08:55:18 Epoch [26000/30000] Loss:0.000091 Loss_1:0.000084 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:38.174450s (8.28min in total, 1.27min remains)
2022-11-29 08:55:56 NUM_SUB: 144;----------------------------
2022-11-29 08:55:56 Epoch [28000/30000] Loss:0.000090 Loss_1:0.000083 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000263 Time:38.099772s (8.91min in total, 0.64min remains)
2022-11-29 08:56:34 Testing & drawing...
2022-11-29 08:56:34 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:56:36 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=144/
2022-11-29 08:56:36 [Loss]
2022-11-29 08:56:36 NUM_SUB: 144; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:56:36 NUM_SUB: 144; Personalized parameter estimation: Parameter containing:
tensor([0.0158, 0.0267, 0.0281, 0.6647, 0.3074, 0.0177, 3.6377, 0.8964, 0.4556,
        0.0145, 0.1126, 0.1157, 0.7001, 0.1689, 0.0176, 1.1941, 0.6977, 0.8000,
        0.0104, 5.0980, 0.6816, 0.0225, 3.7479, 0.8742, 0.0179, 4.9988, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:56:36 NUM_SUB: 144;----------------------------
2022-11-29 08:56:36 Epoch [30000/30000] Loss:0.000089 Loss_1:0.000083 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000250 Time:39.823819s (9.58min in total, 0.00min remains)
2022-11-29 08:56:36 NUM_SUB: 144------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 08:56:36 Testing & drawing...
2022-11-29 08:56:36 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 08:56:37 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=144/
2022-11-29 08:56:37 [Loss]
2022-11-29 08:56:37 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 08:56:37 General parameter estimation: Parameter containing:
tensor([0.0158, 0.0267, 0.0281, 0.6647, 0.3074, 0.0177, 3.6378, 0.8964, 0.4556,
        0.0145, 0.1125, 0.1158, 0.7000, 0.1689, 0.0176, 1.1941, 0.6977, 0.8000,
        0.0104, 5.0982, 0.6816, 0.0225, 3.7481, 0.8742, 0.0179, 4.9990, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 08:56:37 A: prod, degr, TonA, NonA
2022-11-29 08:56:37 [0.32960942 0.47570205 0.18315262 0.01153592]
2022-11-29 08:56:37 T: prod, degr, AonT, NonT
2022-11-29 08:56:37 [0.09870094 0.64760536 0.22618173 0.02751197]
2022-11-29 08:56:37 N: AonN, TonN, ATonN
2022-11-29 08:56:37 [0.01451972 0.95248103 0.03299922]
2022-11-29 08:56:37 using cpu
2022-11-29 08:56:37 epoch = 30000
2022-11-29 08:56:37 epoch_step = 2000
2022-11-29 08:56:37 model_name = SimpleNetworkAD
2022-11-29 08:56:37 now_string = 2022-11-28-18-17-05
2022-11-29 08:56:37 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 08:56:37 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 08:56:37 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 08:56:37 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 08:56:37 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 08:56:37 --------------------------------------------------training start--------------------------------------------------
2022-11-29 08:57:16 NUM_SUB: 145;----------------------------
2022-11-29 08:57:16 Epoch [02000/30000] Loss:0.038524 Loss_1:0.037786 Loss_2:0.000317 Loss_3:0.000000 Lr:0.000833 Time:38.180895s (0.64min in total, 8.91min remains)
2022-11-29 08:57:54 NUM_SUB: 145;----------------------------
2022-11-29 08:57:54 Epoch [04000/30000] Loss:0.030261 Loss_1:0.030134 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000714 Time:38.112238s (1.27min in total, 8.27min remains)
2022-11-29 08:58:32 NUM_SUB: 145;----------------------------
2022-11-29 08:58:32 Epoch [06000/30000] Loss:0.017786 Loss_1:0.017651 Loss_2:0.000040 Loss_3:0.000000 Lr:0.000625 Time:38.258696s (1.91min in total, 7.64min remains)
2022-11-29 08:59:10 NUM_SUB: 145;----------------------------
2022-11-29 08:59:10 Epoch [08000/30000] Loss:0.005749 Loss_1:0.005648 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000556 Time:38.227390s (2.55min in total, 7.00min remains)
2022-11-29 08:59:49 NUM_SUB: 145;----------------------------
2022-11-29 08:59:49 Epoch [10000/30000] Loss:0.001369 Loss_1:0.001294 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000500 Time:38.279405s (3.18min in total, 6.37min remains)
2022-11-29 09:00:27 NUM_SUB: 145;----------------------------
2022-11-29 09:00:27 Epoch [12000/30000] Loss:0.000895 Loss_1:0.000866 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000455 Time:38.252207s (3.82min in total, 5.73min remains)
2022-11-29 09:01:05 NUM_SUB: 145;----------------------------
2022-11-29 09:01:05 Epoch [14000/30000] Loss:0.000835 Loss_1:0.000826 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000417 Time:38.137303s (4.46min in total, 5.09min remains)
2022-11-29 09:01:43 NUM_SUB: 145;----------------------------
2022-11-29 09:01:43 Epoch [16000/30000] Loss:0.000796 Loss_1:0.000790 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000385 Time:38.170680s (5.09min in total, 4.46min remains)
2022-11-29 09:02:21 NUM_SUB: 145;----------------------------
2022-11-29 09:02:21 Epoch [18000/30000] Loss:0.000702 Loss_1:0.000700 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000357 Time:38.240244s (5.73min in total, 3.82min remains)
2022-11-29 09:02:59 NUM_SUB: 145;----------------------------
2022-11-29 09:02:59 Epoch [20000/30000] Loss:0.000505 Loss_1:0.000503 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000333 Time:38.119821s (6.37min in total, 3.18min remains)
2022-11-29 09:03:38 NUM_SUB: 145;----------------------------
2022-11-29 09:03:38 Epoch [22000/30000] Loss:0.000489 Loss_1:0.000488 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.278130s (7.00min in total, 2.55min remains)
2022-11-29 09:04:16 NUM_SUB: 145;----------------------------
2022-11-29 09:04:16 Epoch [24000/30000] Loss:0.000488 Loss_1:0.000487 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.223670s (7.64min in total, 1.91min remains)
2022-11-29 09:04:54 NUM_SUB: 145;----------------------------
2022-11-29 09:04:54 Epoch [26000/30000] Loss:0.000487 Loss_1:0.000486 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.242553s (8.28min in total, 1.27min remains)
2022-11-29 09:05:32 NUM_SUB: 145;----------------------------
2022-11-29 09:05:32 Epoch [28000/30000] Loss:0.000487 Loss_1:0.000486 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.242991s (8.92min in total, 0.64min remains)
2022-11-29 09:06:11 Testing & drawing...
2022-11-29 09:06:11 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:06:12 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=145/
2022-11-29 09:06:12 [Loss]
2022-11-29 09:06:12 NUM_SUB: 145; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:06:12 NUM_SUB: 145; Personalized parameter estimation: Parameter containing:
tensor([2.0322e-01, 1.0410e+00, 9.6769e-03, 2.7404e-36, 3.0742e-01, 1.3145e-02,
        2.0056e+00, 8.9644e-01, 4.5563e-01, 1.0047e-02, 5.3750e-02, 8.8441e-03,
        5.2007e-01, 1.6886e-01, 1.7430e-02, 2.0060e-01, 6.9767e-01, 8.0001e-01,
        1.2597e-02, 2.1367e+00, 6.8161e-01, 2.2427e-02, 2.5671e+00, 8.7416e-01,
        2.2004e-02, 3.1914e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 09:06:12 NUM_SUB: 145;----------------------------
2022-11-29 09:06:12 Epoch [30000/30000] Loss:0.000487 Loss_1:0.000486 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.860804s (9.58min in total, 0.00min remains)
2022-11-29 09:06:12 NUM_SUB: 145------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 09:06:12 Testing & drawing...
2022-11-29 09:06:12 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:06:14 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=145/
2022-11-29 09:06:14 [Loss]
2022-11-29 09:06:14 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:06:14 General parameter estimation: Parameter containing:
tensor([2.0322e-01, 1.0410e+00, 9.6769e-03, 2.6685e-36, 3.0742e-01, 1.3145e-02,
        2.0057e+00, 8.9644e-01, 4.5563e-01, 1.0047e-02, 5.3744e-02, 8.8441e-03,
        5.2011e-01, 1.6886e-01, 1.7430e-02, 2.0059e-01, 6.9767e-01, 8.0001e-01,
        1.2597e-02, 2.1367e+00, 6.8161e-01, 2.2427e-02, 2.5671e+00, 8.7416e-01,
        2.2004e-02, 3.1914e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 09:06:14 A: prod, degr, TonA, NonA
2022-11-29 09:06:14 [0.47479874 0.4999947  0.02260855 0.00259803]
2022-11-29 09:06:14 T: prod, degr, AonT, NonT
2022-11-29 09:06:14 [0.2441309  0.2684711  0.11333988 0.37405813]
2022-11-29 09:06:14 N: AonN, TonN, ATonN
2022-11-29 09:06:14 [0.00541836 0.96064305 0.03393852]
2022-11-29 09:06:14 using cpu
2022-11-29 09:06:14 epoch = 30000
2022-11-29 09:06:14 epoch_step = 2000
2022-11-29 09:06:14 model_name = SimpleNetworkAD
2022-11-29 09:06:14 now_string = 2022-11-28-18-17-05
2022-11-29 09:06:14 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 09:06:14 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 09:06:14 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 09:06:14 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 09:06:14 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 09:06:14 --------------------------------------------------training start--------------------------------------------------
2022-11-29 09:06:53 NUM_SUB: 146;----------------------------
2022-11-29 09:06:53 Epoch [02000/30000] Loss:0.014157 Loss_1:0.013357 Loss_2:0.000385 Loss_3:0.000000 Lr:0.000833 Time:38.809989s (0.65min in total, 9.06min remains)
2022-11-29 09:07:31 NUM_SUB: 146;----------------------------
2022-11-29 09:07:31 Epoch [04000/30000] Loss:0.011903 Loss_1:0.011820 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000714 Time:38.349383s (1.29min in total, 8.36min remains)
2022-11-29 09:20:34 NUM_SUB: 146;----------------------------
2022-11-29 09:20:34 Epoch [06000/30000] Loss:0.009415 Loss_1:0.009326 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000625 Time:782.935105s (14.33min in total, 57.34min remains)
2022-11-29 09:21:16 NUM_SUB: 146;----------------------------
2022-11-29 09:21:16 Epoch [08000/30000] Loss:0.006146 Loss_1:0.006067 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000556 Time:42.242629s (15.04min in total, 41.36min remains)
2022-11-29 09:29:02 NUM_SUB: 146;----------------------------
2022-11-29 09:29:02 Epoch [10000/30000] Loss:0.003678 Loss_1:0.003605 Loss_2:0.000070 Loss_3:0.000000 Lr:0.000500 Time:465.711613s (22.80min in total, 45.60min remains)
2022-11-29 09:30:58 NUM_SUB: 146;----------------------------
2022-11-29 09:30:58 Epoch [12000/30000] Loss:0.003125 Loss_1:0.003086 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:116.317636s (24.74min in total, 37.11min remains)
2022-11-29 09:31:37 NUM_SUB: 146;----------------------------
2022-11-29 09:31:37 Epoch [14000/30000] Loss:0.002828 Loss_1:0.002811 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000417 Time:38.763093s (25.39min in total, 29.01min remains)
2022-11-29 09:32:16 NUM_SUB: 146;----------------------------
2022-11-29 09:32:16 Epoch [16000/30000] Loss:0.002732 Loss_1:0.002721 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000385 Time:38.635327s (26.03min in total, 22.78min remains)
2022-11-29 09:32:54 NUM_SUB: 146;----------------------------
2022-11-29 09:32:54 Epoch [18000/30000] Loss:0.002496 Loss_1:0.002487 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.489489s (26.67min in total, 17.78min remains)
2022-11-29 09:33:33 NUM_SUB: 146;----------------------------
2022-11-29 09:33:33 Epoch [20000/30000] Loss:0.001900 Loss_1:0.001894 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.396562s (27.31min in total, 13.66min remains)
2022-11-29 09:34:11 NUM_SUB: 146;----------------------------
2022-11-29 09:34:11 Epoch [22000/30000] Loss:0.001831 Loss_1:0.001825 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.406454s (27.95min in total, 10.16min remains)
2022-11-29 09:34:50 NUM_SUB: 146;----------------------------
2022-11-29 09:34:50 Epoch [24000/30000] Loss:0.001804 Loss_1:0.001799 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.391016s (28.59min in total, 7.15min remains)
2022-11-29 09:35:28 NUM_SUB: 146;----------------------------
2022-11-29 09:35:28 Epoch [26000/30000] Loss:0.001766 Loss_1:0.001761 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.465735s (29.23min in total, 4.50min remains)
2022-11-29 09:36:06 NUM_SUB: 146;----------------------------
2022-11-29 09:36:06 Epoch [28000/30000] Loss:0.001760 Loss_1:0.001756 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.412595s (29.87min in total, 2.13min remains)
2022-11-29 09:36:45 Testing & drawing...
2022-11-29 09:36:45 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:36:46 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=146/
2022-11-29 09:36:46 [Loss]
2022-11-29 09:36:46 NUM_SUB: 146; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:36:46 NUM_SUB: 146; Personalized parameter estimation: Parameter containing:
tensor([0.2429, 0.7994, 0.0094, 0.0304, 0.3074, 0.1866, 0.7245, 0.8964, 0.4556,
        0.0137, 0.0339, 0.0119, 0.8367, 0.1689, 0.0177, 0.6727, 0.6977, 0.8000,
        0.0123, 3.2700, 0.6816, 0.0221, 3.5678, 0.8742, 0.0213, 4.2242, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:36:46 NUM_SUB: 146;----------------------------
2022-11-29 09:36:46 Epoch [30000/30000] Loss:0.001760 Loss_1:0.001755 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:40.103640s (30.54min in total, 0.00min remains)
2022-11-29 09:36:46 NUM_SUB: 146------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 09:36:46 Testing & drawing...
2022-11-29 09:36:46 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:36:48 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=146/
2022-11-29 09:36:48 [Loss]
2022-11-29 09:36:48 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:36:48 General parameter estimation: Parameter containing:
tensor([0.2429, 0.7994, 0.0094, 0.0304, 0.3074, 0.1866, 0.7245, 0.8964, 0.4556,
        0.0137, 0.0339, 0.0119, 0.8367, 0.1689, 0.0177, 0.6727, 0.6977, 0.8000,
        0.0123, 3.2700, 0.6816, 0.0221, 3.5679, 0.8742, 0.0213, 4.2243, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:36:48 A: prod, degr, TonA, NonA
2022-11-29 09:36:48 [0.4571776  0.49975574 0.01754942 0.02551721]
2022-11-29 09:36:48 T: prod, degr, AonT, NonT
2022-11-29 09:36:48 [0.46150517 0.37896255 0.1102231  0.04930915]
2022-11-29 09:36:48 N: AonN, TonN, ATonN
2022-11-29 09:36:48 [0.00616079 0.97225904 0.02158014]
2022-11-29 09:36:48 using cpu
2022-11-29 09:36:48 epoch = 30000
2022-11-29 09:36:48 epoch_step = 2000
2022-11-29 09:36:48 model_name = SimpleNetworkAD
2022-11-29 09:36:48 now_string = 2022-11-28-18-17-05
2022-11-29 09:36:48 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 09:36:48 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 09:36:48 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 09:36:48 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 09:36:48 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 09:36:48 --------------------------------------------------training start--------------------------------------------------
2022-11-29 09:37:27 NUM_SUB: 147;----------------------------
2022-11-29 09:37:27 Epoch [02000/30000] Loss:0.025434 Loss_1:0.024471 Loss_2:0.000536 Loss_3:0.000000 Lr:0.000833 Time:38.428467s (0.64min in total, 8.97min remains)
2022-11-29 09:38:05 NUM_SUB: 147;----------------------------
2022-11-29 09:38:05 Epoch [04000/30000] Loss:0.020529 Loss_1:0.020323 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000714 Time:38.449157s (1.28min in total, 8.33min remains)
2022-11-29 09:38:44 NUM_SUB: 147;----------------------------
2022-11-29 09:38:44 Epoch [06000/30000] Loss:0.013509 Loss_1:0.013273 Loss_2:0.000166 Loss_3:0.000000 Lr:0.000625 Time:38.479436s (1.92min in total, 7.69min remains)
2022-11-29 09:39:22 NUM_SUB: 147;----------------------------
2022-11-29 09:39:22 Epoch [08000/30000] Loss:0.005383 Loss_1:0.005217 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000556 Time:38.463383s (2.56min in total, 7.05min remains)
2022-11-29 09:40:01 NUM_SUB: 147;----------------------------
2022-11-29 09:40:01 Epoch [10000/30000] Loss:0.002209 Loss_1:0.002129 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000500 Time:38.421560s (3.20min in total, 6.41min remains)
2022-11-29 09:40:39 NUM_SUB: 147;----------------------------
2022-11-29 09:40:39 Epoch [12000/30000] Loss:0.001626 Loss_1:0.001584 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000455 Time:38.543778s (3.85min in total, 5.77min remains)
2022-11-29 09:41:18 NUM_SUB: 147;----------------------------
2022-11-29 09:41:18 Epoch [14000/30000] Loss:0.000635 Loss_1:0.000622 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000417 Time:38.484190s (4.49min in total, 5.13min remains)
2022-11-29 09:41:56 NUM_SUB: 147;----------------------------
2022-11-29 09:41:56 Epoch [16000/30000] Loss:0.000280 Loss_1:0.000271 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000385 Time:38.477691s (5.13min in total, 4.49min remains)
2022-11-29 09:42:35 NUM_SUB: 147;----------------------------
2022-11-29 09:42:35 Epoch [18000/30000] Loss:0.000175 Loss_1:0.000168 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.509895s (5.77min in total, 3.85min remains)
2022-11-29 09:43:13 NUM_SUB: 147;----------------------------
2022-11-29 09:43:13 Epoch [20000/30000] Loss:0.000202 Loss_1:0.000196 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.641606s (6.42min in total, 3.21min remains)
2022-11-29 09:43:52 NUM_SUB: 147;----------------------------
2022-11-29 09:43:52 Epoch [22000/30000] Loss:0.000170 Loss_1:0.000164 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.650828s (7.06min in total, 2.57min remains)
2022-11-29 09:44:30 NUM_SUB: 147;----------------------------
2022-11-29 09:44:30 Epoch [24000/30000] Loss:0.000169 Loss_1:0.000163 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.366541s (7.70min in total, 1.92min remains)
2022-11-29 09:45:09 NUM_SUB: 147;----------------------------
2022-11-29 09:45:09 Epoch [26000/30000] Loss:0.000168 Loss_1:0.000162 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:38.463556s (8.34min in total, 1.28min remains)
2022-11-29 09:45:47 NUM_SUB: 147;----------------------------
2022-11-29 09:45:47 Epoch [28000/30000] Loss:0.000168 Loss_1:0.000162 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:38.530694s (8.98min in total, 0.64min remains)
2022-11-29 09:46:26 Testing & drawing...
2022-11-29 09:46:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:46:27 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=147/
2022-11-29 09:46:27 [Loss]
2022-11-29 09:46:27 NUM_SUB: 147; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:46:27 NUM_SUB: 147; Personalized parameter estimation: Parameter containing:
tensor([0.0158, 0.0438, 0.0101, 1.8036, 0.3074, 0.0193, 1.4619, 0.8964, 0.4556,
        0.0134, 0.0714, 0.0227, 0.2919, 0.1689, 0.0175, 1.7158, 0.6977, 0.8000,
        0.0123, 3.0974, 0.6816, 0.0229, 1.4517, 0.8742, 0.0214, 2.9922, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:46:27 NUM_SUB: 147;----------------------------
2022-11-29 09:46:27 Epoch [30000/30000] Loss:0.000168 Loss_1:0.000162 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:40.179296s (9.65min in total, 0.00min remains)
2022-11-29 09:46:27 NUM_SUB: 147------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 09:46:27 Testing & drawing...
2022-11-29 09:46:27 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:46:29 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=147/
2022-11-29 09:46:29 [Loss]
2022-11-29 09:46:29 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:46:29 General parameter estimation: Parameter containing:
tensor([0.0158, 0.0438, 0.0101, 1.8036, 0.3074, 0.0193, 1.4619, 0.8964, 0.4556,
        0.0134, 0.0714, 0.0227, 0.2918, 0.1689, 0.0175, 1.7159, 0.6977, 0.8000,
        0.0123, 3.0976, 0.6816, 0.0229, 1.4515, 0.8742, 0.0214, 2.9924, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:46:29 A: prod, degr, TonA, NonA
2022-11-29 09:46:29 [0.38121656 0.4909405  0.01414068 0.11370222]
2022-11-29 09:46:29 T: prod, degr, AonT, NonT
2022-11-29 09:46:29 [0.20330252 0.50380516 0.24154419 0.05134812]
2022-11-29 09:46:29 N: AonN, TonN, ATonN
2022-11-29 09:46:29 [0.01299281 0.9416012  0.045406  ]
2022-11-29 09:46:29 using cpu
2022-11-29 09:46:29 epoch = 30000
2022-11-29 09:46:29 epoch_step = 2000
2022-11-29 09:46:29 model_name = SimpleNetworkAD
2022-11-29 09:46:29 now_string = 2022-11-28-18-17-05
2022-11-29 09:46:29 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 09:46:29 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 09:46:29 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 09:46:29 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 09:46:29 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 09:46:29 --------------------------------------------------training start--------------------------------------------------
2022-11-29 09:47:08 NUM_SUB: 148;----------------------------
2022-11-29 09:47:08 Epoch [02000/30000] Loss:0.063782 Loss_1:0.062962 Loss_2:0.000389 Loss_3:0.000000 Lr:0.000833 Time:38.535371s (0.64min in total, 8.99min remains)
2022-11-29 09:47:46 NUM_SUB: 148;----------------------------
2022-11-29 09:47:46 Epoch [04000/30000] Loss:0.050538 Loss_1:0.050231 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000714 Time:38.457670s (1.28min in total, 8.34min remains)
2022-11-29 09:48:25 NUM_SUB: 148;----------------------------
2022-11-29 09:48:25 Epoch [06000/30000] Loss:0.026652 Loss_1:0.026432 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000625 Time:38.532521s (1.93min in total, 7.70min remains)
2022-11-29 09:49:03 NUM_SUB: 148;----------------------------
2022-11-29 09:49:03 Epoch [08000/30000] Loss:0.004388 Loss_1:0.004238 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000556 Time:38.463170s (2.57min in total, 7.06min remains)
2022-11-29 09:49:42 NUM_SUB: 148;----------------------------
2022-11-29 09:49:42 Epoch [10000/30000] Loss:0.001241 Loss_1:0.001173 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000500 Time:38.516148s (3.21min in total, 6.42min remains)
2022-11-29 09:50:20 NUM_SUB: 148;----------------------------
2022-11-29 09:50:20 Epoch [12000/30000] Loss:0.000901 Loss_1:0.000862 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:38.457041s (3.85min in total, 5.77min remains)
2022-11-29 09:50:59 NUM_SUB: 148;----------------------------
2022-11-29 09:50:59 Epoch [14000/30000] Loss:0.000665 Loss_1:0.000650 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000417 Time:38.425454s (4.49min in total, 5.13min remains)
2022-11-29 09:51:38 NUM_SUB: 148;----------------------------
2022-11-29 09:51:38 Epoch [16000/30000] Loss:0.000630 Loss_1:0.000622 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000385 Time:38.983899s (5.14min in total, 4.50min remains)
2022-11-29 09:52:16 NUM_SUB: 148;----------------------------
2022-11-29 09:52:16 Epoch [18000/30000] Loss:0.000623 Loss_1:0.000618 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000357 Time:38.815230s (5.79min in total, 3.86min remains)
2022-11-29 09:52:55 NUM_SUB: 148;----------------------------
2022-11-29 09:52:55 Epoch [20000/30000] Loss:0.000620 Loss_1:0.000616 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000333 Time:38.685256s (6.43min in total, 3.22min remains)
2022-11-29 09:53:34 NUM_SUB: 148;----------------------------
2022-11-29 09:53:34 Epoch [22000/30000] Loss:0.000618 Loss_1:0.000615 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.650636s (7.08min in total, 2.57min remains)
2022-11-29 09:54:12 NUM_SUB: 148;----------------------------
2022-11-29 09:54:12 Epoch [24000/30000] Loss:0.000620 Loss_1:0.000615 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.671699s (7.72min in total, 1.93min remains)
2022-11-29 09:54:51 NUM_SUB: 148;----------------------------
2022-11-29 09:54:51 Epoch [26000/30000] Loss:0.000616 Loss_1:0.000614 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.829733s (8.37min in total, 1.29min remains)
2022-11-29 09:55:30 NUM_SUB: 148;----------------------------
2022-11-29 09:55:30 Epoch [28000/30000] Loss:0.000618 Loss_1:0.000616 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.824053s (9.01min in total, 0.64min remains)
2022-11-29 09:56:09 Testing & drawing...
2022-11-29 09:56:09 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:56:10 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=148/
2022-11-29 09:56:10 [Loss]
2022-11-29 09:56:10 NUM_SUB: 148; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:56:10 NUM_SUB: 148; Personalized parameter estimation: Parameter containing:
tensor([0.1528, 0.8405, 0.0097, 0.2462, 0.3074, 0.2369, 0.6898, 0.8964, 0.4556,
        0.0138, 0.0367, 0.0129, 0.8078, 0.1689, 0.0177, 2.3194, 0.6977, 0.8000,
        0.0123, 3.4381, 0.6816, 0.0222, 3.5221, 0.8742, 0.0206, 4.2142, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:56:10 NUM_SUB: 148;----------------------------
2022-11-29 09:56:10 Epoch [30000/30000] Loss:0.000615 Loss_1:0.000614 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.375916s (9.69min in total, 0.00min remains)
2022-11-29 09:56:10 NUM_SUB: 148------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 09:56:10 Testing & drawing...
2022-11-29 09:56:10 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 09:56:12 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=148/
2022-11-29 09:56:12 [Loss]
2022-11-29 09:56:12 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 09:56:12 General parameter estimation: Parameter containing:
tensor([0.1528, 0.8405, 0.0097, 0.2462, 0.3074, 0.2369, 0.6898, 0.8964, 0.4556,
        0.0138, 0.0367, 0.0129, 0.8078, 0.1689, 0.0177, 2.3194, 0.6977, 0.8000,
        0.0123, 3.4382, 0.6816, 0.0222, 3.5222, 0.8742, 0.0206, 4.2143, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 09:56:12 A: prod, degr, TonA, NonA
2022-11-29 09:56:12 [0.26371992 0.4998471  0.01329917 0.22313382]
2022-11-29 09:56:12 T: prod, degr, AonT, NonT
2022-11-29 09:56:12 [0.436535   0.39897254 0.11076633 0.05372615]
2022-11-29 09:56:12 N: AonN, TonN, ATonN
2022-11-29 09:56:12 [0.00599352 0.97357935 0.02042719]
2022-11-29 09:56:12 using cpu
2022-11-29 09:56:12 epoch = 30000
2022-11-29 09:56:12 epoch_step = 2000
2022-11-29 09:56:12 model_name = SimpleNetworkAD
2022-11-29 09:56:12 now_string = 2022-11-28-18-17-05
2022-11-29 09:56:12 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 09:56:12 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 09:56:12 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 09:56:12 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 09:56:12 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 09:56:12 --------------------------------------------------training start--------------------------------------------------
2022-11-29 09:56:51 NUM_SUB: 149;----------------------------
2022-11-29 09:56:51 Epoch [02000/30000] Loss:0.061469 Loss_1:0.060442 Loss_2:0.000618 Loss_3:0.000000 Lr:0.000833 Time:38.702117s (0.65min in total, 9.03min remains)
2022-11-29 09:57:30 NUM_SUB: 149;----------------------------
2022-11-29 09:57:30 Epoch [04000/30000] Loss:0.047203 Loss_1:0.046720 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000714 Time:38.886387s (1.29min in total, 8.41min remains)
2022-11-29 09:58:09 NUM_SUB: 149;----------------------------
2022-11-29 09:58:09 Epoch [06000/30000] Loss:0.022775 Loss_1:0.022440 Loss_2:0.000180 Loss_3:0.000000 Lr:0.000625 Time:38.752080s (1.94min in total, 7.76min remains)
2022-11-29 09:58:48 NUM_SUB: 149;----------------------------
2022-11-29 09:58:48 Epoch [08000/30000] Loss:0.003428 Loss_1:0.003309 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000556 Time:39.018469s (2.59min in total, 7.12min remains)
2022-11-29 09:59:27 NUM_SUB: 149;----------------------------
2022-11-29 09:59:27 Epoch [10000/30000] Loss:0.001077 Loss_1:0.000993 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000500 Time:39.274105s (3.24min in total, 6.49min remains)
2022-11-29 10:00:06 NUM_SUB: 149;----------------------------
2022-11-29 10:00:06 Epoch [12000/30000] Loss:0.000361 Loss_1:0.000326 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:38.965474s (3.89min in total, 5.84min remains)
2022-11-29 10:00:45 NUM_SUB: 149;----------------------------
2022-11-29 10:00:45 Epoch [14000/30000] Loss:0.000071 Loss_1:0.000048 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:39.063084s (4.54min in total, 5.19min remains)
2022-11-29 10:01:24 NUM_SUB: 149;----------------------------
2022-11-29 10:01:24 Epoch [16000/30000] Loss:0.000056 Loss_1:0.000041 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:38.951650s (5.19min in total, 4.54min remains)
2022-11-29 10:02:03 NUM_SUB: 149;----------------------------
2022-11-29 10:02:03 Epoch [18000/30000] Loss:0.000046 Loss_1:0.000035 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:39.057185s (5.84min in total, 3.90min remains)
2022-11-29 10:02:42 NUM_SUB: 149;----------------------------
2022-11-29 10:02:42 Epoch [20000/30000] Loss:0.000021 Loss_1:0.000013 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:39.178109s (6.50min in total, 3.25min remains)
2022-11-29 10:03:21 NUM_SUB: 149;----------------------------
2022-11-29 10:03:21 Epoch [22000/30000] Loss:0.000022 Loss_1:0.000016 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:39.193001s (7.15min in total, 2.60min remains)
2022-11-29 10:04:01 NUM_SUB: 149;----------------------------
2022-11-29 10:04:01 Epoch [24000/30000] Loss:0.000016 Loss_1:0.000012 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:39.288433s (7.81min in total, 1.95min remains)
2022-11-29 10:04:40 NUM_SUB: 149;----------------------------
2022-11-29 10:04:40 Epoch [26000/30000] Loss:0.000014 Loss_1:0.000012 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:39.303624s (8.46min in total, 1.30min remains)
2022-11-29 10:05:19 NUM_SUB: 149;----------------------------
2022-11-29 10:05:19 Epoch [28000/30000] Loss:0.000014 Loss_1:0.000012 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.319889s (9.12min in total, 0.65min remains)
2022-11-29 10:05:59 Testing & drawing...
2022-11-29 10:05:59 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:06:00 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=149/
2022-11-29 10:06:00 [Loss]
2022-11-29 10:06:00 NUM_SUB: 149; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:06:00 NUM_SUB: 149; Personalized parameter estimation: Parameter containing:
tensor([2.1266e-03, 8.5890e-03, 9.8020e-03, 1.4574e+00, 3.0742e-01, 1.6791e-02,
        3.1109e+00, 8.9644e-01, 4.5563e-01, 1.4238e-02, 3.5809e-02, 1.3192e-02,
        7.9489e-01, 1.6886e-01, 1.7390e-02, 2.8255e+00, 6.9767e-01, 8.0001e-01,
        1.2142e-02, 3.5300e+00, 6.8161e-01, 2.2057e-02, 3.4901e+00, 8.7416e-01,
        2.0628e-02, 4.2284e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:06:00 NUM_SUB: 149;----------------------------
2022-11-29 10:06:00 Epoch [30000/30000] Loss:0.000013 Loss_1:0.000012 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:41.102808s (9.80min in total, 0.00min remains)
2022-11-29 10:06:00 NUM_SUB: 149------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 10:06:00 Testing & drawing...
2022-11-29 10:06:00 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:06:02 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=149/
2022-11-29 10:06:02 [Loss]
2022-11-29 10:06:02 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:06:02 General parameter estimation: Parameter containing:
tensor([2.1265e-03, 8.5887e-03, 9.8021e-03, 1.4573e+00, 3.0742e-01, 1.6791e-02,
        3.1110e+00, 8.9644e-01, 4.5563e-01, 1.4238e-02, 3.5826e-02, 1.3192e-02,
        7.9486e-01, 1.6886e-01, 1.7390e-02, 2.8256e+00, 6.9767e-01, 8.0001e-01,
        1.2142e-02, 3.5301e+00, 6.8161e-01, 2.2057e-02, 3.4902e+00, 8.7416e-01,
        2.0628e-02, 4.2285e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:06:02 A: prod, degr, TonA, NonA
2022-11-29 10:06:02 [0.3165327  0.41747808 0.14857292 0.11741629]
2022-11-29 10:06:02 T: prod, degr, AonT, NonT
2022-11-29 10:06:02 [0.4643803  0.38500652 0.11848517 0.03212805]
2022-11-29 10:06:02 N: AonN, TonN, ATonN
2022-11-29 10:06:02 [0.0057699  0.9735419  0.02068817]
2022-11-29 10:06:02 using cpu
2022-11-29 10:06:02 epoch = 30000
2022-11-29 10:06:02 epoch_step = 2000
2022-11-29 10:06:02 model_name = SimpleNetworkAD
2022-11-29 10:06:02 now_string = 2022-11-28-18-17-05
2022-11-29 10:06:02 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 10:06:02 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 10:06:02 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 10:06:02 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 10:06:02 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 10:06:02 --------------------------------------------------training start--------------------------------------------------
2022-11-29 10:06:42 NUM_SUB: 150;----------------------------
2022-11-29 10:06:42 Epoch [02000/30000] Loss:0.063609 Loss_1:0.062617 Loss_2:0.000591 Loss_3:0.000000 Lr:0.000833 Time:39.637817s (0.66min in total, 9.25min remains)
2022-11-29 10:07:21 NUM_SUB: 150;----------------------------
2022-11-29 10:07:21 Epoch [04000/30000] Loss:0.049847 Loss_1:0.049611 Loss_2:0.000134 Loss_3:0.000000 Lr:0.000714 Time:39.533705s (1.32min in total, 8.58min remains)
2022-11-29 10:08:01 NUM_SUB: 150;----------------------------
2022-11-29 10:08:01 Epoch [06000/30000] Loss:0.027081 Loss_1:0.026909 Loss_2:0.000117 Loss_3:0.000000 Lr:0.000625 Time:39.545356s (1.98min in total, 7.91min remains)
2022-11-29 10:08:40 NUM_SUB: 150;----------------------------
2022-11-29 10:08:40 Epoch [08000/30000] Loss:0.011490 Loss_1:0.011387 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000556 Time:39.408118s (2.64min in total, 7.25min remains)
2022-11-29 10:09:20 NUM_SUB: 150;----------------------------
2022-11-29 10:09:20 Epoch [10000/30000] Loss:0.006792 Loss_1:0.006698 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000500 Time:39.515047s (3.29min in total, 6.59min remains)
2022-11-29 10:09:59 NUM_SUB: 150;----------------------------
2022-11-29 10:09:59 Epoch [12000/30000] Loss:0.002143 Loss_1:0.002108 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:39.501963s (3.95min in total, 5.93min remains)
2022-11-29 10:10:39 NUM_SUB: 150;----------------------------
2022-11-29 10:10:39 Epoch [14000/30000] Loss:0.000497 Loss_1:0.000465 Loss_2:0.000032 Loss_3:0.000000 Lr:0.000417 Time:39.554980s (4.61min in total, 5.27min remains)
2022-11-29 10:11:18 NUM_SUB: 150;----------------------------
2022-11-29 10:11:18 Epoch [16000/30000] Loss:0.000404 Loss_1:0.000386 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:39.574983s (5.27min in total, 4.61min remains)
2022-11-29 10:11:58 NUM_SUB: 150;----------------------------
2022-11-29 10:11:58 Epoch [18000/30000] Loss:0.000378 Loss_1:0.000367 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:39.434260s (5.93min in total, 3.95min remains)
2022-11-29 10:12:37 NUM_SUB: 150;----------------------------
2022-11-29 10:12:37 Epoch [20000/30000] Loss:0.000378 Loss_1:0.000370 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:39.551366s (6.59min in total, 3.29min remains)
2022-11-29 10:13:17 NUM_SUB: 150;----------------------------
2022-11-29 10:13:17 Epoch [22000/30000] Loss:0.000373 Loss_1:0.000366 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:39.572520s (7.25min in total, 2.64min remains)
2022-11-29 10:13:57 NUM_SUB: 150;----------------------------
2022-11-29 10:13:57 Epoch [24000/30000] Loss:0.000371 Loss_1:0.000366 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:39.517135s (7.91min in total, 1.98min remains)
2022-11-29 10:14:36 NUM_SUB: 150;----------------------------
2022-11-29 10:14:36 Epoch [26000/30000] Loss:0.000370 Loss_1:0.000366 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:39.891939s (8.57min in total, 1.32min remains)
2022-11-29 10:15:16 NUM_SUB: 150;----------------------------
2022-11-29 10:15:16 Epoch [28000/30000] Loss:0.000368 Loss_1:0.000365 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:39.411818s (9.23min in total, 0.66min remains)
2022-11-29 10:15:55 Testing & drawing...
2022-11-29 10:15:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:15:57 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=150/
2022-11-29 10:15:57 [Loss]
2022-11-29 10:15:57 NUM_SUB: 150; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:15:57 NUM_SUB: 150; Personalized parameter estimation: Parameter containing:
tensor([0.0257, 0.0916, 0.0127, 0.0876, 0.3074, 0.0180, 0.1170, 0.8964, 0.4556,
        0.0143, 0.0729, 0.0504, 0.5948, 0.1689, 0.0176, 1.5514, 0.6977, 0.8000,
        0.0123, 0.7689, 0.6816, 0.0221, 3.7218, 0.8742, 0.0195, 4.1744, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 10:15:57 NUM_SUB: 150;----------------------------
2022-11-29 10:15:57 Epoch [30000/30000] Loss:0.000367 Loss_1:0.000365 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:41.105636s (9.91min in total, 0.00min remains)
2022-11-29 10:15:57 NUM_SUB: 150------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 10:15:57 Testing & drawing...
2022-11-29 10:15:57 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:15:59 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=150/
2022-11-29 10:15:59 [Loss]
2022-11-29 10:15:59 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:15:59 General parameter estimation: Parameter containing:
tensor([0.0257, 0.0915, 0.0127, 0.0876, 0.3074, 0.0180, 0.1170, 0.8964, 0.4556,
        0.0143, 0.0729, 0.0504, 0.5947, 0.1689, 0.0176, 1.5514, 0.6977, 0.8000,
        0.0123, 0.7689, 0.6816, 0.0221, 3.7220, 0.8742, 0.0195, 4.1746, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 10:15:59 A: prod, degr, TonA, NonA
2022-11-29 10:15:59 [0.23297258 0.49602985 0.11087614 0.16012143]
2022-11-29 10:15:59 T: prod, degr, AonT, NonT
2022-11-29 10:15:59 [0.16978712 0.51388294 0.2530969  0.06323304]
2022-11-29 10:15:59 N: AonN, TonN, ATonN
2022-11-29 10:15:59 [0.18615934 0.78516465 0.02867604]
2022-11-29 10:15:59 using cpu
2022-11-29 10:15:59 epoch = 30000
2022-11-29 10:15:59 epoch_step = 2000
2022-11-29 10:15:59 model_name = SimpleNetworkAD
2022-11-29 10:15:59 now_string = 2022-11-28-18-17-05
2022-11-29 10:15:59 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 10:15:59 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 10:15:59 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 10:15:59 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 10:15:59 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 10:15:59 --------------------------------------------------training start--------------------------------------------------
2022-11-29 10:16:38 NUM_SUB: 151;----------------------------
2022-11-29 10:16:38 Epoch [02000/30000] Loss:0.082624 Loss_1:0.081842 Loss_2:0.000372 Loss_3:0.000000 Lr:0.000833 Time:39.355226s (0.66min in total, 9.18min remains)
2022-11-29 10:17:17 NUM_SUB: 151;----------------------------
2022-11-29 10:17:17 Epoch [04000/30000] Loss:0.065880 Loss_1:0.065548 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000714 Time:39.311211s (1.31min in total, 8.52min remains)
2022-11-29 10:17:57 NUM_SUB: 151;----------------------------
2022-11-29 10:17:57 Epoch [06000/30000] Loss:0.033337 Loss_1:0.033117 Loss_2:0.000043 Loss_3:0.000000 Lr:0.000625 Time:39.299658s (1.97min in total, 7.86min remains)
2022-11-29 10:18:36 NUM_SUB: 151;----------------------------
2022-11-29 10:18:36 Epoch [08000/30000] Loss:0.006800 Loss_1:0.006730 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000556 Time:39.467351s (2.62min in total, 7.22min remains)
2022-11-29 10:19:16 NUM_SUB: 151;----------------------------
2022-11-29 10:19:16 Epoch [10000/30000] Loss:0.004678 Loss_1:0.004618 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000500 Time:39.410892s (3.28min in total, 6.56min remains)
2022-11-29 10:19:55 NUM_SUB: 151;----------------------------
2022-11-29 10:19:55 Epoch [12000/30000] Loss:0.003453 Loss_1:0.003427 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000455 Time:39.463955s (3.94min in total, 5.91min remains)
2022-11-29 10:20:35 NUM_SUB: 151;----------------------------
2022-11-29 10:20:35 Epoch [14000/30000] Loss:0.001681 Loss_1:0.001666 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000417 Time:39.504517s (4.60min in total, 5.25min remains)
2022-11-29 10:21:14 NUM_SUB: 151;----------------------------
2022-11-29 10:21:14 Epoch [16000/30000] Loss:0.001454 Loss_1:0.001443 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000385 Time:39.676402s (5.26min in total, 4.60min remains)
2022-11-29 10:21:53 NUM_SUB: 151;----------------------------
2022-11-29 10:21:53 Epoch [18000/30000] Loss:0.001451 Loss_1:0.001444 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:39.025226s (5.91min in total, 3.94min remains)
2022-11-29 10:22:32 NUM_SUB: 151;----------------------------
2022-11-29 10:22:32 Epoch [20000/30000] Loss:0.001450 Loss_1:0.001444 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.810114s (6.56min in total, 3.28min remains)
2022-11-29 10:23:11 NUM_SUB: 151;----------------------------
2022-11-29 10:23:11 Epoch [22000/30000] Loss:0.001449 Loss_1:0.001443 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:38.430855s (7.20min in total, 2.62min remains)
2022-11-29 10:23:49 NUM_SUB: 151;----------------------------
2022-11-29 10:23:49 Epoch [24000/30000] Loss:0.001449 Loss_1:0.001444 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.234531s (7.83min in total, 1.96min remains)
2022-11-29 10:24:27 NUM_SUB: 151;----------------------------
2022-11-29 10:24:27 Epoch [26000/30000] Loss:0.001448 Loss_1:0.001444 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.370400s (8.47min in total, 1.30min remains)
2022-11-29 10:25:06 NUM_SUB: 151;----------------------------
2022-11-29 10:25:06 Epoch [28000/30000] Loss:0.001447 Loss_1:0.001443 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.381003s (9.11min in total, 0.65min remains)
2022-11-29 10:25:44 Testing & drawing...
2022-11-29 10:25:44 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:25:46 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=151/
2022-11-29 10:25:46 [Loss]
2022-11-29 10:25:46 NUM_SUB: 151; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:25:46 NUM_SUB: 151; Personalized parameter estimation: Parameter containing:
tensor([2.7887e-01, 9.8977e-01, 9.4171e-03, 1.3320e-31, 3.0742e-01, 1.2996e-02,
        4.2800e-02, 8.9644e-01, 4.5563e-01, 1.4210e-02, 6.8511e-02, 5.3068e-02,
        7.9478e-01, 1.6886e-01, 1.7681e-02, 1.5334e+00, 6.9767e-01, 8.0001e-01,
        1.2744e-02, 4.8919e-01, 6.8161e-01, 2.1727e-02, 3.5944e+00, 8.7416e-01,
        2.1485e-02, 4.1405e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:25:46 NUM_SUB: 151;----------------------------
2022-11-29 10:25:46 Epoch [30000/30000] Loss:0.001447 Loss_1:0.001443 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.053935s (9.78min in total, 0.00min remains)
2022-11-29 10:25:46 NUM_SUB: 151------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 10:25:46 Testing & drawing...
2022-11-29 10:25:46 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:25:47 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=151/
2022-11-29 10:25:47 [Loss]
2022-11-29 10:25:47 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:25:47 General parameter estimation: Parameter containing:
tensor([2.7888e-01, 9.8976e-01, 9.4171e-03, 1.3248e-31, 3.0742e-01, 1.2996e-02,
        4.2792e-02, 8.9644e-01, 4.5563e-01, 1.4210e-02, 6.8514e-02, 5.3058e-02,
        7.9473e-01, 1.6886e-01, 1.7681e-02, 1.5333e+00, 6.9767e-01, 8.0001e-01,
        1.2744e-02, 4.8914e-01, 6.8161e-01, 2.1726e-02, 3.5945e+00, 8.7416e-01,
        2.1485e-02, 4.1407e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:25:47 A: prod, degr, TonA, NonA
2022-11-29 10:25:47 [0.46269634 0.5001495  0.01562415 0.0215301 ]
2022-11-29 10:25:47 T: prod, degr, AonT, NonT
2022-11-29 10:25:47 [0.25301707 0.37154812 0.25965106 0.11578378]
2022-11-29 10:25:47 N: AonN, TonN, ATonN
2022-11-29 10:25:47 [0.15349005 0.828135   0.01837492]
2022-11-29 10:25:47 using cpu
2022-11-29 10:25:47 epoch = 30000
2022-11-29 10:25:47 epoch_step = 2000
2022-11-29 10:25:47 model_name = SimpleNetworkAD
2022-11-29 10:25:47 now_string = 2022-11-28-18-17-05
2022-11-29 10:25:47 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 10:25:47 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 10:25:47 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 10:25:47 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 10:25:47 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 10:25:47 --------------------------------------------------training start--------------------------------------------------
2022-11-29 10:26:26 NUM_SUB: 152;----------------------------
2022-11-29 10:26:26 Epoch [02000/30000] Loss:0.067978 Loss_1:0.067068 Loss_2:0.000447 Loss_3:0.000000 Lr:0.000833 Time:38.379189s (0.64min in total, 8.96min remains)
2022-11-29 10:27:04 NUM_SUB: 152;----------------------------
2022-11-29 10:27:04 Epoch [04000/30000] Loss:0.057055 Loss_1:0.056721 Loss_2:0.000067 Loss_3:0.000000 Lr:0.000714 Time:38.419140s (1.28min in total, 8.32min remains)
2022-11-29 10:27:43 NUM_SUB: 152;----------------------------
2022-11-29 10:27:43 Epoch [06000/30000] Loss:0.038196 Loss_1:0.037913 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000625 Time:38.391591s (1.92min in total, 7.68min remains)
2022-11-29 10:28:21 NUM_SUB: 152;----------------------------
2022-11-29 10:28:21 Epoch [08000/30000] Loss:0.013116 Loss_1:0.012898 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000556 Time:38.441614s (2.56min in total, 7.04min remains)
2022-11-29 10:28:59 NUM_SUB: 152;----------------------------
2022-11-29 10:28:59 Epoch [10000/30000] Loss:0.003307 Loss_1:0.003177 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000500 Time:38.341742s (3.20min in total, 6.40min remains)
2022-11-29 10:29:38 NUM_SUB: 152;----------------------------
2022-11-29 10:29:38 Epoch [12000/30000] Loss:0.002701 Loss_1:0.002653 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000455 Time:38.390241s (3.84min in total, 5.76min remains)
2022-11-29 10:30:16 NUM_SUB: 152;----------------------------
2022-11-29 10:30:16 Epoch [14000/30000] Loss:0.002581 Loss_1:0.002555 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000417 Time:38.325028s (4.48min in total, 5.12min remains)
2022-11-29 10:30:54 NUM_SUB: 152;----------------------------
2022-11-29 10:30:54 Epoch [16000/30000] Loss:0.002560 Loss_1:0.002545 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.291036s (5.12min in total, 4.48min remains)
2022-11-29 10:31:33 NUM_SUB: 152;----------------------------
2022-11-29 10:31:33 Epoch [18000/30000] Loss:0.002537 Loss_1:0.002528 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.351652s (5.76min in total, 3.84min remains)
2022-11-29 10:32:11 NUM_SUB: 152;----------------------------
2022-11-29 10:32:11 Epoch [20000/30000] Loss:0.002507 Loss_1:0.002501 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.333942s (6.39min in total, 3.20min remains)
2022-11-29 10:32:49 NUM_SUB: 152;----------------------------
2022-11-29 10:32:49 Epoch [22000/30000] Loss:0.002421 Loss_1:0.002415 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.284129s (7.03min in total, 2.56min remains)
2022-11-29 10:33:28 NUM_SUB: 152;----------------------------
2022-11-29 10:33:28 Epoch [24000/30000] Loss:0.002373 Loss_1:0.002369 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.248241s (7.67min in total, 1.92min remains)
2022-11-29 10:34:06 NUM_SUB: 152;----------------------------
2022-11-29 10:34:06 Epoch [26000/30000] Loss:0.002373 Loss_1:0.002369 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.411970s (8.31min in total, 1.28min remains)
2022-11-29 10:34:44 NUM_SUB: 152;----------------------------
2022-11-29 10:34:44 Epoch [28000/30000] Loss:0.002372 Loss_1:0.002371 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.327689s (8.95min in total, 0.64min remains)
2022-11-29 10:35:23 Testing & drawing...
2022-11-29 10:35:23 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:35:24 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=152/
2022-11-29 10:35:24 [Loss]
2022-11-29 10:35:24 NUM_SUB: 152; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:35:24 NUM_SUB: 152; Personalized parameter estimation: Parameter containing:
tensor([3.6413e-01, 9.2146e-01, 1.0065e-02, 9.8692e-37, 3.0742e-01, 1.4408e-02,
        1.3177e+00, 8.9644e-01, 4.5563e-01, 1.3663e-02, 2.4719e-02, 1.5003e-02,
        9.0543e-01, 1.6886e-01, 1.3665e-02, 1.7533e+00, 6.9767e-01, 8.0001e-01,
        1.2206e-02, 3.8285e+00, 6.8161e-01, 2.1607e-02, 4.1544e+00, 8.7416e-01,
        1.6020e-02, 4.7452e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:35:24 NUM_SUB: 152;----------------------------
2022-11-29 10:35:24 Epoch [30000/30000] Loss:0.002372 Loss_1:0.002370 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.008034s (9.62min in total, 0.00min remains)
2022-11-29 10:35:24 NUM_SUB: 152------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 10:35:24 Testing & drawing...
2022-11-29 10:35:24 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:35:26 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=152/
2022-11-29 10:35:26 [Loss]
2022-11-29 10:35:26 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:35:26 General parameter estimation: Parameter containing:
tensor([3.6414e-01, 9.2145e-01, 1.0065e-02, 9.8692e-37, 3.0742e-01, 1.4408e-02,
        1.3178e+00, 8.9644e-01, 4.5563e-01, 1.3663e-02, 2.4702e-02, 1.5003e-02,
        9.0542e-01, 1.6886e-01, 1.3663e-02, 1.7534e+00, 6.9767e-01, 8.0001e-01,
        1.2206e-02, 3.8285e+00, 6.8161e-01, 2.1607e-02, 4.1545e+00, 8.7416e-01,
        1.6020e-02, 4.7453e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 10:35:26 A: prod, degr, TonA, NonA
2022-11-29 10:35:26 [0.4836286  0.49991468 0.01336819 0.0030885 ]
2022-11-29 10:35:26 T: prod, degr, AonT, NonT
2022-11-29 10:35:26 [0.43043715 0.3178863  0.20960115 0.04207535]
2022-11-29 10:35:26 N: AonN, TonN, ATonN
2022-11-29 10:35:26 [0.00642242 0.9667959  0.02678165]
2022-11-29 10:35:26 using cpu
2022-11-29 10:35:26 epoch = 30000
2022-11-29 10:35:26 epoch_step = 2000
2022-11-29 10:35:26 model_name = SimpleNetworkAD
2022-11-29 10:35:26 now_string = 2022-11-28-18-17-05
2022-11-29 10:35:26 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 10:35:26 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 10:35:26 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 10:35:26 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 10:35:26 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 10:35:26 --------------------------------------------------training start--------------------------------------------------
2022-11-29 10:36:04 NUM_SUB: 153;----------------------------
2022-11-29 10:36:04 Epoch [02000/30000] Loss:0.130095 Loss_1:0.128733 Loss_2:0.000743 Loss_3:0.000000 Lr:0.000833 Time:38.276203s (0.64min in total, 8.93min remains)
2022-11-29 10:36:43 NUM_SUB: 153;----------------------------
2022-11-29 10:36:43 Epoch [04000/30000] Loss:0.105210 Loss_1:0.104396 Loss_2:0.000220 Loss_3:0.000000 Lr:0.000714 Time:38.234796s (1.28min in total, 8.29min remains)
2022-11-29 10:37:21 NUM_SUB: 153;----------------------------
2022-11-29 10:37:21 Epoch [06000/30000] Loss:0.059576 Loss_1:0.058931 Loss_2:0.000235 Loss_3:0.000000 Lr:0.000625 Time:38.358543s (1.91min in total, 7.66min remains)
2022-11-29 10:37:59 NUM_SUB: 153;----------------------------
2022-11-29 10:37:59 Epoch [08000/30000] Loss:0.010694 Loss_1:0.010182 Loss_2:0.000418 Loss_3:0.000000 Lr:0.000556 Time:38.351081s (2.55min in total, 7.02min remains)
2022-11-29 10:38:38 NUM_SUB: 153;----------------------------
2022-11-29 10:38:38 Epoch [10000/30000] Loss:0.002296 Loss_1:0.002030 Loss_2:0.000262 Loss_3:0.000000 Lr:0.000500 Time:38.404495s (3.19min in total, 6.39min remains)
2022-11-29 10:39:16 NUM_SUB: 153;----------------------------
2022-11-29 10:39:16 Epoch [12000/30000] Loss:0.000872 Loss_1:0.000658 Loss_2:0.000213 Loss_3:0.000000 Lr:0.000455 Time:38.304102s (3.83min in total, 5.75min remains)
2022-11-29 10:39:54 NUM_SUB: 153;----------------------------
2022-11-29 10:39:54 Epoch [14000/30000] Loss:0.000641 Loss_1:0.000571 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000417 Time:38.227145s (4.47min in total, 5.11min remains)
2022-11-29 10:40:33 NUM_SUB: 153;----------------------------
2022-11-29 10:40:33 Epoch [16000/30000] Loss:0.000521 Loss_1:0.000495 Loss_2:0.000026 Loss_3:0.000000 Lr:0.000385 Time:38.302227s (5.11min in total, 4.47min remains)
2022-11-29 10:41:11 NUM_SUB: 153;----------------------------
2022-11-29 10:41:11 Epoch [18000/30000] Loss:0.000435 Loss_1:0.000419 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000357 Time:38.683789s (5.75min in total, 3.83min remains)
2022-11-29 10:41:50 NUM_SUB: 153;----------------------------
2022-11-29 10:41:50 Epoch [20000/30000] Loss:0.000415 Loss_1:0.000404 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.776173s (6.40min in total, 3.20min remains)
2022-11-29 10:42:29 NUM_SUB: 153;----------------------------
2022-11-29 10:42:29 Epoch [22000/30000] Loss:0.000409 Loss_1:0.000401 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.756170s (7.04min in total, 2.56min remains)
2022-11-29 10:43:08 NUM_SUB: 153;----------------------------
2022-11-29 10:43:08 Epoch [24000/30000] Loss:0.000407 Loss_1:0.000401 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.909654s (7.69min in total, 1.92min remains)
2022-11-29 10:43:47 NUM_SUB: 153;----------------------------
2022-11-29 10:43:47 Epoch [26000/30000] Loss:0.000405 Loss_1:0.000400 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:39.041128s (8.34min in total, 1.28min remains)
2022-11-29 10:44:26 NUM_SUB: 153;----------------------------
2022-11-29 10:44:26 Epoch [28000/30000] Loss:0.000405 Loss_1:0.000400 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:39.137977s (9.00min in total, 0.64min remains)
2022-11-29 10:46:46 Testing & drawing...
2022-11-29 10:46:46 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:46:48 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=153/
2022-11-29 10:46:48 [Loss]
2022-11-29 10:46:48 NUM_SUB: 153; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:46:48 NUM_SUB: 153; Personalized parameter estimation: Parameter containing:
tensor([0.0168, 0.0379, 0.0217, 1.1999, 0.3074, 0.0596, 1.4507, 0.8964, 0.4556,
        0.0260, 0.0510, 0.0149, 0.2195, 0.1689, 0.0176, 1.0385, 0.6977, 0.8000,
        0.0107, 5.1010, 0.6816, 0.0220, 4.0973, 0.8742, 0.0175, 5.0766, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 10:46:48 NUM_SUB: 153;----------------------------
2022-11-29 10:46:48 Epoch [30000/30000] Loss:0.000405 Loss_1:0.000400 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:141.985152s (11.36min in total, 0.00min remains)
2022-11-29 10:46:48 NUM_SUB: 153------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 10:46:48 Testing & drawing...
2022-11-29 10:46:48 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 10:46:50 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=153/
2022-11-29 10:46:50 [Loss]
2022-11-29 10:46:50 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 10:46:50 General parameter estimation: Parameter containing:
tensor([0.0168, 0.0379, 0.0217, 1.2000, 0.3074, 0.0596, 1.4507, 0.8964, 0.4556,
        0.0260, 0.0510, 0.0149, 0.2195, 0.1689, 0.0176, 1.0385, 0.6977, 0.8000,
        0.0107, 5.1011, 0.6816, 0.0220, 4.0973, 0.8742, 0.0175, 5.0767, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 10:46:50 A: prod, degr, TonA, NonA
2022-11-29 10:46:50 [0.23456277 0.48929253 0.10606422 0.17008045]
2022-11-29 10:46:50 T: prod, degr, AonT, NonT
2022-11-29 10:46:50 [0.278204   0.5087041  0.15027645 0.06281539]
2022-11-29 10:46:50 N: AonN, TonN, ATonN
2022-11-29 10:46:50 [0.01571159 0.93695116 0.04733725]
2022-11-29 10:46:50 using cpu
2022-11-29 10:46:50 epoch = 30000
2022-11-29 10:46:50 epoch_step = 2000
2022-11-29 10:46:50 model_name = SimpleNetworkAD
2022-11-29 10:46:50 now_string = 2022-11-28-18-17-05
2022-11-29 10:46:50 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 10:46:50 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 10:46:50 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 10:46:50 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 10:46:50 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 10:46:50 --------------------------------------------------training start--------------------------------------------------
2022-11-29 10:48:06 NUM_SUB: 154;----------------------------
2022-11-29 10:48:06 Epoch [02000/30000] Loss:0.079896 Loss_1:0.078918 Loss_2:0.000477 Loss_3:0.000000 Lr:0.000833 Time:76.461305s (1.27min in total, 17.84min remains)
2022-11-29 10:50:49 NUM_SUB: 154;----------------------------
2022-11-29 10:50:49 Epoch [04000/30000] Loss:0.066735 Loss_1:0.066342 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000714 Time:162.873383s (3.99min in total, 25.93min remains)
2022-11-29 10:56:01 NUM_SUB: 154;----------------------------
2022-11-29 10:56:01 Epoch [06000/30000] Loss:0.044443 Loss_1:0.044099 Loss_2:0.000106 Loss_3:0.000000 Lr:0.000625 Time:311.629607s (9.18min in total, 36.73min remains)
2022-11-29 10:56:40 NUM_SUB: 154;----------------------------
2022-11-29 10:56:40 Epoch [08000/30000] Loss:0.015525 Loss_1:0.015278 Loss_2:0.000161 Loss_3:0.000000 Lr:0.000556 Time:38.961152s (9.83min in total, 27.04min remains)
2022-11-29 10:57:18 NUM_SUB: 154;----------------------------
2022-11-29 10:57:18 Epoch [10000/30000] Loss:0.004452 Loss_1:0.004312 Loss_2:0.000140 Loss_3:0.000000 Lr:0.000500 Time:38.691022s (10.48min in total, 20.95min remains)
2022-11-29 10:57:57 NUM_SUB: 154;----------------------------
2022-11-29 10:57:57 Epoch [12000/30000] Loss:0.001695 Loss_1:0.001642 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000455 Time:38.573645s (11.12min in total, 16.68min remains)
2022-11-29 10:58:35 NUM_SUB: 154;----------------------------
2022-11-29 10:58:35 Epoch [14000/30000] Loss:0.001464 Loss_1:0.001432 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:38.539298s (11.76min in total, 13.44min remains)
2022-11-29 10:59:14 NUM_SUB: 154;----------------------------
2022-11-29 10:59:14 Epoch [16000/30000] Loss:0.001277 Loss_1:0.001259 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.520997s (12.40min in total, 10.85min remains)
2022-11-29 10:59:52 NUM_SUB: 154;----------------------------
2022-11-29 10:59:52 Epoch [18000/30000] Loss:0.001212 Loss_1:0.001200 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.492507s (13.05min in total, 8.70min remains)
2022-11-29 11:00:31 NUM_SUB: 154;----------------------------
2022-11-29 11:00:31 Epoch [20000/30000] Loss:0.001206 Loss_1:0.001198 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.510071s (13.69min in total, 6.84min remains)
2022-11-29 11:01:10 NUM_SUB: 154;----------------------------
2022-11-29 11:01:10 Epoch [22000/30000] Loss:0.001204 Loss_1:0.001196 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.638605s (14.33min in total, 5.21min remains)
2022-11-29 11:01:48 NUM_SUB: 154;----------------------------
2022-11-29 11:01:48 Epoch [24000/30000] Loss:0.001202 Loss_1:0.001196 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.605728s (14.98min in total, 3.74min remains)
2022-11-29 11:02:27 NUM_SUB: 154;----------------------------
2022-11-29 11:02:27 Epoch [26000/30000] Loss:0.001231 Loss_1:0.001226 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.613838s (15.62min in total, 2.40min remains)
2022-11-29 11:03:05 NUM_SUB: 154;----------------------------
2022-11-29 11:03:05 Epoch [28000/30000] Loss:0.001216 Loss_1:0.001212 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.414054s (16.26min in total, 1.16min remains)
2022-11-29 11:03:44 Testing & drawing...
2022-11-29 11:03:44 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:03:45 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=154/
2022-11-29 11:03:45 [Loss]
2022-11-29 11:03:45 NUM_SUB: 154; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:03:45 NUM_SUB: 154; Personalized parameter estimation: Parameter containing:
tensor([1.5347e-01, 3.3844e-01, 1.0236e-02, 5.3331e-01, 3.0742e-01, 1.5976e-03,
        3.7263e-01, 8.9644e-01, 4.5563e-01, 1.5854e-02, 5.2966e-02, 1.4912e-02,
        2.8276e-01, 1.6886e-01, 1.7069e-02, 2.8868e-01, 6.9767e-01, 8.0001e-01,
        1.2304e-02, 1.8758e+00, 6.8161e-01, 2.2723e-02, 3.1573e+00, 8.7416e-01,
        2.1145e-02, 3.4709e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:03:45 NUM_SUB: 154;----------------------------
2022-11-29 11:03:45 Epoch [30000/30000] Loss:0.001200 Loss_1:0.001198 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.185155s (16.93min in total, 0.00min remains)
2022-11-29 11:03:45 NUM_SUB: 154------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:03:45 Testing & drawing...
2022-11-29 11:03:45 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:03:47 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=154/
2022-11-29 11:03:47 [Loss]
2022-11-29 11:03:47 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:03:47 General parameter estimation: Parameter containing:
tensor([1.5348e-01, 3.3841e-01, 1.0236e-02, 5.3332e-01, 3.0742e-01, 1.6098e-03,
        3.7261e-01, 8.9644e-01, 4.5563e-01, 1.5846e-02, 5.2966e-02, 1.4912e-02,
        2.8278e-01, 1.6886e-01, 1.7069e-02, 2.8862e-01, 6.9767e-01, 8.0001e-01,
        1.2304e-02, 1.8756e+00, 6.8161e-01, 2.2723e-02, 3.1574e+00, 8.7416e-01,
        2.1145e-02, 3.4708e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:03:47 A: prod, degr, TonA, NonA
2022-11-29 11:03:47 [0.47542572 0.4988424  0.02188323 0.00384868]
2022-11-29 11:03:47 T: prod, degr, AonT, NonT
2022-11-29 11:03:47 [0.23099154 0.3672756  0.19278371 0.20894915]
2022-11-29 11:03:47 N: AonN, TonN, ATonN
2022-11-29 11:03:47 [0.03114962 0.90931946 0.05953094]
2022-11-29 11:03:47 using cpu
2022-11-29 11:03:47 epoch = 30000
2022-11-29 11:03:47 epoch_step = 2000
2022-11-29 11:03:47 model_name = SimpleNetworkAD
2022-11-29 11:03:47 now_string = 2022-11-28-18-17-05
2022-11-29 11:03:47 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:03:47 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:03:47 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:03:47 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:03:47 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:03:47 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:04:26 NUM_SUB: 155;----------------------------
2022-11-29 11:04:26 Epoch [02000/30000] Loss:0.073352 Loss_1:0.072165 Loss_2:0.000677 Loss_3:0.000000 Lr:0.000833 Time:38.579609s (0.64min in total, 9.00min remains)
2022-11-29 11:05:04 NUM_SUB: 155;----------------------------
2022-11-29 11:05:04 Epoch [04000/30000] Loss:0.060844 Loss_1:0.060298 Loss_2:0.000139 Loss_3:0.000000 Lr:0.000714 Time:38.391908s (1.28min in total, 8.34min remains)
2022-11-29 11:05:43 NUM_SUB: 155;----------------------------
2022-11-29 11:05:43 Epoch [06000/30000] Loss:0.038600 Loss_1:0.038180 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000625 Time:38.420493s (1.92min in total, 7.69min remains)
2022-11-29 11:06:21 NUM_SUB: 155;----------------------------
2022-11-29 11:06:21 Epoch [08000/30000] Loss:0.008769 Loss_1:0.008516 Loss_2:0.000170 Loss_3:0.000000 Lr:0.000556 Time:38.490018s (2.56min in total, 7.05min remains)
2022-11-29 11:07:00 NUM_SUB: 155;----------------------------
2022-11-29 11:07:00 Epoch [10000/30000] Loss:0.001429 Loss_1:0.001279 Loss_2:0.000149 Loss_3:0.000000 Lr:0.000500 Time:38.435036s (3.21min in total, 6.41min remains)
2022-11-29 11:07:38 NUM_SUB: 155;----------------------------
2022-11-29 11:07:38 Epoch [12000/30000] Loss:0.000947 Loss_1:0.000887 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000455 Time:38.408349s (3.85min in total, 5.77min remains)
2022-11-29 11:08:16 NUM_SUB: 155;----------------------------
2022-11-29 11:08:16 Epoch [14000/30000] Loss:0.000838 Loss_1:0.000804 Loss_2:0.000034 Loss_3:0.000000 Lr:0.000417 Time:38.442680s (4.49min in total, 5.13min remains)
2022-11-29 11:08:55 NUM_SUB: 155;----------------------------
2022-11-29 11:08:55 Epoch [16000/30000] Loss:0.000817 Loss_1:0.000797 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:38.360252s (5.13min in total, 4.48min remains)
2022-11-29 11:09:33 NUM_SUB: 155;----------------------------
2022-11-29 11:09:33 Epoch [18000/30000] Loss:0.000803 Loss_1:0.000791 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.428814s (5.77min in total, 3.84min remains)
2022-11-29 11:10:12 NUM_SUB: 155;----------------------------
2022-11-29 11:10:12 Epoch [20000/30000] Loss:0.000796 Loss_1:0.000789 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:38.401809s (6.41min in total, 3.20min remains)
2022-11-29 11:10:50 NUM_SUB: 155;----------------------------
2022-11-29 11:10:50 Epoch [22000/30000] Loss:0.000793 Loss_1:0.000789 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.533682s (7.05min in total, 2.56min remains)
2022-11-29 11:11:29 NUM_SUB: 155;----------------------------
2022-11-29 11:11:29 Epoch [24000/30000] Loss:0.000791 Loss_1:0.000789 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.465658s (7.69min in total, 1.92min remains)
2022-11-29 11:12:07 NUM_SUB: 155;----------------------------
2022-11-29 11:12:07 Epoch [26000/30000] Loss:0.000790 Loss_1:0.000789 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.381346s (8.33min in total, 1.28min remains)
2022-11-29 11:12:45 NUM_SUB: 155;----------------------------
2022-11-29 11:12:45 Epoch [28000/30000] Loss:0.000789 Loss_1:0.000788 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.467544s (8.97min in total, 0.64min remains)
2022-11-29 11:13:24 Testing & drawing...
2022-11-29 11:13:24 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:13:26 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=155/
2022-11-29 11:13:26 [Loss]
2022-11-29 11:13:26 NUM_SUB: 155; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:13:26 NUM_SUB: 155; Personalized parameter estimation: Parameter containing:
tensor([4.8409e-01, 7.4012e-01, 6.2780e-02, 1.7786e-03, 3.0742e-01, 1.2760e-02,
        7.6541e-01, 8.9644e-01, 4.5563e-01, 1.3891e-02, 2.6980e-02, 1.4936e-02,
        8.3675e-01, 1.6886e-01, 1.7374e-02, 2.0943e+00, 6.9767e-01, 8.0001e-01,
        1.1062e-02, 4.8686e+00, 6.8161e-01, 2.2029e-02, 4.1692e+00, 8.7416e-01,
        1.7930e-02, 5.0084e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:13:26 NUM_SUB: 155;----------------------------
2022-11-29 11:13:26 Epoch [30000/30000] Loss:0.000789 Loss_1:0.000789 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.213826s (9.64min in total, 0.00min remains)
2022-11-29 11:13:26 NUM_SUB: 155------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:13:26 Testing & drawing...
2022-11-29 11:13:26 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:13:27 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=155/
2022-11-29 11:13:27 [Loss]
2022-11-29 11:13:27 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:13:27 General parameter estimation: Parameter containing:
tensor([4.8408e-01, 7.4013e-01, 6.2773e-02, 1.7756e-03, 3.0742e-01, 1.2752e-02,
        7.6542e-01, 8.9644e-01, 4.5563e-01, 1.3891e-02, 2.7012e-02, 1.4936e-02,
        8.3671e-01, 1.6886e-01, 1.7374e-02, 2.0945e+00, 6.9767e-01, 8.0001e-01,
        1.1062e-02, 4.8687e+00, 6.8161e-01, 2.2029e-02, 4.1693e+00, 8.7416e-01,
        1.7930e-02, 5.0085e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:13:27 A: prod, degr, TonA, NonA
2022-11-29 11:13:27 [0.43823266 0.50003743 0.05682671 0.00490323]
2022-11-29 11:13:27 T: prod, degr, AonT, NonT
2022-11-29 11:13:27 [0.32698765 0.4745187  0.1611698  0.0373239 ]
2022-11-29 11:13:27 N: AonN, TonN, ATonN
2022-11-29 11:13:27 [0.01151949 0.9524657  0.0360148 ]
2022-11-29 11:13:27 using cpu
2022-11-29 11:13:27 epoch = 30000
2022-11-29 11:13:27 epoch_step = 2000
2022-11-29 11:13:27 model_name = SimpleNetworkAD
2022-11-29 11:13:27 now_string = 2022-11-28-18-17-05
2022-11-29 11:13:27 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:13:27 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:13:27 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:13:27 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:13:27 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:13:27 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:14:06 NUM_SUB: 156;----------------------------
2022-11-29 11:14:06 Epoch [02000/30000] Loss:0.028729 Loss_1:0.027727 Loss_2:0.000609 Loss_3:0.000000 Lr:0.000833 Time:38.381545s (0.64min in total, 8.96min remains)
2022-11-29 11:14:44 NUM_SUB: 156;----------------------------
2022-11-29 11:14:44 Epoch [04000/30000] Loss:0.023565 Loss_1:0.023361 Loss_2:0.000115 Loss_3:0.000000 Lr:0.000714 Time:38.362753s (1.28min in total, 8.31min remains)
2022-11-29 11:15:23 NUM_SUB: 156;----------------------------
2022-11-29 11:15:23 Epoch [06000/30000] Loss:0.016781 Loss_1:0.016617 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000625 Time:38.376283s (1.92min in total, 7.67min remains)
2022-11-29 11:16:01 NUM_SUB: 156;----------------------------
2022-11-29 11:16:01 Epoch [08000/30000] Loss:0.008543 Loss_1:0.008429 Loss_2:0.000096 Loss_3:0.000000 Lr:0.000556 Time:38.440451s (2.56min in total, 7.04min remains)
2022-11-29 11:16:40 NUM_SUB: 156;----------------------------
2022-11-29 11:16:40 Epoch [10000/30000] Loss:0.005108 Loss_1:0.004989 Loss_2:0.000118 Loss_3:0.000000 Lr:0.000500 Time:38.492698s (3.20min in total, 6.40min remains)
2022-11-29 11:17:18 NUM_SUB: 156;----------------------------
2022-11-29 11:17:18 Epoch [12000/30000] Loss:0.002316 Loss_1:0.002267 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000455 Time:38.548898s (3.84min in total, 5.77min remains)
2022-11-29 11:17:56 NUM_SUB: 156;----------------------------
2022-11-29 11:17:56 Epoch [14000/30000] Loss:0.001359 Loss_1:0.001328 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:38.372660s (4.48min in total, 5.12min remains)
2022-11-29 11:18:35 NUM_SUB: 156;----------------------------
2022-11-29 11:18:35 Epoch [16000/30000] Loss:0.001316 Loss_1:0.001301 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:38.358400s (5.12min in total, 4.48min remains)
2022-11-29 11:19:13 NUM_SUB: 156;----------------------------
2022-11-29 11:19:13 Epoch [18000/30000] Loss:0.001289 Loss_1:0.001279 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.430246s (5.76min in total, 3.84min remains)
2022-11-29 11:19:52 NUM_SUB: 156;----------------------------
2022-11-29 11:19:52 Epoch [20000/30000] Loss:0.001286 Loss_1:0.001279 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.402942s (6.40min in total, 3.20min remains)
2022-11-29 11:20:30 NUM_SUB: 156;----------------------------
2022-11-29 11:20:30 Epoch [22000/30000] Loss:0.001284 Loss_1:0.001280 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.403881s (7.04min in total, 2.56min remains)
2022-11-29 11:21:09 NUM_SUB: 156;----------------------------
2022-11-29 11:21:09 Epoch [24000/30000] Loss:0.001283 Loss_1:0.001280 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.515510s (7.68min in total, 1.92min remains)
2022-11-29 11:21:47 NUM_SUB: 156;----------------------------
2022-11-29 11:21:47 Epoch [26000/30000] Loss:0.001282 Loss_1:0.001280 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.426882s (8.33min in total, 1.28min remains)
2022-11-29 11:22:26 NUM_SUB: 156;----------------------------
2022-11-29 11:22:26 Epoch [28000/30000] Loss:0.001282 Loss_1:0.001279 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.957334s (8.97min in total, 0.64min remains)
2022-11-29 11:23:05 Testing & drawing...
2022-11-29 11:23:05 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:23:07 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=156/
2022-11-29 11:23:07 [Loss]
2022-11-29 11:23:07 NUM_SUB: 156; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:23:07 NUM_SUB: 156; Personalized parameter estimation: Parameter containing:
tensor([4.8917e-01, 7.6648e-01, 3.7007e-03, 2.1664e-37, 3.0742e-01, 1.5573e-02,
        2.0196e+00, 8.9644e-01, 4.5563e-01, 1.4584e-02, 3.0560e-02, 1.3883e-02,
        8.8341e-01, 1.6886e-01, 1.7585e-02, 1.9218e+00, 6.9767e-01, 8.0001e-01,
        1.1846e-02, 3.7643e+00, 6.8161e-01, 2.2506e-02, 3.6815e+00, 8.7416e-01,
        1.7259e-02, 4.2603e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:23:07 NUM_SUB: 156;----------------------------
2022-11-29 11:23:07 Epoch [30000/30000] Loss:0.001281 Loss_1:0.001280 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.607780s (9.65min in total, 0.00min remains)
2022-11-29 11:23:07 NUM_SUB: 156------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:23:07 Testing & drawing...
2022-11-29 11:23:07 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:23:08 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=156/
2022-11-29 11:23:08 [Loss]
2022-11-29 11:23:08 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:23:08 General parameter estimation: Parameter containing:
tensor([4.8917e-01, 7.6648e-01, 3.7001e-03, 2.1664e-37, 3.0742e-01, 1.5573e-02,
        2.0197e+00, 8.9644e-01, 4.5563e-01, 1.4584e-02, 3.0557e-02, 1.3883e-02,
        8.8336e-01, 1.6886e-01, 1.7585e-02, 1.9217e+00, 6.9767e-01, 8.0001e-01,
        1.1846e-02, 3.7641e+00, 6.8161e-01, 2.2506e-02, 3.6815e+00, 8.7416e-01,
        1.7259e-02, 4.2603e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 11:23:08 A: prod, degr, TonA, NonA
2022-11-29 11:23:08 [0.49487698 0.4999928  0.00374321 0.00138699]
2022-11-29 11:23:08 T: prod, degr, AonT, NonT
2022-11-29 11:23:08 [0.36272386 0.4900358  0.10567112 0.04156923]
2022-11-29 11:23:08 N: AonN, TonN, ATonN
2022-11-29 11:23:08 [0.01571425 0.95137185 0.03291396]
2022-11-29 11:23:08 using cpu
2022-11-29 11:23:08 epoch = 30000
2022-11-29 11:23:08 epoch_step = 2000
2022-11-29 11:23:08 model_name = SimpleNetworkAD
2022-11-29 11:23:08 now_string = 2022-11-28-18-17-05
2022-11-29 11:23:08 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:23:08 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:23:08 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:23:08 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:23:08 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:23:08 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:23:47 NUM_SUB: 157;----------------------------
2022-11-29 11:23:47 Epoch [02000/30000] Loss:0.135435 Loss_1:0.133906 Loss_2:0.000799 Loss_3:0.000000 Lr:0.000833 Time:38.806996s (0.65min in total, 9.05min remains)
2022-11-29 11:24:26 NUM_SUB: 157;----------------------------
2022-11-29 11:24:26 Epoch [04000/30000] Loss:0.117387 Loss_1:0.116487 Loss_2:0.000211 Loss_3:0.000000 Lr:0.000714 Time:39.013484s (1.30min in total, 8.43min remains)
2022-11-29 11:25:05 NUM_SUB: 157;----------------------------
2022-11-29 11:25:05 Epoch [06000/30000] Loss:0.077609 Loss_1:0.076853 Loss_2:0.000225 Loss_3:0.000000 Lr:0.000625 Time:38.985032s (1.95min in total, 7.79min remains)
2022-11-29 11:25:44 NUM_SUB: 157;----------------------------
2022-11-29 11:25:44 Epoch [08000/30000] Loss:0.011663 Loss_1:0.011207 Loss_2:0.000319 Loss_3:0.000000 Lr:0.000556 Time:39.211573s (2.60min in total, 7.15min remains)
2022-11-29 11:26:24 NUM_SUB: 157;----------------------------
2022-11-29 11:26:24 Epoch [10000/30000] Loss:0.002982 Loss_1:0.002778 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000500 Time:39.144086s (3.25min in total, 6.51min remains)
2022-11-29 11:27:03 NUM_SUB: 157;----------------------------
2022-11-29 11:27:03 Epoch [12000/30000] Loss:0.000963 Loss_1:0.000877 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000455 Time:39.356319s (3.91min in total, 5.86min remains)
2022-11-29 11:27:42 NUM_SUB: 157;----------------------------
2022-11-29 11:27:42 Epoch [14000/30000] Loss:0.000546 Loss_1:0.000504 Loss_2:0.000042 Loss_3:0.000000 Lr:0.000417 Time:39.289403s (4.56min in total, 5.22min remains)
2022-11-29 11:28:22 NUM_SUB: 157;----------------------------
2022-11-29 11:28:22 Epoch [16000/30000] Loss:0.000246 Loss_1:0.000224 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000385 Time:39.362177s (5.22min in total, 4.57min remains)
2022-11-29 11:29:01 NUM_SUB: 157;----------------------------
2022-11-29 11:29:01 Epoch [18000/30000] Loss:0.000049 Loss_1:0.000034 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000357 Time:39.570620s (5.88min in total, 3.92min remains)
2022-11-29 11:29:41 NUM_SUB: 157;----------------------------
2022-11-29 11:29:41 Epoch [20000/30000] Loss:0.000016 Loss_1:0.000003 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000333 Time:39.542299s (6.54min in total, 3.27min remains)
2022-11-29 11:30:20 NUM_SUB: 157;----------------------------
2022-11-29 11:30:20 Epoch [22000/30000] Loss:0.000010 Loss_1:0.000001 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:39.389857s (7.19min in total, 2.62min remains)
2022-11-29 11:30:59 NUM_SUB: 157;----------------------------
2022-11-29 11:30:59 Epoch [24000/30000] Loss:0.000006 Loss_1:0.000000 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:39.276744s (7.85min in total, 1.96min remains)
2022-11-29 11:31:39 NUM_SUB: 157;----------------------------
2022-11-29 11:31:39 Epoch [26000/30000] Loss:0.000004 Loss_1:0.000000 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:39.395207s (8.51min in total, 1.31min remains)
2022-11-29 11:32:18 NUM_SUB: 157;----------------------------
2022-11-29 11:32:18 Epoch [28000/30000] Loss:0.000003 Loss_1:0.000000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:39.362228s (9.16min in total, 0.65min remains)
2022-11-29 11:32:57 Testing & drawing...
2022-11-29 11:32:57 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:32:59 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=157/
2022-11-29 11:32:59 [Loss]
2022-11-29 11:32:59 NUM_SUB: 157; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:32:59 NUM_SUB: 157; Personalized parameter estimation: Parameter containing:
tensor([0.1679, 0.5580, 0.0223, 0.4631, 0.3074, 0.4281, 0.2225, 0.8964, 0.4556,
        0.1840, 0.2053, 0.0215, 0.2358, 0.1689, 0.0174, 2.2251, 0.6977, 0.8000,
        0.0109, 5.0254, 0.6816, 0.0199, 4.0987, 0.8742, 0.0179, 5.0417, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:32:59 NUM_SUB: 157;----------------------------
2022-11-29 11:32:59 Epoch [30000/30000] Loss:0.000002 Loss_1:0.000000 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.996613s (9.85min in total, 0.00min remains)
2022-11-29 11:32:59 NUM_SUB: 157------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:32:59 Testing & drawing...
2022-11-29 11:32:59 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:33:01 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=157/
2022-11-29 11:33:01 [Loss]
2022-11-29 11:33:01 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:33:01 General parameter estimation: Parameter containing:
tensor([0.1679, 0.5579, 0.0223, 0.4631, 0.3074, 0.4281, 0.2225, 0.8964, 0.4556,
        0.1840, 0.2053, 0.0215, 0.2358, 0.1689, 0.0174, 2.2252, 0.6977, 0.8000,
        0.0109, 5.0254, 0.6816, 0.0199, 4.0987, 0.8742, 0.0179, 5.0416, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:33:01 A: prod, degr, TonA, NonA
2022-11-29 11:33:01 [0.15272339 0.49933878 0.01670405 0.3312338 ]
2022-11-29 11:33:01 T: prod, degr, AonT, NonT
2022-11-29 11:33:01 [0.4505608  0.49624208 0.04989096 0.00330619]
2022-11-29 11:33:01 N: AonN, TonN, ATonN
2022-11-29 11:33:01 [0.01945503 0.9188949  0.0616501 ]
2022-11-29 11:33:01 using cpu
2022-11-29 11:33:01 epoch = 30000
2022-11-29 11:33:01 epoch_step = 2000
2022-11-29 11:33:01 model_name = SimpleNetworkAD
2022-11-29 11:33:01 now_string = 2022-11-28-18-17-05
2022-11-29 11:33:01 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:33:01 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:33:01 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:33:01 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:33:01 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:33:01 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:33:40 NUM_SUB: 158;----------------------------
2022-11-29 11:33:40 Epoch [02000/30000] Loss:0.054181 Loss_1:0.053115 Loss_2:0.000633 Loss_3:0.000000 Lr:0.000833 Time:39.464705s (0.66min in total, 9.21min remains)
2022-11-29 11:34:20 NUM_SUB: 158;----------------------------
2022-11-29 11:34:20 Epoch [04000/30000] Loss:0.042152 Loss_1:0.041825 Loss_2:0.000148 Loss_3:0.000000 Lr:0.000714 Time:39.487887s (1.32min in total, 8.55min remains)
2022-11-29 11:34:59 NUM_SUB: 158;----------------------------
2022-11-29 11:34:59 Epoch [06000/30000] Loss:0.022737 Loss_1:0.022472 Loss_2:0.000132 Loss_3:0.000000 Lr:0.000625 Time:39.509443s (1.97min in total, 7.90min remains)
2022-11-29 11:35:39 NUM_SUB: 158;----------------------------
2022-11-29 11:35:39 Epoch [08000/30000] Loss:0.005978 Loss_1:0.005795 Loss_2:0.000137 Loss_3:0.000000 Lr:0.000556 Time:39.579992s (2.63min in total, 7.24min remains)
2022-11-29 11:36:18 NUM_SUB: 158;----------------------------
2022-11-29 11:36:18 Epoch [10000/30000] Loss:0.001277 Loss_1:0.001126 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000500 Time:39.493310s (3.29min in total, 6.58min remains)
2022-11-29 11:36:58 NUM_SUB: 158;----------------------------
2022-11-29 11:36:58 Epoch [12000/30000] Loss:0.000615 Loss_1:0.000534 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000455 Time:39.569549s (3.95min in total, 5.93min remains)
2022-11-29 11:37:38 NUM_SUB: 158;----------------------------
2022-11-29 11:37:38 Epoch [14000/30000] Loss:0.000335 Loss_1:0.000281 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000417 Time:39.538566s (4.61min in total, 5.27min remains)
2022-11-29 11:38:17 NUM_SUB: 158;----------------------------
2022-11-29 11:38:17 Epoch [16000/30000] Loss:0.000270 Loss_1:0.000239 Loss_2:0.000031 Loss_3:0.000000 Lr:0.000385 Time:39.479471s (5.27min in total, 4.61min remains)
2022-11-29 11:38:57 NUM_SUB: 158;----------------------------
2022-11-29 11:38:57 Epoch [18000/30000] Loss:0.000243 Loss_1:0.000227 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000357 Time:39.460346s (5.93min in total, 3.95min remains)
2022-11-29 11:39:36 NUM_SUB: 158;----------------------------
2022-11-29 11:39:36 Epoch [20000/30000] Loss:0.000229 Loss_1:0.000221 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:39.593925s (6.59min in total, 3.29min remains)
2022-11-29 11:40:16 NUM_SUB: 158;----------------------------
2022-11-29 11:40:16 Epoch [22000/30000] Loss:0.000218 Loss_1:0.000214 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:39.523380s (7.25min in total, 2.63min remains)
2022-11-29 11:40:55 NUM_SUB: 158;----------------------------
2022-11-29 11:40:55 Epoch [24000/30000] Loss:0.000213 Loss_1:0.000211 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:39.516324s (7.90min in total, 1.98min remains)
2022-11-29 11:41:35 NUM_SUB: 158;----------------------------
2022-11-29 11:41:35 Epoch [26000/30000] Loss:0.000214 Loss_1:0.000212 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:39.500939s (8.56min in total, 1.32min remains)
2022-11-29 11:42:14 NUM_SUB: 158;----------------------------
2022-11-29 11:42:14 Epoch [28000/30000] Loss:0.000210 Loss_1:0.000208 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.637059s (9.22min in total, 0.66min remains)
2022-11-29 11:42:54 Testing & drawing...
2022-11-29 11:42:54 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:42:55 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=158/
2022-11-29 11:42:55 [Loss]
2022-11-29 11:42:55 NUM_SUB: 158; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:42:55 NUM_SUB: 158; Personalized parameter estimation: Parameter containing:
tensor([0.0175, 0.0376, 0.0263, 0.9769, 0.3074, 0.0231, 1.7695, 0.8964, 0.4556,
        0.0138, 0.0303, 0.0135, 0.9279, 0.1689, 0.0177, 1.9945, 0.6977, 0.8000,
        0.0113, 4.6075, 0.6816, 0.0214, 3.7486, 0.8742, 0.0189, 4.7001, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:42:55 NUM_SUB: 158;----------------------------
2022-11-29 11:42:55 Epoch [30000/30000] Loss:0.000208 Loss_1:0.000208 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:41.027576s (9.91min in total, 0.00min remains)
2022-11-29 11:42:55 NUM_SUB: 158------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:42:55 Testing & drawing...
2022-11-29 11:42:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:42:57 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=158/
2022-11-29 11:42:57 [Loss]
2022-11-29 11:42:57 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:42:57 General parameter estimation: Parameter containing:
tensor([0.0175, 0.0376, 0.0263, 0.9770, 0.3074, 0.0231, 1.7695, 0.8964, 0.4556,
        0.0138, 0.0303, 0.0135, 0.9279, 0.1689, 0.0177, 1.9946, 0.6977, 0.8000,
        0.0113, 4.6076, 0.6816, 0.0214, 3.7487, 0.8742, 0.0189, 4.7002, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:42:57 A: prod, degr, TonA, NonA
2022-11-29 11:42:57 [0.32725185 0.48842835 0.13296361 0.0513562 ]
2022-11-29 11:42:57 T: prod, degr, AonT, NonT
2022-11-29 11:42:57 [0.34002486 0.52074915 0.09717792 0.04204811]
2022-11-29 11:42:57 N: AonN, TonN, ATonN
2022-11-29 11:42:57 [0.01240431 0.95349437 0.03410126]
2022-11-29 11:42:57 using cpu
2022-11-29 11:42:57 epoch = 30000
2022-11-29 11:42:57 epoch_step = 2000
2022-11-29 11:42:57 model_name = SimpleNetworkAD
2022-11-29 11:42:57 now_string = 2022-11-28-18-17-05
2022-11-29 11:42:57 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:42:57 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:42:57 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:42:57 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:42:57 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:42:57 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:43:36 NUM_SUB: 159;----------------------------
2022-11-29 11:43:36 Epoch [02000/30000] Loss:0.045217 Loss_1:0.044288 Loss_2:0.000493 Loss_3:0.000000 Lr:0.000833 Time:39.264845s (0.65min in total, 9.16min remains)
2022-11-29 11:44:15 NUM_SUB: 159;----------------------------
2022-11-29 11:44:15 Epoch [04000/30000] Loss:0.036818 Loss_1:0.036578 Loss_2:0.000099 Loss_3:0.000000 Lr:0.000714 Time:38.963507s (1.30min in total, 8.47min remains)
2022-11-29 11:44:54 NUM_SUB: 159;----------------------------
2022-11-29 11:44:54 Epoch [06000/30000] Loss:0.023466 Loss_1:0.023263 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000625 Time:38.736535s (1.95min in total, 7.80min remains)
2022-11-29 11:45:33 NUM_SUB: 159;----------------------------
2022-11-29 11:45:33 Epoch [08000/30000] Loss:0.007516 Loss_1:0.007381 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000556 Time:38.692313s (2.59min in total, 7.13min remains)
2022-11-29 11:46:12 NUM_SUB: 159;----------------------------
2022-11-29 11:46:12 Epoch [10000/30000] Loss:0.003595 Loss_1:0.003506 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000500 Time:38.732010s (3.24min in total, 6.48min remains)
2022-11-29 11:46:50 NUM_SUB: 159;----------------------------
2022-11-29 11:46:50 Epoch [12000/30000] Loss:0.002993 Loss_1:0.002940 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:38.778485s (3.89min in total, 5.83min remains)
2022-11-29 11:47:29 NUM_SUB: 159;----------------------------
2022-11-29 11:47:29 Epoch [14000/30000] Loss:0.002550 Loss_1:0.002520 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:38.732203s (4.53min in total, 5.18min remains)
2022-11-29 11:48:08 NUM_SUB: 159;----------------------------
2022-11-29 11:48:08 Epoch [16000/30000] Loss:0.002483 Loss_1:0.002465 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.737976s (5.18min in total, 4.53min remains)
2022-11-29 11:48:47 NUM_SUB: 159;----------------------------
2022-11-29 11:48:47 Epoch [18000/30000] Loss:0.002465 Loss_1:0.002454 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:38.734998s (5.82min in total, 3.88min remains)
2022-11-29 11:49:25 NUM_SUB: 159;----------------------------
2022-11-29 11:49:25 Epoch [20000/30000] Loss:0.002454 Loss_1:0.002447 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000333 Time:38.810322s (6.47min in total, 3.23min remains)
2022-11-29 11:50:04 NUM_SUB: 159;----------------------------
2022-11-29 11:50:04 Epoch [22000/30000] Loss:0.002451 Loss_1:0.002446 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.699613s (7.11min in total, 2.59min remains)
2022-11-29 11:50:43 NUM_SUB: 159;----------------------------
2022-11-29 11:50:43 Epoch [24000/30000] Loss:0.002450 Loss_1:0.002447 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.648674s (7.76min in total, 1.94min remains)
2022-11-29 11:51:21 NUM_SUB: 159;----------------------------
2022-11-29 11:51:21 Epoch [26000/30000] Loss:0.002449 Loss_1:0.002446 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.418494s (8.40min in total, 1.29min remains)
2022-11-29 11:52:00 NUM_SUB: 159;----------------------------
2022-11-29 11:52:00 Epoch [28000/30000] Loss:0.002452 Loss_1:0.002445 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:39.160284s (9.05min in total, 0.65min remains)
2022-11-29 11:52:39 Testing & drawing...
2022-11-29 11:52:39 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:52:40 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=159/
2022-11-29 11:52:40 [Loss]
2022-11-29 11:52:40 NUM_SUB: 159; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:52:40 NUM_SUB: 159; Personalized parameter estimation: Parameter containing:
tensor([0.0597, 0.2934, 0.0105, 0.4544, 0.3074, 0.2427, 0.8625, 0.8964, 0.4556,
        0.0126, 0.0408, 0.0103, 0.5850, 0.1689, 0.0175, 1.5217, 0.6977, 0.8000,
        0.0117, 4.2531, 0.6816, 0.0221, 3.6146, 0.8742, 0.0202, 4.5248, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:52:40 NUM_SUB: 159;----------------------------
2022-11-29 11:52:40 Epoch [30000/30000] Loss:0.002448 Loss_1:0.002446 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.182201s (9.72min in total, 0.00min remains)
2022-11-29 11:52:40 NUM_SUB: 159------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 11:52:40 Testing & drawing...
2022-11-29 11:52:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 11:52:42 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=159/
2022-11-29 11:52:42 [Loss]
2022-11-29 11:52:42 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 11:52:42 General parameter estimation: Parameter containing:
tensor([0.0597, 0.2934, 0.0105, 0.4544, 0.3074, 0.2427, 0.8625, 0.8964, 0.4556,
        0.0126, 0.0408, 0.0103, 0.5850, 0.1689, 0.0175, 1.5217, 0.6977, 0.8000,
        0.0117, 4.2532, 0.6816, 0.0221, 3.6148, 0.8742, 0.0202, 4.5250, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 11:52:42 A: prod, degr, TonA, NonA
2022-11-29 11:52:42 [0.2068978  0.49891964 0.01828288 0.27589968]
2022-11-29 11:52:42 T: prod, degr, AonT, NonT
2022-11-29 11:52:42 [0.32481715 0.5145026  0.09984329 0.06083698]
2022-11-29 11:52:42 N: AonN, TonN, ATonN
2022-11-29 11:52:42 [0.0076893  0.9706071  0.02170356]
2022-11-29 11:52:42 using cpu
2022-11-29 11:52:42 epoch = 30000
2022-11-29 11:52:42 epoch_step = 2000
2022-11-29 11:52:42 model_name = SimpleNetworkAD
2022-11-29 11:52:42 now_string = 2022-11-28-18-17-05
2022-11-29 11:52:42 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 11:52:42 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 11:52:42 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 11:52:42 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 11:52:42 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 11:52:42 --------------------------------------------------training start--------------------------------------------------
2022-11-29 11:53:20 NUM_SUB: 160;----------------------------
2022-11-29 11:53:20 Epoch [02000/30000] Loss:0.027276 Loss_1:0.026256 Loss_2:0.000526 Loss_3:0.000000 Lr:0.000833 Time:38.209412s (0.64min in total, 8.92min remains)
2022-11-29 11:53:59 NUM_SUB: 160;----------------------------
2022-11-29 11:53:59 Epoch [04000/30000] Loss:0.022397 Loss_1:0.022138 Loss_2:0.000085 Loss_3:0.000000 Lr:0.000714 Time:38.303366s (1.28min in total, 8.29min remains)
2022-11-29 11:54:37 NUM_SUB: 160;----------------------------
2022-11-29 11:54:37 Epoch [06000/30000] Loss:0.016062 Loss_1:0.015824 Loss_2:0.000086 Loss_3:0.000000 Lr:0.000625 Time:38.349860s (1.91min in total, 7.66min remains)
2022-11-29 11:55:15 NUM_SUB: 160;----------------------------
2022-11-29 11:55:15 Epoch [08000/30000] Loss:0.007725 Loss_1:0.007576 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000556 Time:38.257665s (2.55min in total, 7.02min remains)
2022-11-29 11:55:54 NUM_SUB: 160;----------------------------
2022-11-29 11:55:54 Epoch [10000/30000] Loss:0.004267 Loss_1:0.004168 Loss_2:0.000097 Loss_3:0.000000 Lr:0.000500 Time:38.375724s (3.19min in total, 6.38min remains)
2022-11-29 11:56:32 NUM_SUB: 160;----------------------------
2022-11-29 11:56:32 Epoch [12000/30000] Loss:0.003763 Loss_1:0.003708 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000455 Time:38.211352s (3.83min in total, 5.74min remains)
2022-11-29 11:57:10 NUM_SUB: 160;----------------------------
2022-11-29 11:57:10 Epoch [14000/30000] Loss:0.003241 Loss_1:0.003211 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000417 Time:38.387350s (4.47min in total, 5.11min remains)
2022-11-29 11:57:49 NUM_SUB: 160;----------------------------
2022-11-29 11:57:49 Epoch [16000/30000] Loss:0.003065 Loss_1:0.003045 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:38.266297s (5.11min in total, 4.47min remains)
2022-11-29 11:58:27 NUM_SUB: 160;----------------------------
2022-11-29 11:58:27 Epoch [18000/30000] Loss:0.003014 Loss_1:0.003001 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.184529s (5.74min in total, 3.83min remains)
2022-11-29 11:59:05 NUM_SUB: 160;----------------------------
2022-11-29 11:59:05 Epoch [20000/30000] Loss:0.003009 Loss_1:0.003000 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.255721s (6.38min in total, 3.19min remains)
2022-11-29 11:59:43 NUM_SUB: 160;----------------------------
2022-11-29 11:59:43 Epoch [22000/30000] Loss:0.003007 Loss_1:0.002999 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.287714s (7.02min in total, 2.55min remains)
2022-11-29 12:00:22 NUM_SUB: 160;----------------------------
2022-11-29 12:00:22 Epoch [24000/30000] Loss:0.003006 Loss_1:0.003001 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.187316s (7.65min in total, 1.91min remains)
2022-11-29 12:01:00 NUM_SUB: 160;----------------------------
2022-11-29 12:01:00 Epoch [26000/30000] Loss:0.003006 Loss_1:0.003002 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.576235s (8.30min in total, 1.28min remains)
2022-11-29 12:01:38 NUM_SUB: 160;----------------------------
2022-11-29 12:01:38 Epoch [28000/30000] Loss:0.003004 Loss_1:0.003000 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.227531s (8.93min in total, 0.64min remains)
2022-11-29 12:02:18 Testing & drawing...
2022-11-29 12:02:18 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:02:19 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=160/
2022-11-29 12:02:19 [Loss]
2022-11-29 12:02:19 NUM_SUB: 160; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:02:19 NUM_SUB: 160; Personalized parameter estimation: Parameter containing:
tensor([0.2904, 0.6194, 0.0135, 0.5056, 0.3074, 0.2482, 0.7893, 0.8964, 0.4556,
        0.0138, 0.0272, 0.0136, 0.9684, 0.1689, 0.0176, 2.0861, 0.6977, 0.8000,
        0.0101, 4.4806, 0.6816, 0.0195, 4.0463, 0.8742, 0.0195, 4.8691, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:02:19 NUM_SUB: 160;----------------------------
2022-11-29 12:02:19 Epoch [30000/30000] Loss:0.003003 Loss_1:0.002999 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:41.058414s (9.62min in total, 0.00min remains)
2022-11-29 12:02:19 NUM_SUB: 160------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 12:02:19 Testing & drawing...
2022-11-29 12:02:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:02:21 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=160/
2022-11-29 12:02:21 [Loss]
2022-11-29 12:02:21 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:02:21 General parameter estimation: Parameter containing:
tensor([0.2904, 0.6194, 0.0135, 0.5056, 0.3074, 0.2482, 0.7893, 0.8964, 0.4556,
        0.0138, 0.0272, 0.0136, 0.9684, 0.1689, 0.0176, 2.0862, 0.6977, 0.8000,
        0.0101, 4.4808, 0.6816, 0.0195, 4.0465, 0.8742, 0.0195, 4.8693, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:02:21 A: prod, degr, TonA, NonA
2022-11-29 12:02:21 [0.43240082 0.49978498 0.01193067 0.05588356]
2022-11-29 12:02:21 T: prod, degr, AonT, NonT
2022-11-29 12:02:21 [0.41929615 0.44881475 0.11853773 0.01335132]
2022-11-29 12:02:21 N: AonN, TonN, ATonN
2022-11-29 12:02:21 [0.00775392 0.9635017  0.02874436]
2022-11-29 12:02:21 using cpu
2022-11-29 12:02:21 epoch = 30000
2022-11-29 12:02:21 epoch_step = 2000
2022-11-29 12:02:21 model_name = SimpleNetworkAD
2022-11-29 12:02:21 now_string = 2022-11-28-18-17-05
2022-11-29 12:02:21 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 12:02:21 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 12:02:21 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 12:02:21 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 12:02:21 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 12:02:21 --------------------------------------------------training start--------------------------------------------------
2022-11-29 12:03:00 NUM_SUB: 161;----------------------------
2022-11-29 12:03:00 Epoch [02000/30000] Loss:0.062487 Loss_1:0.061570 Loss_2:0.000451 Loss_3:0.000000 Lr:0.000833 Time:38.332946s (0.64min in total, 8.94min remains)
2022-11-29 12:03:38 NUM_SUB: 161;----------------------------
2022-11-29 12:03:38 Epoch [04000/30000] Loss:0.048912 Loss_1:0.048635 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000714 Time:38.359741s (1.28min in total, 8.31min remains)
2022-11-29 12:04:16 NUM_SUB: 161;----------------------------
2022-11-29 12:04:16 Epoch [06000/30000] Loss:0.026343 Loss_1:0.026130 Loss_2:0.000057 Loss_3:0.000000 Lr:0.000625 Time:38.242138s (1.92min in total, 7.66min remains)
2022-11-29 12:04:55 NUM_SUB: 161;----------------------------
2022-11-29 12:04:55 Epoch [08000/30000] Loss:0.009217 Loss_1:0.009105 Loss_2:0.000061 Loss_3:0.000000 Lr:0.000556 Time:38.353726s (2.55min in total, 7.03min remains)
2022-11-29 12:05:33 NUM_SUB: 161;----------------------------
2022-11-29 12:05:33 Epoch [10000/30000] Loss:0.005458 Loss_1:0.005381 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000500 Time:38.730280s (3.20min in total, 6.40min remains)
2022-11-29 12:06:12 NUM_SUB: 161;----------------------------
2022-11-29 12:06:12 Epoch [12000/30000] Loss:0.005008 Loss_1:0.004957 Loss_2:0.000047 Loss_3:0.000000 Lr:0.000455 Time:38.535258s (3.84min in total, 5.76min remains)
2022-11-29 12:06:50 NUM_SUB: 161;----------------------------
2022-11-29 12:06:50 Epoch [14000/30000] Loss:0.004714 Loss_1:0.004693 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000417 Time:38.300225s (4.48min in total, 5.12min remains)
2022-11-29 12:07:28 NUM_SUB: 161;----------------------------
2022-11-29 12:07:28 Epoch [16000/30000] Loss:0.004613 Loss_1:0.004599 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000385 Time:38.292509s (5.12min in total, 4.48min remains)
2022-11-29 12:08:07 NUM_SUB: 161;----------------------------
2022-11-29 12:08:07 Epoch [18000/30000] Loss:0.004615 Loss_1:0.004608 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000357 Time:38.259780s (5.76min in total, 3.84min remains)
2022-11-29 12:08:45 NUM_SUB: 161;----------------------------
2022-11-29 12:08:45 Epoch [20000/30000] Loss:0.004578 Loss_1:0.004572 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:38.428854s (6.40min in total, 3.20min remains)
2022-11-29 12:09:23 NUM_SUB: 161;----------------------------
2022-11-29 12:09:23 Epoch [22000/30000] Loss:0.004538 Loss_1:0.004534 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.336388s (7.04min in total, 2.56min remains)
2022-11-29 12:10:02 NUM_SUB: 161;----------------------------
2022-11-29 12:10:02 Epoch [24000/30000] Loss:0.004533 Loss_1:0.004531 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000294 Time:38.387372s (7.68min in total, 1.92min remains)
2022-11-29 12:10:40 NUM_SUB: 161;----------------------------
2022-11-29 12:10:40 Epoch [26000/30000] Loss:0.004532 Loss_1:0.004530 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:38.295629s (8.31min in total, 1.28min remains)
2022-11-29 12:11:18 NUM_SUB: 161;----------------------------
2022-11-29 12:11:18 Epoch [28000/30000] Loss:0.004533 Loss_1:0.004532 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.341371s (8.95min in total, 0.64min remains)
2022-11-29 12:11:57 Testing & drawing...
2022-11-29 12:11:57 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:11:58 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=161/
2022-11-29 12:11:58 [Loss]
2022-11-29 12:11:58 NUM_SUB: 161; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:11:58 NUM_SUB: 161; Personalized parameter estimation: Parameter containing:
tensor([0.3668, 0.9158, 0.0101, 0.0077, 0.3074, 0.0123, 0.9754, 0.8964, 0.4556,
        0.0135, 0.0308, 0.0131, 0.8734, 0.1689, 0.0177, 1.9457, 0.6977, 0.8000,
        0.0117, 3.3436, 0.6816, 0.0226, 2.9780, 0.8742, 0.0213, 3.7664, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:11:59 NUM_SUB: 161;----------------------------
2022-11-29 12:11:59 Epoch [30000/30000] Loss:0.004532 Loss_1:0.004530 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.039311s (9.62min in total, 0.00min remains)
2022-11-29 12:11:59 NUM_SUB: 161------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 12:11:59 Testing & drawing...
2022-11-29 12:11:59 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:12:00 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=161/
2022-11-29 12:12:00 [Loss]
2022-11-29 12:12:00 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:12:00 General parameter estimation: Parameter containing:
tensor([0.3669, 0.9158, 0.0101, 0.0077, 0.3074, 0.0123, 0.9755, 0.8964, 0.4556,
        0.0135, 0.0308, 0.0131, 0.8734, 0.1689, 0.0177, 1.9458, 0.6977, 0.8000,
        0.0117, 3.3436, 0.6816, 0.0226, 2.9780, 0.8742, 0.0213, 3.7664, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:12:00 A: prod, degr, TonA, NonA
2022-11-29 12:12:00 [0.48089862 0.49998054 0.01326308 0.00585775]
2022-11-29 12:12:00 T: prod, degr, AonT, NonT
2022-11-29 12:12:00 [0.41224018 0.39292732 0.12659204 0.06824047]
2022-11-29 12:12:00 N: AonN, TonN, ATonN
2022-11-29 12:12:00 [0.0082082  0.95627767 0.03551415]
2022-11-29 12:12:00 using cpu
2022-11-29 12:12:00 epoch = 30000
2022-11-29 12:12:00 epoch_step = 2000
2022-11-29 12:12:00 model_name = SimpleNetworkAD
2022-11-29 12:12:00 now_string = 2022-11-28-18-17-05
2022-11-29 12:12:00 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 12:12:00 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 12:12:00 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 12:12:00 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 12:12:00 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 12:12:00 --------------------------------------------------training start--------------------------------------------------
2022-11-29 12:12:39 NUM_SUB: 162;----------------------------
2022-11-29 12:12:39 Epoch [02000/30000] Loss:0.070216 Loss_1:0.069309 Loss_2:0.000463 Loss_3:0.000000 Lr:0.000833 Time:38.372811s (0.64min in total, 8.95min remains)
2022-11-29 12:13:17 NUM_SUB: 162;----------------------------
2022-11-29 12:13:17 Epoch [04000/30000] Loss:0.055404 Loss_1:0.055001 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000714 Time:38.294613s (1.28min in total, 8.31min remains)
2022-11-29 12:13:56 NUM_SUB: 162;----------------------------
2022-11-29 12:13:56 Epoch [06000/30000] Loss:0.030158 Loss_1:0.029723 Loss_2:0.000259 Loss_3:0.000000 Lr:0.000625 Time:38.807418s (1.92min in total, 7.70min remains)
2022-11-29 12:14:34 NUM_SUB: 162;----------------------------
2022-11-29 12:14:34 Epoch [08000/30000] Loss:0.008777 Loss_1:0.008559 Loss_2:0.000159 Loss_3:0.000000 Lr:0.000556 Time:38.280840s (2.56min in total, 7.05min remains)
2022-11-29 12:15:13 NUM_SUB: 162;----------------------------
2022-11-29 12:15:13 Epoch [10000/30000] Loss:0.002947 Loss_1:0.002824 Loss_2:0.000121 Loss_3:0.000000 Lr:0.000500 Time:38.469048s (3.20min in total, 6.41min remains)
2022-11-29 12:15:51 NUM_SUB: 162;----------------------------
2022-11-29 12:15:51 Epoch [12000/30000] Loss:0.002135 Loss_1:0.002077 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000455 Time:38.316932s (3.84min in total, 5.76min remains)
2022-11-29 12:16:29 NUM_SUB: 162;----------------------------
2022-11-29 12:16:29 Epoch [14000/30000] Loss:0.001743 Loss_1:0.001706 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000417 Time:38.331577s (4.48min in total, 5.12min remains)
2022-11-29 12:17:07 NUM_SUB: 162;----------------------------
2022-11-29 12:17:07 Epoch [16000/30000] Loss:0.001783 Loss_1:0.001758 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000385 Time:38.312295s (5.12min in total, 4.48min remains)
2022-11-29 12:17:46 NUM_SUB: 162;----------------------------
2022-11-29 12:17:46 Epoch [18000/30000] Loss:0.001658 Loss_1:0.001642 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000357 Time:38.368661s (5.76min in total, 3.84min remains)
2022-11-29 12:18:24 NUM_SUB: 162;----------------------------
2022-11-29 12:18:24 Epoch [20000/30000] Loss:0.001563 Loss_1:0.001552 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:38.345111s (6.40min in total, 3.20min remains)
2022-11-29 12:19:02 NUM_SUB: 162;----------------------------
2022-11-29 12:19:02 Epoch [22000/30000] Loss:0.001499 Loss_1:0.001491 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.286711s (7.04min in total, 2.56min remains)
2022-11-29 12:19:41 NUM_SUB: 162;----------------------------
2022-11-29 12:19:41 Epoch [24000/30000] Loss:0.001495 Loss_1:0.001487 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.404951s (7.68min in total, 1.92min remains)
2022-11-29 12:39:50 NUM_SUB: 162;----------------------------
2022-11-29 12:39:50 Epoch [26000/30000] Loss:0.001525 Loss_1:0.001518 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:1209.298416s (27.83min in total, 4.28min remains)
2022-11-29 12:42:18 NUM_SUB: 162;----------------------------
2022-11-29 12:42:18 Epoch [28000/30000] Loss:0.001492 Loss_1:0.001485 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000263 Time:147.333437s (30.29min in total, 2.16min remains)
2022-11-29 12:42:56 Testing & drawing...
2022-11-29 12:42:56 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:42:58 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=162/
2022-11-29 12:42:58 [Loss]
2022-11-29 12:42:58 NUM_SUB: 162; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:42:58 NUM_SUB: 162; Personalized parameter estimation: Parameter containing:
tensor([0.0159, 0.0396, 0.0101, 1.7633, 0.3074, 0.0166, 1.6390, 0.8964, 0.4556,
        0.0139, 0.0280, 0.0141, 0.8898, 0.1689, 0.0175, 2.2532, 0.6977, 0.8000,
        0.0123, 3.0684, 0.6816, 0.0224, 2.8110, 0.8742, 0.0215, 3.5196, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:42:58 NUM_SUB: 162;----------------------------
2022-11-29 12:42:58 Epoch [30000/30000] Loss:0.001491 Loss_1:0.001485 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:40.122439s (30.96min in total, 0.00min remains)
2022-11-29 12:42:58 NUM_SUB: 162------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 12:42:58 Testing & drawing...
2022-11-29 12:42:58 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:42:59 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=162/
2022-11-29 12:42:59 [Loss]
2022-11-29 12:42:59 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:42:59 General parameter estimation: Parameter containing:
tensor([0.0159, 0.0396, 0.0101, 1.7633, 0.3074, 0.0166, 1.6390, 0.8964, 0.4556,
        0.0139, 0.0280, 0.0141, 0.8899, 0.1689, 0.0175, 2.2533, 0.6977, 0.8000,
        0.0123, 3.0683, 0.6816, 0.0224, 2.8109, 0.8742, 0.0215, 3.5196, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:42:59 A: prod, degr, TonA, NonA
2022-11-29 12:42:59 [0.40808788 0.47656354 0.0336972  0.08165138]
2022-11-29 12:42:59 T: prod, degr, AonT, NonT
2022-11-29 12:42:59 [0.40652987 0.3850949  0.15028515 0.05809003]
2022-11-29 12:42:59 N: AonN, TonN, ATonN
2022-11-29 12:42:59 [0.01341105 0.93438035 0.05220852]
2022-11-29 12:42:59 using cpu
2022-11-29 12:42:59 epoch = 30000
2022-11-29 12:42:59 epoch_step = 2000
2022-11-29 12:42:59 model_name = SimpleNetworkAD
2022-11-29 12:42:59 now_string = 2022-11-28-18-17-05
2022-11-29 12:42:59 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 12:42:59 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 12:42:59 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 12:42:59 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 12:42:59 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 12:42:59 --------------------------------------------------training start--------------------------------------------------
2022-11-29 12:43:38 NUM_SUB: 163;----------------------------
2022-11-29 12:43:38 Epoch [02000/30000] Loss:0.043721 Loss_1:0.042547 Loss_2:0.000744 Loss_3:0.000000 Lr:0.000833 Time:38.528093s (0.64min in total, 8.99min remains)
2022-11-29 12:44:16 NUM_SUB: 163;----------------------------
2022-11-29 12:44:16 Epoch [04000/30000] Loss:0.032578 Loss_1:0.032246 Loss_2:0.000211 Loss_3:0.000000 Lr:0.000714 Time:38.439646s (1.28min in total, 8.34min remains)
2022-11-29 12:44:55 NUM_SUB: 163;----------------------------
2022-11-29 12:44:55 Epoch [06000/30000] Loss:0.015085 Loss_1:0.014845 Loss_2:0.000167 Loss_3:0.000000 Lr:0.000625 Time:38.494558s (1.92min in total, 7.70min remains)
2022-11-29 12:45:33 NUM_SUB: 163;----------------------------
2022-11-29 12:45:33 Epoch [08000/30000] Loss:0.002622 Loss_1:0.002466 Loss_2:0.000144 Loss_3:0.000000 Lr:0.000556 Time:38.509208s (2.57min in total, 7.06min remains)
2022-11-29 12:46:12 NUM_SUB: 163;----------------------------
2022-11-29 12:46:12 Epoch [10000/30000] Loss:0.001685 Loss_1:0.001591 Loss_2:0.000092 Loss_3:0.000000 Lr:0.000500 Time:38.455492s (3.21min in total, 6.41min remains)
2022-11-29 12:46:50 NUM_SUB: 163;----------------------------
2022-11-29 12:46:50 Epoch [12000/30000] Loss:0.001317 Loss_1:0.001261 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000455 Time:38.517055s (3.85min in total, 5.77min remains)
2022-11-29 12:47:29 NUM_SUB: 163;----------------------------
2022-11-29 12:47:29 Epoch [14000/30000] Loss:0.000665 Loss_1:0.000638 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:38.511914s (4.49min in total, 5.13min remains)
2022-11-29 12:48:07 NUM_SUB: 163;----------------------------
2022-11-29 12:48:07 Epoch [16000/30000] Loss:0.000254 Loss_1:0.000214 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.491928s (5.13min in total, 4.49min remains)
2022-11-29 12:48:46 NUM_SUB: 163;----------------------------
2022-11-29 12:48:46 Epoch [18000/30000] Loss:0.000168 Loss_1:0.000159 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.630411s (5.78min in total, 3.85min remains)
2022-11-29 12:49:25 NUM_SUB: 163;----------------------------
2022-11-29 12:49:25 Epoch [20000/30000] Loss:0.000159 Loss_1:0.000154 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.596211s (6.42min in total, 3.21min remains)
2022-11-29 12:50:03 NUM_SUB: 163;----------------------------
2022-11-29 12:50:03 Epoch [22000/30000] Loss:0.000193 Loss_1:0.000189 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:38.521774s (7.06min in total, 2.57min remains)
2022-11-29 12:50:42 NUM_SUB: 163;----------------------------
2022-11-29 12:50:42 Epoch [24000/30000] Loss:0.000148 Loss_1:0.000146 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.538931s (7.70min in total, 1.93min remains)
2022-11-29 12:51:20 NUM_SUB: 163;----------------------------
2022-11-29 12:51:20 Epoch [26000/30000] Loss:0.000150 Loss_1:0.000148 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.577409s (8.35min in total, 1.28min remains)
2022-11-29 12:51:59 NUM_SUB: 163;----------------------------
2022-11-29 12:51:59 Epoch [28000/30000] Loss:0.000139 Loss_1:0.000137 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.464213s (8.99min in total, 0.64min remains)
2022-11-29 12:52:37 Testing & drawing...
2022-11-29 12:52:37 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:52:39 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=163/
2022-11-29 12:52:39 [Loss]
2022-11-29 12:52:39 NUM_SUB: 163; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:52:39 NUM_SUB: 163; Personalized parameter estimation: Parameter containing:
tensor([0.0183, 0.0351, 0.0311, 0.5844, 0.3074, 0.0138, 2.7528, 0.8964, 0.4556,
        0.0136, 0.1126, 0.1212, 0.7036, 0.1689, 0.0177, 1.0156, 0.6977, 0.8000,
        0.0095, 4.9877, 0.6816, 0.0093, 3.2803, 0.8742, 0.0153, 4.8910, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:52:39 NUM_SUB: 163;----------------------------
2022-11-29 12:52:39 Epoch [30000/30000] Loss:0.000134 Loss_1:0.000133 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.274989s (9.66min in total, 0.00min remains)
2022-11-29 12:52:39 NUM_SUB: 163------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 12:52:39 Testing & drawing...
2022-11-29 12:52:39 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 12:52:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=163/
2022-11-29 12:52:41 [Loss]
2022-11-29 12:52:41 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 12:52:41 General parameter estimation: Parameter containing:
tensor([0.0183, 0.0351, 0.0311, 0.5844, 0.3074, 0.0138, 2.7529, 0.8964, 0.4556,
        0.0136, 0.1126, 0.1212, 0.7036, 0.1689, 0.0177, 1.0156, 0.6977, 0.8000,
        0.0095, 4.9878, 0.6816, 0.0093, 3.2804, 0.8742, 0.0153, 4.8911, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 12:52:41 A: prod, degr, TonA, NonA
2022-11-29 12:52:41 [0.3075205  0.481211   0.20114724 0.01012126]
2022-11-29 12:52:41 T: prod, degr, AonT, NonT
2022-11-29 12:52:41 [0.09371715 0.6255071  0.2501698  0.03060587]
2022-11-29 12:52:41 N: AonN, TonN, ATonN
2022-11-29 12:52:41 [0.02882773 0.90677077 0.06440149]
2022-11-29 12:52:41 using cpu
2022-11-29 12:52:41 epoch = 30000
2022-11-29 12:52:41 epoch_step = 2000
2022-11-29 12:52:41 model_name = SimpleNetworkAD
2022-11-29 12:52:41 now_string = 2022-11-28-18-17-05
2022-11-29 12:52:41 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 12:52:41 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 12:52:41 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 12:52:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 12:52:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 12:52:41 --------------------------------------------------training start--------------------------------------------------
2022-11-29 12:53:19 NUM_SUB: 164;----------------------------
2022-11-29 12:53:19 Epoch [02000/30000] Loss:0.036168 Loss_1:0.035153 Loss_2:0.000565 Loss_3:0.000000 Lr:0.000833 Time:38.533458s (0.64min in total, 8.99min remains)
2022-11-29 12:53:58 NUM_SUB: 164;----------------------------
2022-11-29 12:53:58 Epoch [04000/30000] Loss:0.029553 Loss_1:0.029300 Loss_2:0.000098 Loss_3:0.000000 Lr:0.000714 Time:38.424887s (1.28min in total, 8.34min remains)
2022-11-29 12:54:36 NUM_SUB: 164;----------------------------
2022-11-29 12:54:36 Epoch [06000/30000] Loss:0.019652 Loss_1:0.019447 Loss_2:0.000082 Loss_3:0.000000 Lr:0.000625 Time:38.399462s (1.92min in total, 7.69min remains)
2022-11-29 12:55:14 NUM_SUB: 164;----------------------------
2022-11-29 12:55:14 Epoch [08000/30000] Loss:0.007035 Loss_1:0.006914 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000556 Time:38.294679s (2.56min in total, 7.04min remains)
2022-11-29 12:55:53 NUM_SUB: 164;----------------------------
2022-11-29 12:55:53 Epoch [10000/30000] Loss:0.002761 Loss_1:0.002676 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000500 Time:38.530024s (3.20min in total, 6.41min remains)
2022-11-29 12:56:31 NUM_SUB: 164;----------------------------
2022-11-29 12:56:31 Epoch [12000/30000] Loss:0.001928 Loss_1:0.001877 Loss_2:0.000051 Loss_3:0.000000 Lr:0.000455 Time:38.370567s (3.84min in total, 5.76min remains)
2022-11-29 12:57:10 NUM_SUB: 164;----------------------------
2022-11-29 12:57:10 Epoch [14000/30000] Loss:0.000738 Loss_1:0.000708 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000417 Time:38.362978s (4.48min in total, 5.12min remains)
2022-11-29 12:57:48 NUM_SUB: 164;----------------------------
2022-11-29 12:57:48 Epoch [16000/30000] Loss:0.000629 Loss_1:0.000611 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000385 Time:38.445397s (5.12min in total, 4.48min remains)
2022-11-29 12:58:27 NUM_SUB: 164;----------------------------
2022-11-29 12:58:27 Epoch [18000/30000] Loss:0.000620 Loss_1:0.000610 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000357 Time:38.499684s (5.76min in total, 3.84min remains)
2022-11-29 12:59:05 NUM_SUB: 164;----------------------------
2022-11-29 12:59:05 Epoch [20000/30000] Loss:0.000615 Loss_1:0.000609 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.449671s (6.41min in total, 3.20min remains)
2022-11-29 12:59:44 NUM_SUB: 164;----------------------------
2022-11-29 12:59:44 Epoch [22000/30000] Loss:0.000611 Loss_1:0.000608 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000313 Time:38.462498s (7.05min in total, 2.56min remains)
2022-11-29 13:00:22 NUM_SUB: 164;----------------------------
2022-11-29 13:00:22 Epoch [24000/30000] Loss:0.000608 Loss_1:0.000606 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.462798s (7.69min in total, 1.92min remains)
2022-11-29 13:01:00 NUM_SUB: 164;----------------------------
2022-11-29 13:01:00 Epoch [26000/30000] Loss:0.000605 Loss_1:0.000603 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.431286s (8.33min in total, 1.28min remains)
2022-11-29 13:01:39 NUM_SUB: 164;----------------------------
2022-11-29 13:01:39 Epoch [28000/30000] Loss:0.000602 Loss_1:0.000601 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:38.518725s (8.97min in total, 0.64min remains)
2022-11-29 13:02:18 Testing & drawing...
2022-11-29 13:02:18 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:02:19 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=164/
2022-11-29 13:02:19 [Loss]
2022-11-29 13:02:19 NUM_SUB: 164; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:02:19 NUM_SUB: 164; Personalized parameter estimation: Parameter containing:
tensor([0.4526, 0.8016, 0.0139, 0.2249, 0.3074, 0.0122, 0.7692, 0.8964, 0.4556,
        0.0140, 0.0266, 0.0136, 0.9786, 0.1689, 0.0175, 2.4645, 0.6977, 0.8000,
        0.0117, 4.2269, 0.6816, 0.0218, 3.8648, 0.8742, 0.0194, 4.6008, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 13:02:19 NUM_SUB: 164;----------------------------
2022-11-29 13:02:19 Epoch [30000/30000] Loss:0.000601 Loss_1:0.000600 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.505956s (9.65min in total, 0.00min remains)
2022-11-29 13:02:19 NUM_SUB: 164------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 13:02:20 Testing & drawing...
2022-11-29 13:02:20 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:02:21 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=164/
2022-11-29 13:02:21 [Loss]
2022-11-29 13:02:21 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:02:21 General parameter estimation: Parameter containing:
tensor([0.4526, 0.8016, 0.0139, 0.2249, 0.3074, 0.0122, 0.7692, 0.8964, 0.4556,
        0.0140, 0.0266, 0.0136, 0.9786, 0.1689, 0.0175, 2.4646, 0.6977, 0.8000,
        0.0117, 4.2269, 0.6816, 0.0218, 3.8648, 0.8742, 0.0194, 4.6008, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 13:02:21 A: prod, degr, TonA, NonA
2022-11-29 13:02:21 [0.4816026  0.49987915 0.01301568 0.00550253]
2022-11-29 13:02:21 T: prod, degr, AonT, NonT
2022-11-29 13:02:21 [0.402459   0.44786474 0.11543516 0.03424112]
2022-11-29 13:02:21 N: AonN, TonN, ATonN
2022-11-29 13:02:21 [0.01049989 0.9576005  0.03189961]
2022-11-29 13:02:21 using cpu
2022-11-29 13:02:21 epoch = 30000
2022-11-29 13:02:21 epoch_step = 2000
2022-11-29 13:02:21 model_name = SimpleNetworkAD
2022-11-29 13:02:21 now_string = 2022-11-28-18-17-05
2022-11-29 13:02:21 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 13:02:21 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 13:02:21 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 13:02:21 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 13:02:21 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 13:02:21 --------------------------------------------------training start--------------------------------------------------
2022-11-29 13:03:00 NUM_SUB: 165;----------------------------
2022-11-29 13:03:00 Epoch [02000/30000] Loss:0.041618 Loss_1:0.040727 Loss_2:0.000398 Loss_3:0.000000 Lr:0.000833 Time:39.046462s (0.65min in total, 9.11min remains)
2022-11-29 13:03:39 NUM_SUB: 165;----------------------------
2022-11-29 13:03:39 Epoch [04000/30000] Loss:0.034623 Loss_1:0.034389 Loss_2:0.000050 Loss_3:0.000000 Lr:0.000714 Time:38.838977s (1.30min in total, 8.44min remains)
2022-11-29 13:04:18 NUM_SUB: 165;----------------------------
2022-11-29 13:04:18 Epoch [06000/30000] Loss:0.023366 Loss_1:0.023119 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000625 Time:38.765677s (1.94min in total, 7.78min remains)
2022-11-29 13:04:57 NUM_SUB: 165;----------------------------
2022-11-29 13:04:57 Epoch [08000/30000] Loss:0.008003 Loss_1:0.007869 Loss_2:0.000063 Loss_3:0.000000 Lr:0.000556 Time:38.864904s (2.59min in total, 7.13min remains)
2022-11-29 13:05:36 NUM_SUB: 165;----------------------------
2022-11-29 13:05:36 Epoch [10000/30000] Loss:0.001844 Loss_1:0.001762 Loss_2:0.000078 Loss_3:0.000000 Lr:0.000500 Time:38.974952s (3.24min in total, 6.48min remains)
2022-11-29 13:06:15 NUM_SUB: 165;----------------------------
2022-11-29 13:06:15 Epoch [12000/30000] Loss:0.001541 Loss_1:0.001496 Loss_2:0.000045 Loss_3:0.000000 Lr:0.000455 Time:39.183555s (3.89min in total, 5.84min remains)
2022-11-29 13:06:54 NUM_SUB: 165;----------------------------
2022-11-29 13:06:54 Epoch [14000/30000] Loss:0.001355 Loss_1:0.001339 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000417 Time:39.295148s (4.55min in total, 5.20min remains)
2022-11-29 13:07:34 NUM_SUB: 165;----------------------------
2022-11-29 13:07:34 Epoch [16000/30000] Loss:0.001335 Loss_1:0.001323 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000385 Time:39.334775s (5.21min in total, 4.55min remains)
2022-11-29 13:08:13 NUM_SUB: 165;----------------------------
2022-11-29 13:08:13 Epoch [18000/30000] Loss:0.001312 Loss_1:0.001307 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:39.239326s (5.86min in total, 3.91min remains)
2022-11-29 13:08:52 NUM_SUB: 165;----------------------------
2022-11-29 13:08:52 Epoch [20000/30000] Loss:0.001310 Loss_1:0.001307 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000333 Time:39.422892s (6.52min in total, 3.26min remains)
2022-11-29 13:09:32 NUM_SUB: 165;----------------------------
2022-11-29 13:09:32 Epoch [22000/30000] Loss:0.001322 Loss_1:0.001318 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000313 Time:39.310315s (7.17min in total, 2.61min remains)
2022-11-29 13:10:10 NUM_SUB: 165;----------------------------
2022-11-29 13:10:10 Epoch [24000/30000] Loss:0.001308 Loss_1:0.001306 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.537314s (7.81min in total, 1.95min remains)
2022-11-29 13:10:49 NUM_SUB: 165;----------------------------
2022-11-29 13:10:49 Epoch [26000/30000] Loss:0.001307 Loss_1:0.001307 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:38.554587s (8.46min in total, 1.30min remains)
2022-11-29 13:11:27 NUM_SUB: 165;----------------------------
2022-11-29 13:11:27 Epoch [28000/30000] Loss:0.001307 Loss_1:0.001307 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.621969s (9.10min in total, 0.65min remains)
2022-11-29 13:12:06 Testing & drawing...
2022-11-29 13:12:06 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:12:08 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=165/
2022-11-29 13:12:08 [Loss]
2022-11-29 13:12:08 NUM_SUB: 165; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:12:08 NUM_SUB: 165; Personalized parameter estimation: Parameter containing:
tensor([0.3091, 0.9412, 0.0095, 0.1348, 0.3074, 0.0086, 0.8359, 0.8964, 0.4556,
        0.0131, 0.0310, 0.0132, 0.8425, 0.1689, 0.0176, 1.3663, 0.6977, 0.8000,
        0.0123, 3.5139, 0.6816, 0.0222, 3.7839, 0.8742, 0.0212, 4.4507, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 13:12:08 NUM_SUB: 165;----------------------------
2022-11-29 13:12:08 Epoch [30000/30000] Loss:0.001307 Loss_1:0.001307 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:40.275212s (9.77min in total, 0.00min remains)
2022-11-29 13:12:08 NUM_SUB: 165------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 13:12:08 Testing & drawing...
2022-11-29 13:12:08 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:12:09 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=165/
2022-11-29 13:12:09 [Loss]
2022-11-29 13:12:09 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:12:09 General parameter estimation: Parameter containing:
tensor([0.3090, 0.9412, 0.0095, 0.1348, 0.3074, 0.0086, 0.8359, 0.8964, 0.4556,
        0.0131, 0.0310, 0.0132, 0.8425, 0.1689, 0.0176, 1.3664, 0.6977, 0.8000,
        0.0123, 3.5140, 0.6816, 0.0222, 3.7840, 0.8742, 0.0212, 4.4507, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 13:12:09 A: prod, degr, TonA, NonA
2022-11-29 13:12:09 [0.4811944  0.50001866 0.01416601 0.00462089]
2022-11-29 13:12:09 T: prod, degr, AonT, NonT
2022-11-29 13:12:09 [0.41746998 0.3384217  0.15133259 0.09277578]
2022-11-29 13:12:09 N: AonN, TonN, ATonN
2022-11-29 13:12:09 [0.00539122 0.96921057 0.0253982 ]
2022-11-29 13:12:09 using cpu
2022-11-29 13:12:09 epoch = 30000
2022-11-29 13:12:09 epoch_step = 2000
2022-11-29 13:12:09 model_name = SimpleNetworkAD
2022-11-29 13:12:09 now_string = 2022-11-28-18-17-05
2022-11-29 13:12:09 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 13:12:09 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 13:12:09 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 13:12:09 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 13:12:09 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 13:12:09 --------------------------------------------------training start--------------------------------------------------
2022-11-29 13:12:48 NUM_SUB: 166;----------------------------
2022-11-29 13:12:48 Epoch [02000/30000] Loss:0.102319 Loss_1:0.101403 Loss_2:0.000489 Loss_3:0.000000 Lr:0.000833 Time:38.647255s (0.64min in total, 9.02min remains)
2022-11-29 13:13:27 NUM_SUB: 166;----------------------------
2022-11-29 13:13:27 Epoch [04000/30000] Loss:0.082178 Loss_1:0.081860 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000714 Time:38.595599s (1.29min in total, 8.37min remains)
2022-11-29 13:14:05 NUM_SUB: 166;----------------------------
2022-11-29 13:14:05 Epoch [06000/30000] Loss:0.040019 Loss_1:0.039755 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000625 Time:38.346235s (1.93min in total, 7.71min remains)
2022-11-29 13:14:44 NUM_SUB: 166;----------------------------
2022-11-29 13:14:44 Epoch [08000/30000] Loss:0.003636 Loss_1:0.003524 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000556 Time:38.648861s (2.57min in total, 7.07min remains)
2022-11-29 13:15:22 NUM_SUB: 166;----------------------------
2022-11-29 13:15:22 Epoch [10000/30000] Loss:0.000564 Loss_1:0.000491 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000500 Time:38.676100s (3.22min in total, 6.43min remains)
2022-11-29 13:16:01 NUM_SUB: 166;----------------------------
2022-11-29 13:16:01 Epoch [12000/30000] Loss:0.000332 Loss_1:0.000295 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000455 Time:38.597328s (3.86min in total, 5.79min remains)
2022-11-29 13:16:39 NUM_SUB: 166;----------------------------
2022-11-29 13:16:39 Epoch [14000/30000] Loss:0.000304 Loss_1:0.000290 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000417 Time:38.429404s (4.50min in total, 5.14min remains)
2022-11-29 13:17:18 NUM_SUB: 166;----------------------------
2022-11-29 13:17:18 Epoch [16000/30000] Loss:0.000295 Loss_1:0.000287 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000385 Time:38.338035s (5.14min in total, 4.50min remains)
2022-11-29 13:17:56 NUM_SUB: 166;----------------------------
2022-11-29 13:17:56 Epoch [18000/30000] Loss:0.000291 Loss_1:0.000287 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000357 Time:38.518932s (5.78min in total, 3.85min remains)
2022-11-29 13:18:35 NUM_SUB: 166;----------------------------
2022-11-29 13:18:35 Epoch [20000/30000] Loss:0.000290 Loss_1:0.000287 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.424639s (6.42min in total, 3.21min remains)
2022-11-29 13:19:13 NUM_SUB: 166;----------------------------
2022-11-29 13:19:13 Epoch [22000/30000] Loss:0.000289 Loss_1:0.000287 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:38.436982s (7.06min in total, 2.57min remains)
2022-11-29 13:19:51 NUM_SUB: 166;----------------------------
2022-11-29 13:19:51 Epoch [24000/30000] Loss:0.000288 Loss_1:0.000287 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:38.417203s (7.70min in total, 1.93min remains)
2022-11-29 13:37:51 NUM_SUB: 166;----------------------------
2022-11-29 13:37:51 Epoch [26000/30000] Loss:0.000288 Loss_1:0.000287 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000278 Time:1079.630518s (25.70min in total, 3.95min remains)
2022-11-29 13:38:29 NUM_SUB: 166;----------------------------
2022-11-29 13:38:29 Epoch [28000/30000] Loss:0.000288 Loss_1:0.000287 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000263 Time:38.371965s (26.33min in total, 1.88min remains)
2022-11-29 13:54:37 Testing & drawing...
2022-11-29 13:54:37 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:54:38 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=166/
2022-11-29 13:54:38 [Loss]
2022-11-29 13:54:38 NUM_SUB: 166; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:54:38 NUM_SUB: 166; Personalized parameter estimation: Parameter containing:
tensor([4.0017e-01, 8.8193e-01, 1.0588e-02, 5.8121e-15, 3.0742e-01, 7.6457e-03,
        6.4993e-01, 8.9644e-01, 4.5563e-01, 1.2922e-02, 4.5759e-02, 1.0685e-02,
        6.0720e-01, 1.6886e-01, 1.7601e-02, 1.6012e+00, 6.9767e-01, 8.0001e-01,
        1.0084e-02, 3.8569e+00, 6.8161e-01, 2.2510e-02, 3.3423e+00, 8.7416e-01,
        2.0658e-02, 4.2023e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 13:54:38 NUM_SUB: 166;----------------------------
2022-11-29 13:54:38 Epoch [30000/30000] Loss:0.000288 Loss_1:0.000288 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:968.888158s (42.48min in total, 0.00min remains)
2022-11-29 13:54:38 NUM_SUB: 166------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 13:54:38 Testing & drawing...
2022-11-29 13:54:38 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 13:54:40 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=166/
2022-11-29 13:54:40 [Loss]
2022-11-29 13:54:40 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 13:54:40 General parameter estimation: Parameter containing:
tensor([4.0019e-01, 8.8191e-01, 1.0588e-02, 5.7215e-15, 3.0742e-01, 7.6638e-03,
        6.4992e-01, 8.9644e-01, 4.5563e-01, 1.2922e-02, 4.5752e-02, 1.0685e-02,
        6.0722e-01, 1.6886e-01, 1.7601e-02, 1.6013e+00, 6.9767e-01, 8.0001e-01,
        1.0084e-02, 3.8570e+00, 6.8161e-01, 2.2510e-02, 3.3424e+00, 8.7416e-01,
        2.0658e-02, 4.2024e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 13:54:40 A: prod, degr, TonA, NonA
2022-11-29 13:54:40 [0.4811781  0.49987653 0.01273101 0.00621435]
2022-11-29 13:54:40 T: prod, degr, AonT, NonT
2022-11-29 13:54:40 [0.30164093 0.50344634 0.09016043 0.10475229]
2022-11-29 13:54:40 N: AonN, TonN, ATonN
2022-11-29 13:54:40 [0.00726284 0.9686243  0.02411289]
2022-11-29 13:54:40 using cpu
2022-11-29 13:54:40 epoch = 30000
2022-11-29 13:54:40 epoch_step = 2000
2022-11-29 13:54:40 model_name = SimpleNetworkAD
2022-11-29 13:54:40 now_string = 2022-11-28-18-17-05
2022-11-29 13:54:40 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 13:54:40 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 13:54:40 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 13:54:40 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 13:54:40 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 13:54:40 --------------------------------------------------training start--------------------------------------------------
2022-11-29 14:10:34 NUM_SUB: 167;----------------------------
2022-11-29 14:10:34 Epoch [02000/30000] Loss:0.071627 Loss_1:0.070893 Loss_2:0.000333 Loss_3:0.000000 Lr:0.000833 Time:953.593067s (15.89min in total, 222.51min remains)
2022-11-29 14:18:14 NUM_SUB: 167;----------------------------
2022-11-29 14:18:14 Epoch [04000/30000] Loss:0.052046 Loss_1:0.051837 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000714 Time:460.328601s (23.57min in total, 153.17min remains)
2022-11-29 14:18:52 NUM_SUB: 167;----------------------------
2022-11-29 14:18:52 Epoch [06000/30000] Loss:0.019335 Loss_1:0.019211 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000625 Time:38.254698s (24.20min in total, 96.81min remains)
2022-11-29 14:20:11 NUM_SUB: 167;----------------------------
2022-11-29 14:20:11 Epoch [08000/30000] Loss:0.003917 Loss_1:0.003877 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000556 Time:78.558848s (25.51min in total, 70.16min remains)
2022-11-29 14:21:11 NUM_SUB: 167;----------------------------
2022-11-29 14:21:11 Epoch [10000/30000] Loss:0.003266 Loss_1:0.003215 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000500 Time:60.193815s (26.52min in total, 53.03min remains)
2022-11-29 14:22:13 NUM_SUB: 167;----------------------------
2022-11-29 14:22:13 Epoch [12000/30000] Loss:0.002475 Loss_1:0.002463 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000455 Time:61.571174s (27.54min in total, 41.31min remains)
2022-11-29 14:23:14 NUM_SUB: 167;----------------------------
2022-11-29 14:23:14 Epoch [14000/30000] Loss:0.001813 Loss_1:0.001805 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000417 Time:61.332406s (28.56min in total, 32.64min remains)
2022-11-29 14:23:52 NUM_SUB: 167;----------------------------
2022-11-29 14:23:52 Epoch [16000/30000] Loss:0.001664 Loss_1:0.001660 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000385 Time:38.260669s (29.20min in total, 25.55min remains)
2022-11-29 14:24:52 NUM_SUB: 167;----------------------------
2022-11-29 14:24:52 Epoch [18000/30000] Loss:0.001458 Loss_1:0.001456 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000357 Time:59.298318s (30.19min in total, 20.13min remains)
2022-11-29 14:25:53 NUM_SUB: 167;----------------------------
2022-11-29 14:25:53 Epoch [20000/30000] Loss:0.000917 Loss_1:0.000915 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:61.362170s (31.21min in total, 15.61min remains)
2022-11-29 14:26:54 NUM_SUB: 167;----------------------------
2022-11-29 14:26:54 Epoch [22000/30000] Loss:0.000870 Loss_1:0.000867 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:61.130941s (32.23min in total, 11.72min remains)
2022-11-29 14:27:55 NUM_SUB: 167;----------------------------
2022-11-29 14:27:55 Epoch [24000/30000] Loss:0.000878 Loss_1:0.000875 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:61.141971s (33.25min in total, 8.31min remains)
2022-11-29 14:28:33 NUM_SUB: 167;----------------------------
2022-11-29 14:28:33 Epoch [26000/30000] Loss:0.000866 Loss_1:0.000863 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.170935s (33.89min in total, 5.21min remains)
2022-11-29 14:29:35 NUM_SUB: 167;----------------------------
2022-11-29 14:29:35 Epoch [28000/30000] Loss:0.000865 Loss_1:0.000863 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:61.323763s (34.91min in total, 2.49min remains)
2022-11-29 14:30:37 Testing & drawing...
2022-11-29 14:30:37 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:30:39 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=167/
2022-11-29 14:30:39 [Loss]
2022-11-29 14:30:39 NUM_SUB: 167; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:30:39 NUM_SUB: 167; Personalized parameter estimation: Parameter containing:
tensor([0.2173, 1.0258, 0.0093, 0.0105, 0.3074, 0.0134, 0.1208, 0.8964, 0.4556,
        0.0143, 0.1660, 0.1018, 0.4030, 0.1689, 0.0175, 1.8973, 0.6977, 0.8000,
        0.0124, 1.1252, 0.6816, 0.0222, 0.8802, 0.8742, 0.0224, 2.1759, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:30:39 NUM_SUB: 167;----------------------------
2022-11-29 14:30:39 Epoch [30000/30000] Loss:0.000864 Loss_1:0.000862 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:64.139595s (35.98min in total, 0.00min remains)
2022-11-29 14:30:39 NUM_SUB: 167------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 14:30:39 Testing & drawing...
2022-11-29 14:30:39 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:30:40 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=167/
2022-11-29 14:30:40 [Loss]
2022-11-29 14:30:40 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:30:40 General parameter estimation: Parameter containing:
tensor([0.2173, 1.0258, 0.0093, 0.0105, 0.3074, 0.0134, 0.1208, 0.8964, 0.4556,
        0.0143, 0.1660, 0.1018, 0.4030, 0.1689, 0.0175, 1.8974, 0.6977, 0.8000,
        0.0124, 1.1254, 0.6816, 0.0222, 0.8801, 0.8742, 0.0224, 2.1761, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:30:40 A: prod, degr, TonA, NonA
2022-11-29 14:30:40 [0.4530671  0.50001234 0.01946321 0.02745732]
2022-11-29 14:30:40 T: prod, degr, AonT, NonT
2022-11-29 14:30:40 [0.1375411  0.3740431  0.45092458 0.03749121]
2022-11-29 14:30:40 N: AonN, TonN, ATonN
2022-11-29 14:30:40 [0.02632375 0.92507035 0.04860585]
2022-11-29 14:30:41 using cpu
2022-11-29 14:30:41 epoch = 30000
2022-11-29 14:30:41 epoch_step = 2000
2022-11-29 14:30:41 model_name = SimpleNetworkAD
2022-11-29 14:30:41 now_string = 2022-11-28-18-17-05
2022-11-29 14:30:41 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 14:30:41 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 14:30:41 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 14:30:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 14:30:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 14:30:41 --------------------------------------------------training start--------------------------------------------------
2022-11-29 14:31:42 NUM_SUB: 168;----------------------------
2022-11-29 14:31:42 Epoch [02000/30000] Loss:0.073985 Loss_1:0.072921 Loss_2:0.000629 Loss_3:0.000000 Lr:0.000833 Time:61.294910s (1.02min in total, 14.30min remains)
2022-11-29 14:32:43 NUM_SUB: 168;----------------------------
2022-11-29 14:32:43 Epoch [04000/30000] Loss:0.060239 Loss_1:0.059787 Loss_2:0.000151 Loss_3:0.000000 Lr:0.000714 Time:61.498077s (2.05min in total, 13.30min remains)
2022-11-29 14:33:45 NUM_SUB: 168;----------------------------
2022-11-29 14:33:45 Epoch [06000/30000] Loss:0.035373 Loss_1:0.034966 Loss_2:0.000203 Loss_3:0.000000 Lr:0.000625 Time:62.063162s (3.08min in total, 12.32min remains)
2022-11-29 14:34:24 NUM_SUB: 168;----------------------------
2022-11-29 14:34:24 Epoch [08000/30000] Loss:0.009546 Loss_1:0.009254 Loss_2:0.000239 Loss_3:0.000000 Lr:0.000556 Time:38.261323s (3.72min in total, 10.23min remains)
2022-11-29 14:35:24 NUM_SUB: 168;----------------------------
2022-11-29 14:35:24 Epoch [10000/30000] Loss:0.003601 Loss_1:0.003383 Loss_2:0.000214 Loss_3:0.000000 Lr:0.000500 Time:60.134161s (4.72min in total, 9.44min remains)
2022-11-29 14:36:25 NUM_SUB: 168;----------------------------
2022-11-29 14:36:25 Epoch [12000/30000] Loss:0.003187 Loss_1:0.003019 Loss_2:0.000168 Loss_3:0.000000 Lr:0.000455 Time:61.431548s (5.74min in total, 8.62min remains)
2022-11-29 14:37:27 NUM_SUB: 168;----------------------------
2022-11-29 14:37:27 Epoch [14000/30000] Loss:0.002106 Loss_1:0.002054 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000417 Time:61.448036s (6.77min in total, 7.74min remains)
2022-11-29 14:38:28 NUM_SUB: 168;----------------------------
2022-11-29 14:38:28 Epoch [16000/30000] Loss:0.002430 Loss_1:0.002395 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000385 Time:61.436131s (7.79min in total, 6.82min remains)
2022-11-29 14:39:30 NUM_SUB: 168;----------------------------
2022-11-29 14:39:30 Epoch [18000/30000] Loss:0.002130 Loss_1:0.002106 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000357 Time:61.437394s (8.82min in total, 5.88min remains)
2022-11-29 14:40:08 NUM_SUB: 168;----------------------------
2022-11-29 14:40:08 Epoch [20000/30000] Loss:0.001987 Loss_1:0.001969 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000333 Time:38.243080s (9.45min in total, 4.73min remains)
2022-11-29 14:41:09 NUM_SUB: 168;----------------------------
2022-11-29 14:41:09 Epoch [22000/30000] Loss:0.001980 Loss_1:0.001966 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000313 Time:61.450940s (10.48min in total, 3.81min remains)
2022-11-29 14:42:11 NUM_SUB: 168;----------------------------
2022-11-29 14:42:11 Epoch [24000/30000] Loss:0.002088 Loss_1:0.002078 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000294 Time:61.389016s (11.50min in total, 2.88min remains)
2022-11-29 14:43:11 NUM_SUB: 168;----------------------------
2022-11-29 14:43:11 Epoch [26000/30000] Loss:0.001972 Loss_1:0.001964 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:60.340137s (12.51min in total, 1.92min remains)
2022-11-29 14:44:05 NUM_SUB: 168;----------------------------
2022-11-29 14:44:05 Epoch [28000/30000] Loss:0.002011 Loss_1:0.001955 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:54.349132s (13.41min in total, 0.96min remains)
2022-11-29 14:44:54 Testing & drawing...
2022-11-29 14:44:54 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:44:56 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=168/
2022-11-29 14:44:56 [Loss]
2022-11-29 14:44:56 NUM_SUB: 168; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:44:56 NUM_SUB: 168; Personalized parameter estimation: Parameter containing:
tensor([0.0178, 0.1077, 0.0207, 1.1011, 0.3074, 0.3121, 1.5574, 0.8964, 0.4556,
        0.0137, 0.0333, 0.0139, 0.9366, 0.1689, 0.0179, 1.5112, 0.6977, 0.8000,
        0.0108, 4.8763, 0.6816, 0.0225, 3.8303, 0.8742, 0.0185, 4.8716, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:44:56 NUM_SUB: 168;----------------------------
2022-11-29 14:44:56 Epoch [30000/30000] Loss:0.001981 Loss_1:0.001966 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000250 Time:50.578203s (14.26min in total, 0.00min remains)
2022-11-29 14:44:56 NUM_SUB: 168------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 14:44:56 Testing & drawing...
2022-11-29 14:44:56 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:44:58 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=168/
2022-11-29 14:44:58 [Loss]
2022-11-29 14:44:58 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:44:58 General parameter estimation: Parameter containing:
tensor([0.0178, 0.1079, 0.0207, 1.1013, 0.3074, 0.3119, 1.5576, 0.8964, 0.4556,
        0.0137, 0.0333, 0.0139, 0.9366, 0.1689, 0.0179, 1.5112, 0.6977, 0.8000,
        0.0108, 4.8765, 0.6816, 0.0225, 3.8304, 0.8742, 0.0185, 4.8717, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:44:58 A: prod, degr, TonA, NonA
2022-11-29 14:44:58 [0.09818909 0.4917398  0.02742723 0.38264385]
2022-11-29 14:44:58 T: prod, degr, AonT, NonT
2022-11-29 14:44:58 [0.27600473 0.5546871  0.08501973 0.08428847]
2022-11-29 14:44:58 N: AonN, TonN, ATonN
2022-11-29 14:44:58 [0.01450475 0.9476401  0.03785513]
2022-11-29 14:44:58 using cpu
2022-11-29 14:44:58 epoch = 30000
2022-11-29 14:44:58 epoch_step = 2000
2022-11-29 14:44:58 model_name = SimpleNetworkAD
2022-11-29 14:44:58 now_string = 2022-11-28-18-17-05
2022-11-29 14:44:58 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 14:44:58 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 14:44:58 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 14:44:58 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 14:44:58 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 14:44:58 --------------------------------------------------training start--------------------------------------------------
2022-11-29 14:45:57 NUM_SUB: 169;----------------------------
2022-11-29 14:45:57 Epoch [02000/30000] Loss:0.068520 Loss_1:0.067218 Loss_2:0.000792 Loss_3:0.000000 Lr:0.000833 Time:59.196624s (0.99min in total, 13.81min remains)
2022-11-29 14:46:58 NUM_SUB: 169;----------------------------
2022-11-29 14:46:58 Epoch [04000/30000] Loss:0.057259 Loss_1:0.056695 Loss_2:0.000223 Loss_3:0.000000 Lr:0.000714 Time:61.441593s (2.01min in total, 13.07min remains)
2022-11-29 14:48:01 NUM_SUB: 169;----------------------------
2022-11-29 14:48:01 Epoch [06000/30000] Loss:0.037561 Loss_1:0.037108 Loss_2:0.000200 Loss_3:0.000000 Lr:0.000625 Time:62.604805s (3.05min in total, 12.22min remains)
2022-11-29 14:49:02 NUM_SUB: 169;----------------------------
2022-11-29 14:49:02 Epoch [08000/30000] Loss:0.011187 Loss_1:0.010900 Loss_2:0.000197 Loss_3:0.000000 Lr:0.000556 Time:61.420796s (4.08min in total, 11.21min remains)
2022-11-29 14:50:03 NUM_SUB: 169;----------------------------
2022-11-29 14:50:03 Epoch [10000/30000] Loss:0.002341 Loss_1:0.002168 Loss_2:0.000170 Loss_3:0.000000 Lr:0.000500 Time:60.976544s (5.09min in total, 10.19min remains)
2022-11-29 14:50:42 NUM_SUB: 169;----------------------------
2022-11-29 14:50:42 Epoch [12000/30000] Loss:0.001860 Loss_1:0.001765 Loss_2:0.000094 Loss_3:0.000000 Lr:0.000455 Time:38.214761s (5.73min in total, 8.60min remains)
2022-11-29 14:51:43 NUM_SUB: 169;----------------------------
2022-11-29 14:51:43 Epoch [14000/30000] Loss:0.001457 Loss_1:0.001396 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000417 Time:61.142848s (6.75min in total, 7.71min remains)
2022-11-29 14:52:43 NUM_SUB: 169;----------------------------
2022-11-29 14:52:43 Epoch [16000/30000] Loss:0.001238 Loss_1:0.001200 Loss_2:0.000036 Loss_3:0.000000 Lr:0.000385 Time:60.157970s (7.75min in total, 6.78min remains)
2022-11-29 14:53:44 NUM_SUB: 169;----------------------------
2022-11-29 14:53:44 Epoch [18000/30000] Loss:0.001153 Loss_1:0.001135 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:61.164580s (8.77min in total, 5.85min remains)
2022-11-29 14:54:33 NUM_SUB: 169;----------------------------
2022-11-29 14:54:33 Epoch [20000/30000] Loss:0.001106 Loss_1:0.001095 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:49.345604s (9.59min in total, 4.80min remains)
2022-11-29 14:55:12 NUM_SUB: 169;----------------------------
2022-11-29 14:55:12 Epoch [22000/30000] Loss:0.001064 Loss_1:0.001056 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.207299s (10.23min in total, 3.72min remains)
2022-11-29 14:56:26 NUM_SUB: 169;----------------------------
2022-11-29 14:56:26 Epoch [24000/30000] Loss:0.001061 Loss_1:0.001055 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:74.301453s (11.47min in total, 2.87min remains)
2022-11-29 14:57:27 NUM_SUB: 169;----------------------------
2022-11-29 14:57:27 Epoch [26000/30000] Loss:0.001059 Loss_1:0.001055 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:61.326831s (12.49min in total, 1.92min remains)
2022-11-29 14:58:11 NUM_SUB: 169;----------------------------
2022-11-29 14:58:11 Epoch [28000/30000] Loss:0.001078 Loss_1:0.001076 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:43.600488s (13.22min in total, 0.94min remains)
2022-11-29 14:58:50 Testing & drawing...
2022-11-29 14:58:50 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:58:52 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=169/
2022-11-29 14:58:52 [Loss]
2022-11-29 14:58:52 NUM_SUB: 169; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:58:52 NUM_SUB: 169; Personalized parameter estimation: Parameter containing:
tensor([0.0178, 0.0213, 0.0228, 1.7826, 0.3074, 0.0082, 1.8266, 0.8964, 0.4556,
        0.0136, 0.0257, 0.0144, 0.9873, 0.1689, 0.0176, 2.3091, 0.6977, 0.8000,
        0.0074, 5.3673, 0.6816, 0.0123, 4.1758, 0.8742, 0.0169, 5.3566, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:58:52 NUM_SUB: 169;----------------------------
2022-11-29 14:58:52 Epoch [30000/30000] Loss:0.001063 Loss_1:0.001061 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.900898s (13.90min in total, 0.00min remains)
2022-11-29 14:58:52 NUM_SUB: 169------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 14:58:52 Testing & drawing...
2022-11-29 14:58:52 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 14:58:53 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=169/
2022-11-29 14:58:53 [Loss]
2022-11-29 14:58:53 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 14:58:53 General parameter estimation: Parameter containing:
tensor([0.0178, 0.0214, 0.0228, 1.7827, 0.3074, 0.0082, 1.8266, 0.8964, 0.4556,
        0.0136, 0.0257, 0.0144, 0.9873, 0.1689, 0.0176, 2.3091, 0.6977, 0.8000,
        0.0074, 5.3675, 0.6816, 0.0123, 4.1759, 0.8742, 0.0169, 5.3568, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 14:58:53 A: prod, degr, TonA, NonA
2022-11-29 14:58:53 [0.41916525 0.48599315 0.07464379 0.02019781]
2022-11-29 14:58:53 T: prod, degr, AonT, NonT
2022-11-29 14:58:53 [0.30597332 0.5570022  0.11022136 0.02680307]
2022-11-29 14:58:53 N: AonN, TonN, ATonN
2022-11-29 14:58:53 [0.01841816 0.916916   0.06466578]
2022-11-29 14:58:54 using cpu
2022-11-29 14:58:54 epoch = 30000
2022-11-29 14:58:54 epoch_step = 2000
2022-11-29 14:58:54 model_name = SimpleNetworkAD
2022-11-29 14:58:54 now_string = 2022-11-28-18-17-05
2022-11-29 14:58:54 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 14:58:54 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 14:58:54 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 14:58:54 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 14:58:54 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 14:58:54 --------------------------------------------------training start--------------------------------------------------
2022-11-29 15:00:36 NUM_SUB: 170;----------------------------
2022-11-29 15:00:36 Epoch [02000/30000] Loss:0.043843 Loss_1:0.042507 Loss_2:0.000912 Loss_3:0.000000 Lr:0.000833 Time:102.231516s (1.70min in total, 23.85min remains)
2022-11-29 15:01:14 NUM_SUB: 170;----------------------------
2022-11-29 15:01:14 Epoch [04000/30000] Loss:0.032537 Loss_1:0.032073 Loss_2:0.000379 Loss_3:0.000000 Lr:0.000714 Time:38.135853s (2.34min in total, 15.21min remains)
2022-11-29 15:02:15 NUM_SUB: 170;----------------------------
2022-11-29 15:02:15 Epoch [06000/30000] Loss:0.016612 Loss_1:0.016399 Loss_2:0.000142 Loss_3:0.000000 Lr:0.000625 Time:61.089482s (3.36min in total, 13.43min remains)
2022-11-29 15:03:17 NUM_SUB: 170;----------------------------
2022-11-29 15:03:17 Epoch [08000/30000] Loss:0.004422 Loss_1:0.004327 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000556 Time:62.281317s (4.40min in total, 12.09min remains)
2022-11-29 15:04:19 NUM_SUB: 170;----------------------------
2022-11-29 15:04:19 Epoch [10000/30000] Loss:0.002583 Loss_1:0.002505 Loss_2:0.000077 Loss_3:0.000000 Lr:0.000500 Time:61.614841s (5.42min in total, 10.85min remains)
2022-11-29 15:05:17 NUM_SUB: 170;----------------------------
2022-11-29 15:05:17 Epoch [12000/30000] Loss:0.001718 Loss_1:0.001665 Loss_2:0.000053 Loss_3:0.000000 Lr:0.000455 Time:58.414341s (6.40min in total, 9.59min remains)
2022-11-29 15:06:02 NUM_SUB: 170;----------------------------
2022-11-29 15:06:02 Epoch [14000/30000] Loss:0.000353 Loss_1:0.000321 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000417 Time:44.617618s (7.14min in total, 8.16min remains)
2022-11-29 15:06:40 NUM_SUB: 170;----------------------------
2022-11-29 15:06:40 Epoch [16000/30000] Loss:0.000125 Loss_1:0.000104 Loss_2:0.000021 Loss_3:0.000000 Lr:0.000385 Time:38.202928s (7.78min in total, 6.80min remains)
2022-11-29 15:07:59 NUM_SUB: 170;----------------------------
2022-11-29 15:07:59 Epoch [18000/30000] Loss:0.000111 Loss_1:0.000097 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000357 Time:79.190285s (9.10min in total, 6.06min remains)
2022-11-29 15:08:49 NUM_SUB: 170;----------------------------
2022-11-29 15:08:49 Epoch [20000/30000] Loss:0.000094 Loss_1:0.000084 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000333 Time:49.531175s (9.92min in total, 4.96min remains)
2022-11-29 15:10:03 NUM_SUB: 170;----------------------------
2022-11-29 15:10:03 Epoch [22000/30000] Loss:0.000074 Loss_1:0.000067 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:73.785094s (11.15min in total, 4.06min remains)
2022-11-29 15:11:04 NUM_SUB: 170;----------------------------
2022-11-29 15:11:04 Epoch [24000/30000] Loss:0.000080 Loss_1:0.000075 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:61.302819s (12.17min in total, 3.04min remains)
2022-11-29 15:11:42 NUM_SUB: 170;----------------------------
2022-11-29 15:11:42 Epoch [26000/30000] Loss:0.000061 Loss_1:0.000056 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.200488s (12.81min in total, 1.97min remains)
2022-11-29 15:12:43 NUM_SUB: 170;----------------------------
2022-11-29 15:12:43 Epoch [28000/30000] Loss:0.000058 Loss_1:0.000054 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:61.206606s (13.83min in total, 0.99min remains)
2022-11-29 15:13:46 Testing & drawing...
2022-11-29 15:13:46 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:13:47 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=170/
2022-11-29 15:13:47 [Loss]
2022-11-29 15:13:47 NUM_SUB: 170; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:13:47 NUM_SUB: 170; Personalized parameter estimation: Parameter containing:
tensor([0.0078, 0.0237, 0.0156, 0.6578, 0.3074, 0.0177, 2.7334, 0.8964, 0.4556,
        0.0140, 0.0303, 0.0126, 0.8368, 0.1689, 0.0178, 2.1193, 0.6977, 0.8000,
        0.0120, 3.6545, 0.6816, 0.0201, 3.1297, 0.8742, 0.0207, 3.9283, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:13:47 NUM_SUB: 170;----------------------------
2022-11-29 15:13:47 Epoch [30000/30000] Loss:0.000056 Loss_1:0.000053 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:63.902509s (14.90min in total, 0.00min remains)
2022-11-29 15:13:47 NUM_SUB: 170------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 15:13:47 Testing & drawing...
2022-11-29 15:13:47 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:13:49 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=170/
2022-11-29 15:13:49 [Loss]
2022-11-29 15:13:49 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:13:49 General parameter estimation: Parameter containing:
tensor([0.0078, 0.0237, 0.0156, 0.6578, 0.3074, 0.0177, 2.7336, 0.8964, 0.4556,
        0.0140, 0.0303, 0.0126, 0.8367, 0.1689, 0.0178, 2.1194, 0.6977, 0.8000,
        0.0120, 3.6544, 0.6816, 0.0201, 3.1296, 0.8742, 0.0207, 3.9282, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:13:49 A: prod, degr, TonA, NonA
2022-11-29 15:13:49 [0.27206755 0.46874273 0.22123563 0.03795412]
2022-11-29 15:13:49 T: prod, degr, AonT, NonT
2022-11-29 15:13:49 [0.37966883 0.4684691  0.10420297 0.04765905]
2022-11-29 15:13:49 N: AonN, TonN, ATonN
2022-11-29 15:13:49 [0.01580155 0.93890214 0.04529629]
2022-11-29 15:13:49 using cpu
2022-11-29 15:13:49 epoch = 30000
2022-11-29 15:13:49 epoch_step = 2000
2022-11-29 15:13:49 model_name = SimpleNetworkAD
2022-11-29 15:13:49 now_string = 2022-11-28-18-17-05
2022-11-29 15:13:49 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 15:13:49 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 15:13:49 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 15:13:49 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 15:13:49 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 15:13:49 --------------------------------------------------training start--------------------------------------------------
2022-11-29 15:14:51 NUM_SUB: 171;----------------------------
2022-11-29 15:14:51 Epoch [02000/30000] Loss:0.063792 Loss_1:0.062957 Loss_2:0.000442 Loss_3:0.000000 Lr:0.000833 Time:61.484967s (1.02min in total, 14.35min remains)
2022-11-29 15:15:52 NUM_SUB: 171;----------------------------
2022-11-29 15:15:52 Epoch [04000/30000] Loss:0.048140 Loss_1:0.047896 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000714 Time:61.455512s (2.05min in total, 13.32min remains)
2022-11-29 15:16:54 NUM_SUB: 171;----------------------------
2022-11-29 15:16:54 Epoch [06000/30000] Loss:0.021377 Loss_1:0.021174 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000625 Time:62.306233s (3.09min in total, 12.35min remains)
2022-11-29 15:17:33 NUM_SUB: 171;----------------------------
2022-11-29 15:17:33 Epoch [08000/30000] Loss:0.005173 Loss_1:0.004667 Loss_2:0.000498 Loss_3:0.000000 Lr:0.000556 Time:38.347179s (3.73min in total, 10.25min remains)
2022-11-29 15:18:34 NUM_SUB: 171;----------------------------
2022-11-29 15:18:34 Epoch [10000/30000] Loss:0.003531 Loss_1:0.003379 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000500 Time:61.781168s (4.76min in total, 9.51min remains)
2022-11-29 15:19:36 NUM_SUB: 171;----------------------------
2022-11-29 15:19:36 Epoch [12000/30000] Loss:0.002241 Loss_1:0.002204 Loss_2:0.000035 Loss_3:0.000000 Lr:0.000455 Time:61.376219s (5.78min in total, 8.67min remains)
2022-11-29 15:20:37 NUM_SUB: 171;----------------------------
2022-11-29 15:20:37 Epoch [14000/30000] Loss:0.001444 Loss_1:0.001411 Loss_2:0.000033 Loss_3:0.000000 Lr:0.000417 Time:61.600988s (6.81min in total, 7.78min remains)
2022-11-29 15:21:39 NUM_SUB: 171;----------------------------
2022-11-29 15:21:39 Epoch [16000/30000] Loss:0.001231 Loss_1:0.001216 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:61.461277s (7.83min in total, 6.85min remains)
2022-11-29 15:22:39 NUM_SUB: 171;----------------------------
2022-11-29 15:22:39 Epoch [18000/30000] Loss:0.001185 Loss_1:0.001178 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000357 Time:59.975108s (8.83min in total, 5.89min remains)
2022-11-29 15:23:17 NUM_SUB: 171;----------------------------
2022-11-29 15:23:17 Epoch [20000/30000] Loss:0.001118 Loss_1:0.001111 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000333 Time:38.285862s (9.47min in total, 4.73min remains)
2022-11-29 15:24:19 NUM_SUB: 171;----------------------------
2022-11-29 15:24:19 Epoch [22000/30000] Loss:0.001042 Loss_1:0.001039 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000313 Time:62.161202s (10.50min in total, 3.82min remains)
2022-11-29 15:25:22 NUM_SUB: 171;----------------------------
2022-11-29 15:25:22 Epoch [24000/30000] Loss:0.001046 Loss_1:0.001043 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000294 Time:62.393434s (11.54min in total, 2.89min remains)
2022-11-29 15:26:23 NUM_SUB: 171;----------------------------
2022-11-29 15:26:23 Epoch [26000/30000] Loss:0.001030 Loss_1:0.001027 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000278 Time:61.360268s (12.57min in total, 1.93min remains)
2022-11-29 15:27:25 NUM_SUB: 171;----------------------------
2022-11-29 15:27:25 Epoch [28000/30000] Loss:0.001027 Loss_1:0.001025 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:61.535502s (13.59min in total, 0.97min remains)
2022-11-29 15:28:03 Testing & drawing...
2022-11-29 15:28:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:28:04 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=171/
2022-11-29 15:28:04 [Loss]
2022-11-29 15:28:04 NUM_SUB: 171; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:28:04 NUM_SUB: 171; Personalized parameter estimation: Parameter containing:
tensor([0.0156, 0.0545, 0.0088, 0.1795, 0.3074, 0.0099, 1.5889, 0.8964, 0.4556,
        0.0101, 0.1183, 0.0815, 0.4420, 0.1689, 0.0174, 1.7662, 0.6977, 0.8000,
        0.0124, 2.0713, 0.6816, 0.0226, 2.1592, 0.8742, 0.0218, 2.5754, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:28:04 NUM_SUB: 171;----------------------------
2022-11-29 15:28:04 Epoch [30000/30000] Loss:0.001025 Loss_1:0.001023 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.849339s (14.26min in total, 0.00min remains)
2022-11-29 15:28:04 NUM_SUB: 171------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 15:28:04 Testing & drawing...
2022-11-29 15:28:04 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:28:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=171/
2022-11-29 15:28:30 [Loss]
2022-11-29 15:28:30 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:28:30 General parameter estimation: Parameter containing:
tensor([0.0156, 0.0545, 0.0088, 0.1795, 0.3074, 0.0099, 1.5890, 0.8964, 0.4556,
        0.0101, 0.1183, 0.0815, 0.4420, 0.1689, 0.0174, 1.7663, 0.6977, 0.8000,
        0.0124, 2.0712, 0.6816, 0.0226, 2.1592, 0.8742, 0.0218, 2.5754, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:28:30 A: prod, degr, TonA, NonA
2022-11-29 15:28:30 [0.33215782 0.49389985 0.13093427 0.04300812]
2022-11-29 15:28:30 T: prod, degr, AonT, NonT
2022-11-29 15:28:30 [0.11338153 0.556045   0.29827031 0.03230312]
2022-11-29 15:28:30 N: AonN, TonN, ATonN
2022-11-29 15:28:30 [0.02990303 0.9152726  0.05482441]
2022-11-29 15:28:31 using cpu
2022-11-29 15:28:31 epoch = 30000
2022-11-29 15:28:31 epoch_step = 2000
2022-11-29 15:28:31 model_name = SimpleNetworkAD
2022-11-29 15:28:31 now_string = 2022-11-28-18-17-05
2022-11-29 15:28:31 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 15:28:31 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 15:28:31 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 15:28:31 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 15:28:31 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 15:28:31 --------------------------------------------------training start--------------------------------------------------
2022-11-29 15:29:09 NUM_SUB: 172;----------------------------
2022-11-29 15:29:09 Epoch [02000/30000] Loss:0.033882 Loss_1:0.032658 Loss_2:0.000805 Loss_3:0.000000 Lr:0.000833 Time:38.283248s (0.64min in total, 8.93min remains)
2022-11-29 15:29:59 NUM_SUB: 172;----------------------------
2022-11-29 15:29:59 Epoch [04000/30000] Loss:0.027271 Loss_1:0.026996 Loss_2:0.000244 Loss_3:0.000000 Lr:0.000714 Time:49.700254s (1.47min in total, 9.53min remains)
2022-11-29 15:30:37 NUM_SUB: 172;----------------------------
2022-11-29 15:30:37 Epoch [06000/30000] Loss:0.017032 Loss_1:0.016782 Loss_2:0.000204 Loss_3:0.000000 Lr:0.000625 Time:38.528619s (2.11min in total, 8.43min remains)
2022-11-29 15:31:16 NUM_SUB: 172;----------------------------
2022-11-29 15:31:16 Epoch [08000/30000] Loss:0.005277 Loss_1:0.005118 Loss_2:0.000143 Loss_3:0.000000 Lr:0.000556 Time:38.522272s (2.75min in total, 7.56min remains)
2022-11-29 15:31:54 NUM_SUB: 172;----------------------------
2022-11-29 15:31:54 Epoch [10000/30000] Loss:0.002597 Loss_1:0.002492 Loss_2:0.000105 Loss_3:0.000000 Lr:0.000500 Time:38.655812s (3.39min in total, 6.79min remains)
2022-11-29 15:32:33 NUM_SUB: 172;----------------------------
2022-11-29 15:32:33 Epoch [12000/30000] Loss:0.001727 Loss_1:0.001668 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000455 Time:38.437987s (4.04min in total, 6.05min remains)
2022-11-29 15:33:11 NUM_SUB: 172;----------------------------
2022-11-29 15:33:11 Epoch [14000/30000] Loss:0.000265 Loss_1:0.000225 Loss_2:0.000040 Loss_3:0.000000 Lr:0.000417 Time:38.557636s (4.68min in total, 5.35min remains)
2022-11-29 15:33:50 NUM_SUB: 172;----------------------------
2022-11-29 15:33:50 Epoch [16000/30000] Loss:0.000043 Loss_1:0.000023 Loss_2:0.000020 Loss_3:0.000000 Lr:0.000385 Time:38.531504s (5.32min in total, 4.66min remains)
2022-11-29 15:34:28 NUM_SUB: 172;----------------------------
2022-11-29 15:34:28 Epoch [18000/30000] Loss:0.000034 Loss_1:0.000022 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.570885s (5.96min in total, 3.98min remains)
2022-11-29 15:35:07 NUM_SUB: 172;----------------------------
2022-11-29 15:35:07 Epoch [20000/30000] Loss:0.000023 Loss_1:0.000015 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:38.516068s (6.61min in total, 3.30min remains)
2022-11-29 15:35:46 NUM_SUB: 172;----------------------------
2022-11-29 15:35:46 Epoch [22000/30000] Loss:0.000032 Loss_1:0.000027 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:38.666405s (7.25min in total, 2.64min remains)
2022-11-29 15:36:24 NUM_SUB: 172;----------------------------
2022-11-29 15:36:24 Epoch [24000/30000] Loss:0.000021 Loss_1:0.000018 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:38.499021s (7.89min in total, 1.97min remains)
2022-11-29 15:37:03 NUM_SUB: 172;----------------------------
2022-11-29 15:37:03 Epoch [26000/30000] Loss:0.000015 Loss_1:0.000013 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.679824s (8.54min in total, 1.31min remains)
2022-11-29 15:37:41 NUM_SUB: 172;----------------------------
2022-11-29 15:37:41 Epoch [28000/30000] Loss:0.000014 Loss_1:0.000013 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.530953s (9.18min in total, 0.66min remains)
2022-11-29 15:38:20 Testing & drawing...
2022-11-29 15:38:20 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:38:22 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=172/
2022-11-29 15:38:22 [Loss]
2022-11-29 15:38:22 NUM_SUB: 172; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:38:22 NUM_SUB: 172; Personalized parameter estimation: Parameter containing:
tensor([0.0191, 0.0301, 0.0238, 0.6886, 0.3074, 0.0144, 1.6286, 0.8964, 0.4556,
        0.0142, 0.0755, 0.0757, 0.7326, 0.1689, 0.0178, 1.3486, 0.6977, 0.8000,
        0.0106, 5.1921, 0.6816, 0.0224, 3.9358, 0.8742, 0.0176, 5.0885, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:38:22 NUM_SUB: 172;----------------------------
2022-11-29 15:38:22 Epoch [30000/30000] Loss:0.000014 Loss_1:0.000013 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:40.441954s (9.85min in total, 0.00min remains)
2022-11-29 15:38:22 NUM_SUB: 172------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 15:38:22 Testing & drawing...
2022-11-29 15:38:22 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:38:23 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=172/
2022-11-29 15:38:23 [Loss]
2022-11-29 15:38:23 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:38:23 General parameter estimation: Parameter containing:
tensor([0.0191, 0.0300, 0.0238, 0.6885, 0.3074, 0.0144, 1.6285, 0.8964, 0.4556,
        0.0142, 0.0755, 0.0757, 0.7325, 0.1689, 0.0178, 1.3486, 0.6977, 0.8000,
        0.0106, 5.1922, 0.6816, 0.0224, 3.9359, 0.8742, 0.0176, 5.0886, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 15:38:23 A: prod, degr, TonA, NonA
2022-11-29 15:38:23 [0.3295428  0.48138556 0.15568532 0.03338633]
2022-11-29 15:38:23 T: prod, degr, AonT, NonT
2022-11-29 15:38:23 [0.12471301 0.6156663  0.23107807 0.02854265]
2022-11-29 15:38:23 N: AonN, TonN, ATonN
2022-11-29 15:38:23 [0.01620244 0.94615144 0.03764616]
2022-11-29 15:38:24 using cpu
2022-11-29 15:38:24 epoch = 30000
2022-11-29 15:38:24 epoch_step = 2000
2022-11-29 15:38:24 model_name = SimpleNetworkAD
2022-11-29 15:38:24 now_string = 2022-11-28-18-17-05
2022-11-29 15:38:24 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 15:38:24 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 15:38:24 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 15:38:24 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 15:38:24 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 15:38:24 --------------------------------------------------training start--------------------------------------------------
2022-11-29 15:39:02 NUM_SUB: 173;----------------------------
2022-11-29 15:39:02 Epoch [02000/30000] Loss:0.067298 Loss_1:0.065848 Loss_2:0.000703 Loss_3:0.000000 Lr:0.000833 Time:38.515087s (0.64min in total, 8.99min remains)
2022-11-29 15:39:41 NUM_SUB: 173;----------------------------
2022-11-29 15:39:41 Epoch [04000/30000] Loss:0.056004 Loss_1:0.055256 Loss_2:0.000151 Loss_3:0.000000 Lr:0.000714 Time:38.582837s (1.28min in total, 8.35min remains)
2022-11-29 15:40:43 NUM_SUB: 173;----------------------------
2022-11-29 15:40:43 Epoch [06000/30000] Loss:0.036369 Loss_1:0.035814 Loss_2:0.000138 Loss_3:0.000000 Lr:0.000625 Time:62.206229s (2.32min in total, 9.29min remains)
2022-11-29 15:41:29 NUM_SUB: 173;----------------------------
2022-11-29 15:41:29 Epoch [08000/30000] Loss:0.008722 Loss_1:0.008458 Loss_2:0.000160 Loss_3:0.000000 Lr:0.000556 Time:46.544014s (3.10min in total, 8.52min remains)
2022-11-29 15:42:09 NUM_SUB: 173;----------------------------
2022-11-29 15:42:09 Epoch [10000/30000] Loss:0.002152 Loss_1:0.002014 Loss_2:0.000136 Loss_3:0.000000 Lr:0.000500 Time:39.490749s (3.76min in total, 7.51min remains)
2022-11-29 15:42:47 NUM_SUB: 173;----------------------------
2022-11-29 15:42:47 Epoch [12000/30000] Loss:0.001799 Loss_1:0.001724 Loss_2:0.000074 Loss_3:0.000000 Lr:0.000455 Time:38.202291s (4.39min in total, 6.59min remains)
2022-11-29 15:44:12 NUM_SUB: 173;----------------------------
2022-11-29 15:44:12 Epoch [14000/30000] Loss:0.001221 Loss_1:0.001180 Loss_2:0.000041 Loss_3:0.000000 Lr:0.000417 Time:84.392978s (5.80min in total, 6.63min remains)
2022-11-29 15:45:13 NUM_SUB: 173;----------------------------
2022-11-29 15:45:13 Epoch [16000/30000] Loss:0.000946 Loss_1:0.000917 Loss_2:0.000028 Loss_3:0.000000 Lr:0.000385 Time:61.506306s (6.82min in total, 5.97min remains)
2022-11-29 15:46:15 NUM_SUB: 173;----------------------------
2022-11-29 15:46:15 Epoch [18000/30000] Loss:0.000915 Loss_1:0.000899 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000357 Time:62.382447s (7.86min in total, 5.24min remains)
2022-11-29 15:47:16 NUM_SUB: 173;----------------------------
2022-11-29 15:47:16 Epoch [20000/30000] Loss:0.000920 Loss_1:0.000910 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000333 Time:60.785273s (8.88min in total, 4.44min remains)
2022-11-29 15:47:54 NUM_SUB: 173;----------------------------
2022-11-29 15:47:54 Epoch [22000/30000] Loss:0.000903 Loss_1:0.000897 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:38.220060s (9.51min in total, 3.46min remains)
2022-11-29 15:48:56 NUM_SUB: 173;----------------------------
2022-11-29 15:48:56 Epoch [24000/30000] Loss:0.000900 Loss_1:0.000896 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:61.433834s (10.54min in total, 2.63min remains)
2022-11-29 15:49:57 NUM_SUB: 173;----------------------------
2022-11-29 15:49:57 Epoch [26000/30000] Loss:0.000899 Loss_1:0.000897 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:61.530228s (11.56min in total, 1.78min remains)
2022-11-29 15:50:39 NUM_SUB: 173;----------------------------
2022-11-29 15:50:39 Epoch [28000/30000] Loss:0.000899 Loss_1:0.000897 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:41.317311s (12.25min in total, 0.88min remains)
2022-11-29 15:52:01 Testing & drawing...
2022-11-29 15:52:01 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:52:03 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=173/
2022-11-29 15:52:03 [Loss]
2022-11-29 15:52:03 NUM_SUB: 173; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:52:03 NUM_SUB: 173; Personalized parameter estimation: Parameter containing:
tensor([4.9183e-01, 7.3128e-01, 8.2599e-02, 4.5116e-02, 3.0742e-01, 1.8436e-02,
        7.3642e-01, 8.9644e-01, 4.5563e-01, 1.3431e-02, 2.4073e-02, 1.4389e-02,
        7.0320e-01, 1.6886e-01, 1.7547e-02, 1.5156e+00, 6.9767e-01, 8.0001e-01,
        8.3937e-03, 4.9234e+00, 6.8161e-01, 2.1507e-02, 4.5674e+00, 8.7416e-01,
        4.1925e-03, 5.1452e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 15:52:03 NUM_SUB: 173;----------------------------
2022-11-29 15:52:03 Epoch [30000/30000] Loss:0.000899 Loss_1:0.000898 Loss_2:0.000000 Loss_3:0.000000 Lr:0.000250 Time:84.254392s (13.66min in total, 0.00min remains)
2022-11-29 15:52:03 NUM_SUB: 173------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 15:52:03 Testing & drawing...
2022-11-29 15:52:03 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 15:52:05 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=173/
2022-11-29 15:52:05 [Loss]
2022-11-29 15:52:05 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 15:52:05 General parameter estimation: Parameter containing:
tensor([4.9183e-01, 7.3129e-01, 8.2596e-02, 4.5114e-02, 3.0742e-01, 1.8434e-02,
        7.3642e-01, 8.9644e-01, 4.5563e-01, 1.3431e-02, 2.4138e-02, 1.4389e-02,
        7.0317e-01, 1.6886e-01, 1.7547e-02, 1.5155e+00, 6.9767e-01, 8.0001e-01,
        8.3937e-03, 4.9236e+00, 6.8161e-01, 2.1506e-02, 4.5675e+00, 8.7416e-01,
        4.1884e-03, 5.1453e+00, 9.5274e-01, 3.6165e-02], requires_grad=True);
2022-11-29 15:52:05 A: prod, degr, TonA, NonA
2022-11-29 15:52:05 [0.4247539  0.49995056 0.07114244 0.0041531 ]
2022-11-29 15:52:05 T: prod, degr, AonT, NonT
2022-11-29 15:52:05 [0.31441075 0.4473167  0.20667817 0.03159437]
2022-11-29 15:52:05 N: AonN, TonN, ATonN
2022-11-29 15:52:05 [0.00999478 0.9797898  0.01021546]
2022-11-29 15:52:05 using cpu
2022-11-29 15:52:05 epoch = 30000
2022-11-29 15:52:05 epoch_step = 2000
2022-11-29 15:52:05 model_name = SimpleNetworkAD
2022-11-29 15:52:05 now_string = 2022-11-28-18-17-05
2022-11-29 15:52:05 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 15:52:05 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 15:52:05 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 15:52:05 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 15:52:05 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 15:52:05 --------------------------------------------------training start--------------------------------------------------
2022-11-29 15:53:06 NUM_SUB: 174;----------------------------
2022-11-29 15:53:06 Epoch [02000/30000] Loss:0.055368 Loss_1:0.053928 Loss_2:0.001011 Loss_3:0.000000 Lr:0.000833 Time:61.455898s (1.02min in total, 14.34min remains)
2022-11-29 15:53:44 NUM_SUB: 174;----------------------------
2022-11-29 15:53:44 Epoch [04000/30000] Loss:0.044059 Loss_1:0.043566 Loss_2:0.000247 Loss_3:0.000000 Lr:0.000714 Time:38.253199s (1.66min in total, 10.80min remains)
2022-11-29 15:54:25 NUM_SUB: 174;----------------------------
2022-11-29 15:54:25 Epoch [06000/30000] Loss:0.026049 Loss_1:0.025725 Loss_2:0.000143 Loss_3:0.000000 Lr:0.000625 Time:41.012627s (2.35min in total, 9.38min remains)
2022-11-29 15:55:47 NUM_SUB: 174;----------------------------
2022-11-29 15:55:47 Epoch [08000/30000] Loss:0.005440 Loss_1:0.005280 Loss_2:0.000103 Loss_3:0.000000 Lr:0.000556 Time:81.990870s (3.71min in total, 10.21min remains)
2022-11-29 15:56:49 NUM_SUB: 174;----------------------------
2022-11-29 15:56:49 Epoch [10000/30000] Loss:0.000402 Loss_1:0.000293 Loss_2:0.000108 Loss_3:0.000000 Lr:0.000500 Time:61.407204s (4.74min in total, 9.47min remains)
2022-11-29 15:59:01 NUM_SUB: 174;----------------------------
2022-11-29 15:59:01 Epoch [12000/30000] Loss:0.000149 Loss_1:0.000101 Loss_2:0.000048 Loss_3:0.000000 Lr:0.000455 Time:131.673490s (6.93min in total, 10.39min remains)
2022-11-29 16:00:02 NUM_SUB: 174;----------------------------
2022-11-29 16:00:02 Epoch [14000/30000] Loss:0.000071 Loss_1:0.000048 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:61.537972s (7.96min in total, 9.09min remains)
2022-11-29 16:00:40 NUM_SUB: 174;----------------------------
2022-11-29 16:00:40 Epoch [16000/30000] Loss:0.000047 Loss_1:0.000032 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:38.193617s (8.59min in total, 7.52min remains)
2022-11-29 16:01:42 NUM_SUB: 174;----------------------------
2022-11-29 16:01:42 Epoch [18000/30000] Loss:0.000026 Loss_1:0.000016 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:61.500249s (9.62min in total, 6.41min remains)
2022-11-29 16:02:43 NUM_SUB: 174;----------------------------
2022-11-29 16:02:43 Epoch [20000/30000] Loss:0.000019 Loss_1:0.000012 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:61.193441s (10.64min in total, 5.32min remains)
2022-11-29 16:03:45 NUM_SUB: 174;----------------------------
2022-11-29 16:03:45 Epoch [22000/30000] Loss:0.000011 Loss_1:0.000006 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000313 Time:61.796767s (11.67min in total, 4.24min remains)
2022-11-29 16:04:46 NUM_SUB: 174;----------------------------
2022-11-29 16:04:46 Epoch [24000/30000] Loss:0.000009 Loss_1:0.000007 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000294 Time:61.370820s (12.69min in total, 3.17min remains)
2022-11-29 16:05:24 NUM_SUB: 174;----------------------------
2022-11-29 16:05:24 Epoch [26000/30000] Loss:0.000011 Loss_1:0.000009 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.274147s (13.33min in total, 2.05min remains)
2022-11-29 16:06:26 NUM_SUB: 174;----------------------------
2022-11-29 16:06:26 Epoch [28000/30000] Loss:0.000005 Loss_1:0.000004 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000263 Time:61.556182s (14.35min in total, 1.03min remains)
2022-11-29 16:07:28 Testing & drawing...
2022-11-29 16:07:28 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:07:30 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=174/
2022-11-29 16:07:30 [Loss]
2022-11-29 16:07:30 NUM_SUB: 174; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:07:30 NUM_SUB: 174; Personalized parameter estimation: Parameter containing:
tensor([0.0069, 0.0133, 0.0098, 2.1215, 0.3074, 0.0176, 3.0240, 0.8964, 0.4556,
        0.0135, 0.0319, 0.0134, 0.8371, 0.1689, 0.0174, 2.0133, 0.6977, 0.8000,
        0.0118, 4.1410, 0.6816, 0.0225, 3.7427, 0.8742, 0.0203, 4.5620, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:07:30 NUM_SUB: 174;----------------------------
2022-11-29 16:07:30 Epoch [30000/30000] Loss:0.000004 Loss_1:0.000003 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:64.115398s (15.42min in total, 0.00min remains)
2022-11-29 16:07:30 NUM_SUB: 174------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:07:30 Testing & drawing...
2022-11-29 16:07:30 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:07:32 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=174/
2022-11-29 16:07:32 [Loss]
2022-11-29 16:07:32 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:07:32 General parameter estimation: Parameter containing:
tensor([0.0069, 0.0133, 0.0098, 2.1215, 0.3074, 0.0176, 3.0241, 0.8964, 0.4556,
        0.0135, 0.0319, 0.0134, 0.8371, 0.1689, 0.0174, 2.0134, 0.6977, 0.8000,
        0.0118, 4.1411, 0.6816, 0.0225, 3.7427, 0.8742, 0.0203, 4.5621, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:07:32 A: prod, degr, TonA, NonA
2022-11-29 16:07:32 [0.4624617  0.4380937  0.04648984 0.0529548 ]
2022-11-29 16:07:32 T: prod, degr, AonT, NonT
2022-11-29 16:07:32 [0.38424176 0.44461194 0.12409354 0.04705278]
2022-11-29 16:07:32 N: AonN, TonN, ATonN
2022-11-29 16:07:32 [0.0082263  0.964964   0.02680969]
2022-11-29 16:07:32 using cpu
2022-11-29 16:07:32 epoch = 30000
2022-11-29 16:07:32 epoch_step = 2000
2022-11-29 16:07:32 model_name = SimpleNetworkAD
2022-11-29 16:07:32 now_string = 2022-11-28-18-17-05
2022-11-29 16:07:32 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:07:32 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:07:32 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:07:32 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:07:32 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:07:32 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:09:44 NUM_SUB: 175;----------------------------
2022-11-29 16:09:44 Epoch [02000/30000] Loss:0.168935 Loss_1:0.168032 Loss_2:0.000353 Loss_3:0.000000 Lr:0.000833 Time:131.637836s (2.19min in total, 30.72min remains)
2022-11-29 16:10:22 NUM_SUB: 175;----------------------------
2022-11-29 16:10:22 Epoch [04000/30000] Loss:0.106978 Loss_1:0.106283 Loss_2:0.000083 Loss_3:0.000000 Lr:0.000714 Time:38.161219s (2.83min in total, 18.40min remains)
2022-11-29 16:11:00 NUM_SUB: 175;----------------------------
2022-11-29 16:11:00 Epoch [06000/30000] Loss:0.021664 Loss_1:0.021315 Loss_2:0.000111 Loss_3:0.000000 Lr:0.000625 Time:38.280011s (3.47min in total, 13.87min remains)
2022-11-29 16:11:38 NUM_SUB: 175;----------------------------
2022-11-29 16:11:38 Epoch [08000/30000] Loss:0.005668 Loss_1:0.005478 Loss_2:0.000152 Loss_3:0.000000 Lr:0.000556 Time:38.170306s (4.10min in total, 11.29min remains)
2022-11-29 16:12:16 NUM_SUB: 175;----------------------------
2022-11-29 16:12:16 Epoch [10000/30000] Loss:0.001409 Loss_1:0.001306 Loss_2:0.000101 Loss_3:0.000000 Lr:0.000500 Time:38.262936s (4.74min in total, 9.48min remains)
2022-11-29 16:12:55 NUM_SUB: 175;----------------------------
2022-11-29 16:12:55 Epoch [12000/30000] Loss:0.000508 Loss_1:0.000468 Loss_2:0.000039 Loss_3:0.000000 Lr:0.000455 Time:38.149542s (5.38min in total, 8.07min remains)
2022-11-29 16:13:33 NUM_SUB: 175;----------------------------
2022-11-29 16:13:33 Epoch [14000/30000] Loss:0.000182 Loss_1:0.000154 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000417 Time:38.196042s (6.01min in total, 6.87min remains)
2022-11-29 16:14:11 NUM_SUB: 175;----------------------------
2022-11-29 16:14:11 Epoch [16000/30000] Loss:0.000124 Loss_1:0.000106 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000385 Time:38.179469s (6.65min in total, 5.82min remains)
2022-11-29 16:14:49 NUM_SUB: 175;----------------------------
2022-11-29 16:14:49 Epoch [18000/30000] Loss:0.000088 Loss_1:0.000076 Loss_2:0.000012 Loss_3:0.000000 Lr:0.000357 Time:38.174142s (7.29min in total, 4.86min remains)
2022-11-29 16:15:27 NUM_SUB: 175;----------------------------
2022-11-29 16:15:27 Epoch [20000/30000] Loss:0.000060 Loss_1:0.000052 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.239658s (7.92min in total, 3.96min remains)
2022-11-29 16:16:06 NUM_SUB: 175;----------------------------
2022-11-29 16:16:06 Epoch [22000/30000] Loss:0.000055 Loss_1:0.000049 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.837072s (8.57min in total, 3.12min remains)
2022-11-29 16:16:45 NUM_SUB: 175;----------------------------
2022-11-29 16:16:45 Epoch [24000/30000] Loss:0.000054 Loss_1:0.000048 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000294 Time:38.761655s (9.22min in total, 2.30min remains)
2022-11-29 16:17:23 NUM_SUB: 175;----------------------------
2022-11-29 16:17:23 Epoch [26000/30000] Loss:0.000052 Loss_1:0.000047 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000278 Time:38.211439s (9.85min in total, 1.52min remains)
2022-11-29 16:18:01 NUM_SUB: 175;----------------------------
2022-11-29 16:18:01 Epoch [28000/30000] Loss:0.000051 Loss_1:0.000047 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.207559s (10.49min in total, 0.75min remains)
2022-11-29 16:18:40 Testing & drawing...
2022-11-29 16:18:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:18:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=175/
2022-11-29 16:18:41 [Loss]
2022-11-29 16:18:41 NUM_SUB: 175; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:18:41 NUM_SUB: 175; Personalized parameter estimation: Parameter containing:
tensor([0.0109, 0.0589, 0.0096, 2.0992, 0.3074, 0.0160, 3.9146, 0.8964, 0.4556,
        0.0141, 0.0295, 0.0140, 0.9733, 0.1689, 0.0174, 2.8128, 0.6977, 0.8000,
        0.0126, 2.6346, 0.6816, 0.0180, 3.3675, 0.8742, 0.0219, 4.0841, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:18:41 NUM_SUB: 175;----------------------------
2022-11-29 16:18:41 Epoch [30000/30000] Loss:0.000049 Loss_1:0.000047 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.849505s (11.16min in total, 0.00min remains)
2022-11-29 16:18:41 NUM_SUB: 175------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:18:41 Testing & drawing...
2022-11-29 16:18:41 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:18:43 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=175/
2022-11-29 16:18:43 [Loss]
2022-11-29 16:18:43 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:18:43 General parameter estimation: Parameter containing:
tensor([0.0109, 0.0589, 0.0096, 2.0994, 0.3074, 0.0160, 3.9147, 0.8964, 0.4556,
        0.0141, 0.0295, 0.0140, 0.9733, 0.1689, 0.0174, 2.8129, 0.6977, 0.8000,
        0.0126, 2.6346, 0.6816, 0.0180, 3.3675, 0.8742, 0.0219, 4.0841, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:18:43 A: prod, degr, TonA, NonA
2022-11-29 16:18:43 [0.46054927 0.4745244  0.03153915 0.0333872 ]
2022-11-29 16:18:43 T: prod, degr, AonT, NonT
2022-11-29 16:18:43 [0.5569143  0.224326   0.1555582  0.06320148]
2022-11-29 16:18:43 N: AonN, TonN, ATonN
2022-11-29 16:18:43 [0.00412897 0.96461356 0.03125746]
2022-11-29 16:18:43 using cpu
2022-11-29 16:18:43 epoch = 30000
2022-11-29 16:18:43 epoch_step = 2000
2022-11-29 16:18:43 model_name = SimpleNetworkAD
2022-11-29 16:18:43 now_string = 2022-11-28-18-17-05
2022-11-29 16:18:43 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:18:43 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:18:43 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:18:43 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:18:43 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:18:43 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:19:21 NUM_SUB: 176;----------------------------
2022-11-29 16:19:21 Epoch [02000/30000] Loss:0.160582 Loss_1:0.159265 Loss_2:0.000887 Loss_3:0.000000 Lr:0.000833 Time:38.297970s (0.64min in total, 8.94min remains)
2022-11-29 16:20:00 NUM_SUB: 176;----------------------------
2022-11-29 16:20:00 Epoch [04000/30000] Loss:0.129269 Loss_1:0.128546 Loss_2:0.000342 Loss_3:0.000000 Lr:0.000714 Time:38.234696s (1.28min in total, 8.29min remains)
2022-11-29 16:20:38 NUM_SUB: 176;----------------------------
2022-11-29 16:20:38 Epoch [06000/30000] Loss:0.072616 Loss_1:0.072078 Loss_2:0.000226 Loss_3:0.000000 Lr:0.000625 Time:38.165013s (1.91min in total, 7.65min remains)
2022-11-29 16:21:16 NUM_SUB: 176;----------------------------
2022-11-29 16:21:16 Epoch [08000/30000] Loss:0.010980 Loss_1:0.010583 Loss_2:0.000268 Loss_3:0.000000 Lr:0.000556 Time:38.328341s (2.55min in total, 7.01min remains)
2022-11-29 16:21:54 NUM_SUB: 176;----------------------------
2022-11-29 16:21:54 Epoch [10000/30000] Loss:0.000997 Loss_1:0.000812 Loss_2:0.000169 Loss_3:0.000000 Lr:0.000500 Time:38.175683s (3.19min in total, 6.37min remains)
2022-11-29 16:22:32 NUM_SUB: 176;----------------------------
2022-11-29 16:22:32 Epoch [12000/30000] Loss:0.000533 Loss_1:0.000448 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000455 Time:38.241180s (3.82min in total, 5.74min remains)
2022-11-29 16:23:11 NUM_SUB: 176;----------------------------
2022-11-29 16:23:11 Epoch [14000/30000] Loss:0.000318 Loss_1:0.000273 Loss_2:0.000044 Loss_3:0.000000 Lr:0.000417 Time:38.141754s (4.46min in total, 5.10min remains)
2022-11-29 16:23:49 NUM_SUB: 176;----------------------------
2022-11-29 16:23:49 Epoch [16000/30000] Loss:0.000228 Loss_1:0.000201 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000385 Time:38.292161s (5.10min in total, 4.46min remains)
2022-11-29 16:24:27 NUM_SUB: 176;----------------------------
2022-11-29 16:24:27 Epoch [18000/30000] Loss:0.000135 Loss_1:0.000118 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:38.241383s (5.74min in total, 3.82min remains)
2022-11-29 16:25:05 NUM_SUB: 176;----------------------------
2022-11-29 16:25:05 Epoch [20000/30000] Loss:0.000058 Loss_1:0.000046 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000333 Time:38.225225s (6.37min in total, 3.19min remains)
2022-11-29 16:25:44 NUM_SUB: 176;----------------------------
2022-11-29 16:25:44 Epoch [22000/30000] Loss:0.000055 Loss_1:0.000046 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000313 Time:38.148758s (7.01min in total, 2.55min remains)
2022-11-29 16:26:22 NUM_SUB: 176;----------------------------
2022-11-29 16:26:22 Epoch [24000/30000] Loss:0.000053 Loss_1:0.000046 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:38.302648s (7.65min in total, 1.91min remains)
2022-11-29 16:27:00 NUM_SUB: 176;----------------------------
2022-11-29 16:27:00 Epoch [26000/30000] Loss:0.000051 Loss_1:0.000046 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000278 Time:38.224657s (8.28min in total, 1.27min remains)
2022-11-29 16:27:38 NUM_SUB: 176;----------------------------
2022-11-29 16:27:38 Epoch [28000/30000] Loss:0.000049 Loss_1:0.000045 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000263 Time:38.283085s (8.92min in total, 0.64min remains)
2022-11-29 16:28:17 Testing & drawing...
2022-11-29 16:28:17 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:28:18 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=176/
2022-11-29 16:28:18 [Loss]
2022-11-29 16:28:18 NUM_SUB: 176; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:28:18 NUM_SUB: 176; Personalized parameter estimation: Parameter containing:
tensor([0.0115, 0.0207, 0.0054, 3.9077, 0.3074, 0.0186, 3.3269, 0.8964, 0.4556,
        0.0321, 0.0497, 0.0151, 0.2416, 0.1689, 0.0175, 1.3534, 0.6977, 0.8000,
        0.0115, 4.5571, 0.6816, 0.0203, 4.5993, 0.8742, 0.0158, 5.2431, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:28:18 NUM_SUB: 176;----------------------------
2022-11-29 16:28:18 Epoch [30000/30000] Loss:0.000047 Loss_1:0.000045 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:39.885926s (9.59min in total, 0.00min remains)
2022-11-29 16:28:18 NUM_SUB: 176------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:28:18 Testing & drawing...
2022-11-29 16:28:18 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:28:20 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=176/
2022-11-29 16:28:20 [Loss]
2022-11-29 16:28:20 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:28:20 General parameter estimation: Parameter containing:
tensor([0.0115, 0.0207, 0.0054, 3.9078, 0.3074, 0.0186, 3.3271, 0.8964, 0.4556,
        0.0321, 0.0497, 0.0151, 0.2417, 0.1689, 0.0175, 1.3535, 0.6977, 0.8000,
        0.0115, 4.5572, 0.6816, 0.0203, 4.5995, 0.8742, 0.0158, 5.2432, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:28:20 A: prod, degr, TonA, NonA
2022-11-29 16:28:20 [0.494072   0.46151948 0.01424203 0.03016648]
2022-11-29 16:28:20 T: prod, degr, AonT, NonT
2022-11-29 16:28:20 [0.4256696  0.34153292 0.18847989 0.04431757]
2022-11-29 16:28:20 N: AonN, TonN, ATonN
2022-11-29 16:28:20 [0.00750849 0.95866835 0.03382317]
2022-11-29 16:28:20 using cpu
2022-11-29 16:28:20 epoch = 30000
2022-11-29 16:28:20 epoch_step = 2000
2022-11-29 16:28:20 model_name = SimpleNetworkAD
2022-11-29 16:28:20 now_string = 2022-11-28-18-17-05
2022-11-29 16:28:20 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:28:20 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:28:20 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:28:20 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:28:20 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:28:20 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:28:59 NUM_SUB: 177;----------------------------
2022-11-29 16:28:59 Epoch [02000/30000] Loss:0.047563 Loss_1:0.046014 Loss_2:0.001137 Loss_3:0.000000 Lr:0.000833 Time:38.519794s (0.64min in total, 8.99min remains)
2022-11-29 16:29:37 NUM_SUB: 177;----------------------------
2022-11-29 16:29:37 Epoch [04000/30000] Loss:0.035024 Loss_1:0.034577 Loss_2:0.000307 Loss_3:0.000000 Lr:0.000714 Time:38.285268s (1.28min in total, 8.32min remains)
2022-11-29 16:30:15 NUM_SUB: 177;----------------------------
2022-11-29 16:30:15 Epoch [06000/30000] Loss:0.018938 Loss_1:0.018659 Loss_2:0.000165 Loss_3:0.000000 Lr:0.000625 Time:38.404170s (1.92min in total, 7.68min remains)
2022-11-29 16:30:54 NUM_SUB: 177;----------------------------
2022-11-29 16:30:54 Epoch [08000/30000] Loss:0.005738 Loss_1:0.005564 Loss_2:0.000134 Loss_3:0.000000 Lr:0.000556 Time:38.269743s (2.56min in total, 7.03min remains)
2022-11-29 16:31:32 NUM_SUB: 177;----------------------------
2022-11-29 16:31:32 Epoch [10000/30000] Loss:0.001873 Loss_1:0.001739 Loss_2:0.000131 Loss_3:0.000000 Lr:0.000500 Time:38.467757s (3.20min in total, 6.40min remains)
2022-11-29 16:32:10 NUM_SUB: 177;----------------------------
2022-11-29 16:32:10 Epoch [12000/30000] Loss:0.000957 Loss_1:0.000892 Loss_2:0.000064 Loss_3:0.000000 Lr:0.000455 Time:38.308137s (3.84min in total, 5.76min remains)
2022-11-29 16:32:49 NUM_SUB: 177;----------------------------
2022-11-29 16:32:49 Epoch [14000/30000] Loss:0.000440 Loss_1:0.000401 Loss_2:0.000037 Loss_3:0.000000 Lr:0.000417 Time:38.313019s (4.48min in total, 5.12min remains)
2022-11-29 16:33:27 NUM_SUB: 177;----------------------------
2022-11-29 16:33:27 Epoch [16000/30000] Loss:0.000349 Loss_1:0.000324 Loss_2:0.000024 Loss_3:0.000000 Lr:0.000385 Time:38.346527s (5.12min in total, 4.48min remains)
2022-11-29 16:34:05 NUM_SUB: 177;----------------------------
2022-11-29 16:34:05 Epoch [18000/30000] Loss:0.000329 Loss_1:0.000311 Loss_2:0.000017 Loss_3:0.000000 Lr:0.000357 Time:38.220299s (5.75min in total, 3.83min remains)
2022-11-29 16:34:43 NUM_SUB: 177;----------------------------
2022-11-29 16:34:43 Epoch [20000/30000] Loss:0.000318 Loss_1:0.000305 Loss_2:0.000013 Loss_3:0.000000 Lr:0.000333 Time:38.194698s (6.39min in total, 3.19min remains)
2022-11-29 16:35:22 NUM_SUB: 177;----------------------------
2022-11-29 16:35:22 Epoch [22000/30000] Loss:0.000315 Loss_1:0.000304 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000313 Time:38.484688s (7.03min in total, 2.56min remains)
2022-11-29 16:36:00 NUM_SUB: 177;----------------------------
2022-11-29 16:36:00 Epoch [24000/30000] Loss:0.000313 Loss_1:0.000304 Loss_2:0.000009 Loss_3:0.000000 Lr:0.000294 Time:38.254642s (7.67min in total, 1.92min remains)
2022-11-29 16:36:38 NUM_SUB: 177;----------------------------
2022-11-29 16:36:38 Epoch [26000/30000] Loss:0.000315 Loss_1:0.000308 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:38.303662s (8.31min in total, 1.28min remains)
2022-11-29 16:37:17 NUM_SUB: 177;----------------------------
2022-11-29 16:37:17 Epoch [28000/30000] Loss:0.000310 Loss_1:0.000304 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:38.263849s (8.94min in total, 0.64min remains)
2022-11-29 16:37:55 Testing & drawing...
2022-11-29 16:37:55 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:37:57 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=177/
2022-11-29 16:37:57 [Loss]
2022-11-29 16:37:57 NUM_SUB: 177; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:37:57 NUM_SUB: 177; Personalized parameter estimation: Parameter containing:
tensor([0.0137, 0.0167, 0.0230, 1.9727, 0.3074, 0.0184, 4.1712, 0.8964, 0.4556,
        0.0140, 0.0305, 0.0136, 0.9156, 0.1689, 0.0174, 2.7018, 0.6977, 0.8000,
        0.0088, 5.0845, 0.6816, 0.0174, 3.9694, 0.8742, 0.0168, 5.0837, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:37:57 NUM_SUB: 177;----------------------------
2022-11-29 16:37:57 Epoch [30000/30000] Loss:0.000309 Loss_1:0.000304 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000250 Time:39.900686s (9.61min in total, 0.00min remains)
2022-11-29 16:37:57 NUM_SUB: 177------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:37:57 Testing & drawing...
2022-11-29 16:37:57 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:37:58 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=177/
2022-11-29 16:37:58 [Loss]
2022-11-29 16:37:58 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:37:58 General parameter estimation: Parameter containing:
tensor([0.0137, 0.0167, 0.0230, 1.9728, 0.3074, 0.0184, 4.1713, 0.8964, 0.4556,
        0.0140, 0.0305, 0.0136, 0.9156, 0.1689, 0.0174, 2.7019, 0.6977, 0.8000,
        0.0088, 5.0846, 0.6816, 0.0174, 3.9695, 0.8742, 0.0168, 5.0839, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:37:58 A: prod, degr, TonA, NonA
2022-11-29 16:37:58 [0.4768357  0.45293507 0.0602129  0.01001637]
2022-11-29 16:37:58 T: prod, degr, AonT, NonT
2022-11-29 16:37:58 [0.33440852 0.562866   0.08760147 0.01512405]
2022-11-29 16:37:58 N: AonN, TonN, ATonN
2022-11-29 16:37:58 [0.01294636 0.9507368  0.03631683]
2022-11-29 16:37:58 using cpu
2022-11-29 16:37:58 epoch = 30000
2022-11-29 16:37:58 epoch_step = 2000
2022-11-29 16:37:58 model_name = SimpleNetworkAD
2022-11-29 16:37:58 now_string = 2022-11-28-18-17-05
2022-11-29 16:37:58 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:37:58 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:37:58 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:37:58 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:37:58 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:37:58 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:38:37 NUM_SUB: 178;----------------------------
2022-11-29 16:38:37 Epoch [02000/30000] Loss:0.107718 Loss_1:0.106985 Loss_2:0.000361 Loss_3:0.000000 Lr:0.000833 Time:38.280177s (0.64min in total, 8.93min remains)
2022-11-29 16:39:15 NUM_SUB: 178;----------------------------
2022-11-29 16:39:15 Epoch [04000/30000] Loss:0.074438 Loss_1:0.074091 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000714 Time:38.310140s (1.28min in total, 8.30min remains)
2022-11-29 16:39:53 NUM_SUB: 178;----------------------------
2022-11-29 16:39:53 Epoch [06000/30000] Loss:0.020784 Loss_1:0.020595 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000625 Time:38.163729s (1.91min in total, 7.65min remains)
2022-11-29 16:40:32 NUM_SUB: 178;----------------------------
2022-11-29 16:40:32 Epoch [08000/30000] Loss:0.005462 Loss_1:0.005382 Loss_2:0.000079 Loss_3:0.000000 Lr:0.000556 Time:38.532867s (2.55min in total, 7.03min remains)
2022-11-29 16:41:10 NUM_SUB: 178;----------------------------
2022-11-29 16:41:10 Epoch [10000/30000] Loss:0.004282 Loss_1:0.004201 Loss_2:0.000081 Loss_3:0.000000 Lr:0.000500 Time:38.379480s (3.19min in total, 6.39min remains)
2022-11-29 16:41:48 NUM_SUB: 178;----------------------------
2022-11-29 16:41:48 Epoch [12000/30000] Loss:0.001751 Loss_1:0.001721 Loss_2:0.000030 Loss_3:0.000000 Lr:0.000455 Time:38.259582s (3.83min in total, 5.75min remains)
2022-11-29 16:42:27 NUM_SUB: 178;----------------------------
2022-11-29 16:42:27 Epoch [14000/30000] Loss:0.000192 Loss_1:0.000167 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:38.239186s (4.47min in total, 5.11min remains)
2022-11-29 16:43:05 NUM_SUB: 178;----------------------------
2022-11-29 16:43:05 Epoch [16000/30000] Loss:0.000154 Loss_1:0.000140 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:38.229123s (5.11min in total, 4.47min remains)
2022-11-29 16:43:43 NUM_SUB: 178;----------------------------
2022-11-29 16:43:43 Epoch [18000/30000] Loss:0.000126 Loss_1:0.000118 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000357 Time:38.222993s (5.74min in total, 3.83min remains)
2022-11-29 16:44:21 NUM_SUB: 178;----------------------------
2022-11-29 16:44:21 Epoch [20000/30000] Loss:0.000080 Loss_1:0.000075 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000333 Time:38.184625s (6.38min in total, 3.19min remains)
2022-11-29 16:44:59 NUM_SUB: 178;----------------------------
2022-11-29 16:44:59 Epoch [22000/30000] Loss:0.000014 Loss_1:0.000011 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000313 Time:38.222720s (7.02min in total, 2.55min remains)
2022-11-29 16:45:38 NUM_SUB: 178;----------------------------
2022-11-29 16:45:38 Epoch [24000/30000] Loss:0.000011 Loss_1:0.000009 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000294 Time:38.647091s (7.66min in total, 1.92min remains)
2022-11-29 16:46:16 NUM_SUB: 178;----------------------------
2022-11-29 16:46:16 Epoch [26000/30000] Loss:0.000012 Loss_1:0.000010 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000278 Time:38.408250s (8.30min in total, 1.28min remains)
2022-11-29 16:46:55 NUM_SUB: 178;----------------------------
2022-11-29 16:46:55 Epoch [28000/30000] Loss:0.000011 Loss_1:0.000009 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.423933s (8.94min in total, 0.64min remains)
2022-11-29 16:47:33 Testing & drawing...
2022-11-29 16:47:33 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:47:35 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=178/
2022-11-29 16:47:35 [Loss]
2022-11-29 16:47:35 NUM_SUB: 178; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:47:35 NUM_SUB: 178; Personalized parameter estimation: Parameter containing:
tensor([0.0167, 0.4721, 0.0102, 0.5350, 0.3074, 0.4185, 1.3528, 0.8964, 0.4556,
        0.0149, 0.0954, 0.0954, 0.6695, 0.1689, 0.0176, 2.2584, 0.6977, 0.8000,
        0.0125, 2.1064, 0.6816, 0.0221, 2.6109, 0.8742, 0.0220, 3.1202, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:47:35 NUM_SUB: 178;----------------------------
2022-11-29 16:47:35 Epoch [30000/30000] Loss:0.000011 Loss_1:0.000009 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000250 Time:40.137942s (9.61min in total, 0.00min remains)
2022-11-29 16:47:35 NUM_SUB: 178------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:47:35 Testing & drawing...
2022-11-29 16:47:35 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:47:37 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=178/
2022-11-29 16:47:37 [Loss]
2022-11-29 16:47:37 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:47:37 General parameter estimation: Parameter containing:
tensor([0.0167, 0.4722, 0.0102, 0.5351, 0.3074, 0.4184, 1.3529, 0.8964, 0.4556,
        0.0149, 0.0954, 0.0954, 0.6695, 0.1689, 0.0176, 2.2585, 0.6977, 0.8000,
        0.0125, 2.1063, 0.6816, 0.0221, 2.6109, 0.8742, 0.0220, 3.1202, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:47:37 A: prod, degr, TonA, NonA
2022-11-29 16:47:37 [0.05656563 0.49845544 0.01451665 0.43046227]
2022-11-29 16:47:37 T: prod, degr, AonT, NonT
2022-11-29 16:47:37 [0.19451123 0.38285094 0.39161524 0.03102257]
2022-11-29 16:47:37 N: AonN, TonN, ATonN
2022-11-29 16:47:37 [0.0147459  0.9442383  0.04101584]
2022-11-29 16:47:37 using cpu
2022-11-29 16:47:37 epoch = 30000
2022-11-29 16:47:37 epoch_step = 2000
2022-11-29 16:47:37 model_name = SimpleNetworkAD
2022-11-29 16:47:37 now_string = 2022-11-28-18-17-05
2022-11-29 16:47:37 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:47:37 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:47:37 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:47:37 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:47:37 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:47:37 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:48:15 NUM_SUB: 179;----------------------------
2022-11-29 16:48:15 Epoch [02000/30000] Loss:0.034053 Loss_1:0.033209 Loss_2:0.000394 Loss_3:0.000000 Lr:0.000833 Time:38.424552s (0.64min in total, 8.97min remains)
2022-11-29 16:48:53 NUM_SUB: 179;----------------------------
2022-11-29 16:48:53 Epoch [04000/30000] Loss:0.028321 Loss_1:0.028172 Loss_2:0.000052 Loss_3:0.000000 Lr:0.000714 Time:38.168297s (1.28min in total, 8.30min remains)
2022-11-29 16:49:32 NUM_SUB: 179;----------------------------
2022-11-29 16:49:32 Epoch [06000/30000] Loss:0.019172 Loss_1:0.019010 Loss_2:0.000056 Loss_3:0.000000 Lr:0.000625 Time:38.322947s (1.92min in total, 7.66min remains)
2022-11-29 16:50:10 NUM_SUB: 179;----------------------------
2022-11-29 16:50:10 Epoch [08000/30000] Loss:0.007032 Loss_1:0.006917 Loss_2:0.000068 Loss_3:0.000000 Lr:0.000556 Time:38.253968s (2.55min in total, 7.02min remains)
2022-11-29 16:50:48 NUM_SUB: 179;----------------------------
2022-11-29 16:50:48 Epoch [10000/30000] Loss:0.002016 Loss_1:0.001930 Loss_2:0.000084 Loss_3:0.000000 Lr:0.000500 Time:38.273481s (3.19min in total, 6.38min remains)
2022-11-29 16:51:27 NUM_SUB: 179;----------------------------
2022-11-29 16:51:27 Epoch [12000/30000] Loss:0.001508 Loss_1:0.001458 Loss_2:0.000049 Loss_3:0.000000 Lr:0.000455 Time:38.395123s (3.83min in total, 5.75min remains)
2022-11-29 16:52:05 NUM_SUB: 179;----------------------------
2022-11-29 16:52:05 Epoch [14000/30000] Loss:0.001246 Loss_1:0.001222 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000417 Time:38.212284s (4.47min in total, 5.11min remains)
2022-11-29 16:52:43 NUM_SUB: 179;----------------------------
2022-11-29 16:52:43 Epoch [16000/30000] Loss:0.001223 Loss_1:0.001207 Loss_2:0.000016 Loss_3:0.000000 Lr:0.000385 Time:38.197210s (5.10min in total, 4.47min remains)
2022-11-29 16:53:21 NUM_SUB: 179;----------------------------
2022-11-29 16:53:21 Epoch [18000/30000] Loss:0.001215 Loss_1:0.001202 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:38.262463s (5.74min in total, 3.83min remains)
2022-11-29 16:54:00 NUM_SUB: 179;----------------------------
2022-11-29 16:54:00 Epoch [20000/30000] Loss:0.001210 Loss_1:0.001202 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:38.189905s (6.38min in total, 3.19min remains)
2022-11-29 16:54:38 NUM_SUB: 179;----------------------------
2022-11-29 16:54:38 Epoch [22000/30000] Loss:0.001206 Loss_1:0.001199 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:38.409010s (7.02min in total, 2.55min remains)
2022-11-29 16:55:16 NUM_SUB: 179;----------------------------
2022-11-29 16:55:16 Epoch [24000/30000] Loss:0.001203 Loss_1:0.001198 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000294 Time:38.328606s (7.66min in total, 1.91min remains)
2022-11-29 16:55:55 NUM_SUB: 179;----------------------------
2022-11-29 16:55:55 Epoch [26000/30000] Loss:0.001201 Loss_1:0.001197 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000278 Time:38.202172s (8.29min in total, 1.28min remains)
2022-11-29 16:56:33 NUM_SUB: 179;----------------------------
2022-11-29 16:56:33 Epoch [28000/30000] Loss:0.001200 Loss_1:0.001197 Loss_2:0.000002 Loss_3:0.000000 Lr:0.000263 Time:38.344119s (8.93min in total, 0.64min remains)
2022-11-29 16:57:11 Testing & drawing...
2022-11-29 16:57:11 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:57:13 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=179/
2022-11-29 16:57:13 [Loss]
2022-11-29 16:57:13 NUM_SUB: 179; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:57:13 NUM_SUB: 179; Personalized parameter estimation: Parameter containing:
tensor([0.0964, 0.3404, 0.0090, 0.6594, 0.3074, 0.0840, 1.1352, 0.8964, 0.4556,
        0.0137, 0.0358, 0.0133, 0.7793, 0.1689, 0.0176, 1.1214, 0.6977, 0.8000,
        0.0124, 2.6015, 0.6816, 0.0225, 2.8286, 0.8742, 0.0140, 3.2925, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:57:13 NUM_SUB: 179;----------------------------
2022-11-29 16:57:13 Epoch [30000/30000] Loss:0.001199 Loss_1:0.001197 Loss_2:0.000001 Loss_3:0.000000 Lr:0.000250 Time:39.948869s (9.60min in total, 0.00min remains)
2022-11-29 16:57:13 NUM_SUB: 179------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 16:57:13 Testing & drawing...
2022-11-29 16:57:13 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 16:57:14 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=179/
2022-11-29 16:57:14 [Loss]
2022-11-29 16:57:14 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 16:57:14 General parameter estimation: Parameter containing:
tensor([0.0964, 0.3403, 0.0090, 0.6594, 0.3074, 0.0840, 1.1352, 0.8964, 0.4556,
        0.0137, 0.0358, 0.0133, 0.7792, 0.1689, 0.0176, 1.1215, 0.6977, 0.8000,
        0.0124, 2.6014, 0.6816, 0.0225, 2.8285, 0.8742, 0.0140, 3.2924, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 16:57:14 A: prod, degr, TonA, NonA
2022-11-29 16:57:14 [0.40349165 0.49943066 0.01674874 0.08032893]
2022-11-29 16:57:14 T: prod, degr, AonT, NonT
2022-11-29 16:57:14 [0.38900915 0.35704547 0.13784347 0.1161019 ]
2022-11-29 16:57:14 N: AonN, TonN, ATonN
2022-11-29 16:57:14 [0.01028904 0.96194625 0.02776473]
2022-11-29 16:57:15 using cpu
2022-11-29 16:57:15 epoch = 30000
2022-11-29 16:57:15 epoch_step = 2000
2022-11-29 16:57:15 model_name = SimpleNetworkAD
2022-11-29 16:57:15 now_string = 2022-11-28-18-17-05
2022-11-29 16:57:15 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 16:57:15 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 16:57:15 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 16:57:15 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 16:57:15 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 16:57:15 --------------------------------------------------training start--------------------------------------------------
2022-11-29 16:57:53 NUM_SUB: 180;----------------------------
2022-11-29 16:57:53 Epoch [02000/30000] Loss:0.093915 Loss_1:0.092895 Loss_2:0.000581 Loss_3:0.000000 Lr:0.000833 Time:38.271038s (0.64min in total, 8.93min remains)
2022-11-29 16:58:31 NUM_SUB: 180;----------------------------
2022-11-29 16:58:31 Epoch [04000/30000] Loss:0.068365 Loss_1:0.067938 Loss_2:0.000154 Loss_3:0.000000 Lr:0.000714 Time:38.188235s (1.27min in total, 8.28min remains)
2022-11-29 16:59:09 NUM_SUB: 180;----------------------------
2022-11-29 16:59:09 Epoch [06000/30000] Loss:0.024316 Loss_1:0.023959 Loss_2:0.000184 Loss_3:0.000000 Lr:0.000625 Time:38.202481s (1.91min in total, 7.64min remains)
2022-11-29 16:59:47 NUM_SUB: 180;----------------------------
2022-11-29 16:59:47 Epoch [08000/30000] Loss:0.003561 Loss_1:0.003350 Loss_2:0.000176 Loss_3:0.000000 Lr:0.000556 Time:38.189668s (2.55min in total, 7.01min remains)
2022-11-29 17:00:26 NUM_SUB: 180;----------------------------
2022-11-29 17:00:26 Epoch [10000/30000] Loss:0.001452 Loss_1:0.001334 Loss_2:0.000112 Loss_3:0.000000 Lr:0.000500 Time:38.373171s (3.19min in total, 6.37min remains)
2022-11-29 17:01:04 NUM_SUB: 180;----------------------------
2022-11-29 17:01:04 Epoch [12000/30000] Loss:0.001168 Loss_1:0.001113 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000455 Time:38.188061s (3.82min in total, 5.74min remains)
2022-11-29 17:01:42 NUM_SUB: 180;----------------------------
2022-11-29 17:01:42 Epoch [14000/30000] Loss:0.001106 Loss_1:0.001085 Loss_2:0.000022 Loss_3:0.000000 Lr:0.000417 Time:38.255749s (4.46min in total, 5.10min remains)
2022-11-29 17:02:22 NUM_SUB: 180;----------------------------
2022-11-29 17:02:22 Epoch [16000/30000] Loss:0.001070 Loss_1:0.001056 Loss_2:0.000014 Loss_3:0.000000 Lr:0.000385 Time:39.213815s (5.11min in total, 4.48min remains)
2022-11-29 17:03:00 NUM_SUB: 180;----------------------------
2022-11-29 17:03:00 Epoch [18000/30000] Loss:0.001014 Loss_1:0.001003 Loss_2:0.000010 Loss_3:0.000000 Lr:0.000357 Time:38.454374s (5.76min in total, 3.84min remains)
2022-11-29 17:03:38 NUM_SUB: 180;----------------------------
2022-11-29 17:03:38 Epoch [20000/30000] Loss:0.000725 Loss_1:0.000717 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000333 Time:38.473373s (6.40min in total, 3.20min remains)
2022-11-29 17:04:17 NUM_SUB: 180;----------------------------
2022-11-29 17:04:17 Epoch [22000/30000] Loss:0.000557 Loss_1:0.000549 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000313 Time:38.384661s (7.04min in total, 2.56min remains)
2022-11-29 17:04:55 NUM_SUB: 180;----------------------------
2022-11-29 17:04:55 Epoch [24000/30000] Loss:0.000503 Loss_1:0.000495 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000294 Time:38.370539s (7.68min in total, 1.92min remains)
2022-11-29 17:05:34 NUM_SUB: 180;----------------------------
2022-11-29 17:05:34 Epoch [26000/30000] Loss:0.000492 Loss_1:0.000485 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000278 Time:38.419629s (8.32min in total, 1.28min remains)
2022-11-29 17:06:12 NUM_SUB: 180;----------------------------
2022-11-29 17:06:12 Epoch [28000/30000] Loss:0.000489 Loss_1:0.000482 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000263 Time:38.496157s (8.96min in total, 0.64min remains)
2022-11-29 17:06:50 Testing & drawing...
2022-11-29 17:06:51 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 17:06:52 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=180/
2022-11-29 17:06:52 [Loss]
2022-11-29 17:06:52 NUM_SUB: 180; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 17:06:52 NUM_SUB: 180; Personalized parameter estimation: Parameter containing:
tensor([0.0181, 0.0291, 0.0111, 2.3936, 0.3074, 0.0133, 2.9510, 0.8964, 0.4556,
        0.0129, 0.0410, 0.0109, 0.6542, 0.1689, 0.0174, 1.8164, 0.6977, 0.8000,
        0.0116, 4.4151, 0.6816, 0.0226, 3.4739, 0.8742, 0.0194, 4.5256, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 17:06:52 NUM_SUB: 180;----------------------------
2022-11-29 17:06:52 Epoch [30000/30000] Loss:0.000501 Loss_1:0.000494 Loss_2:0.000007 Loss_3:0.000000 Lr:0.000250 Time:40.032501s (9.63min in total, 0.00min remains)
2022-11-29 17:06:52 NUM_SUB: 180------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 17:06:52 Testing & drawing...
2022-11-29 17:06:52 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 17:06:54 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=180/
2022-11-29 17:06:54 [Loss]
2022-11-29 17:06:54 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 17:06:54 General parameter estimation: Parameter containing:
tensor([0.0181, 0.0293, 0.0111, 2.3938, 0.3074, 0.0133, 2.9513, 0.8964, 0.4556,
        0.0129, 0.0410, 0.0109, 0.6542, 0.1689, 0.0174, 1.8165, 0.6977, 0.8000,
        0.0116, 4.4152, 0.6816, 0.0226, 3.4741, 0.8742, 0.0194, 4.5258, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 17:06:54 A: prod, degr, TonA, NonA
2022-11-29 17:06:54 [0.48701692 0.47940773 0.01060185 0.0229735 ]
2022-11-29 17:06:54 T: prod, degr, AonT, NonT
2022-11-29 17:06:54 [0.29381287 0.5643956  0.08140587 0.06038559]
2022-11-29 17:06:54 N: AonN, TonN, ATonN
2022-11-29 17:06:54 [0.01072931 0.9629611  0.0263096 ]
2022-11-29 17:06:54 using cpu
2022-11-29 17:06:54 epoch = 30000
2022-11-29 17:06:54 epoch_step = 2000
2022-11-29 17:06:54 model_name = SimpleNetworkAD
2022-11-29 17:06:54 now_string = 2022-11-28-18-17-05
2022-11-29 17:06:54 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 17:06:54 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 17:06:54 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 17:06:54 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 17:06:54 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 17:06:54 --------------------------------------------------training start--------------------------------------------------
2022-11-29 17:07:33 NUM_SUB: 181;----------------------------
2022-11-29 17:07:33 Epoch [02000/30000] Loss:0.031338 Loss_1:0.030512 Loss_2:0.000424 Loss_3:0.000000 Lr:0.000833 Time:38.529901s (0.64min in total, 8.99min remains)
2022-11-29 17:08:11 NUM_SUB: 181;----------------------------
2022-11-29 17:08:11 Epoch [04000/30000] Loss:0.025043 Loss_1:0.024877 Loss_2:0.000062 Loss_3:0.000000 Lr:0.000714 Time:38.487832s (1.28min in total, 8.34min remains)
2022-11-29 17:08:50 NUM_SUB: 181;----------------------------
2022-11-29 17:08:50 Epoch [06000/30000] Loss:0.015693 Loss_1:0.015570 Loss_2:0.000059 Loss_3:0.000000 Lr:0.000625 Time:38.517060s (1.93min in total, 7.70min remains)
2022-11-29 17:09:28 NUM_SUB: 181;----------------------------
2022-11-29 17:09:28 Epoch [08000/30000] Loss:0.004698 Loss_1:0.004624 Loss_2:0.000060 Loss_3:0.000000 Lr:0.000556 Time:38.443346s (2.57min in total, 7.06min remains)
2022-11-29 17:10:06 NUM_SUB: 181;----------------------------
2022-11-29 17:10:06 Epoch [10000/30000] Loss:0.002504 Loss_1:0.002437 Loss_2:0.000066 Loss_3:0.000000 Lr:0.000500 Time:38.443581s (3.21min in total, 6.41min remains)
2022-11-29 17:10:45 NUM_SUB: 181;----------------------------
2022-11-29 17:10:45 Epoch [12000/30000] Loss:0.001790 Loss_1:0.001762 Loss_2:0.000027 Loss_3:0.000000 Lr:0.000455 Time:38.486299s (3.85min in total, 5.77min remains)
2022-11-29 17:11:24 NUM_SUB: 181;----------------------------
2022-11-29 17:11:24 Epoch [14000/30000] Loss:0.001055 Loss_1:0.001031 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000417 Time:38.685890s (4.49min in total, 5.14min remains)
2022-11-29 17:16:02 NUM_SUB: 181;----------------------------
2022-11-29 17:16:02 Epoch [16000/30000] Loss:0.000972 Loss_1:0.000956 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000385 Time:278.849414s (9.14min in total, 8.00min remains)
2022-11-29 17:20:30 NUM_SUB: 181;----------------------------
2022-11-29 17:20:30 Epoch [18000/30000] Loss:0.000960 Loss_1:0.000948 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000357 Time:267.662914s (13.60min in total, 9.07min remains)
2022-11-29 17:41:58 NUM_SUB: 181;----------------------------
2022-11-29 17:41:58 Epoch [20000/30000] Loss:0.000957 Loss_1:0.000948 Loss_2:0.000008 Loss_3:0.000000 Lr:0.000333 Time:1287.885328s (35.07min in total, 17.53min remains)
2022-11-29 18:00:04 NUM_SUB: 181;----------------------------
2022-11-29 18:00:04 Epoch [22000/30000] Loss:0.000954 Loss_1:0.000948 Loss_2:0.000006 Loss_3:0.000000 Lr:0.000313 Time:1085.884876s (53.16min in total, 19.33min remains)
2022-11-29 18:00:43 NUM_SUB: 181;----------------------------
2022-11-29 18:00:43 Epoch [24000/30000] Loss:0.000953 Loss_1:0.000947 Loss_2:0.000005 Loss_3:0.000000 Lr:0.000294 Time:38.636639s (53.81min in total, 13.45min remains)
2022-11-29 18:01:21 NUM_SUB: 181;----------------------------
2022-11-29 18:01:21 Epoch [26000/30000] Loss:0.000951 Loss_1:0.000947 Loss_2:0.000004 Loss_3:0.000000 Lr:0.000278 Time:38.477128s (54.45min in total, 8.38min remains)
2022-11-29 18:02:00 NUM_SUB: 181;----------------------------
2022-11-29 18:02:00 Epoch [28000/30000] Loss:0.000951 Loss_1:0.000947 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000263 Time:38.509746s (55.09min in total, 3.94min remains)
2022-11-29 18:02:38 Testing & drawing...
2022-11-29 18:02:38 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 18:02:40 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=181/
2022-11-29 18:02:40 [Loss]
2022-11-29 18:02:40 NUM_SUB: 181; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 18:02:40 NUM_SUB: 181; Personalized parameter estimation: Parameter containing:
tensor([0.1730, 0.6341, 0.0095, 0.0879, 0.3074, 0.1920, 0.7597, 0.8964, 0.4556,
        0.0143, 0.1203, 0.1186, 0.6637, 0.1689, 0.0175, 1.0283, 0.6977, 0.8000,
        0.0122, 3.7305, 0.6816, 0.0223, 3.5386, 0.8742, 0.0210, 4.2877, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 18:02:40 NUM_SUB: 181;----------------------------
2022-11-29 18:02:40 Epoch [30000/30000] Loss:0.000955 Loss_1:0.000952 Loss_2:0.000003 Loss_3:0.000000 Lr:0.000250 Time:40.041431s (55.76min in total, 0.00min remains)
2022-11-29 18:02:40 NUM_SUB: 181------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 18:02:40 Testing & drawing...
2022-11-29 18:02:40 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 18:02:41 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=181/
2022-11-29 18:02:41 [Loss]
2022-11-29 18:02:41 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 18:02:41 General parameter estimation: Parameter containing:
tensor([0.1731, 0.6340, 0.0095, 0.0879, 0.3074, 0.1921, 0.7596, 0.8964, 0.4556,
        0.0143, 0.1203, 0.1186, 0.6637, 0.1689, 0.0175, 1.0283, 0.6977, 0.8000,
        0.0122, 3.7306, 0.6816, 0.0223, 3.5387, 0.8742, 0.0210, 4.2878, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 18:02:41 A: prod, degr, TonA, NonA
2022-11-29 18:02:41 [0.33821017 0.500292   0.01763423 0.14386356]
2022-11-29 18:02:41 T: prod, degr, AonT, NonT
2022-11-29 18:02:41 [0.14160393 0.48104325 0.33351943 0.04383341]
2022-11-29 18:02:41 N: AonN, TonN, ATonN
2022-11-29 18:02:41 [0.00735417 0.97196716 0.02067862]
2022-11-29 18:02:41 using cpu
2022-11-29 18:02:41 epoch = 30000
2022-11-29 18:02:41 epoch_step = 2000
2022-11-29 18:02:41 model_name = SimpleNetworkAD
2022-11-29 18:02:41 now_string = 2022-11-28-18-17-05
2022-11-29 18:02:41 model_save_path_last = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_last.pt
2022-11-29 18:02:41 model_save_path_best = ./train/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_best.pt
2022-11-29 18:02:41 loss_save_path = ./loss/20391127_200_1128_30000_2000_0.001_2022-11-28-18-17-05_loss_30000.npy
2022-11-29 18:02:41 args = {'epoch': 30000, 'log_path': 'logs/20391127_200_1128_2.txt', 'mode': 'origin', 'epoch_step': 2000, 'name': '20391127_200_1128', 'python': 'ModelBYCC.py', 'id': '2', 'lr': 0.001, 'main_path': '.', 'save_step': 29999, 'seed': 100, 'sw': 0, 'sw_step': 50000, 'overall_start': '2022-11-28-18-17-05'}
2022-11-29 18:02:41 config = {'T_all': 200.0, 'T': 200.0, 'T_unit': 0.1, 'T_N': 2000, 'N': 2000, 'Node': 3, 'ub': 200.0, 'lb': 0.0, 'only_truth_flag': False, 'truth_rate': 1, 'truth_length': 2000, 'continue_period': 0.2, 'round_bit': 3, 'continue_id': None, 'mapping_overall_flag': False, 'loss2_partial_flag': False}
2022-11-29 18:02:41 --------------------------------------------------training start--------------------------------------------------
2022-11-29 18:03:20 NUM_SUB: 182;----------------------------
2022-11-29 18:03:20 Epoch [02000/30000] Loss:0.033206 Loss_1:0.032282 Loss_2:0.000464 Loss_3:0.000000 Lr:0.000833 Time:38.503116s (0.64min in total, 8.98min remains)
2022-11-29 18:03:58 NUM_SUB: 182;----------------------------
2022-11-29 18:03:58 Epoch [04000/30000] Loss:0.028130 Loss_1:0.027918 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000714 Time:38.497236s (1.28min in total, 8.34min remains)
2022-11-29 18:04:37 NUM_SUB: 182;----------------------------
2022-11-29 18:04:37 Epoch [06000/30000] Loss:0.020820 Loss_1:0.020618 Loss_2:0.000069 Loss_3:0.000000 Lr:0.000625 Time:38.549762s (1.93min in total, 7.70min remains)
2022-11-29 18:05:16 NUM_SUB: 182;----------------------------
2022-11-29 18:05:16 Epoch [08000/30000] Loss:0.010557 Loss_1:0.010420 Loss_2:0.000089 Loss_3:0.000000 Lr:0.000556 Time:38.621951s (2.57min in total, 7.07min remains)
2022-11-29 18:05:54 NUM_SUB: 182;----------------------------
2022-11-29 18:05:54 Epoch [10000/30000] Loss:0.005711 Loss_1:0.005604 Loss_2:0.000107 Loss_3:0.000000 Lr:0.000500 Time:38.543994s (3.21min in total, 6.42min remains)
2022-11-29 18:06:33 NUM_SUB: 182;----------------------------
2022-11-29 18:06:33 Epoch [12000/30000] Loss:0.004157 Loss_1:0.004111 Loss_2:0.000046 Loss_3:0.000000 Lr:0.000455 Time:38.521091s (3.85min in total, 5.78min remains)
2022-11-29 18:07:11 NUM_SUB: 182;----------------------------
2022-11-29 18:07:11 Epoch [14000/30000] Loss:0.002490 Loss_1:0.002450 Loss_2:0.000038 Loss_3:0.000000 Lr:0.000417 Time:38.397558s (4.49min in total, 5.14min remains)
2022-11-29 18:07:50 NUM_SUB: 182;----------------------------
2022-11-29 18:07:50 Epoch [16000/30000] Loss:0.001636 Loss_1:0.001607 Loss_2:0.000029 Loss_3:0.000000 Lr:0.000385 Time:38.447468s (5.13min in total, 4.49min remains)
2022-11-29 18:08:28 NUM_SUB: 182;----------------------------
2022-11-29 18:08:28 Epoch [18000/30000] Loss:0.001616 Loss_1:0.001590 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000357 Time:38.443119s (5.78min in total, 3.85min remains)
2022-11-29 18:09:06 NUM_SUB: 182;----------------------------
2022-11-29 18:09:06 Epoch [20000/30000] Loss:0.001615 Loss_1:0.001556 Loss_2:0.000054 Loss_3:0.000000 Lr:0.000333 Time:38.391595s (6.42min in total, 3.21min remains)
2022-11-29 18:09:45 NUM_SUB: 182;----------------------------
2022-11-29 18:09:45 Epoch [22000/30000] Loss:0.001538 Loss_1:0.001513 Loss_2:0.000025 Loss_3:0.000000 Lr:0.000313 Time:38.288919s (7.05min in total, 2.56min remains)
2022-11-29 18:10:23 NUM_SUB: 182;----------------------------
2022-11-29 18:10:23 Epoch [24000/30000] Loss:0.001508 Loss_1:0.001484 Loss_2:0.000023 Loss_3:0.000000 Lr:0.000294 Time:38.394173s (7.69min in total, 1.92min remains)
2022-11-29 18:11:02 NUM_SUB: 182;----------------------------
2022-11-29 18:11:02 Epoch [26000/30000] Loss:0.001485 Loss_1:0.001465 Loss_2:0.000018 Loss_3:0.000000 Lr:0.000278 Time:38.440539s (8.33min in total, 1.28min remains)
2022-11-29 18:11:40 NUM_SUB: 182;----------------------------
2022-11-29 18:11:40 Epoch [28000/30000] Loss:0.001468 Loss_1:0.001453 Loss_2:0.000015 Loss_3:0.000000 Lr:0.000263 Time:38.516673s (8.98min in total, 0.64min remains)
2022-11-29 18:12:18 Testing & drawing...
2022-11-29 18:12:19 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 18:12:20 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=182/
2022-11-29 18:12:20 [Loss]
2022-11-29 18:12:20 NUM_SUB: 182; True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 18:12:20 NUM_SUB: 182; Personalized parameter estimation: Parameter containing:
tensor([0.0941, 0.2653, 0.0078, 0.0098, 0.3074, 0.1226, 1.6287, 0.8964, 0.4556,
        0.0187, 0.0550, 0.0126, 0.3129, 0.1689, 0.0176, 0.8469, 0.6977, 0.8000,
        0.0115, 0.5981, 0.6816, 0.0197, 3.5097, 0.8742, 0.0208, 3.7224, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 18:12:20 NUM_SUB: 182;----------------------------
2022-11-29 18:12:20 Epoch [30000/30000] Loss:0.001457 Loss_1:0.001445 Loss_2:0.000011 Loss_3:0.000000 Lr:0.000250 Time:40.172118s (9.65min in total, 0.00min remains)
2022-11-29 18:12:20 NUM_SUB: 182------------------------- FINISHED TRAINING ---------------------------------------------
2022-11-29 18:12:20 Testing & drawing...
2022-11-29 18:12:20 Test: save figure in ./figure/20391127_200_1128_id=100_2022-11-28-18-17-05/
2022-11-29 18:12:22 Test: save pred in ./saves/20391127_200_1128_id=100_2022-11-28-18-17-05_sub=182/
2022-11-29 18:12:22 [Loss]
2022-11-29 18:12:22 True parameter : tensor([1.0000e-04, 1.0000e-03, 2.4540e-01, 3.9000e-03, 1.1000e-03, 1.0000e-03,
        2.3000e-03, 1.0000e+00, 1.2000e-03, 8.2400e-01, 1.2000e-03]);
2022-11-29 18:12:22 General parameter estimation: Parameter containing:
tensor([0.0941, 0.2653, 0.0078, 0.0098, 0.3074, 0.1225, 1.6287, 0.8964, 0.4556,
        0.0187, 0.0550, 0.0126, 0.3130, 0.1689, 0.0176, 0.8467, 0.6977, 0.8000,
        0.0115, 0.5979, 0.6816, 0.0197, 3.5099, 0.8742, 0.0208, 3.7227, 0.9527,
        0.0362], requires_grad=True);
2022-11-29 18:12:22 A: prod, degr, TonA, NonA
2022-11-29 18:12:22 [0.3442378  0.4983256  0.02838486 0.12905173]
2022-11-29 18:12:22 T: prod, degr, AonT, NonT
2022-11-29 18:12:22 [0.2795951  0.42302698 0.15169849 0.14567944]
2022-11-29 18:12:22 N: AonN, TonN, ATonN
2022-11-29 18:12:22 [0.2013615  0.7558934  0.04274502]
